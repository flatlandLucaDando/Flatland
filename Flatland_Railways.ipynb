{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flatland-Railways.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPEtL2KV5Y7geriYfxC3W4a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flatlandLucaDando/Flatland/blob/flatland_v_3_deterministic/Flatland_Railways.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5ClfqgfTCe9"
      },
      "source": [
        "# Introduction \n",
        "\n",
        "---\n",
        "\n",
        "This is a Workbook to execute the Flatland-RealWorld 3.06 code on colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CucPq4ISq0N"
      },
      "source": [
        "First thing is important to import some libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5WlT8daadWG",
        "outputId": "b8a80692-53b5-4bc9-aa9e-2a9d0e658b25"
      },
      "source": [
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # Clone GitHub repository\n",
        "    !git clone --single-branch --branch flatland_v_3_deterministic https://github.com/flatlandLucaDando/Flatland.git\n",
        "    # Copy files required to run the code\n",
        "    !pip install flatland-rl\n",
        "\n",
        "    # Restart Runtime\n",
        "    import os\n",
        "    os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Flatland'...\n",
            "remote: Enumerating objects: 1403, done.\u001b[K\n",
            "remote: Counting objects: 100% (1403/1403), done.\u001b[K\n",
            "remote: Compressing objects: 100% (711/711), done.\u001b[K\n",
            "remote: Total 1403 (delta 751), reused 1320 (delta 675), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1403/1403), 3.42 MiB | 4.81 MiB/s, done.\n",
            "Resolving deltas: 100% (751/751), done.\n",
            "Collecting flatland-rl\n",
            "  Downloading flatland_rl-3.0.6-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.17 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (4.8.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (21.2.0)\n",
            "Collecting importlib-resources<2,>=1.0.1\n",
            "  Downloading importlib_resources-1.5.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting svgutils>=0.3.1\n",
            "  Downloading svgutils-0.3.4-py3-none-any.whl (10 kB)\n",
            "Collecting tox>=3.5.2\n",
            "  Downloading tox-3.24.4-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (7.1.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (3.2.2)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyarrow>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (3.0.0)\n",
            "Collecting recordtype>=1.3\n",
            "  Downloading recordtype-1.3-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (2.6.3)\n",
            "Collecting timeout-decorator>=0.4.1\n",
            "  Downloading timeout-decorator-0.5.0.tar.gz (4.8 kB)\n",
            "Collecting gym==0.14.0\n",
            "  Downloading gym-0.14.0.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (1.1.5)\n",
            "Collecting pytest<5,>=3.8.2\n",
            "  Downloading pytest-4.6.11-py2.py3-none-any.whl (231 kB)\n",
            "\u001b[K     |████████████████████████████████| 231 kB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (0.10.1)\n",
            "Collecting msgpack==0.6.1\n",
            "  Downloading msgpack-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (245 kB)\n",
            "\u001b[K     |████████████████████████████████| 245 kB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (1.15.0)\n",
            "Collecting crowdai-api>=0.1.21\n",
            "  Downloading crowdai_api-0.1.22.tar.gz (9.2 kB)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (1.19.5)\n",
            "Collecting pytest-runner>=4.2\n",
            "  Using cached pytest_runner-5.3.1-py3-none-any.whl (7.1 kB)\n",
            "Collecting msgpack-numpy>=0.4.4.0\n",
            "  Downloading msgpack_numpy-0.4.7.1-py2.py3-none-any.whl (6.7 kB)\n",
            "Requirement already satisfied: Pillow>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (7.1.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (2.4.1)\n",
            "Collecting ipycanvas\n",
            "  Downloading ipycanvas-0.9.1-py2.py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym==0.14.0->flatland-rl) (1.4.1)\n",
            "Collecting pyglet<=1.3.2,>=1.2.0\n",
            "  Downloading pyglet-1.3.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 54.0 MB/s \n",
            "\u001b[?25hCollecting cloudpickle~=1.2.0\n",
            "  Downloading cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from crowdai-api>=0.1.21->flatland-rl) (2.23.0)\n",
            "Collecting python-gitlab>=1.3.0\n",
            "  Downloading python_gitlab-2.10.1-py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 49.7 MB/s \n",
            "\u001b[?25hCollecting redis\n",
            "  Downloading redis-4.0.2-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 13.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.17->flatland-rl) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.17->flatland-rl) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->flatland-rl) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->flatland-rl) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->flatland-rl) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->flatland-rl) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->flatland-rl) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym==0.14.0->flatland-rl) (0.16.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest<5,>=3.8.2->flatland-rl) (1.4.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest<5,>=3.8.2->flatland-rl) (21.3)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest<5,>=3.8.2->flatland-rl) (8.11.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest<5,>=3.8.2->flatland-rl) (0.2.5)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest<5,>=3.8.2->flatland-rl) (1.11.0)\n",
            "Collecting requests-toolbelt>=0.9.1\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting requests>=2.18.4\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 844 kB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->crowdai-api>=0.1.21->flatland-rl) (2.0.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->crowdai-api>=0.1.21->flatland-rl) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->crowdai-api>=0.1.21->flatland-rl) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->crowdai-api>=0.1.21->flatland-rl) (2021.10.8)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from svgutils>=0.3.1->flatland-rl) (4.2.6)\n",
            "Collecting virtualenv!=20.0.0,!=20.0.1,!=20.0.2,!=20.0.3,!=20.0.4,!=20.0.5,!=20.0.6,!=20.0.7,>=16.0.0\n",
            "  Downloading virtualenv-20.10.0-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 16.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from tox>=3.5.2->flatland-rl) (0.10.2)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from tox>=3.5.2->flatland-rl) (3.4.0)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.3-py2.py3-none-any.whl (496 kB)\n",
            "\u001b[K     |████████████████████████████████| 496 kB 51.5 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.4.0-py3-none-any.whl (14 kB)\n",
            "Collecting backports.entry-points-selectable>=1.0.4\n",
            "  Downloading backports.entry_points_selectable-1.1.1-py2.py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: ipywidgets>=7.6.0 in /usr/local/lib/python3.7/dist-packages (from ipycanvas->flatland-rl) (7.6.5)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.1.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (3.5.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (1.0.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.1.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.5.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (4.10.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.3.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (4.8.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (4.9.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.3.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.12.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.6.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (1.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (4.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.5.1)\n",
            "Collecting deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->redis->crowdai-api>=0.1.21->flatland-rl) (1.13.3)\n",
            "Building wheels for collected packages: gym, crowdai-api, timeout-decorator\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.14.0-py3-none-any.whl size=1637522 sha256=c83a808731fc81e7bfc9835b35fbb6db6345f1bc763fbbb36ad4cda308e5de23\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/34/78/36550f249167fda9e42e1dd9af84b400abf6c162d1c07ab4e1\n",
            "  Building wheel for crowdai-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crowdai-api: filename=crowdai_api-0.1.22-py2.py3-none-any.whl size=10001 sha256=e991ed06cb0c5989192b0240d85754f3ef35ecae5e0a0d203e5d1361ee410047\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/f9/9b/8d1b851e4636aee2ba22b033bdb893e75b4342fa9865c39e23\n",
            "  Building wheel for timeout-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for timeout-decorator: filename=timeout_decorator-0.5.0-py3-none-any.whl size=5028 sha256=aa451d8aaf92ee185eca543ebb6b026cb88ba713172130640c2cab6a4ee82c14\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/64/ac/de1dd54f9a6e48b846e9cb5e4176d6f063380e7f83d69807ad\n",
            "Successfully built gym crowdai-api timeout-decorator\n",
            "Installing collected packages: requests, requests-toolbelt, platformdirs, distlib, deprecated, backports.entry-points-selectable, virtualenv, redis, python-gitlab, pyglet, pluggy, msgpack, cloudpickle, tox, timeout-decorator, svgutils, recordtype, pytest-runner, pytest, msgpack-numpy, ipycanvas, importlib-resources, gym, dataclasses, crowdai-api, flatland-rl\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyglet\n",
            "    Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.2\n",
            "    Uninstalling msgpack-1.0.2:\n",
            "      Successfully uninstalled msgpack-1.0.2\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.4.0\n",
            "    Uninstalling importlib-resources-5.4.0:\n",
            "      Successfully uninstalled importlib-resources-5.4.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires cloudpickle>=1.3, but you have cloudpickle 1.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed backports.entry-points-selectable-1.1.1 cloudpickle-1.2.2 crowdai-api-0.1.22 dataclasses-0.6 deprecated-1.2.13 distlib-0.3.3 flatland-rl-3.0.6 gym-0.14.0 importlib-resources-1.5.0 ipycanvas-0.9.1 msgpack-0.6.1 msgpack-numpy-0.4.7.1 platformdirs-2.4.0 pluggy-0.13.1 pyglet-1.3.2 pytest-4.6.11 pytest-runner-5.3.1 python-gitlab-2.10.1 recordtype-1.3 redis-4.0.2 requests-2.26.0 requests-toolbelt-0.9.1 svgutils-0.3.4 timeout-decorator-0.5.0 tox-3.24.4 virtualenv-20.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0SHU5OFSwlp"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "import random\n",
        "import sys\n",
        "from argparse import ArgumentParser, Namespace\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "import psutil\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch\n",
        "from typing import Callable, Tuple, Optional, Dict, List\n",
        "from numpy.random.mtrand import RandomState"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e5ILy1PYV9o"
      },
      "source": [
        "# Structure Rail\n",
        "Contein the basilar structure of the rail, with the high velocity rails and the right, left, nord or sud rails\n",
        "\n",
        "With i_flag you can select the different rails configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8M6jhCIYvPL"
      },
      "source": [
        "i = 3\n",
        "\n",
        "if i == 1:\n",
        "\t# One rail, so no right or left rails  \n",
        "\tright_rails = [(0,0)]\n",
        "\tleft_rails = [(0,0)]\n",
        "\tdown_rails = [(0,0)]\n",
        "\tup_rails = [(0,0)]\n",
        "\n",
        "\tav_line = [(0,0)]\n",
        "\n",
        "if i ==2:\n",
        "\t# Rails where the direction is right\n",
        "\tright_rails = []\n",
        "\tfor i in range(8):\n",
        "\t\tright_rails.append((5,i+6))\n",
        "\t# Rails where the direction is left\n",
        "\tleft_rails = []\n",
        "\tfor i in range(8):\n",
        "\t\tleft_rails.append((6,i+6))\n",
        "\n",
        "\tdown_rails = [(0,0)]\n",
        "\tup_rails = [(0,0)]\n",
        "\n",
        "\tav_line = [(0,0)]\n",
        "\n",
        "if i == 3:\n",
        "\t# One rail, so no right or left rails  \n",
        "\tright_rails = [(0,0)]\n",
        "\tleft_rails = [(0,0)]\n",
        "\tdown_rails = [(0,0)]\n",
        "\tup_rails = [(0,0)]\n",
        "\n",
        "\tav_line = [(0,0)]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25VWq_QpYWH0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEEkAbhEXvTb"
      },
      "source": [
        "# Data Structures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tCkoOAPX3WZ"
      },
      "source": [
        "## Convoy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH2WxoxeXyDg"
      },
      "source": [
        "from enum import Enum\n",
        "import itertools\n",
        "\n",
        "# Type of a convoy, can be high velocity or regional\n",
        "# The velocity are given by default depending on the type of convoy, 360 for HV, 180 for IC, 120 for Regional\n",
        "class Type_of_convoy(Enum):\n",
        "\tHIGH_VELOCITY = 1\n",
        "\tINTERCITY = 2\n",
        "\tREGIONAL = 3\n",
        "\n",
        "# A convoy is a locomotive + wagons.\n",
        "class Convoy:\n",
        "\n",
        "\t# For the id\n",
        "\tid_iter = itertools.count()\n",
        "\n",
        "\tdef __init__(self, train_type, schedule = []):\n",
        "\n",
        "\t\t# identifier of the train\n",
        "\t\tself.id = next(Convoy.id_iter)\n",
        "\t\t# type of train (High velocity, Intercity, regional)\n",
        "\t\tself.train_type = train_type\n",
        "\t\t# schedule of the train\n",
        "\t\tself.schedule = []\n",
        "\n",
        "\t\tif train_type == Type_of_convoy.HIGH_VELOCITY:\n",
        "\t\t\tself.maximum_velocity = 1\n",
        "\t\tif train_type == Type_of_convoy.INTERCITY:\n",
        "\t\t\tself.maximum_velocity = 1/2\n",
        "\t\tif train_type == Type_of_convoy.REGIONAL:\n",
        "\t\t\tself.maximum_velocity = 1/3\n",
        "\n",
        "\tdef add_train_run(self, train_run):\n",
        "\t\tself.schedule.append(train_run)\n",
        "\n",
        "\t# Discover the starting time of a certain run\n",
        "\tdef starting_time(self, run_number):\n",
        "\t\treturn self.schedule[run_number][0]\n",
        "\n",
        "\t# Convert velocity (maximum possible velocity is 360)\n",
        "\tdef velocity_conversion(self):\n",
        "\t\tprint(self.maximum_velocity * 360)\n",
        "\n",
        "\t# Verificate that a schedule is possible (if someone want to write manually)\n",
        "\tdef schedule_verification(self, schedule, num_trains_run):\n",
        "\t\tif type(schedule) == list:\n",
        "\t\t\trow_num = len(schedule)\n",
        "\t\t\tcolumn_num = len(schedule[0])\n",
        "\t\t\tif row_num >  1:\n",
        "\t\t\t\tfor num_of_runs in range(num_trains_run - 1):\n",
        "\t\t\t\t\tfor steps in range(len(schedule) - 1):\n",
        "\t\t\t\t\t\tif schedule[num_of_runs][step + 1] <= schedule[num_of_runs][step]:\n",
        "\t\t\t\t\t\t\tprint('==========================================================')\n",
        "\t\t\t\t\t\t\tprint('The time to connect stations',step,'and',step + 1,'have to be > 0')\n",
        "\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor steps in range(len(schedule) - 1):\n",
        "\t\t\t\t\tif schedule[num_of_runs][step + 1] <= schedule[num_of_runs][step]:\n",
        "\t\t\t\t\t\tprint('==========================================================')\n",
        "\t\t\t\t\t\tprint('The time to connect stations',step,'and',step + 1,'have to be > 0')\n",
        "\t\telse:\n",
        "\t\t\tprint('A schedule should comprend different stations')\n",
        "\t\treturn True\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q80GIJJEX8Yk"
      },
      "source": [
        "## Line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG_B-nASX-r1"
      },
      "source": [
        "import itertools\n",
        "\n",
        "# A line is considered from a city to another, tipically joining several cities\n",
        "class Line:\n",
        "\n",
        "\t# For the id\n",
        "\tid_iter = itertools.count()\n",
        "\n",
        "\tdef __init__(self, type_line, stations, stops):\n",
        "\t\t# ID of the line\n",
        "\t\tself.id = next(Line.id_iter)\n",
        "\t\t# type of line (High velocity or regional)\n",
        "\t\tself.type_line = type_line\n",
        "\t\t# Stations where the line pass from\n",
        "\t\tself.stations = stations\n",
        "\t\t# Stops are stations where the train have to stop\n",
        "\t\t# Is an array with 0 where not stop and 1 where train stops\n",
        "\t\tself.stops = stops\n",
        "\n",
        "\t\tif type(stations) == int or type(stops) == int:\n",
        "\t\t\tprint('The stations of a line should be more than one, and the dimension of the stops should be the same of the stations')\n",
        "\t\telse:\n",
        "\t\t\tif(len(stations)) != (len(stops)):\n",
        "\t\t\t\tprint('Stations and Stops have to be the same lenght')\n",
        "\n",
        "\n",
        "\tdef inversion_of_line(self):\n",
        "\t\tself.direction = self.direction * -1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcqtL8kcYBb3"
      },
      "source": [
        "## Rail Connection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZXAlq4oYFw6"
      },
      "source": [
        "from enum import Enum\n",
        "import itertools\n",
        "\n",
        "# A connection can be: High velocity or normal\n",
        "# The velocity are given by default depending on the type of connection, 360 for HV and 120 for normal\n",
        "class Connection_type(Enum):\n",
        "\tHIGH_VELOCITY_RAIL = 1\n",
        "\tNORMAL_RAIL = 2\n",
        "\n",
        "\n",
        "# A physical connection between two stations\n",
        "class Rail_connection:\n",
        "\n",
        "\t# For the id\n",
        "\tid_iter = itertools.count()\n",
        "\n",
        "\tdef __init__(self, station_a, station_b, rail_connection_type, additional_runtime_percent, max_speed_usable: int = 1/2):\n",
        "\t\t# each railway section has an id\n",
        "\t\tself.id = next(Rail_connection.id_iter)\n",
        "\t\t# Station A and B are the two connected stations\n",
        "\t\tself.station_a = station_a\n",
        "\t\tself.station_b = station_b\n",
        "\t\t# A connection can be: High velocity or normal\n",
        "\t\tself.rail_connection_type = rail_connection_type\n",
        "\t\t# Maximum speed usable in the rails\n",
        "\t\tself.max_speed_usable = max_speed_usable\n",
        "\t\t# Additional Runtime Percent is the percent [0-1] of the min run time that is added to the min run time, if the train is on schedule.\n",
        "\t\t# In general, he actual run time is computed as min run time + max(0, (min run time*additionalRuntimePercent)-actual_delay).\n",
        "\t\tself.additional_runtime_percent = additional_runtime_percent\n",
        "\n",
        "\t\tif rail_connection_type == Connection_type.HIGH_VELOCITY_RAIL:\n",
        "\t\t\tself.max_speed_usable = 1\n",
        "\t\tif rail_connection_type == Connection_type.NORMAL_RAIL:\n",
        "\t\t\tself.max_speed_usable = 1 / 2"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDV9yKClYIy_"
      },
      "source": [
        "## Station"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8gBNXfkYMss"
      },
      "source": [
        "from flatland.core.grid.grid_utils import Vec2dOperations as Vec2d\n",
        "\n",
        "# Station\n",
        "class Station:\n",
        "\n",
        "\t# TODO metti valori precisi per min wait time (lis)\n",
        "\tdef __init__(self, name, position, capacity, min_wait_time, additional_wait_percent, importance, railway_topology):\n",
        "\t\t# Name of the station (e.g. Milano, Torino etc etc)\n",
        "\t\tself.name = name\n",
        "\t\t# Position (y,x) of the station in the railway\n",
        "\t\tself.position = position\n",
        "\t\t# Capacity of the station, num of rails in the station\n",
        "\t\tself.capacity = capacity\n",
        "\t\t# Minimum wait time for the trains, a train can't stop less than the min wait time\n",
        "\t\tself.min_wait_time = min_wait_time\n",
        "\t\t# Additional wait percent is the percent [0-1] of the minWaitTime that is added to the minWait at each stop, if the train is on schedule. \n",
        "\t\t# In general, the actual (runtime) stopping time is computed as minWaitTime + max(0, (minWaitTime*additionalWaitTimePercent)-actual_delay).\n",
        "\t\tself.additional_wait_percent = additional_wait_percent\n",
        "\t\t# Stations have different importance depending on how much they are big and how much people they transport depending on the time\n",
        "\t\tself.importance = importance\n",
        "\t\t# Rails of the station\n",
        "\t\tself.rails = (0,0)\n",
        "\t\t\n",
        "\t\treturn\n",
        "\t\t'''\n",
        "\t\tif capacity == 1:\n",
        "\t\t\tself.rails = None\n",
        "\t\telse:\n",
        "\t\t\tself.rails = self.calculate_rails(railway_topology)\n",
        "\t\treturn\n",
        "\t\t'''\n",
        "\n",
        "\tdef time_in_station(self, train_velocity):\n",
        "\t\t# The len of the rails is given by the station\n",
        "\t\tlen_rails = len(self.rails_in_station[0])\n",
        "\t\t# The time needed is given by the formula (len * 1/velocity + waiting time + 10% of time)\n",
        "\t\ttime_needed =  len_rails * int(pow(train_velocity, -1)) + self.min_wait_time[0]\n",
        "\t\ttime_needed += int(time_needed/10)\n",
        "\t\treturn time_needed\n",
        "\n",
        "\tdef calculate_rails(self, railway_topology):\n",
        "\t\t# Number of rails of the station\n",
        "\t\tnum_of_rails = self.capacity\n",
        "\t\tcenter_of_station = self.position \n",
        "\t\trail_shape = railway_topology.grid.shape\n",
        "\n",
        "\t\t#Flag\n",
        "\t\tright = False  # Flag to understand where to go right or left\n",
        "\t\tnorth = True    # Flag to understand where to go right or left\n",
        "\n",
        "\t\t# Indicating the incrementing number north or sud (in case of horizontal station), east ovest (in case of vertical stations)\n",
        "\t\tdifference_from_original = 0 \n",
        "\n",
        "\t\t# Counter\n",
        "\t\tcounter_of_rails = 0\n",
        "\t\t# Rails of the station, has the position of the rails. Each row is a rail\n",
        "\t\tself.rails = []\n",
        "\t\t# Contein the single rail positions\n",
        "\t\tsingle_rail_in_station = []\n",
        "\n",
        "\t\t# Counter to check the station is well positioned, to avoid the while goes for eternity\n",
        "\t\tcounter = 0\n",
        "\n",
        "\t\t# Starting position the center of station\n",
        "\t\tcurrent_position = (self.position[0], self.position[1])\n",
        "\n",
        "\t\twhile counter_of_rails < num_of_rails:\n",
        "\n",
        "\t\t\tcounter += 1\n",
        "\n",
        "\t\t\tif counter > 500:\n",
        "\t\t\t\traise ImportError('The position of the station, or the capacity should be different, check for the right position or capacity, cant calculate the rails')\n",
        "\n",
        "\t\t\t# Horizontal rail\n",
        "\t\t\tif railway_topology.grid[current_position] == 1025:\n",
        "\t\t\t\t# The starting rail is a rail of the station\n",
        "\t\t\t\tsingle_rail_in_station.append(current_position)\n",
        "\t\t\t\t# Going to left\n",
        "\t\t\t\tif not right:\n",
        "\t\t\t\t\tnew_pos = (0,-1)\n",
        "\t\t\t\t# Going to right\n",
        "\t\t\t\tif right:\n",
        "\t\t\t\t\tnew_pos = (0, 1)\n",
        "\t\t\t\t# Update the position to left or right\n",
        "\t\t\t\tcurrent_position = Vec2d.add(current_position, new_pos)\n",
        "\n",
        "\t\t\t\t# is position inside the grid?\n",
        "\t\t\t\tif current_position[0] >= rail_shape[0] or current_position[0] < 0 or current_position[1] >= rail_shape[1] or current_position[1] < 0:\n",
        "\t\t\t\t\tcontinue \n",
        "\t\t\t\t# Current position != 0 and going left?\n",
        "\t\t\t\t# Starting going to left\n",
        "\t\t\t\tif railway_topology.grid[current_position] != 0 and not right:\n",
        "\t\t\t\t\t# If not 0 the rail is in the station\n",
        "\t\t\t\t\tsingle_rail_in_station.append(current_position)\n",
        "\t\t\t\t\t# I'm arrived at the end of the rail in station\n",
        "\t\t\t\t\tif railway_topology.grid[current_position] != 1025:\n",
        "\t\t\t\t\t\t# The entrance is on left\n",
        "\t\t\t\t\t\tif current_position[0] == self.position[0]:\n",
        "\t\t\t\t\t\t\tself.station_entrance = current_position\n",
        "\t\t\t\t\t\t# Restart the position to the original once\n",
        "\t\t\t\t\t\t# If I'm north or sud the new original position is north or sud with respect to the real original\n",
        "\t\t\t\t\t\tif difference_from_original == 0:\n",
        "\t\t\t\t\t\t\tcurrent_position = (self.position[0], self.position[1])\n",
        "\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\tcurrent_position = (self.position[0] + difference_from_original, self.position[1])\n",
        "\t\t\t\t\t\t# Then going to right\n",
        "\t\t\t\t\t\tright = True\n",
        "\t\t\t\t\t\tcontinue\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t# Current position != 0 and going right?\t            \t\t\n",
        "\t\t\t\tif railway_topology.grid[current_position] != 0 and right:\n",
        "\t\t\t\t\t# If not 0 the rail is in the station\n",
        "\t\t\t\t\tsingle_rail_in_station.append(current_position)\n",
        "\t\t\t\t\t# I'm arrived at the end of the rail in station\n",
        "\t\t\t\t\tif railway_topology.grid[current_position] != 1025:\n",
        "\t\t\t\t\t\t# The exit is on right\n",
        "\t\t\t\t\t\tif current_position[0] == self.position[0]:\n",
        "\t\t\t\t\t\t\tself.station_exit = current_position\n",
        "\t\t\t\t\t\tself.rails.append(single_rail_in_station)\n",
        "\t\t\t\t\t\t# Restart the position from original once\n",
        "\t\t\t\t\t\tcurrent_position = (self.position[0], self.position[1])\n",
        "\t\t\t\t\t\t# A rail is ended\n",
        "\t\t\t\t\t\tcounter_of_rails += 1\n",
        "\t\t\t\t\t\t# Resetting the flag\n",
        "\t\t\t\t\t\tright = False\n",
        "\t\t\t\t\t\tif north:\n",
        "\t\t\t\t\t\t\t# Going to north, checking if at north there is a rail or not \n",
        "\t\t\t\t\t\t\tnew_pos = (-1, 0)\n",
        "\t\t\t\t\t\t\tposition = Vec2d.add(current_position, new_pos)\n",
        "\t\t\t\t\t\t\tif railway_topology.grid[position] != 0:\n",
        "\t\t\t\t\t\t\t\t# Checking if there is a rail\n",
        "\t\t\t\t\t\t\t\tcurrent_position = Vec2d.add(current_position, new_pos)\n",
        "\t\t\t\t\t\t\t\t# Resetting the single rail\n",
        "\t\t\t\t\t\t\t\tsingle_rail_in_station = []\n",
        "\t\t\t\t\t\t\t\t# I'm one step north, so I'm one row up in the matrix\n",
        "\t\t\t\t\t\t\t\tdifference_from_original -= 1\n",
        "\t\t\t\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\t\t# No rails upper, so I have to go down\n",
        "\t\t\t\t\t\t\t\tnorth = False\n",
        "\t\t\t\t\t\t\t\t# Restart the position from original once\n",
        "\t\t\t\t\t\t\t\tcurrent_position = (self.position[0], self.position[1])\n",
        "\t\t\t\t\t\t\t\t# I'm at the original position, so difference is 0\n",
        "\t\t\t\t\t\t\t\tdifference_from_original = 0\n",
        "\t\t\t\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\t# Going south\n",
        "\t\t\t\t\t\t\tnew_pos = (+1, 0)\n",
        "\t\t\t\t\t\t\tposition = Vec2d.add(current_position, new_pos)\n",
        "\t\t\t\t\t\t\t# Check if south I have a rail or not\n",
        "\t\t\t\t\t\t\tif railway_topology.grid[position] != 0:\n",
        "\t\t\t\t\t\t\t\tcurrent_position = Vec2d.add(current_position, new_pos)\n",
        "\t\t\t\t\t\t\t\t# Resetting the single rail\n",
        "\t\t\t\t\t\t\t\tsingle_rail_in_station = []\n",
        "\t\t\t\t\t\t\t\t# I'm one step south, so I'm one row down in the matrix\n",
        "\t\t\t\t\t\t\t\tdifference_from_original += 1\n",
        "\t\t\t\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\t\t# No rails down, so I have to go up\n",
        "\t\t\t\t\t\t\t\tnorth = True\n",
        "\t\t\t\t\t\t\t\t# Restart the position from original once\n",
        "\t\t\t\t\t\t\t\tcurrent_position = (self.position[0], self.position[1])\n",
        "\t\t\t\t\t\t\t\t# I'm at the original position, so difference is 0\n",
        "\t\t\t\t\t\t\t\tdifference_from_original = 0\n",
        "\t\t\t\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t# Vertical rail same as for horizontal, but starting from south and north, and then left and right\n",
        "\t\t\telif railway_topology.grid[current_position] == 32800:\n",
        "\t\t\t\t# The starting rail is a rail of the station\n",
        "\t\t\t\tsingle_rail_in_station.append(current_position)\n",
        "\t\t\t\t# Going down\n",
        "\t\t\t\tif not north:\n",
        "\t\t\t\t\tnew_pos = (+1,0)\n",
        "\t\t\t\t# Going to right\n",
        "\t\t\t\tif north:\n",
        "\t\t\t\t\tnew_pos = (-1, 0)\n",
        "\t\t\t\t# Update the position to left or right\n",
        "\t\t\t\tcurrent_position = Vec2d.add(current_position, new_pos)\n",
        "\n",
        "\t\t\t\t# is position inside the grid?\n",
        "\t\t\t\tif current_position[0] >= rail_shape[0] or current_position[0] < 0 or current_position[1] >= rail_shape[1] or current_position[1] < 0:\n",
        "\t\t\t\t\tcontinue \n",
        "\t\t\t\t# Current position != 0 and going left?\n",
        "\t\t\t\t# Starting going to left\n",
        "\t\t\t\tif railway_topology.grid[current_position] != 0 and not north:\n",
        "\t\t\t\t\t# If not 0 the rail is in the station\n",
        "\t\t\t\t\tsingle_rail_in_station.append(current_position)\n",
        "\t\t\t\t\t# I'm arrived at the end of the rail in station\n",
        "\t\t\t\t\tif railway_topology.grid[current_position] != 32800:\n",
        "\t\t\t\t\t\t# The entrance is on left\n",
        "\t\t\t\t\t\tif current_position[1] == self.position[1]:\n",
        "\t\t\t\t\t\t\tself.station_entrance = current_position\n",
        "\t\t\t\t\t\t# Restart the position to the original once\n",
        "\t\t\t\t\t\t# If I'm north or sud the new original position is north or sud with respect to the real original\n",
        "\t\t\t\t\t\tif difference_from_original == 0:\n",
        "\t\t\t\t\t\t\tcurrent_position = (self.position[0], self.position[1])\n",
        "\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\tcurrent_position = (self.position[0], self.position[1] + difference_from_original)\n",
        "\t\t\t\t\t\t# Then going to right\n",
        "\t\t\t\t\t\tnorth = True\n",
        "\t\t\t\t\t\tcontinue\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t# Current position != 0 and going right?\t            \t\t\n",
        "\t\t\t\tif railway_topology.grid[current_position] != 0 and north:\n",
        "\t\t\t\t\t# If not 0 the rail is in the station\n",
        "\t\t\t\t\tsingle_rail_in_station.append(current_position)\n",
        "\t\t\t\t\t# I'm arrived at the end of the rail in station\n",
        "\t\t\t\t\tif railway_topology.grid[current_position] != 32800:\n",
        "\t\t\t\t\t\t# The exit is on right\n",
        "\t\t\t\t\t\tif current_position[1] == self.position[1]:\n",
        "\t\t\t\t\t\t\tself.station_exit = current_position\n",
        "\t\t\t\t\t\tself.rails.append(single_rail_in_station)\n",
        "\t\t\t\t\t\t# Restart the position from original once\n",
        "\t\t\t\t\t\tcurrent_position = (self.position[0], self.position[1])\n",
        "\t\t\t\t\t\t# A rail is ended\n",
        "\t\t\t\t\t\tcounter_of_rails += 1\n",
        "\t\t\t\t\t\t# Resetting the flag\n",
        "\t\t\t\t\t\tnorth = False\n",
        "\t\t\t\t\t\tif not right:\n",
        "\t\t\t\t\t\t\t# Going to left, checking if at north there is a rail or not \n",
        "\t\t\t\t\t\t\tnew_pos = (0, -1)\n",
        "\t\t\t\t\t\t\tposition = Vec2d.add(current_position, new_pos)\n",
        "\t\t\t\t\t\t\tif railway_topology.grid[position] != 0:\n",
        "\t\t\t\t\t\t\t\t# Checking if there is a rail\n",
        "\t\t\t\t\t\t\t\tcurrent_position = Vec2d.add(current_position, new_pos)\n",
        "\t\t\t\t\t\t\t\t# Resetting the single rail\n",
        "\t\t\t\t\t\t\t\tsingle_rail_in_station = []\n",
        "\t\t\t\t\t\t\t\t# I'm one step north, so I'm one row up in the matrix\n",
        "\t\t\t\t\t\t\t\tdifference_from_original -= 1\n",
        "\t\t\t\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\t\t# No rails upper, so I have to go down\n",
        "\t\t\t\t\t\t\t\tright = True\n",
        "\t\t\t\t\t\t\t\t# Restart the position from original once\n",
        "\t\t\t\t\t\t\t\tcurrent_position = (self.position[0], self.position[1])\n",
        "\t\t\t\t\t\t\t\t# I'm at the original position, so difference is 0\n",
        "\t\t\t\t\t\t\t\tdifference_from_original = 0\n",
        "\t\t\t\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\t# Going south\n",
        "\t\t\t\t\t\t\tnew_pos = (0, +1)\n",
        "\t\t\t\t\t\t\tposition = Vec2d.add(current_position, new_pos)\n",
        "\t\t\t\t\t\t\t# Check if south I have a rail or not\n",
        "\t\t\t\t\t\t\tif railway_topology.grid[position] != 0:\n",
        "\t\t\t\t\t\t\t\tcurrent_position = Vec2d.add(current_position, new_pos)\n",
        "\t\t\t\t\t\t\t\t# Resetting the single rail\n",
        "\t\t\t\t\t\t\t\tsingle_rail_in_station = []\n",
        "\t\t\t\t\t\t\t\t# I'm one step south, so I'm one row down in the matrix\n",
        "\t\t\t\t\t\t\t\tdifference_from_original += 1\n",
        "\t\t\t\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\t\t# No rails down, so I have to go up\n",
        "\t\t\t\t\t\t\t\tright = False\n",
        "\t\t\t\t\t\t\t\t# Restart the position from original once\n",
        "\t\t\t\t\t\t\t\tcurrent_position = (self.position[0], self.position[1])\n",
        "\t\t\t\t\t\t\t\t# I'm at the original position, so difference is 0\n",
        "\t\t\t\t\t\t\t\tdifference_from_original = 0\n",
        "\t\t\t\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t# Eliminate duplicates\n",
        "\t\trails_position = []\n",
        "\t\trails_position_single = []\n",
        "\t\tfor i in range(len(self.rails)):\n",
        "\t\t\tfor j in range(len(self.rails[i])):\n",
        "\t\t\t\tif self.rails[i][j] not in rails_position_single:\n",
        "\t\t\t\t\trails_position_single.append(self.rails[i][j])\n",
        "\t\t\trails_position.append(rails_position_single)\n",
        "\t\t\trails_position_single = []\n",
        "\t\tself.rails = rails_position"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B01cYfcYNyt"
      },
      "source": [
        "## Train Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdHNpaAeYQjE"
      },
      "source": [
        "# A train run is the run on a line for a train (e.g. Genova-Milano --- Milano-Genova)\n",
        "# The train run consider each intermediate station the train has to pass between the two \"principal\" stations\n",
        "class Train_run:\n",
        "\n",
        "\tdef __init__(self, line_belongin, starting_time, from_depot: bool = False, to_depot: bool = False, inverse_train_direction: bool = False):\n",
        "\t\t# Line in which the train run is, so it contein informations about the stations to stop and etc etc\n",
        "\t\tself.line_belongin = line_belongin\n",
        "\t\t# Starting time of the run\n",
        "\t\tself.starting_time = starting_time\n",
        "\t\t# FromDepot indicates whether this run starts from a depot. Similar for ToDepot.\n",
        "\t\tself.from_depot = from_depot\n",
        "\t\tself.to_depot = to_depot\n",
        "\t\t# If inverse line direction \n",
        "\t\tself.inverse_train_direction = inverse_train_direction\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKFkmlccTHt9"
      },
      "source": [
        "# Flatland Custom Rail Generator\n",
        "\n",
        "--- \n",
        "A custom rail is a rail defined by a matrix. Each cell of the matrix define the type of cell in the 2-D grid of the flatland environment\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SSP2ltVXxHv"
      },
      "source": [
        "## Different type of cell\n",
        "\n",
        "<img src=\"https://i.imgur.com/ruiRuep.jpg\" width=\"500\"/> <img src=\"https://i.imgur.com/sABiSuc.jpg\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecRto8qiVvXz"
      },
      "source": [
        "* This is the function to create a custom rail"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlyvYqEJViux"
      },
      "source": [
        "\"\"\"Rail generators (infrastructure manager, \"Infrastrukturbetreiber\").\"\"\"\n",
        "from typing import Callable, Tuple, Optional, Dict, List\n",
        "\n",
        "from numpy.random.mtrand import RandomState\n",
        "\n",
        "from flatland.core.grid.grid4 import Grid4TransitionsEnum\n",
        "from flatland.core.grid.rail_env_grid import RailEnvTransitions\n",
        "from flatland.core.transition_map import GridTransitionMap\n",
        "\n",
        "\n",
        "RailGeneratorProduct = Tuple[GridTransitionMap, Optional[Dict]]\n",
        "\"\"\" A rail generator returns a RailGenerator Product, which is just\n",
        "    a GridTransitionMap followed by an (optional) dict/\n",
        "\"\"\"\n",
        "\n",
        "RailGenerator = Callable[[int, int, int, int], RailGeneratorProduct]\n",
        "\n",
        "# Number of agents are given by timetables (the num of the rows), target stations are also given by timetable \n",
        "def rail_custom_generator(rail_spec, train_stations_position: list = None, timetable: list = None):\n",
        "\n",
        "    \"\"\"\n",
        "    Utility to convert a rail given by manual specification as a map of tuples\n",
        "    (cell_type, rotation), to a transition map with the correct 16-bit\n",
        "    transitions specifications.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    rail_spec : list of list of tuples\n",
        "        List (rows) of lists (columns) of tuples, each specifying a rail_spec_of_cell for\n",
        "        the RailEnv environment as (cell_type, rotation), with rotation being\n",
        "        clock-wise and in [0, 90, 180, 270].\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    function\n",
        "        Generator function that always returns a GridTransitionMap object with\n",
        "        the matrix of correct 16-bit bitmaps for each rail_spec_of_cell.\n",
        "\n",
        "    New features:\n",
        "    -------------\n",
        "        Train station poition: to define the position of the station\n",
        "        Target station: Define the target of the different agents\n",
        "        Timetable: timetable contein the intermediate station and the time at which pass across them\n",
        "    \"\"\"\n",
        "\n",
        "    def custom_generator(width: int, height: int, num_agents: int, num_resets: int = 0,\n",
        "                  np_random: RandomState = None) -> RailGenerator:\n",
        "\n",
        "        # All the cities are oriented in the same way in my model\n",
        "        city_orientations = 1\n",
        "\n",
        "        # Taking the number of agents from timetable\n",
        "        num_of_agents = len(timetable)\n",
        "\n",
        "        # Taking the target stations from timetable\n",
        "        target_stations = []\n",
        "\n",
        "        for agent in range(num_agents):\n",
        "            target_stations.append(timetable[agent][-1])\n",
        "      \n",
        "        rail_env_transitions = RailEnvTransitions()\n",
        "\n",
        "        height = len(rail_spec)\n",
        "        width = len(rail_spec[0])\n",
        "        rail = GridTransitionMap(width=width, height=height, transitions=rail_env_transitions)\n",
        "\n",
        "        for r in range(height):\n",
        "            for c in range(width):\n",
        "                rail_spec_of_cell = rail_spec[r][c]\n",
        "                index_basic_type_of_cell_ = rail_spec_of_cell[0]\n",
        "                rotation_cell_ = rail_spec_of_cell[1]\n",
        "                if index_basic_type_of_cell_ < 0 or index_basic_type_of_cell_ >= len(rail_env_transitions.transitions):\n",
        "                    print(\"ERROR - invalid rail_spec_of_cell type=\", index_basic_type_of_cell_)\n",
        "                    return []\n",
        "                basic_type_of_cell_ = rail_env_transitions.transitions[index_basic_type_of_cell_]\n",
        "                effective_transition_cell = rail_env_transitions.rotate_transition(basic_type_of_cell_, rotation_cell_)\n",
        "                rail.set_transitions((r, c), effective_transition_cell)\n",
        "\n",
        "        return rail,  {'agents_hints': {\n",
        "            'num_agents': num_of_agents,            \n",
        "            'city_positions': train_stations_position,\n",
        "            'train_stations': train_stations_position,\n",
        "            'city_orientations': city_orientations,\n",
        "            'targets' : target_stations,\n",
        "            'timetable' : timetable \n",
        "        }}\n",
        "\n",
        "    return custom_generator\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBH5g0GFWHld"
      },
      "source": [
        "* these are the utilities for the environment\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-PIRK0HWP_t"
      },
      "source": [
        "from flatland.core.env_observation_builder import ObservationBuilder\n",
        "from flatland.envs.observations import TreeObsForRailEnv\n",
        "from flatland.envs.predictions import ShortestPathPredictorForRailEnv\n",
        "from flatland.envs.rail_env import RailEnv\n",
        "from flatland.envs.rail_generators import rail_from_file\n",
        "from flatland.envs.line_generators import line_from_file\n",
        "from flatland.envs.rail_env import RailEnvActions\n",
        "from flatland.envs.step_utils.states import TrainState\n",
        "\n",
        "\n",
        "def load_flatland_environment_from_file(file_name: str,\n",
        "                                        load_from_package: str = None,\n",
        "                                        obs_builder_object: ObservationBuilder = None,\n",
        "                                        record_steps = False,\n",
        "                                        ) -> RailEnv:\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_name : str\n",
        "        The pickle file.\n",
        "    load_from_package : str\n",
        "        The python module to import from. Example: 'env_data.tests'\n",
        "        This requires that there are `__init__.py` files in the folder structure we load the file from.\n",
        "    obs_builder_object: ObservationBuilder\n",
        "        The obs builder for the `RailEnv` that is created.\n",
        "\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    RailEnv\n",
        "        The environment loaded from the pickle file.\n",
        "    \"\"\"\n",
        "    if obs_builder_object is None:\n",
        "        obs_builder_object = TreeObsForRailEnv(\n",
        "            max_depth=2,\n",
        "            predictor=ShortestPathPredictorForRailEnv(max_depth=10))\n",
        "    environment = RailEnv(width=1, height=1, rail_generator=rail_from_file(file_name, load_from_package),\n",
        "                          line_generator=line_from_file(file_name, load_from_package),\n",
        "                          number_of_agents=1,\n",
        "                          obs_builder_object=obs_builder_object,\n",
        "                          record_steps=record_steps,\n",
        "                          )\n",
        "    return environment\n",
        "\n",
        "# TODO riferisciti a un agente (EnvAgent)\n",
        "# Usa le azioni dell'agente specifico\n",
        "def delay_a_train(delay: int, delay_time: int, time_of_train_generation: int, actions, train):\n",
        "    \n",
        "    i_agent = train.handle\n",
        "    train_velocity = train.speed_counter.speed\n",
        "\n",
        "    \n",
        "    actions_scheduled = [0] * (len(actions[i_agent]) + delay)\n",
        "    \n",
        "    # Copy the actions scheduled for the train before the delay\n",
        "    for i in range(delay_time - time_of_train_generation):\n",
        "        actions_scheduled[i] = actions[i_agent][i]\n",
        "    # Delay the train (STOP)  \n",
        "    for i in range(delay):\n",
        "        if (i + delay_time - time_of_train_generation) < 0 or (delay_time - time_of_train_generation) > len(actions[i_agent]):\n",
        "            raise ImportError('The train is not present in the environment, check the delay time')\n",
        "        actions_scheduled[i + delay_time - time_of_train_generation] = RailEnvActions.STOP_MOVING\n",
        "    # Copy the actions scheduled for the train after the delay\n",
        "    for i in range(len(actions[i_agent]) - (delay_time - time_of_train_generation)):\n",
        "        actions_scheduled[i + delay_time - time_of_train_generation + delay] = actions[i_agent][i + delay_time - time_of_train_generation]\n",
        "    \n",
        "    actions[i_agent] = actions_scheduled\n",
        "    return \n",
        "\n",
        "\n",
        "# Function to convert decimal number to base number\n",
        "def actions_decimal_to_base(base, number_to_convert, num_agents):\n",
        "    division = number_to_convert\n",
        "    result = []\n",
        "    while division != 0:\n",
        "        result.append(division % base)\n",
        "        division = int(division / base)\n",
        "    actions_to_perform = result[::-1]\n",
        "    if len(actions_to_perform) < num_agents:\n",
        "        zero_to_add = num_agents - len(actions_to_perform)\n",
        "        for i in range(zero_to_add):\n",
        "            actions_to_perform.insert(0,0)\n",
        "    return actions_to_perform\n",
        "\n",
        "\n",
        "def make_a_deterministic_interruption(agent_to_interrupt, interruption_time):\n",
        "    state = agent_to_interrupt.state\n",
        "    if state == TrainState.MOVING:\n",
        "        agent_to_interrupt.malfunction_handler.malfunction_down_counter = interruption_time\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hRGASyFWbbg"
      },
      "source": [
        "# Custom schedule generator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyOVeCkwWi3y"
      },
      "source": [
        "\"\"\"Schedule generators (railway undertaking, \"EVU\").\"\"\"\n",
        "from typing import Tuple, List, Callable, Mapping, Optional, Any\n",
        "\n",
        "from enum import IntEnum\n",
        "from numpy.random.mtrand import RandomState\n",
        " \n",
        "from flatland.core.transition_map import GridTransitionMap\n",
        "from flatland.envs.agent_utils import EnvAgent\n",
        "from typing import List, NamedTuple, Callable\n",
        "\n",
        "from flatland.core.grid.grid4 import Grid4TransitionsEnum\n",
        "from flatland.core.grid.grid_utils import IntVector2DArray\n",
        "\n",
        "\n",
        "Schedule = NamedTuple('Schedule', [('agent_positions', IntVector2DArray),\n",
        "                                   ('agent_directions', List[Grid4TransitionsEnum]),\n",
        "                                   ('agent_targets', IntVector2DArray),\n",
        "                                   ('agent_speeds', List[float]),\n",
        "                                   ('agent_malfunction_rates', List[int]),\n",
        "                                   ('max_episode_steps', int)]) \n",
        "\n",
        "def check_rail_road_direction(rail: GridTransitionMap, timetable):\n",
        "    # To establish the direction of trains in the railroas I define a simple law, as for the cars, each trains has to \n",
        "    # go the direction that let them to have the right free\n",
        "\n",
        "    agents_direction = [0]*len(timetable)\n",
        "    path_result = [0]*len(timetable)\n",
        "\n",
        "    #print(rail.grid[7 ,13],rail.grid[7 ,12],rail.grid[7 ,11],rail.grid[7 ,10],rail.grid[7 ,9],rail.grid[7 ,8],rail.grid[7 ,7],rail.grid[7 ,6], rail.grid[7 ,5])\n",
        "    \n",
        "    for i in range (len(timetable)):\n",
        "        # Consider the a_star result to calculate the direction\n",
        "        path_result[i] = (a_star(rail,timetable[i][0][0],timetable[i][0][1]))\n",
        "        if path_result[i] == []:\n",
        "            agents_direction[i] = 1\n",
        "            continue\n",
        "        if len(path_result[i]) == 1:\n",
        "            agents_direction[i] = 1\n",
        "            continue\n",
        "        difference_x = path_result[i][0][1] - path_result[i][1][1]\n",
        "        difference_y = path_result[i][0][0] - path_result[i][1][0]\n",
        "        if difference_y == 1:\n",
        "            agents_direction[i] = 0\n",
        "        if difference_x ==  -1:\n",
        "            agents_direction[i] = 1\n",
        "        if difference_y == -1:\n",
        "            agents_direction[i] = 2\n",
        "        if difference_x == 1:\n",
        "            agents_direction[i] = 3\n",
        "\n",
        "    return agents_direction\n",
        "\n",
        "AgentPosition = Tuple[int, int]\n",
        "ScheduleGenerator = Callable[[GridTransitionMap, int, Optional[Any], Optional[int]], Schedule]\n",
        "\n",
        "\n",
        "\n",
        "class RailEnvActions(IntEnum):\n",
        "\tDO_NOTHING = 0  # implies change of direction in a dead-end!\n",
        "\tMOVE_LEFT = 1\n",
        "\tMOVE_FORWARD = 2\n",
        "\tMOVE_RIGHT = 3\n",
        "\tSTOP_MOVING = 4\n",
        "\tREVERSE = 5\n",
        "\n",
        "\t@staticmethod\n",
        "\tdef to_char(a: int):\n",
        "\t\treturn {\n",
        "\t\t\t0: 'B',\n",
        "\t\t\t1: 'L',\n",
        "\t\t\t2: 'F',\n",
        "\t\t\t3: 'R',\n",
        "\t\t\t4: 'S',\n",
        "\t\t\t5: 'G'\n",
        "\t\t}[a]\n",
        "\n",
        "\n",
        "def custom_schedule_generator(timetable, speed_ratio_map: Mapping[float, float] = None, seed: int = 1) -> ScheduleGenerator:\n",
        "\n",
        "#class Custom_schedule_generator(BaseSchedGen):\n",
        "\t\"\"\"\n",
        "\n",
        "\tThis is a custom schedule generator, create a schedule with the timetable, and the station where the trains should pass\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef generate_custom(rail: GridTransitionMap, num_agents: int, hints: Any = None, num_resets: int = 0,\n",
        "\t\t\t\t  np_random: RandomState = None) -> Schedule:\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tThe generator that assigns tasks to all the agents\n",
        "\t\t:param rail: Rail infrastructure given by the rail_generator\n",
        "\t\t:param num_agents: Number of agents to include in the schedule\n",
        "\t\t:param hints: Hints provided by the rail_generator These include positions of start/target positions\n",
        "\t\t:param num_resets: How often the generator has been reset.\n",
        "\t\t:return: Returns the generator to the rail constructor\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\ttrain_stations = hints['train_stations']\n",
        "\t\tcity_positions = hints['city_positions']\n",
        "\t\tcity_orientation = hints['city_orientations']\n",
        "\t\tmax_num_agents = hints['num_agents']\n",
        "\n",
        "\t\tif num_agents > max_num_agents:\n",
        "\t\t\tnum_agents = max_num_agents\n",
        "\t\t\twarnings.warn(\"Too many agents! Changes number of agents.\")\n",
        "\t\t# Place agents and targets within available train stations\n",
        "\t\tagents_position = []\n",
        "\t\tagents_target = []\n",
        "\t\tagents_direction = []\n",
        "\n",
        "\t\t# Define the agent positions\n",
        "\t\t# TODO capisci se così va bene o no\n",
        "\t\tfor agent_i in range (len(timetable)):\n",
        "\t\t\tagents_position.append(timetable[agent_i][0][0])\n",
        "\t\t\tagents_target.append(timetable[agent_i][0][-1])\n",
        "\n",
        "\n",
        "\t\t# Define the direction of the trains based on the rail they occupy\n",
        "\t\t# Input --> the topology of the network, the position of the trains\n",
        "\t\t# Output --> an array with the directions of the trains\n",
        "\t\t# DIRECTIONS: 0 = UP, 1 = RIGHT, 2 = DOWN, 3 = LEFT\n",
        "\n",
        "\t\tagents_direction = check_rail_road_direction(rail, timetable)\n",
        "\n",
        "\n",
        "\t\t_runtime_seed = seed + num_resets\n",
        "\n",
        "\t\tif speed_ratio_map:\n",
        "\t\t\tspeeds = speed_initialization_helper(num_agents, speed_ratio_map, seed=_runtime_seed, np_random=np_random)\n",
        "\t\telse:\n",
        "\t\t\tspeeds = [1.0] * len(agents_position)\n",
        "\n",
        "\t\t# We add multiply factors to the max number of time steps to simplify task in Flatland challenge.\n",
        "\t\t# These factors might change in the future.\n",
        "\t\ttimedelay_factor = 4\n",
        "\t\talpha = 2\n",
        "\t\tmax_episode_steps = 1000\n",
        "\n",
        "\t\t#print(agents_position, agents_target, agents_direction)\n",
        "\n",
        "\t\treturn Schedule(agent_positions=agents_position, agent_directions=agents_direction,\n",
        "\t\t\t\t\t\tagent_targets=agents_target, agent_speeds=speeds, agent_malfunction_rates=None,\n",
        "\t\t\t\t\t\tmax_episode_steps=max_episode_steps)\n",
        "\n",
        "\treturn generate_custom  #(station_to_traverse = [(21, 37), (15, 51)])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11emYfouXAL5"
      },
      "source": [
        "* These are the plan to follow utils\n",
        "*testo in corsivo*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKROm4gyXOr6"
      },
      "source": [
        "# import chain\n",
        "from itertools import chain\n",
        "from enum import IntEnum\n",
        "import random\n",
        "# This is to test if the timetable is valid or not\n",
        "from flatland.core.grid.grid4_astar import a_star\n",
        "\n",
        "class RailEnvActions(IntEnum):\n",
        "    DO_NOTHING = 0  # implies change of direction in a dead-end!\n",
        "    MOVE_LEFT = 1\n",
        "    MOVE_FORWARD = 2\n",
        "    MOVE_RIGHT = 3\n",
        "    STOP_MOVING = 4\n",
        "    REVERSE = 5\n",
        "\n",
        "    @staticmethod\n",
        "    def to_char(a: int):\n",
        "        return {\n",
        "            0: 'B',\n",
        "            1: 'L',\n",
        "            2: 'F',\n",
        "            3: 'R',\n",
        "            4: 'S',\n",
        "            5: 'G'\n",
        "        }[a]\n",
        "\n",
        "# Check if the timetable is feaseble or not\n",
        "def control_timetable(timetable, railway_topology):\n",
        "    # Check for all the trains\n",
        "    for trains in range (len(timetable)):       \n",
        "        # Check for all the stations\n",
        "        # Calculate the difference of two different times, so i don't need the last term to cycle          \n",
        "        for stations in range (len(timetable[trains][1]) - 1):   \n",
        "            if (timetable[trains][1][stations] - timetable[trains][1][stations + 1]) >= 0:\n",
        "                print('===================================================================================================================================')\n",
        "                print('Attention!!! The agent number', trains, 'has a problem in the timetable, times to reach stations', stations, 'and', (stations+1), 'are not right')\n",
        "                print('The time to reach the successive station SHOULD BE > 0, pay attenction to the timetable')\n",
        "                # Function that check if the time to reach a station defined by the timetable are possible or not,\n",
        "                # Return the time minimum time to reach two different stations depending on the distance and on the line type (high velocity, regional...)\n",
        "            time_to_next_station = time_to_reach_next_station(timetable[trains][0][stations], timetable[trains][0][stations + 1], railway_topology, timetable, trains)\n",
        "            # Control if the time to reach the next station is possible (considering maximum velocities of lines and the distances between two stations)\n",
        "            if time_to_next_station > (timetable[trains][1][stations+1]- timetable[trains][1][stations]):\n",
        "                print('===================================================================================================================================')\n",
        "                print('Attention!!! Agent number', trains, 'has a problem in the timetable, times to reach stations', stations, 'and', (stations+1), 'are not right')\n",
        "                print('The time to reach the next station SHOULD BE HIGHER. The minimum time to reach the station should be:', time_to_next_station)\n",
        "    return\n",
        "\n",
        "# TODO aggiungere dei controlli \n",
        "# - controllare che la posizione in cui si mette il goal del secondo treno sia possibile\n",
        "# - controllare il tempo necessario nella stazione (in base anche alla rialzatura in cui si mette il treno \n",
        "#   e.g. treno spostato su di due caselle, tempo necessario + 4 * velocità alla meno uno)\n",
        "\n",
        "def divide_trains_in_station_rails(timetable, railway_topology):\n",
        "    # The number of different stations presented in the timetable\n",
        "    different_stations = 0\n",
        "    # The position of different stations presented in the timetable\n",
        "    station_positions = []\n",
        "    # Check how many different stations are in the timetable\n",
        "    for i in range(len(timetable)): # for all the trains\n",
        "        for k in range(len(timetable[i][0])): # for all the stations\n",
        "            if timetable[i][0][k] not in station_positions:\n",
        "                station_positions.append(timetable[i][0][k])\n",
        "                different_stations += 1\n",
        "\n",
        "    # Indexes contein the indexes of the station like this\n",
        "    # 0 for the first station in station position \n",
        "    # 1 for the second and so on\n",
        "    indexes = []\n",
        "    # Local variable for the loop\n",
        "    single_index = []\n",
        "\n",
        "    for j in range(len(timetable)): # for all the trains\n",
        "        single_index = [0]*len(timetable[j][0])\n",
        "        for k in range(len(timetable[j][0])): # for all the stations\n",
        "            for i in range(len(station_positions)): # for all the different stations discovered\n",
        "                if station_positions[i] == timetable[j][0][k]:\n",
        "                    single_index[k] = i\n",
        "        indexes.append(single_index)\n",
        "    \n",
        "    # Stations have a capacity, if more trains with respect to the capacity\n",
        "    # of the station are present there is a problem\n",
        "    counter_of_trains = [0] * different_stations  # counter of trains in a certain station\n",
        "    \n",
        "    # TODO fai un ciclo for che cicli gli step nella tabella oraria per aggiornare il counter trains\n",
        "    # quando più treni sono nella stessa stazione aumenta, quando un treno esce dalla stazione diminuisce\n",
        "    # aggiungi una lettera che cicli sulle due stazioni\t(ad ora le stazioni girano su tutta la timetable)\n",
        "    # Calculating the maximum time the agents have to stay in env \n",
        "    \n",
        "     # Here controll if two or more trains have to reach the same station at the same time\n",
        "    for m in range(len(timetable)):  # for all the trains m\n",
        "        for n in range(len(timetable)): # for all the trains n with m!=n\n",
        "            for k in range(len(timetable[m][1])): # for all the stations of m\n",
        "                for l in range(len(timetable[n][1])): # for all the stations of n\n",
        "                    if m!=n and m<n:\n",
        "                        # time at which the trains have to reach the stations\n",
        "                        time_train_a = timetable[m][1][k]\n",
        "                        time_train_b = timetable[n][1][l]\n",
        "                        # if they have to reach the same stations\n",
        "                        if indexes[m][k] == indexes[n][l]: \n",
        "                            threshold_time = calculate_time_in_station(timetable,m,n,k,l)\n",
        "                            # if the time at which they have to reach the station is similar (calculated the time needed in the stations for the trains)\n",
        "                            if time_train_a - time_train_b < threshold_time and time_train_a - time_train_b > -threshold_time:\n",
        "                                # I change the goal of the convoy that first reach the station\n",
        "                                timetable[n][0][l] = (station_positions[indexes[n][l]][0] - 1, station_positions[indexes[n][l]][1])\n",
        "                            \n",
        "\n",
        "\n",
        "# Define the scheduled actions the agents have to do\n",
        "def action_to_do(timetable, railway_topology):\n",
        "    # Path to do to arrive to the right station\n",
        "\n",
        "    # L'idea vuole essere quella di avere un tempo necessario per stare in stazione\n",
        "    # Se due treni nell'intorno di tempo devono stare nella stessa stazione bisogna indirizzarli \n",
        "    # in binari liberi diversi, quindi il passaggio diventa diverso.\n",
        "\n",
        "    path_result = []\n",
        "    # Calculate the path for all the trains\n",
        "    for train_i in range (len(timetable)):\n",
        "        # Number of stations in the train i\n",
        "        num_of_stations = len(timetable[train_i][0])\n",
        "        # The partial result a train run\n",
        "        path_partial_result = []\n",
        "        for station in range(num_of_stations - 1): \n",
        "            path_partial_result.append(a_star(railway_topology,timetable[train_i][0][station],timetable[train_i][0][station + 1]))\n",
        "            if path_partial_result == []:\n",
        "                raise ImportError('There s not a path between station', station, 'and station', station + 1 )\n",
        "\n",
        "        # Final result for all the trains and train runs\n",
        "        path_result.append(path_partial_result)\n",
        "\n",
        "    # Calculate the actions that have to be done\n",
        "    actions_to_do = []\n",
        "    for train_i in range (len(timetable)):\n",
        "        # Number of stations in the train i\n",
        "        num_of_stations = len(timetable[train_i][0])\n",
        "        # Flag that tells me that the next step is particular\n",
        "        next = False\n",
        "        # Each train occupy a row in the action_to_do matrix \n",
        "        actions_single_train = []\n",
        "        # I need the direction of the last run for the reverse action\n",
        "        direction_last_run = 0\n",
        "        for station in range (num_of_stations - 1):\n",
        "            # Each train occupy a row in the action_to_do matrix \n",
        "            actions_single_train_run = []\n",
        "            for step in range (len(path_result[train_i][station])):\n",
        "                # If i'm restarting from the final station of the train run, i have to wait till is the time to restart\n",
        "                if len(path_result[train_i][station]) == 1:\n",
        "                    time_to_wait = timetable[train_i][1][station + 1] - timetable[train_i][1][station]\n",
        "                    for i in range(time_to_wait):\n",
        "                        actions_single_train_run.append(RailEnvActions.STOP_MOVING)\n",
        "                    continue\n",
        "                # Calculate the direction of the trains at each step\n",
        "                if step == 0:\n",
        "                    difference_y = path_result[train_i][station][step][0] - path_result[train_i][station][step + 1][0]\n",
        "                    difference_x = path_result[train_i][station][step][1] - path_result[train_i][station][step + 1][1]\n",
        "                    if difference_y == 1:\n",
        "                        direction = 0\n",
        "                    if difference_x ==  -1:\n",
        "                        direction = 1\n",
        "                    if difference_y == -1:\n",
        "                        direction = 2\n",
        "                    if difference_x == 1:\n",
        "                        direction = 3 \n",
        "                else:\n",
        "                    difference_y = path_result[train_i][station][step - 1][0] - path_result[train_i][station][step][0]\n",
        "                    difference_x = path_result[train_i][station][step - 1][1] - path_result[train_i][station][step][1]\n",
        "                    if difference_y == 1:\n",
        "                        direction = 0\n",
        "                    if difference_x ==  -1:\n",
        "                        direction = 1\n",
        "                    if difference_y == -1:\n",
        "                        direction = 2\n",
        "                    if difference_x == 1:\n",
        "                        direction = 3 \n",
        "                # Variable to count the number of possible path at each cell, is an int with the number of possible path\n",
        "                if not step == 0:\n",
        "                    # Specific case, a train is at the boarder of two different lines, \n",
        "                    # if this appen I have to consider the previous transition at the next time stamp due to the fact the velocity changes\n",
        "                    if next:\n",
        "                        multiple_path = railway_topology.get_transitions(path_result[train_i][station][step-1][0],path_result[train_i][station][step-1][1],prev_direction).count(1)\n",
        "                        next = False\n",
        "                    elif (path_result[train_i][station][step] in av_line) and not (path_result[train_i][station][step - 1] in av_line):\n",
        "                        multiple_path = railway_topology.get_transitions(path_result[train_i][station][step][0],path_result[train_i][station][step][1],prev_direction).count(1)\n",
        "                        next = True\n",
        "                    else:\n",
        "                        multiple_path = railway_topology.get_transitions(path_result[train_i][station][step-1][0],path_result[train_i][station][step-1][1],prev_direction).count(1)\n",
        "                # Starting with a move forward direction for the train\n",
        "                if step == 0:\n",
        "                    #actions_single_train.append(RailEnvActions.MOVE_FORWARD)\n",
        "                    prev_direction = direction\n",
        "                # If I'm not at the start of the train \n",
        "                else:\n",
        "                    # The direction doesn't change\n",
        "                    if num_of_stations > 1 and station >= 1 and step <= 1:\n",
        "                        if (direction - direction_last_run == 2 or direction - direction_last_run == -2):\n",
        "                            # If I'm in an hig velocity line velocity is define only by the type of train\n",
        "                            actions_single_train_run.append(RailEnvActions.REVERSE)\n",
        "                            prev_direction = direction\n",
        "                            continue\n",
        "\n",
        "                    if direction - prev_direction == 0:\n",
        "                        # If I'm in an hig velocity line velocity is define only by the type of train\n",
        "                        if path_result[train_i][station][step - 1] in av_line:\n",
        "                            velocity = timetable[train_i][2]\n",
        "                        # If I'm in other line velocity is the minimum between 1/2 (the velocity of the line) and the type of train velocity\n",
        "                        else:\n",
        "                            velocity = min(timetable[train_i][2], 1/2)\n",
        "                        for i in range(int(pow(velocity, -1))):\n",
        "                            #print('Test per capire come varia',i, 'Treno numero', train_i)\n",
        "                            actions_single_train_run.append(RailEnvActions.MOVE_FORWARD)\n",
        "                        # I'm arrived at the station?\n",
        "                        if step == (len(path_result[train_i][station]) - 1):\n",
        "                            # If the next station is the last one of the train run I don't have to stop for the min wait time\n",
        "                            if station != (num_of_stations - 2):\n",
        "                                if len(path_result[train_i][station + 1]) == 1:\n",
        "                                    continue\n",
        "                            # If is an intermediate station I need to stop the min wait time\n",
        "                            for i in range(3):   # TODO ADD THE WAITING TIMES OF THE STATIONS\n",
        "                                actions_single_train_run.append(RailEnvActions.STOP_MOVING)\n",
        "\n",
        "                        prev_direction = direction\n",
        "                    # I have to reverse the train direction when I arrive at the ending station\n",
        "                    elif ((direction - prev_direction) == -2) or ((direction - prev_direction) == 2):\n",
        "                        # If I'm in an hig velocity line velocity is define only by the type of train\n",
        "                        if path_result[train_i][station][step - 1] in av_line:\n",
        "                            velocity = timetable[train_i][2]\n",
        "                        else:\n",
        "                            velocity = min(timetable[train_i][2], 1/2)\n",
        "                        for i in range(int(pow(velocity, -1))):\n",
        "                            actions_single_train_run.append(RailEnvActions.REVERSE)\n",
        "                        prev_direction = direction\n",
        "                    # I have to move to left \n",
        "                    # and I have more then one possible path, so I go left at the deviation\n",
        "                    # Depending on the direction of march the results can be -1 or -3\n",
        "                    elif ((direction - prev_direction == -1) and (multiple_path > 1)) or ((direction - prev_direction == +3)):\n",
        "                        # If I'm in an hig velocity line velocity is define only by the type of train\n",
        "                        if path_result[train_i][station][step - 1] in av_line:\n",
        "                            velocity = timetable[train_i][2]\n",
        "                        # If I'm in other line velocity is the minimum between 1/2 (the velocity of the line) and the type of train velocity\n",
        "                        else:\n",
        "                            velocity = min(timetable[train_i][2], 1/2)\n",
        "                        for i in range(int(pow(velocity, -1))):\n",
        "                            actions_single_train_run.append(RailEnvActions.MOVE_LEFT)\n",
        "                        prev_direction = direction\n",
        "                    # I have to move right \n",
        "                    # and I have more then one possible path, so I go left at the deviation \n",
        "                    # Depending on the direction of march the results can be +1 or -3\n",
        "                    elif ((direction - prev_direction == 1) and (multiple_path > 1)) or ((direction - prev_direction == -3) ):\n",
        "                        # If I'm in an hig velocity line velocity is define only by the type of train\n",
        "                        if path_result[train_i][station][step - 1] in av_line:\n",
        "                            velocity = timetable[train_i][2]\n",
        "                        # If I'm in other line velocity is the minimum between 1/2 (the velocity of the line) and the type of train velocity\n",
        "                        else:\n",
        "                            velocity = min(timetable[train_i][2], 1/2)\n",
        "                        for i in range(int(pow(velocity, -1))):\n",
        "                            actions_single_train_run.append(RailEnvActions.MOVE_RIGHT)\n",
        "                        prev_direction = direction\n",
        "                    else:\n",
        "                        if path_result[train_i][station][step - 1] in av_line:\n",
        "                            velocity = timetable[train_i][2]\n",
        "                        else:\n",
        "                            velocity = min(timetable[train_i][2], 1/2)\n",
        "                        for i in range(int(pow(velocity, -1))):\n",
        "                            actions_single_train_run.append(RailEnvActions.MOVE_FORWARD)\n",
        "                        # I'm arrived at the station?\n",
        "                        if step == (len(path_result[train_i][station]) - 1):\n",
        "                            for i in range(3):   # TODO ADD THE WAITING TIMES OF THE STATIONS\n",
        "                                actions_single_train_run.append(RailEnvActions.STOP_MOVING)\n",
        "                        prev_direction = direction\n",
        "            direction_last_run = direction\n",
        "\n",
        "            actions_single_train.append(actions_single_train_run)\n",
        " \n",
        "        if isinstance(actions_single_train[0], list):\n",
        "            len(actions_single_train)\n",
        "            actions_single_train = list(chain.from_iterable(actions_single_train))\n",
        "        actions_to_do.append(actions_single_train)\n",
        "\n",
        "    return actions_to_do\n",
        "\n",
        "# Calculate the time to reach the stations to understand if timetable is right\n",
        "def time_to_reach_next_station(departure_station_position, arrival_station_position, railway_topology, schedule, train_number):\n",
        "    # First thing check the distance between two stations \n",
        "    result = a_star(railway_topology, departure_station_position, arrival_station_position)\n",
        "    # Maximum velocity a train can achieve\n",
        "    train_velocity = schedule[train_number][2]\n",
        "\n",
        "    lenght_path = len(result)  # distance between stations\n",
        "\n",
        "    # Array when I put at each step the time needed to make the path\n",
        "    # The total time is the sum of the numbers\n",
        "    time_array = []\n",
        "    # Check the at each step which train i am and which line im in\n",
        "    for step in range(lenght_path):\n",
        "        if (result[step]) in av_line:\n",
        "            time_array.append(pow(train_velocity,-1))\n",
        "        else:\n",
        "            time_array.append(pow(min(train_velocity, 1/2), -1))\n",
        "    time_needed = sum(time_array)\n",
        "\n",
        "    #print((time_needed + int(time_needed/10))) DEBUG\n",
        "\n",
        "    # Adding to the time a 10% to face with problems in case it's neaded\n",
        "    return (time_needed + int(time_needed/10))\n",
        "\n",
        "# TODO calculate the av_rails, in order to distinguish them\n",
        "# TODO calculate the right,left,up,down rails, in order to distinguish them\n",
        "# TODO understad if the velocities are realistic or not (360 km for high velocity, 180 and 120 is realistic or not?)\n",
        "\n",
        "def calculate_timetable(convoys, railway_topology):\n",
        "    # The timetable that should be returned\n",
        "    timetable = []\n",
        "    # For each convoy\n",
        "    for convoy_i in range(len(convoys)):\n",
        "        # For each train run defined\n",
        "        single_convoy_schedule = convoys[convoy_i].schedule\n",
        "        single_convoy_schedule_len = len(convoys[convoy_i].schedule)\n",
        "        single_convoy = []\n",
        "        for num_of_runs in range(single_convoy_schedule_len):\n",
        "            # The single train run\n",
        "            single_train_run = []\n",
        "            # The number of station to pass\n",
        "            num_of_stations = len(single_convoy_schedule[num_of_runs].line_belongin.stations)\n",
        "            # The station to stop\n",
        "            stations_to_stop_position = []\n",
        "            # Direction not inverted?\n",
        "            if not single_convoy_schedule[num_of_runs].inverse_train_direction:\n",
        "                for i in range(num_of_stations):\n",
        "                    # append the station position in the right order\n",
        "                    stations_to_stop_position.append(single_convoy_schedule[num_of_runs].line_belongin.stations[i].position)\n",
        "            # Direction inverdet?\n",
        "            else:\n",
        "                for i in range(num_of_stations):\n",
        "                    # append the station position in inverted order\n",
        "                    stations_to_stop_position.append(single_convoy_schedule[num_of_runs].line_belongin.stations[num_of_stations - 1 - i].position)\n",
        "            # Adding the starting time\n",
        "            single_train_run.append(single_convoy_schedule[num_of_runs].starting_time)\n",
        "\n",
        "            for stations in range(num_of_stations -1):\n",
        "                departure_station_position = stations_to_stop_position[stations]\n",
        "                arrival_station_position = stations_to_stop_position[stations + 1]\n",
        "                # First thing check the distance between two stations\n",
        "                result = a_star(railway_topology, departure_station_position, arrival_station_position)\n",
        "                # Maximum velocity a train can achieve\n",
        "                train_velocity = convoys[convoy_i].maximum_velocity \n",
        "\n",
        "                lenght_path = len(result)  # distance between stations\n",
        "\n",
        "                # Array when I put at each step the time needed to make the path\n",
        "                # The total time is the sum of the numbers\n",
        "                time_array = []\n",
        "\n",
        "                # Check the at each step which train i am and which line im in\n",
        "                # Train should be in the middle of two line type\n",
        "                for step in range(lenght_path):\n",
        "                    if (result[step]) in av_line:\n",
        "                        time_array.append(pow(train_velocity,-1))\n",
        "                    else:\n",
        "                        time_array.append(pow(min(train_velocity, 1/2), -1))\n",
        "                time_needed = sum(time_array)\n",
        "                # Adding to the time a 10% to face with problems in case it's neaded\n",
        "                time_needed = time_needed + int(time_needed/10)\n",
        "\n",
        "                # Adding the precedence time \n",
        "                if stations != (num_of_stations - 1):\n",
        "                    if len(single_train_run) == 1 and type(single_convoy_schedule[num_of_runs].line_belongin.stations[stations].min_wait_time) == int:\n",
        "                        single_train_run.append(int(time_needed + single_train_run[0] + single_convoy_schedule[num_of_runs].line_belongin.stations[stations].min_wait_time))\n",
        "                    else:\n",
        "                        # sum of time needed, the precedence time and the waiting time at the station\n",
        "                        single_train_run.append(int(time_needed + single_train_run[stations] + single_convoy_schedule[num_of_runs].line_belongin.stations[stations].min_wait_time[0]))\n",
        "\n",
        "            single_convoy.append(stations_to_stop_position)\n",
        "            single_convoy.append(single_train_run)\n",
        "            \n",
        "        timetable.append(single_convoy)\n",
        "\n",
        "    # This is needed in order to obtein the timetable-standard structure\n",
        "    final_timetable = [] # The final timetable\n",
        "    timetable_single_convoy = [] # Timetable of a single convoy\n",
        "    timetable_position_example = [] # Partial timetable with the position of the stations to pass\n",
        "    timetable_time_example = []  # Partial timetable with the time at which reach the stations\n",
        "    single_position_timetable = []  # position and time of a single train run\n",
        "    single_time_timetable = []\n",
        "\n",
        "    for i in range(len(timetable)):\n",
        "        for j in range(len(timetable[i])):\n",
        "            if j % 2 == 0:\n",
        "                timetable_position_example.append(timetable[i][j])\n",
        "            else:\n",
        "                timetable_time_example.append(timetable[i][j])\n",
        "        for k in range(len(timetable_position_example)):\n",
        "            single_position_timetable += (timetable_position_example[k])\n",
        "        for k in range(len(timetable_time_example)):\n",
        "            single_time_timetable += timetable_time_example[k]\n",
        "        # The standard timetable form is (positions, time, train velocity)\n",
        "        timetable_single_convoy.append(single_position_timetable)\n",
        "        timetable_single_convoy.append(single_time_timetable)\n",
        "        timetable_single_convoy.append(convoys[i].maximum_velocity)\n",
        "        # Final timetable\n",
        "        final_timetable.append(timetable_single_convoy)\n",
        "        # Restart the partial results\n",
        "        single_position_timetable = []\n",
        "        timetable_position_example = []\n",
        "        single_time_timetable = []\n",
        "        timetable_time_example = []\n",
        "        timetable_single_convoy = []\n",
        "\n",
        "    return final_timetable\n",
        "\n",
        "def calculate_time_in_station(timetable,train_a,train_b,index_a,index_b):\n",
        "    time_a = 15\n",
        "    time_b = 15\n",
        "    if index_a != 0:\n",
        "        time_a = timetable[train_a][1][index_a] - timetable[train_a][1][index_a - 1] + 15\n",
        "    if index_b != 0:\n",
        "        time_b = timetable[train_b][1][index_b] - timetable[train_b][1][index_b - 1] + 15\n",
        "    return max(time_a,time_b)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNlNKBMYZgVW"
      },
      "source": [
        "# Rail Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hNWqYVGZmPi"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT5xWtspZlzI"
      },
      "source": [
        "from flatland.envs.rail_env import RailEnvActions\n",
        "\n",
        "# Import your own Agent or use RLlib to train agents on Flatland\n",
        "# As an example we use a random agent instead\n",
        "class RandomAgent:\n",
        "\n",
        "\tdef __init__(self, state_size, action_size):\n",
        "\t\tself.state_size = state_size\n",
        "\t\tself.action_size = action_size\n",
        "\n",
        "\n",
        "\t# HERE DEFINE THE ACTIONS TO DO IN CASE THE AGENT IS NOT IN THE DETERMINISTIC PART \n",
        "\t# For now the agents can only move forward (for DEBUG)\n",
        "\tdef act(self, state):\n",
        "\t\treturn RailEnvActions.MOVE_FORWARD\n",
        "\n",
        "\tdef step(self, memories):\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tStep function to improve agent by adjusting policy given the observations\n",
        "\n",
        "\t\t:param memories: SARS Tuple to be\n",
        "\t\t:return:\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\treturn\n",
        "\n",
        "\tdef save(self, filename):\n",
        "\t\t# Store the current policy\n",
        "\t\treturn\n",
        "\n",
        "\tdef load(self, filename):\n",
        "\t\t# Load a policy\n",
        "\t\treturn"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqtaVQZNZ39v"
      },
      "source": [
        "## Environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXdkQKaRadDL"
      },
      "source": [
        "### Rewards and Penalities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImedOM4oaKbh"
      },
      "source": [
        "Here define the penalities and rewards for the agents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4zDuy13aJVH"
      },
      "source": [
        "# Penalities \n",
        "step_penality = - 0.1      # a step is time passing, so a penality for each step is needed\n",
        "stop_penality = - 0.1      # penality for stopping a moving agent\n",
        "reverse_penality = - 0.1   # penality for reversing the march of an agent\n",
        "\n",
        "target_reward = 100         # reward for an agent reaching his final target\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVWfJEALailv"
      },
      "source": [
        "### Training Flag\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afVzyw0Pak3a"
      },
      "source": [
        "example_training = 'training1'"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_86tpr-Z7Au"
      },
      "source": [
        "\"\"\"\n",
        "Definition of the RailEnv environment.\n",
        "\"\"\"\n",
        "import random\n",
        "\n",
        "from typing import List, Optional, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "from gym.utils import seeding\n",
        "\n",
        "from flatland.utils.rendertools import RenderTool, AgentRenderVariant\n",
        "from flatland.core.env import Environment\n",
        "from flatland.core.env_observation_builder import ObservationBuilder\n",
        "from flatland.core.grid.grid4 import Grid4Transitions\n",
        "from flatland.core.transition_map import GridTransitionMap\n",
        "from flatland.envs.agent_utils import EnvAgent\n",
        "from flatland.envs.distance_map import DistanceMap\n",
        "from flatland.envs.rail_env_action import RailEnvActions\n",
        "\n",
        "from flatland.envs import malfunction_generators as mal_gen\n",
        "from flatland.envs import rail_generators as rail_gen\n",
        "from flatland.envs import line_generators as line_gen\n",
        "from flatland.envs.timetable_generators import timetable_generator\n",
        "from flatland.envs import persistence\n",
        "from flatland.envs import agent_chains as ac\n",
        "\n",
        "from flatland.envs.observations import GlobalObsForRailEnv\n",
        "\n",
        "from flatland.envs.timetable_generators import timetable_generator\n",
        "from flatland.envs.step_utils.states import TrainState, StateTransitionSignals\n",
        "from flatland.envs.step_utils.transition_utils import check_valid_action\n",
        "from flatland.envs.step_utils import action_preprocessing\n",
        "from flatland.envs.step_utils import env_utils\n",
        "\n",
        "class RailEnv(Environment):\n",
        "    \"\"\"\n",
        "    RailEnv environment class.\n",
        "\n",
        "    RailEnv is an environment inspired by a (simplified version of) a rail\n",
        "    network, in which agents (trains) have to navigate to their target\n",
        "    locations in the shortest time possible, while at the same time cooperating\n",
        "    to avoid bottlenecks.\n",
        "\n",
        "    The valid actions in the environment are:\n",
        "\n",
        "     -   0: do nothing (continue moving or stay still)\n",
        "     -   1: turn left at switch and move to the next cell; if the agent was not moving, movement is started\n",
        "     -   2: move to the next cell in front of the agent; if the agent was not moving, movement is started\n",
        "     -   3: turn right at switch and move to the next cell; if the agent was not moving, movement is started\n",
        "     -   4: stop moving\n",
        "     -   5: invert the direction of march\n",
        "\n",
        "    Moving forward in a dead-end cell makes the agent turn 180 degrees and step\n",
        "    to the cell it came from.\n",
        "\n",
        "    The actions of the agents are executed in order of their handle to prevent\n",
        "    deadlocks and to allow them to learn relative priorities.\n",
        "\n",
        "    Reward Function:\n",
        "\n",
        "    It costs each agent a step_penalty for every time-step taken in the environment. Independent of the movement\n",
        "    of the agent. Currently all other penalties such as penalty for stopping, starting and invalid actions are set to 0.\n",
        "\n",
        "    alpha = 1\n",
        "    beta = 1\n",
        "    Reward function parameters:\n",
        "\n",
        "    - invalid_action_penalty = 0\n",
        "    - step_penalty = -alpha\n",
        "    - global_reward = beta\n",
        "    - epsilon = avoid rounding errors\n",
        "    - stop_penalty = 0  # penalty for stopping a moving agent\n",
        "    - start_penalty = 0  # penalty for starting a stopped agent\n",
        "\n",
        "    Stochastic malfunctioning of trains:\n",
        "    Trains in RailEnv can malfunction if they are halted too often (either by their own choice or because an invalid\n",
        "    action or cell is selected.\n",
        "\n",
        "    Every time an agent stops, an agent has a certain probability of malfunctioning. Malfunctions of trains follow a\n",
        "    poisson process with a certain rate. Not all trains will be affected by malfunctions during episodes to keep\n",
        "    complexity managable.\n",
        "\n",
        "    TODO: currently, the parameters that control the stochasticity of the environment are hard-coded in init().\n",
        "    For Round 2, they will be passed to the constructor as arguments, to allow for more flexibility.\n",
        "\n",
        "    \"\"\"\n",
        "    # Epsilon to avoid rounding errors\n",
        "    epsilon = 0.01\n",
        "    # NEW : REW: Sparse Reward\n",
        "    alpha = 0.05\n",
        "    beta = 1\n",
        "    step_penalty = -1 * alpha\n",
        "    global_reward = 1 * beta\n",
        "    invalid_action_penalty = 0  # previously -2; GIACOMO: we decided that invalid actions will carry no penalty\n",
        "    stop_penalty = -0.5  # penalty for stopping a moving agent\n",
        "    reverse_penality = -0.5\n",
        "    start_penalty = 0  # penalty for starting a stopped agent\n",
        "    cancellation_factor = 1\n",
        "    cancellation_time_buffer = 0\n",
        "\n",
        "    def __init__(self,\n",
        "                 width,\n",
        "                 height,\n",
        "                 max_episode_steps,\n",
        "                 rail_generator=None,\n",
        "                 line_generator=None,  # : line_gen.LineGenerator = line_gen.random_line_generator(),\n",
        "                 number_of_agents=2,\n",
        "                 obs_builder_object: ObservationBuilder = GlobalObsForRailEnv(),\n",
        "                 malfunction_generator_and_process_data=None,  # mal_gen.no_malfunction_generator(),\n",
        "                 malfunction_generator=None,\n",
        "                 remove_agents_at_target=True,\n",
        "                 random_seed=None,\n",
        "                 record_steps=False,\n",
        "                 close_following=True,\n",
        "                 ):\n",
        "        \"\"\"\n",
        "        Environment init.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        rail_generator : function\n",
        "            The rail_generator function is a function that takes the width,\n",
        "            height and agents handles of a  rail environment, along with the number of times\n",
        "            the env has been reset, and returns a GridTransitionMap object and a list of\n",
        "            starting positions, targets, and initial orientations for agent handle.\n",
        "            The rail_generator can pass a distance map in the hints or information for specific line_generators.\n",
        "            Implementations can be found in flatland/envs/rail_generators.py\n",
        "        line_generator : function\n",
        "            The line_generator function is a function that takes the grid, the number of agents and optional hints\n",
        "            and returns a list of starting positions, targets, initial orientations and speed for all agent handles.\n",
        "            Implementations can be found in flatland/envs/line_generators.py\n",
        "        width : int\n",
        "            The width of the rail map. Potentially in the future,\n",
        "            a range of widths to sample from.\n",
        "        height : int\n",
        "            The height of the rail map. Potentially in the future,\n",
        "            a range of heights to sample from.\n",
        "        number_of_agents : int\n",
        "            Number of agents to spawn on the map. Potentially in the future,\n",
        "            a range of number of agents to sample from.\n",
        "        obs_builder_object: ObservationBuilder object\n",
        "            ObservationBuilder-derived object that takes builds observation\n",
        "            vectors for each agent.\n",
        "        remove_agents_at_target : bool\n",
        "            If remove_agents_at_target is set to true then the agents will be removed by placing to\n",
        "            RailEnv.DEPOT_POSITION when the agent has reach it's target position.\n",
        "        random_seed : int or None\n",
        "            if None, then its ignored, else the random generators are seeded with this number to ensure\n",
        "            that stochastic operations are replicable across multiple operations\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        if malfunction_generator_and_process_data is not None:\n",
        "            print(\"DEPRECATED - RailEnv arg: malfunction_and_process_data - use malfunction_generator\")\n",
        "            self.malfunction_generator, self.malfunction_process_data = malfunction_generator_and_process_data\n",
        "        elif malfunction_generator is not None:\n",
        "            self.malfunction_generator = malfunction_generator\n",
        "            # malfunction_process_data is not used\n",
        "            # self.malfunction_generator, self.malfunction_process_data = malfunction_generator_and_process_data\n",
        "            self.malfunction_process_data = self.malfunction_generator.get_process_data()\n",
        "        # replace default values here because we can't use default args values because of cyclic imports\n",
        "        else:\n",
        "            self.malfunction_generator = mal_gen.NoMalfunctionGen()\n",
        "            self.malfunction_process_data = self.malfunction_generator.get_process_data()\n",
        "        \n",
        "        self.number_of_agents = number_of_agents\n",
        "\n",
        "        if rail_generator is None:\n",
        "            rail_generator = rail_gen.sparse_rail_generator()\n",
        "        self.rail_generator = rail_generator\n",
        "        if line_generator is None:\n",
        "            line_generator = line_gen.sparse_line_generator()\n",
        "        self.line_generator = line_generator\n",
        "\n",
        "        self.rail: Optional[GridTransitionMap] = None\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "\n",
        "        self.remove_agents_at_target = remove_agents_at_target\n",
        "\n",
        "        self.obs_builder = obs_builder_object\n",
        "        self.obs_builder.set_env(self)\n",
        "\n",
        "        self._max_episode_steps: Optional[int] = max_episode_steps\n",
        "        self._elapsed_steps = 0\n",
        "\n",
        "        self.obs_dict = {}\n",
        "        self.rewards_dict = {}\n",
        "        self.dev_obs_dict = {}\n",
        "        self.dev_pred_dict = {}\n",
        "\n",
        "        self.agents: List[EnvAgent] = []\n",
        "        self.num_resets = 0\n",
        "        self.distance_map = DistanceMap(self.agents, self.height, self.width)\n",
        "\n",
        "        self.action_space = [6]\n",
        "\n",
        "        self._seed()\n",
        "        if random_seed:\n",
        "            self._seed(seed=random_seed)\n",
        "\n",
        "        self.agent_positions = None\n",
        "\n",
        "        self.run_once = [0]*(self.number_of_agents)   # Flag to check when a train has started   \n",
        "\n",
        "        # save episode timesteps ie agent positions, orientations.  (not yet actions / observations)\n",
        "        self.record_steps = record_steps  # whether to save timesteps\n",
        "        # save timesteps in here: [[[row, col, dir, malfunction],...nAgents], ...nSteps]\n",
        "        self.cur_episode = []\n",
        "        self.list_actions = []  # save actions in here\n",
        "\n",
        "        self.motionCheck = ac.MotionCheck()\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        random.seed(seed)\n",
        "        self.random_seed = seed\n",
        "\n",
        "        # Keep track of all the seeds in order\n",
        "        if not hasattr(self, 'seed_history'):\n",
        "            self.seed_history = [seed]\n",
        "        if self.seed_history[-1] != seed:\n",
        "            self.seed_history.append(seed)\n",
        "\n",
        "        return [seed]\n",
        "\n",
        "    # no more agent_handles\n",
        "    def get_agent_handles(self):\n",
        "        return range(self.get_num_agents())\n",
        "    \n",
        "    def get_num_agents(self) -> int:\n",
        "        return len(self.agents)\n",
        "\n",
        "    def add_agent(self, agent):\n",
        "        \"\"\" Add static info for a single agent.\n",
        "            Returns the index of the new agent.\n",
        "        \"\"\"\n",
        "        self.agents.append(agent)\n",
        "        return len(self.agents) - 1\n",
        "\n",
        "    def reset_agents(self):\n",
        "        \"\"\" Reset the agents to their starting positions\n",
        "        \"\"\"\n",
        "        for agent in self.agents:\n",
        "            agent.reset()\n",
        "        self.active_agents = [i for i in range(len(self.agents))]\n",
        "\n",
        "    def action_required(self, agent):\n",
        "        \"\"\"\n",
        "        Check if an agent needs to provide an action\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        agent: RailEnvAgent\n",
        "        Agent we want to check\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        True: Agent needs to provide an action\n",
        "        False: Agent cannot provide an action\n",
        "        \"\"\"\n",
        "        return agent.state == TrainState.READY_TO_DEPART or \\\n",
        "               ( agent.state.is_on_map_state() and agent.speed_counter.is_cell_entry )\n",
        "\n",
        "    def reset(self, regenerate_rail: bool = True, regenerate_schedule: bool = True, *,\n",
        "              random_seed: int = None) -> Tuple[Dict, Dict]:\n",
        "        \"\"\"\n",
        "        reset(regenerate_rail, regenerate_schedule, activate_agents, random_seed)\n",
        "\n",
        "        The method resets the rail environment\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        regenerate_rail : bool, optional\n",
        "            regenerate the rails\n",
        "        regenerate_schedule : bool, optional\n",
        "            regenerate the schedule and the static agents\n",
        "        random_seed : int, optional\n",
        "            random seed for environment\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        observation_dict: Dict\n",
        "            Dictionary with an observation for each agent\n",
        "        info_dict: Dict with agent specific information\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if random_seed:\n",
        "            self._seed(random_seed)\n",
        "\n",
        "        optionals = {}\n",
        "        if regenerate_rail or self.rail is None:\n",
        "\n",
        "            if \"__call__\" in dir(self.rail_generator):\n",
        "                rail, optionals = self.rail_generator(\n",
        "                    self.width, self.height, self.number_of_agents, self.num_resets, self.np_random)\n",
        "            elif \"generate\" in dir(self.rail_generator):\n",
        "                rail, optionals = self.rail_generator.generate(\n",
        "                    self.width, self.height, self.number_of_agents, self.num_resets, self.np_random)\n",
        "            else:\n",
        "                raise ValueError(\"Could not invoke __call__ or generate on rail_generator\")\n",
        "\n",
        "            self.rail = rail\n",
        "            self.height, self.width = self.rail.grid.shape\n",
        "\n",
        "            # Do a new set_env call on the obs_builder to ensure\n",
        "            # that obs_builder specific instantiations are made according to the\n",
        "            # specifications of the current environment : like width, height, etc\n",
        "            self.obs_builder.set_env(self)\n",
        "\n",
        "        if optionals and 'distance_map' in optionals:\n",
        "            self.distance_map.set(optionals['distance_map'])\n",
        "\n",
        "        if regenerate_schedule or regenerate_rail or self.get_num_agents() == 0:\n",
        "            agents_hints = None\n",
        "            if optionals and 'agents_hints' in optionals:\n",
        "                agents_hints = optionals['agents_hints']\n",
        "\n",
        "            line = self.line_generator(self.rail, self.number_of_agents, agents_hints, \n",
        "                                               self.num_resets, self.np_random)\n",
        "            self.agents = EnvAgent.from_line(line)\n",
        "\n",
        "            # Reset distance map - basically initializing\n",
        "            self.distance_map.reset(self.agents, self.rail)\n",
        "\n",
        "            # NEW : Time Schedule Generation\n",
        "            timetable = timetable_generator(self.agents, self.distance_map, \n",
        "                                               agents_hints, self.np_random)\n",
        "\n",
        "            #self._max_episode_steps = 250\n",
        "\n",
        "            for agent_i, agent in enumerate(self.agents):\n",
        "                agent.earliest_departure = timetable.earliest_departures[agent_i]         \n",
        "                agent.latest_arrival = timetable.latest_arrivals[agent_i]\n",
        "        else:\n",
        "            self.distance_map.reset(self.agents, self.rail)\n",
        "        \n",
        "        # Reset agents to initial states\n",
        "        self.reset_agents()\n",
        "\n",
        "        self.run_once = [0]*(self.number_of_agents)   # Flag to check when a train has started\n",
        "\n",
        "        self.num_resets += 1\n",
        "        self._elapsed_steps = 0\n",
        "\n",
        "        # Agent positions map\n",
        "        self.agent_positions = np.zeros((self.height, self.width), dtype=int) - 1\n",
        "        self._update_agent_positions_map(ignore_old_positions=False)\n",
        "\n",
        "        self.dones = dict.fromkeys(list(range(self.get_num_agents())) + [\"__all__\"], False)\n",
        "\n",
        "        # Reset the state of the observation builder with the new environment\n",
        "        self.obs_builder.reset()\n",
        "\n",
        "        # Empty the episode store of agent positions\n",
        "        self.cur_episode = []\n",
        "\n",
        "        info_dict = self.get_info_dict()\n",
        "        # Return the new observation vectors for each agent\n",
        "        observation_dict: Dict = self._get_observations()\n",
        "        if hasattr(self, \"renderer\") and self.renderer is not None:\n",
        "            self.renderer = None\n",
        "        return observation_dict, info_dict\n",
        "\n",
        "\n",
        "    def _update_agent_positions_map(self, ignore_old_positions=True):\n",
        "        \"\"\" Update the agent_positions array for agents that changed positions \"\"\"\n",
        "        for agent in self.agents:\n",
        "            if not ignore_old_positions or agent.old_position != agent.position:\n",
        "                if agent.position is not None:\n",
        "                    self.agent_positions[agent.position] = agent.handle\n",
        "                if agent.old_position is not None:\n",
        "                    self.agent_positions[agent.old_position] = -1\n",
        "    \n",
        "    def generate_state_transition_signals(self, agent, preprocessed_action, movement_allowed, target_time):\n",
        "        \"\"\" Generate State Transitions Signals used in the state machine \"\"\"\n",
        "        st_signals = StateTransitionSignals()\n",
        "        \n",
        "        # Malfunction starts when in_malfunction is set to true\n",
        "        st_signals.in_malfunction = agent.malfunction_handler.in_malfunction\n",
        "\n",
        "        # Malfunction counter complete - Malfunction ends next timestep\n",
        "        st_signals.malfunction_counter_complete = agent.malfunction_handler.malfunction_counter_complete\n",
        "\n",
        "        # Earliest departure reached - Train is allowed to move now\n",
        "        st_signals.earliest_departure_reached = self._elapsed_steps >= agent.earliest_departure\n",
        "\n",
        "        # Stop Action Given\n",
        "        st_signals.stop_action_given = (preprocessed_action == RailEnvActions.STOP_MOVING)\n",
        "\n",
        "        # Valid Movement action Given\n",
        "        st_signals.valid_movement_action_given = preprocessed_action.is_moving_action() and movement_allowed\n",
        "\n",
        "        # Target Reached\n",
        "        if self._elapsed_steps >= target_time:\n",
        "            # agent.target = [agent.target[0] - 1, agent.target[1]]\n",
        "            st_signals.target_reached = env_utils.fast_position_equal(agent.position, agent.target)\n",
        "        else:\n",
        "            st_signals.target_reached = False\n",
        "\n",
        "        # Movement conflict - Multiple trains trying to move into same cell\n",
        "        # If speed counter is not in cell exit, the train can enter the cell\n",
        "        st_signals.movement_conflict = (not movement_allowed) and agent.speed_counter.is_cell_exit\n",
        "\n",
        "        return st_signals\n",
        "\n",
        "    def _handle_end_reward(self, agent: EnvAgent) -> int:\n",
        "        '''\n",
        "        Handles end-of-episode reward for a particular agent.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        agent : EnvAgent\n",
        "        '''\n",
        "        i_agent = agent.handle\n",
        "\n",
        "        if training == 'training0':\n",
        "            if i_agent != 0:\n",
        "                reward = 0\n",
        "                return reward\n",
        "        if training == 'training1' or training == 'training1.1':\n",
        "            if i_agent > 1:\n",
        "                reward = 0\n",
        "                return reward\n",
        "\n",
        "        reward = None\n",
        "        # agent done? (arrival_time is not None)\n",
        "        if agent.state == TrainState.DONE:\n",
        "            # if agent arrived earlier or on time = 0\n",
        "            # if agent arrived later = -ve reward based on how late\n",
        "            reward = target_reward\n",
        "            i_agent = agent.handle\n",
        "            self.dones[i_agent] = True\n",
        "            # DELAY\n",
        "            #reward = min(agent.latest_arrival - agent.arrival_time, 0)\n",
        "\n",
        "        # Agents not done (arrival_time is None)\n",
        "        else:\n",
        "            # CANCELLED check (never departed)\n",
        "            if (agent.state.is_off_map_state()):\n",
        "                reward = -1 * self.cancellation_factor * \\\n",
        "                    (agent.get_travel_time_on_shortest_path(self.distance_map) + self.cancellation_time_buffer)\n",
        "\n",
        "            # Departed but never reached\n",
        "            if (agent.state.is_on_map_state()):\n",
        "                reward = -0.5\n",
        "                # DELAY\n",
        "                #reward = agent.get_current_delay(self._elapsed_steps, self.distance_map)\n",
        "        \n",
        "        return reward\n",
        "\n",
        "    def preprocess_action(self, action, agent):\n",
        "        \"\"\"\n",
        "        Preprocess the provided action\n",
        "            * Change to DO_NOTHING if illegal action\n",
        "            * Block all actions when in waiting state\n",
        "            * Check MOVE_LEFT/MOVE_RIGHT actions on current position else try MOVE_FORWARD\n",
        "        \"\"\"\n",
        "        action = action_preprocessing.preprocess_raw_action(action, agent.state, agent.action_saver.saved_action)\n",
        "        action = action_preprocessing.preprocess_action_when_waiting(action, agent.state)\n",
        "\n",
        "        # Try moving actions on current position\n",
        "        current_position, current_direction = agent.position, agent.direction\n",
        "        if current_position is None: # Agent not added on map yet\n",
        "            current_position, current_direction = agent.initial_position, agent.initial_direction\n",
        "        \n",
        "        action = action_preprocessing.preprocess_moving_action(action, self.rail, current_position, current_direction)\n",
        "\n",
        "        # Check transitions, bounts for executing the action in the given position and directon\n",
        "        if action.is_moving_action() and not check_valid_action(action, self.rail, current_position, current_direction):\n",
        "            action = RailEnvActions.STOP_MOVING\n",
        "\n",
        "        return action\n",
        "    \n",
        "    def clear_rewards_dict(self):\n",
        "        \"\"\" Reset the rewards dictionary \"\"\"\n",
        "        self.rewards_dict = {i_agent: 0 for i_agent in range(len(self.agents))}\n",
        "\n",
        "    def get_info_dict(self):\n",
        "        \"\"\" \n",
        "        Returns dictionary of infos for all agents \n",
        "        dict_keys : action_required - \n",
        "                    malfunction - Counter value for malfunction > 0 means train is in malfunction\n",
        "                    speed - Speed of the train\n",
        "                    state - State from the trains's state machine\n",
        "        \"\"\"\n",
        "        info_dict = {\n",
        "            'action_required': {i: self.action_required(agent) for i, agent in enumerate(self.agents)},\n",
        "            'malfunction': {\n",
        "                i: agent.malfunction_handler.malfunction_down_counter for i, agent in enumerate(self.agents)\n",
        "            },\n",
        "            'speed': {i: agent.speed_counter.speed for i, agent in enumerate(self.agents)},\n",
        "            'state': {i: agent.state for i, agent in enumerate(self.agents)}\n",
        "        }\n",
        "        return info_dict\n",
        "    \n",
        "    def update_step_rewards(self, i_agent):\n",
        "        \"\"\"\n",
        "        Update the rewards dict for agent id i_agent for every timestep\n",
        "        \"\"\"\n",
        "        if training == 'training0' and i_agent != 0:\n",
        "            return\n",
        "        elif (training == 'training1' or training == 'training1.1') and i_agent > 1:\n",
        "            return\n",
        "\n",
        "        action = self.agents[i_agent].action_saver.saved_action\n",
        "        moving = self.agents[i_agent].moving\n",
        "        state = self.agents[i_agent].state\n",
        "\n",
        "        reward = None\n",
        "\n",
        "        reward = step_penality\n",
        "\n",
        "        if action == RailEnvActions.REVERSE:\n",
        "            reward += reverse_penality\n",
        "        if not moving or state == TrainState.STOPPED:\n",
        "            reward += stop_penality\n",
        "        \n",
        "        self.rewards_dict[i_agent] += reward\n",
        "\n",
        "    def end_of_episode_update(self, have_all_agents_ended):\n",
        "        \"\"\" \n",
        "        Updates made when episode ends\n",
        "        Parameters: have_all_agents_ended - Indicates if all agents have reached done state\n",
        "        \"\"\"\n",
        "        if have_all_agents_ended or \\\n",
        "           ( (self._max_episode_steps is not None) and (self._elapsed_steps >= self._max_episode_steps)):\n",
        "\n",
        "            for i_agent, agent in enumerate(self.agents):\n",
        "                \n",
        "                reward = self._handle_end_reward(agent)\n",
        "                self.rewards_dict[i_agent] += reward\n",
        "                \n",
        "                #self.dones[i_agent] = True\n",
        "\n",
        "            #self.dones[\"__all__\"] = True\n",
        "\n",
        "    def handle_done_state(self, agent):\n",
        "        \"\"\" Any updates to agent to be made in Done state \"\"\"\n",
        "        if agent.state == TrainState.DONE and agent.arrival_time is None:\n",
        "            agent.arrival_time = self._elapsed_steps\n",
        "            if self.remove_agents_at_target:\n",
        "                agent.position = None\n",
        "\n",
        "    def step(self, action_dict_: Dict[int, RailEnvActions]):\n",
        "        \"\"\"\n",
        "        Updates rewards for the agents at a step.\n",
        "        \"\"\"\n",
        "        self._elapsed_steps += 1\n",
        "\n",
        "        # Not allowed to step further once done\n",
        "        if self.dones[\"__all__\"]:\n",
        "            raise Exception(\"Episode is done, cannot call step()\")\n",
        "\n",
        "        self.clear_rewards_dict()\n",
        "\n",
        "        have_all_agents_ended = True # Boolean flag to check if all agents are done\n",
        "\n",
        "        self.motionCheck = ac.MotionCheck()  # reset the motion check\n",
        "\n",
        "        temp_transition_data = {}\n",
        "        \n",
        "        for agent in self.agents:\n",
        "            i_agent = agent.handle\n",
        "\n",
        "            # Build info dict\n",
        "            rail, optionals = self.rail_generator(\n",
        "                self.width, self.height, self.number_of_agents, self.num_resets, self.np_random)\n",
        "\n",
        "            agent = self.agents[i_agent]\n",
        "\n",
        "            # Calculate velocities that the agents have to mantein\n",
        "            velocities = self.check_speed(optionals['agents_hints'])   # TODO variare velocità in base alla stazione da raggiungere     \n",
        "\n",
        "            agent.speed_counter.speed = velocities[i_agent]\n",
        "\n",
        "            # Starting time of the agent\n",
        "            starting_time = optionals['agents_hints']['timetable'][i_agent][1][0]\n",
        "            ending_time = optionals['agents_hints']['timetable'][i_agent][1][-1]\n",
        "\n",
        "            agent.earliest_departure = starting_time\n",
        "            agent.latest_arrival = ending_time\n",
        "\n",
        "            agent.old_position = agent.position\n",
        "            agent.old_direction = agent.direction\n",
        "            # Generate malfunction\n",
        "            agent.malfunction_handler.generate_malfunction(self.malfunction_generator, self.np_random)\n",
        "\n",
        "            # Get action for the agent\n",
        "            action = action_dict_.get(i_agent, RailEnvActions.DO_NOTHING)\n",
        "\n",
        "            preprocessed_action = self.preprocess_action(action, agent)\n",
        "\n",
        "            # Save moving actions in not already saved\n",
        "            agent.action_saver.save_action_if_allowed(preprocessed_action, agent.state)\n",
        "\n",
        "            # Train's next position can change if current stopped in a fractional speed or train is at cell's exit\n",
        "\n",
        "            position_update_allowed = agent.speed_counter.is_cell_exit and \\\n",
        "                        not agent.malfunction_handler.malfunction_down_counter > 0 and \\\n",
        "                        not preprocessed_action == RailEnvActions.STOP_MOVING                            \n",
        "\n",
        "            #position_update_allowed = (agent.speed_counter.is_cell_exit or agent.state == TrainState.STOPPED)\n",
        "\n",
        "            # Calculate new position\n",
        "            # Keep agent in same place if already done\n",
        "            if agent.state == TrainState.DONE:\n",
        "                new_position, new_direction = agent.position, agent.direction\n",
        "            elif agent.state == TrainState.MALFUNCTION:\n",
        "                new_position, new_direction = agent.position, agent.direction\n",
        "            # Add agent to the map if not on it yet\n",
        "            elif agent.position is None and agent.action_saver.is_action_saved:\n",
        "                new_position = agent.initial_position\n",
        "                new_direction = agent.initial_direction       \n",
        "            # If movement is allowed apply saved action independent of other agents\n",
        "            elif agent.action_saver.is_action_saved and position_update_allowed:\n",
        "                saved_action = agent.action_saver.saved_action\n",
        "                # Apply action independent of other agents and get temporary new position and direction\n",
        "                new_position, new_direction  = env_utils.apply_action_independent(saved_action, \n",
        "                                                                             self.rail, \n",
        "                                                                             agent.position, \n",
        "                                                                             agent.direction)\n",
        "                preprocessed_action = saved_action\n",
        "            else:\n",
        "                new_position, new_direction = agent.position, agent.direction\n",
        "\n",
        "            temp_transition_data[i_agent] = env_utils.AgentTransitionData(position=new_position,\n",
        "                                                                direction=new_direction,\n",
        "                                                                preprocessed_action=preprocessed_action)\n",
        "            \n",
        "            # This is for storing and later checking for conflicts of agents trying to occupy same cell                                                    \n",
        "            self.motionCheck.addAgent(i_agent, agent.position, new_position)\n",
        "\n",
        "        # Find conflicts between trains trying to occupy same cell  TODO controlla i bug\n",
        "        self.motionCheck.find_conflicts()\n",
        "        \n",
        "        for agent in self.agents:\n",
        "            i_agent = agent.handle\n",
        "\n",
        "            ## Update positions\n",
        "            if agent.malfunction_handler.in_malfunction:\n",
        "                movement_allowed = False\n",
        "            else:\n",
        "                movement_allowed = self.motionCheck.check_motion(i_agent, agent.position) \n",
        "\n",
        "\n",
        "            movement_inside_cell = agent.state == TrainState.STOPPED and not agent.speed_counter.is_cell_exit\n",
        "            movement_allowed = movement_allowed or movement_inside_cell\n",
        "\n",
        "            # Fetch the saved transition data\n",
        "            agent_transition_data = temp_transition_data[i_agent]\n",
        "            preprocessed_action = agent_transition_data.preprocessed_action\n",
        "\n",
        "            ## Update states\n",
        "            state_transition_signals = self.generate_state_transition_signals(agent, preprocessed_action, movement_allowed, ending_time)\n",
        "            agent.state_machine.set_transition_signals(state_transition_signals)\n",
        "            agent.state_machine.step()\n",
        "\n",
        "            # Needed when not removing agents at target\n",
        "            movement_allowed = movement_allowed and agent.state != TrainState.DONE\n",
        "\n",
        "            # Agent is being added to map\n",
        "            if agent.state.is_on_map_state():\n",
        "                if agent.state_machine.previous_state.is_off_map_state():\n",
        "                    agent.position = agent.initial_position\n",
        "                    agent.direction = agent.initial_direction\n",
        "            # Speed counter completes\n",
        "                elif movement_allowed and (agent.speed_counter.is_cell_exit):\n",
        "                    agent.position = agent_transition_data.position\n",
        "                    agent.direction = agent_transition_data.direction\n",
        "                    agent.state_machine.update_if_reached(agent.position, agent.target)\n",
        "\n",
        "            # Off map or on map state and position should match\n",
        "            env_utils.state_position_sync_check(agent.state, agent.position, agent.handle)\n",
        "\n",
        "            # Handle done state actions, optionally remove agents\n",
        "            self.handle_done_state(agent)\n",
        "            \n",
        "            if training == 'training0':\n",
        "                if i_agent == 0:\n",
        "                    have_all_agents_ended &= (agent.state == TrainState.DONE)\n",
        "\n",
        "            elif training == 'training1' or training == 'training1.1':\n",
        "                if i_agent < 2:\n",
        "                    have_all_agents_ended &= (agent.state == TrainState.DONE)\n",
        "\n",
        "            else:\n",
        "                have_all_agents_ended &= (agent.state == TrainState.DONE)\n",
        "\n",
        "            ## Update rewards\n",
        "            self.update_step_rewards(i_agent)\n",
        "\n",
        "            ## Update counters (malfunction and speed)\n",
        "            agent.speed_counter.update_counter(agent.state, agent.old_position)\n",
        "                                            #    agent.state_machine.previous_state)\n",
        "            agent.malfunction_handler.update_counter()\n",
        "\n",
        "            # Clear old action when starting in new cell\n",
        "            if agent.speed_counter.is_cell_entry and agent.position is not None:\n",
        "                agent.action_saver.clear_saved_action()\n",
        "        \n",
        "        # Check if episode has ended and update rewards and dones\n",
        "        self.end_of_episode_update(have_all_agents_ended)\n",
        "\n",
        "        self._update_agent_positions_map()\n",
        "\n",
        "        return self._get_observations(), self.rewards_dict, self.dones, self.get_info_dict() \n",
        "\n",
        "    def record_timestep(self, dActions):\n",
        "        \"\"\" \n",
        "        Record the positions and orientations of all agents in memory, in the cur_episode\n",
        "        \"\"\"\n",
        "        list_agents_state = []\n",
        "        for i_agent in range(self.get_num_agents()):\n",
        "            agent = self.agents[i_agent]\n",
        "            # the int cast is to avoid numpy types which may cause problems with msgpack\n",
        "            # in env v2, agents may have position None, before starting\n",
        "            if agent.position is None:\n",
        "                pos = (0, 0)\n",
        "            else:\n",
        "                pos = (int(agent.position[0]), int(agent.position[1]))\n",
        "            # print(\"pos:\", pos, type(pos[0]))\n",
        "            list_agents_state.append([\n",
        "                    *pos, int(agent.direction), \n",
        "                    agent.malfunction_handler.malfunction_down_counter,  \n",
        "                    int(agent.status),\n",
        "                    int(agent.position in self.motionCheck.svDeadlocked)\n",
        "                    ])\n",
        "\n",
        "        self.cur_episode.append(list_agents_state)\n",
        "        self.list_actions.append(dActions)\n",
        "\n",
        "    def _get_observations(self):\n",
        "        \"\"\"\n",
        "        Utility which returns the dictionary of observations for an agent with respect to environment\n",
        "        \"\"\"\n",
        "        # print(f\"_get_obs - num agents: {self.get_num_agents()} {list(range(self.get_num_agents()))}\")\n",
        "        self.obs_dict = self.obs_builder.get_many(list(range(self.get_num_agents())))\n",
        "        return self.obs_dict\n",
        "\n",
        "    def get_valid_directions_on_grid(self, row: int, col: int) -> List[int]:\n",
        "        \"\"\"\n",
        "        Returns directions in which the agent can move\n",
        "        \"\"\"\n",
        "        return Grid4Transitions.get_entry_directions(self.rail.get_full_transitions(row, col))\n",
        "\n",
        "    def _exp_distirbution_synced(self, rate: float) -> float:\n",
        "        \"\"\"\n",
        "        Generates sample from exponential distribution\n",
        "        We need this to guarantee synchronity between different instances with same seed.\n",
        "        :param rate:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        u = self.np_random.rand()\n",
        "        x = - np.log(1 - u) * rate\n",
        "        return x\n",
        "\n",
        "    def _is_agent_ok(self, agent: EnvAgent) -> bool:\n",
        "        \"\"\"\n",
        "        Check if an agent is ok, meaning it can move and is not malfuncitoinig\n",
        "        Parameters\n",
        "        ----------\n",
        "        agent\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        True if agent is ok, False otherwise\n",
        "\n",
        "        \"\"\"\n",
        "        return agent.malfunction_handler.in_malfunction\n",
        "        \n",
        "\n",
        "    def save(self, filename):\n",
        "        print(\"DEPRECATED call to env.save() - pls call RailEnvPersister.save()\")\n",
        "        persistence.RailEnvPersister.save(self, filename)\n",
        "\n",
        "    def render(self, mode=\"rgb_array\", gl=\"PGL\", agent_render_variant=AgentRenderVariant.ONE_STEP_BEHIND,\n",
        "            show_debug=False, clear_debug_text=True, show=False,\n",
        "            screen_height=600, screen_width=800,\n",
        "            show_observations=False, show_predictions=False,\n",
        "            show_rowcols=False, return_image=True):\n",
        "        \"\"\"\n",
        "        This methods provides the option to render the\n",
        "        environment's behavior as an image or to a window.\n",
        "        Parameters\n",
        "        ----------\n",
        "        mode\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Image if mode is rgb_array, opens a window otherwise\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"renderer\") or self.renderer is None:\n",
        "            self.initialize_renderer(mode=mode, gl=gl,  # gl=\"TKPILSVG\",\n",
        "                                    agent_render_variant=agent_render_variant,\n",
        "                                    show_debug=show_debug,\n",
        "                                    clear_debug_text=clear_debug_text,\n",
        "                                    show=show,\n",
        "                                    screen_height=screen_height,  # Adjust these parameters to fit your resolution\n",
        "                                    screen_width=screen_width)\n",
        "        return self.update_renderer(mode=mode, show=show, show_observations=show_observations,\n",
        "                                    show_predictions=show_predictions,\n",
        "                                    show_rowcols=show_rowcols, return_image=return_image)\n",
        "\n",
        "    def initialize_renderer(self, mode, gl,\n",
        "                agent_render_variant,\n",
        "                show_debug,\n",
        "                clear_debug_text,\n",
        "                show,\n",
        "                screen_height,\n",
        "                screen_width):\n",
        "        # Initiate the renderer\n",
        "        self.renderer = RenderTool(self, gl=gl,  # gl=\"TKPILSVG\",\n",
        "                                agent_render_variant=agent_render_variant,\n",
        "                                show_debug=show_debug,\n",
        "                                clear_debug_text=clear_debug_text,\n",
        "                                screen_height=screen_height,  # Adjust these parameters to fit your resolution\n",
        "                                screen_width=screen_width)  # Adjust these parameters to fit your resolution\n",
        "        self.renderer.show = show\n",
        "        self.renderer.reset()\n",
        "\n",
        "    def update_renderer(self, mode, show, show_observations, show_predictions,\n",
        "                    show_rowcols, return_image):\n",
        "        \"\"\"\n",
        "        This method updates the render.\n",
        "        Parameters\n",
        "        ----------\n",
        "        mode\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Image if mode is rgb_array, None otherwise\n",
        "        \"\"\"\n",
        "        image = self.renderer.render_env(show=show, show_observations=show_observations,\n",
        "                                show_predictions=show_predictions,\n",
        "                                show_rowcols=show_rowcols, return_image=return_image)\n",
        "        if mode == 'rgb_array':\n",
        "            return image[:, :, :3]\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"\n",
        "        This methods closes any renderer window.\n",
        "        \"\"\"\n",
        "        if hasattr(self, \"renderer\") and self.renderer is not None:\n",
        "            try:\n",
        "                if self.renderer.show:\n",
        "                    self.renderer.close_window()\n",
        "            except Exception as e:\n",
        "                print(\"Could Not close window due to:\",e)\n",
        "            self.renderer = None\n",
        "\n",
        "\n",
        "    def check_speed(self, agents_hints):\n",
        "\n",
        "    # Velocity depending on the train type and on the line (Take the minimum between the two possible velocities)\n",
        "        train_velocities = [0]*self.number_of_agents\n",
        "\n",
        "        # Check for all the agents\n",
        "        for i_agent, agent in enumerate(self.agents):\n",
        "\n",
        "            # the i_agent\n",
        "            agent = self.agents[i_agent]\n",
        "\n",
        "            # Check if the agent is in the environment or not\n",
        "            if agent.position != None:\n",
        "\n",
        "                # If the agent is in the line i the max velocity is x\n",
        "\n",
        "                # High velocity line case\n",
        "                if (agent.position in av_line):  \n",
        "                    train_velocities[i_agent] = min(1, agents_hints['timetable'][i_agent][2])                \n",
        "                # Regional line case\n",
        "                else:\n",
        "                    train_velocities[i_agent] = min(1/2, agents_hints['timetable'][i_agent][2])\n",
        "\n",
        "            # If agent is not in the environment deafault velocity is 1/2\n",
        "            else:\n",
        "                train_velocities[i_agent] = 1/2\n",
        "\n",
        "        return train_velocities"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_SDC43AZXBw"
      },
      "source": [
        "# Simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HpZdeKva-43"
      },
      "source": [
        "Timer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yjH2BFlbAHQ"
      },
      "source": [
        "from timeit import default_timer\n",
        "\n",
        "\n",
        "class Timer(object):\n",
        "    \"\"\"\n",
        "    Utility to measure times.\n",
        "\n",
        "    TODO:\n",
        "    - add \"lap\" method to make it easier to measure average time (+std) when measuring the same thing multiple times.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.total_time = 0.0\n",
        "        self.start_time = 0.0\n",
        "        self.end_time = 0.0\n",
        "\n",
        "    def start(self):\n",
        "        self.start_time = default_timer()\n",
        "\n",
        "    def end(self):\n",
        "        self.total_time += default_timer() - self.start_time\n",
        "\n",
        "    def get(self):\n",
        "        return self.total_time\n",
        "\n",
        "    def get_current(self):\n",
        "        return default_timer() - self.start_time\n",
        "\n",
        "    def reset(self):\n",
        "        self.__init__()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.get()\n",
        "\n",
        "import numpy as np\n",
        "from flatland.envs.observations import TreeObsForRailEnv\n",
        "\n",
        "def max_lt(seq, val):\n",
        "    \"\"\"\n",
        "    Return greatest item in seq for which item < val applies.\n",
        "    None is returned if seq was empty or all items in seq were >= val.\n",
        "    \"\"\"\n",
        "    max = 0\n",
        "    idx = len(seq) - 1\n",
        "    while idx >= 0:\n",
        "        if seq[idx] < val and seq[idx] >= 0 and seq[idx] > max:\n",
        "            max = seq[idx]\n",
        "        idx -= 1\n",
        "    return max\n",
        "\n",
        "\n",
        "def min_gt(seq, val):\n",
        "    \"\"\"\n",
        "    Return smallest item in seq for which item > val applies.\n",
        "    None is returned if seq was empty or all items in seq were >= val.\n",
        "    \"\"\"\n",
        "    min = np.inf\n",
        "    idx = len(seq) - 1\n",
        "    while idx >= 0:\n",
        "        if seq[idx] >= val and seq[idx] < min:\n",
        "            min = seq[idx]\n",
        "        idx -= 1\n",
        "    return min\n",
        "\n",
        "\n",
        "def norm_obs_clip(obs, clip_min=-1, clip_max=1, fixed_radius=0, normalize_to_range=False):\n",
        "    \"\"\"\n",
        "    This function returns the difference between min and max value of an observation\n",
        "    :param obs: Observation that should be normalized\n",
        "    :param clip_min: min value where observation will be clipped\n",
        "    :param clip_max: max value where observation will be clipped\n",
        "    :return: returnes normalized and clipped observatoin\n",
        "    \"\"\"\n",
        "    if fixed_radius > 0:\n",
        "        max_obs = fixed_radius\n",
        "    else:\n",
        "        max_obs = max(1, max_lt(obs, 1000)) + 1\n",
        "\n",
        "    min_obs = 0  # min(max_obs, min_gt(obs, 0))\n",
        "    if normalize_to_range:\n",
        "        min_obs = min_gt(obs, 0)\n",
        "    if min_obs > max_obs:\n",
        "        min_obs = max_obs\n",
        "    if max_obs == min_obs:\n",
        "        return np.clip(np.array(obs) / max_obs, clip_min, clip_max)\n",
        "    norm = np.abs(max_obs - min_obs)\n",
        "    return np.clip((np.array(obs) - min_obs) / norm, clip_min, clip_max)\n",
        "\n",
        "\n",
        "def _split_node_into_feature_groups(node) -> (np.ndarray, np.ndarray, np.ndarray):\n",
        "    data = np.zeros(6)\n",
        "    distance = np.zeros(1)\n",
        "    agent_data = np.zeros(4)\n",
        "\n",
        "    data[0] = node.dist_own_target_encountered\n",
        "    data[1] = node.dist_other_target_encountered\n",
        "    data[2] = node.dist_other_agent_encountered\n",
        "    data[3] = node.dist_potential_conflict\n",
        "    data[4] = node.dist_unusable_switch\n",
        "    data[5] = node.dist_to_next_branch\n",
        "\n",
        "    distance[0] = node.dist_min_to_target\n",
        "\n",
        "    agent_data[0] = node.num_agents_same_direction\n",
        "    agent_data[1] = node.num_agents_opposite_direction\n",
        "    agent_data[2] = node.num_agents_malfunctioning\n",
        "    agent_data[3] = node.speed_min_fractional\n",
        "\n",
        "    return data, distance, agent_data\n",
        "\n",
        "\n",
        "def _split_subtree_into_feature_groups(node, current_tree_depth: int, max_tree_depth: int) -> (np.ndarray, np.ndarray, np.ndarray):\n",
        "    if node == -np.inf:\n",
        "        remaining_depth = max_tree_depth - current_tree_depth\n",
        "        # reference: https://stackoverflow.com/questions/515214/total-number-of-nodes-in-a-tree-data-structure\n",
        "        num_remaining_nodes = int((4 ** (remaining_depth + 1) - 1) / (4 - 1))\n",
        "        return [-np.inf] * num_remaining_nodes * 6, [-np.inf] * num_remaining_nodes, [-np.inf] * num_remaining_nodes * 4\n",
        "\n",
        "    data, distance, agent_data = _split_node_into_feature_groups(node)\n",
        "\n",
        "    if not node.childs:\n",
        "        return data, distance, agent_data\n",
        "\n",
        "    for direction in TreeObsForRailEnv.tree_explored_actions_char:\n",
        "        sub_data, sub_distance, sub_agent_data = _split_subtree_into_feature_groups(node.childs[direction], current_tree_depth + 1, max_tree_depth)\n",
        "        data = np.concatenate((data, sub_data))\n",
        "        distance = np.concatenate((distance, sub_distance))\n",
        "        agent_data = np.concatenate((agent_data, sub_agent_data))\n",
        "\n",
        "    return data, distance, agent_data\n",
        "\n",
        "\n",
        "def split_tree_into_feature_groups(tree, max_tree_depth: int) -> (np.ndarray, np.ndarray, np.ndarray):\n",
        "    \"\"\"\n",
        "    This function splits the tree into three difference arrays of values\n",
        "    \"\"\"\n",
        "    data, distance, agent_data = _split_node_into_feature_groups(tree)\n",
        "\n",
        "    for direction in TreeObsForRailEnv.tree_explored_actions_char:\n",
        "        sub_data, sub_distance, sub_agent_data = _split_subtree_into_feature_groups(tree.childs[direction], 1, max_tree_depth)\n",
        "        data = np.concatenate((data, sub_data))\n",
        "        distance = np.concatenate((distance, sub_distance))\n",
        "        agent_data = np.concatenate((agent_data, sub_agent_data))\n",
        "\n",
        "    return data, distance, agent_data\n",
        "\n",
        "\n",
        "def normalize_observation(observation, tree_depth: int, observation_radius=0):\n",
        "    \"\"\"\n",
        "    This function normalizes the observation used by the RL algorithm\n",
        "    \"\"\"\n",
        "    data, distance, agent_data = split_tree_into_feature_groups(observation, tree_depth)\n",
        "\n",
        "    data = norm_obs_clip(data, fixed_radius=observation_radius)\n",
        "    distance = norm_obs_clip(distance, normalize_to_range=True)\n",
        "    agent_data = np.clip(agent_data, -1, 1)\n",
        "    normalized_obs = np.concatenate((np.concatenate((data, distance)), agent_data))\n",
        "    return normalized_obs\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuASmxBLbk1K"
      },
      "source": [
        "## RL Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZVhjovKbnwa"
      },
      "source": [
        "import copy\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "from collections import namedtuple, deque, Iterable\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DuelingQNetwork(nn.Module):\n",
        "    \"\"\"Dueling Q-network (https://arxiv.org/abs/1511.06581)\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, hidsize1=128, hidsize2=128):\n",
        "        super(DuelingQNetwork, self).__init__()\n",
        "\n",
        "        # value network\n",
        "        self.fc1_val = nn.Linear(state_size, hidsize1)\n",
        "        self.fc2_val = nn.Linear(hidsize1, hidsize2)\n",
        "        self.fc4_val = nn.Linear(hidsize2, 1)\n",
        "\n",
        "        # advantage network\n",
        "        self.fc1_adv = nn.Linear(state_size, hidsize1)\n",
        "        self.fc2_adv = nn.Linear(hidsize1, hidsize2)\n",
        "        self.fc4_adv = nn.Linear(hidsize2, action_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        val = F.relu(self.fc1_val(x))\n",
        "        val = F.relu(self.fc2_val(val))\n",
        "        val = self.fc4_val(val)\n",
        "\n",
        "        # advantage calculation\n",
        "        adv = F.relu(self.fc1_adv(x))\n",
        "        adv = F.relu(self.fc2_adv(adv))\n",
        "        adv = self.fc4_adv(adv)\n",
        "\n",
        "        return val + adv - adv.mean()\n",
        "\n",
        "class Policy:\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def save(self, filename):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def load(self, filename):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class DDDQNPolicy(Policy):\n",
        "    \"\"\"Dueling Double DQN policy\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, parameters, evaluation_mode=False):\n",
        "        self.evaluation_mode = evaluation_mode\n",
        "\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.double_dqn = True\n",
        "        self.hidsize = 1\n",
        "\n",
        "        if not evaluation_mode:\n",
        "            self.hidsize = parameters.hidden_size\n",
        "            self.buffer_size = parameters.buffer_size\n",
        "            self.batch_size = parameters.batch_size\n",
        "            self.update_every = parameters.update_every\n",
        "            self.learning_rate = parameters.learning_rate\n",
        "            self.tau = parameters.tau\n",
        "            self.gamma = parameters.gamma\n",
        "            self.buffer_min_size = parameters.buffer_min_size\n",
        "\n",
        "        # Device\n",
        "        if parameters.use_gpu and torch.cuda.is_available():\n",
        "            self.device = torch.device(\"cuda:0\")\n",
        "            # print(\"🐇 Using GPU\")\n",
        "        else:\n",
        "            self.device = torch.device(\"cpu\")\n",
        "            # print(\"🐢 Using CPU\")\n",
        "\n",
        "        # Q-Network\n",
        "        self.qnetwork_local = DuelingQNetwork(state_size, action_size, hidsize1=self.hidsize, hidsize2=self.hidsize).to(self.device)\n",
        "\n",
        "        if not evaluation_mode:\n",
        "            self.qnetwork_target = copy.deepcopy(self.qnetwork_local)\n",
        "            self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=self.learning_rate)\n",
        "            self.memory = ReplayBuffer(action_size, self.buffer_size, self.batch_size, self.device)\n",
        "\n",
        "            self.t_step = 0\n",
        "            self.loss = 0.0\n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
        "        self.qnetwork_local.eval()\n",
        "        with torch.no_grad():\n",
        "            action_values = self.qnetwork_local(state)\n",
        "        self.qnetwork_local.train()\n",
        "\n",
        "        # Epsilon-greedy action selection\n",
        "        if random.random() > eps:\n",
        "            return np.argmax(action_values.cpu().data.numpy())\n",
        "        else:\n",
        "            return random.choice(np.arange(self.action_size))\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        assert not self.evaluation_mode, \"Policy has been initialized for evaluation only.\"\n",
        "\n",
        "        # Save experience in replay memory\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "\n",
        "        # Learn every UPDATE_EVERY time steps.\n",
        "        self.t_step = (self.t_step + 1) % self.update_every\n",
        "        if self.t_step == 0:\n",
        "            # If enough samples are available in memory, get random subset and learn\n",
        "            if len(self.memory) > self.buffer_min_size and len(self.memory) > self.batch_size:\n",
        "                self._learn()\n",
        "\n",
        "    def _learn(self):\n",
        "        experiences = self.memory.sample()\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        # Get expected Q values from local model\n",
        "        q_expected = self.qnetwork_local(states).gather(1, actions)\n",
        "\n",
        "        if self.double_dqn:\n",
        "            # Double DQN\n",
        "            q_best_action = self.qnetwork_local(next_states).max(1)[1]\n",
        "            q_targets_next = self.qnetwork_target(next_states).gather(1, q_best_action.unsqueeze(-1))\n",
        "        else:\n",
        "            # DQN\n",
        "            q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(-1)\n",
        "\n",
        "        # Compute Q targets for current states\n",
        "        q_targets = rewards + (self.gamma * q_targets_next * (1 - dones))\n",
        "\n",
        "        # Compute loss\n",
        "        self.loss = F.mse_loss(q_expected, q_targets)\n",
        "\n",
        "        # Minimize the loss\n",
        "        self.optimizer.zero_grad()\n",
        "        self.loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Update target network\n",
        "        self._soft_update(self.qnetwork_local, self.qnetwork_target, self.tau)\n",
        "\n",
        "    def _soft_update(self, local_model, target_model, tau):\n",
        "        # Soft update model parameters.\n",
        "        # θ_target = τ*θ_local + (1 - τ)*θ_target\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)\n",
        "\n",
        "    def save(self, filename):\n",
        "        torch.save(self.qnetwork_local.state_dict(), filename + \".local\")\n",
        "        torch.save(self.qnetwork_target.state_dict(), filename + \".target\")\n",
        "\n",
        "    def load(self, filename):\n",
        "        if os.path.exists(filename + \".local\"):\n",
        "            self.qnetwork_local.load_state_dict(torch.load(filename + \".local\"))\n",
        "        if os.path.exists(filename + \".target\"):\n",
        "            self.qnetwork_target.load_state_dict(torch.load(filename + \".target\"))\n",
        "\n",
        "    def save_replay_buffer(self, filename):\n",
        "        memory = self.memory.memory\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(list(memory)[-500000:], f)\n",
        "\n",
        "    def load_replay_buffer(self, filename):\n",
        "        with open(filename, 'rb') as f:\n",
        "            self.memory.memory = pickle.load(f)\n",
        "\n",
        "    def test(self):\n",
        "        self.act(np.array([[0] * self.state_size]))\n",
        "        self._learn()\n",
        "\n",
        "\n",
        "Experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
        "\n",
        "    def __init__(self, action_size, buffer_size, batch_size, device):\n",
        "        \"\"\"Initialize a ReplayBuffer object.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            action_size (int): dimension of each action\n",
        "            buffer_size (int): maximum size of buffer\n",
        "            batch_size (int): size of each training batch\n",
        "        \"\"\"\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=buffer_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Add a new experience to memory.\"\"\"\n",
        "        e = Experience(np.expand_dims(state, 0), action, reward, np.expand_dims(next_state, 0), done)\n",
        "        self.memory.append(e)\n",
        "\n",
        "    def sample(self):\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "\n",
        "        states = torch.from_numpy(self.__v_stack_impr([e.state for e in experiences if e is not None])) \\\n",
        "            .float().to(self.device)\n",
        "        actions = torch.from_numpy(self.__v_stack_impr([e.action for e in experiences if e is not None])) \\\n",
        "            .long().to(self.device)\n",
        "        rewards = torch.from_numpy(self.__v_stack_impr([e.reward for e in experiences if e is not None])) \\\n",
        "            .float().to(self.device)\n",
        "        next_states = torch.from_numpy(self.__v_stack_impr([e.next_state for e in experiences if e is not None])) \\\n",
        "            .float().to(self.device)\n",
        "        dones = torch.from_numpy(self.__v_stack_impr([e.done for e in experiences if e is not None]).astype(np.uint8)) \\\n",
        "            .float().to(self.device)\n",
        "\n",
        "        return states, actions, rewards, next_states, dones\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)\n",
        "\n",
        "    def __v_stack_impr(self, states):\n",
        "        sub_dim = len(states[0][0]) if isinstance(states[0], Iterable) else 1\n",
        "        np_states = np.reshape(np.array(states), (len(states), sub_dim))\n",
        "        return np_states\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMZuh-ENcPpx"
      },
      "source": [
        "## Network Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "8JIixnrEcK7i",
        "outputId": "84e5c84d-c831-461e-e5bd-b42fe3e74898"
      },
      "source": [
        "!pip install argparse\n",
        "from argparse import ArgumentParser, Namespace\n",
        "\n",
        "\n",
        "parser = ArgumentParser()\n",
        "parser.add_argument(\"-n\", \"--n_episodes\", help=\"number of episodes to run\", default=2500, type=int)\n",
        "parser.add_argument(\"-t\", \"--training_env_config\", help=\"training config id (eg 0 for Test_0)\", default=0, type=int)\n",
        "parser.add_argument(\"-e\", \"--evaluation_env_config\", help=\"evaluation config id (eg 0 for Test_0)\", default=0, type=int)\n",
        "parser.add_argument(\"--n_evaluation_episodes\", help=\"number of evaluation episodes\", default=25, type=int)\n",
        "parser.add_argument(\"--checkpoint_interval\", help=\"checkpoint interval\", default=100, type=int)\n",
        "parser.add_argument(\"--eps_start\", help=\"max exploration\", default=1.0, type=float)\n",
        "parser.add_argument(\"--eps_end\", help=\"min exploration\", default=0.01, type=float)\n",
        "parser.add_argument(\"--eps_decay\", help=\"exploration decay\", default=0.99, type=float)\n",
        "parser.add_argument(\"--buffer_size\", help=\"replay buffer size\", default=int(1e5), type=int)\n",
        "parser.add_argument(\"--buffer_min_size\", help=\"min buffer size to start training\", default=0, type=int)\n",
        "parser.add_argument(\"--restore_replay_buffer\", help=\"replay buffer to restore\", default=\"\", type=str)\n",
        "parser.add_argument(\"--save_replay_buffer\", help=\"save replay buffer at each evaluation interval\", default=False, type=bool)\n",
        "parser.add_argument(\"--batch_size\", help=\"minibatch size\", default=128, type=int)\n",
        "parser.add_argument(\"--gamma\", help=\"discount factor\", default=0.99, type=float)\n",
        "parser.add_argument(\"--tau\", help=\"soft update of target parameters\", default=1e-3, type=float)\n",
        "parser.add_argument(\"--learning_rate\", help=\"learning rate\", default=0.5e-4, type=float)\n",
        "parser.add_argument(\"--hidden_size\", help=\"hidden size (2 fc layers)\", default=128, type=int)\n",
        "parser.add_argument(\"--update_every\", help=\"how often to update the network\", default=8, type=int)\n",
        "parser.add_argument(\"--use_gpu\", help=\"use GPU if available\", default=True, type=bool)\n",
        "parser.add_argument(\"--num_threads\", help=\"number of threads PyTorch can use\", default=1, type=int)\n",
        "parser.add_argument(\"--render\", help=\"render 1 episode in 100\", default=False, type=bool)\n",
        "parser.add_argument(\"--track\", help=\"whether to track using wandb\", default=False, type=bool)\n",
        "training_params = parser.parse_args()\n",
        "\n",
        "\n",
        "obs_params = {\n",
        "    \"observation_tree_depth\": 2,\n",
        "    \"observation_radius\": 10,\n",
        "    \"observation_max_path_depth\": 30\n",
        "}"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] [-n N_EPISODES] [-t TRAINING_ENV_CONFIG]\n",
            "                             [-e EVALUATION_ENV_CONFIG]\n",
            "                             [--n_evaluation_episodes N_EVALUATION_EPISODES]\n",
            "                             [--checkpoint_interval CHECKPOINT_INTERVAL]\n",
            "                             [--eps_start EPS_START] [--eps_end EPS_END]\n",
            "                             [--eps_decay EPS_DECAY]\n",
            "                             [--buffer_size BUFFER_SIZE]\n",
            "                             [--buffer_min_size BUFFER_MIN_SIZE]\n",
            "                             [--restore_replay_buffer RESTORE_REPLAY_BUFFER]\n",
            "                             [--save_replay_buffer SAVE_REPLAY_BUFFER]\n",
            "                             [--batch_size BATCH_SIZE] [--gamma GAMMA]\n",
            "                             [--tau TAU] [--learning_rate LEARNING_RATE]\n",
            "                             [--hidden_size HIDDEN_SIZE]\n",
            "                             [--update_every UPDATE_EVERY] [--use_gpu USE_GPU]\n",
            "                             [--num_threads NUM_THREADS] [--render RENDER]\n",
            "                             [--track TRACK]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-fa27cbc8-f74e-496a-822e-0f02a624dc8e.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi0nPdXHZzXU"
      },
      "source": [
        "\n",
        "# In Flatland you can use custom observation builders and predicitors\n",
        "# Observation builders generate the observation needed by the controller\n",
        "# Preditctors can be used to do short time prediction which can help in avoiding conflicts in the network\n",
        "from flatland.envs.malfunction_generators import malfunction_from_params, MalfunctionParameters, ParamMalfunctionGen\n",
        "from flatland.envs.observations import TreeObsForRailEnv, GlobalObsForRailEnv\n",
        "# First of all we import the Flatland rail environment\n",
        "from flatland.envs.rail_env import RailEnv\n",
        "from flatland.envs.rail_env import RailEnvActions\n",
        "# Import the railway generators\n",
        "from flatland.utils.rendertools import RenderTool, AgentRenderVariant\n",
        "# Import the agent class\n",
        "from flatland.envs.step_utils.states import TrainState\n",
        "from flatland.envs.predictions import ShortestPathPredictorForRailEnv\n"
      ],
      "execution_count": 45,
      "outputs": []
    }
  ]
}