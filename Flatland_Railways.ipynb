{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flatlandLucaDando/Flatland/blob/flatland_v_3_deterministic/Flatland_Railways.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C2D4VVH366B"
      },
      "source": [
        "# ISTRUZIONI\n",
        "\n",
        "Bisogna eseguire le caselle in ordine, alcune caselle sono molto importanti per configurare l'esempio da utilizzare.\n",
        "\n",
        "*   Structure rail definisce i binari (destri, sinistri, su e giù)\n",
        "*   Example definisce l'esempio (l'infrastruttura) che si vuole considerare\n",
        "*   Rewards and Penalities definisce i valori delle rewards\n",
        "*   Training flag definisce il training che si vuole considerare\n",
        "*   In Configuration si può variare volendo la configurazione\n",
        "*   Simulation Values sono i valori della simulazione, come la lunghezza degli episodi, il numero di episodi etc etc\n",
        "\n",
        "Tutte queste celle di codice possono essere modificate per variare i test e training che si vogliono eseguire\n",
        "\n",
        "---\n",
        "\n",
        "P.s. La prima cella restituisce un errore ma non ci sono problemi, il tutto funge lo stesso\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5ClfqgfTCe9"
      },
      "source": [
        "# Introduction \n",
        "\n",
        "---\n",
        "\n",
        "This is a Workbook to execute the Flatland-RealWorld 3.06 code on colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CucPq4ISq0N"
      },
      "source": [
        "First thing is important to import some libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5WlT8daadWG",
        "outputId": "5bdd498f-c264-4de3-911d-13ee59c05002"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Flatland'...\n",
            "remote: Enumerating objects: 3464, done.\u001b[K\n",
            "remote: Total 3464 (delta 0), reused 0 (delta 0), pack-reused 3464\u001b[K\n",
            "Receiving objects: 100% (3464/3464), 19.28 MiB | 22.36 MiB/s, done.\n",
            "Resolving deltas: 100% (1798/1798), done.\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Collecting flatland-rl\n",
            "  Downloading flatland_rl-3.0.8-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting crowdai-api>=0.1.21\n",
            "  Downloading crowdai_api-0.1.22.tar.gz (9.2 kB)\n",
            "Collecting msgpack-numpy>=0.4.4.0\n",
            "  Downloading msgpack_numpy-0.4.7.1-py2.py3-none-any.whl (6.7 kB)\n",
            "Requirement already satisfied: Pillow>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (7.1.2)\n",
            "Collecting tox>=3.5.2\n",
            "  Downloading tox-3.24.4-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting pytest-runner>=4.2\n",
            "  Using cached pytest_runner-5.3.1-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (3.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.17 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (4.8.2)\n",
            "Collecting ipycanvas\n",
            "  Downloading ipycanvas-0.10.2-py2.py3-none-any.whl (253 kB)\n",
            "\u001b[K     |████████████████████████████████| 253 kB 45.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (1.1.5)\n",
            "Collecting svgutils>=0.3.1\n",
            "  Downloading svgutils-0.3.4-py3-none-any.whl (10 kB)\n",
            "Collecting timeout-decorator>=0.4.1\n",
            "  Downloading timeout-decorator-0.5.0.tar.gz (4.8 kB)\n",
            "Collecting pytest<5,>=3.8.2\n",
            "  Downloading pytest-4.6.11-py2.py3-none-any.whl (231 kB)\n",
            "\u001b[K     |████████████████████████████████| 231 kB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (21.2.0)\n",
            "Collecting importlib-resources<2,>=1.0.1\n",
            "  Downloading importlib_resources-1.5.0-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (1.19.5)\n",
            "Collecting msgpack==0.6.1\n",
            "  Downloading msgpack-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (245 kB)\n",
            "\u001b[K     |████████████████████████████████| 245 kB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (3.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (2.6.3)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (7.1.2)\n",
            "Collecting gym==0.14.0\n",
            "  Downloading gym-0.14.0.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 35.1 MB/s \n",
            "\u001b[?25hCollecting recordtype>=1.3\n",
            "  Downloading recordtype-1.3-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (2.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from flatland-rl) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym==0.14.0->flatland-rl) (1.4.1)\n",
            "Collecting pyglet<=1.3.2,>=1.2.0\n",
            "  Downloading pyglet-1.3.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 40.3 MB/s \n",
            "\u001b[?25hCollecting cloudpickle~=1.2.0\n",
            "  Downloading cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from crowdai-api>=0.1.21->flatland-rl) (2.23.0)\n",
            "Collecting python-gitlab>=1.3.0\n",
            "  Downloading python_gitlab-2.10.1-py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 33.7 MB/s \n",
            "\u001b[?25hCollecting redis\n",
            "  Downloading redis-4.0.2-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 43.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.17->flatland-rl) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.17->flatland-rl) (3.10.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->flatland-rl) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->flatland-rl) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->flatland-rl) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->flatland-rl) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.1->flatland-rl) (2018.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym==0.14.0->flatland-rl) (0.16.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest<5,>=3.8.2->flatland-rl) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest<5,>=3.8.2->flatland-rl) (8.12.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest<5,>=3.8.2->flatland-rl) (0.2.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytest<5,>=3.8.2->flatland-rl) (21.3)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest<5,>=3.8.2->flatland-rl) (1.11.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting requests>=2.18.4\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 791 kB/s \n",
            "\u001b[?25hCollecting requests-toolbelt>=0.9.1\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->crowdai-api>=0.1.21->flatland-rl) (2.0.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->crowdai-api>=0.1.21->flatland-rl) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->crowdai-api>=0.1.21->flatland-rl) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->crowdai-api>=0.1.21->flatland-rl) (2.10)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from svgutils>=0.3.1->flatland-rl) (4.2.6)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from tox>=3.5.2->flatland-rl) (3.4.0)\n",
            "Collecting virtualenv!=20.0.0,!=20.0.1,!=20.0.2,!=20.0.3,!=20.0.4,!=20.0.5,!=20.0.6,!=20.0.7,>=16.0.0\n",
            "  Downloading virtualenv-20.10.0-py2.py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 21.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from tox>=3.5.2->flatland-rl) (0.10.2)\n",
            "Collecting backports.entry-points-selectable>=1.0.4\n",
            "  Downloading backports.entry_points_selectable-1.1.1-py2.py3-none-any.whl (6.2 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 46.4 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.4.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: ipywidgets>=7.6.0 in /usr/local/lib/python3.7/dist-packages (from ipycanvas->flatland-rl) (7.6.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (3.5.2)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (4.10.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.2.0)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (1.0.2)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.1.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.3.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.7.5)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (4.9.1)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (2.11.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.12.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (2.0.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.8.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.6.0->ipycanvas->flatland-rl) (0.5.1)\n",
            "Collecting deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->redis->crowdai-api>=0.1.21->flatland-rl) (1.13.3)\n",
            "Building wheels for collected packages: gym, crowdai-api, timeout-decorator\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.14.0-py3-none-any.whl size=1637522 sha256=ca459f06c73476c5aaa5cc09b8c81e222b859e9d16b87e19e37e4db62ed9dbfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/34/78/36550f249167fda9e42e1dd9af84b400abf6c162d1c07ab4e1\n",
            "  Building wheel for crowdai-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crowdai-api: filename=crowdai_api-0.1.22-py2.py3-none-any.whl size=10001 sha256=90bee2ff25c3ea9d3414e5d37b32d9d6429a3a25626ada182d6421423b2c9156\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/f9/9b/8d1b851e4636aee2ba22b033bdb893e75b4342fa9865c39e23\n",
            "  Building wheel for timeout-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for timeout-decorator: filename=timeout_decorator-0.5.0-py3-none-any.whl size=5028 sha256=5afd72884ef732f573bb39a9c9dfd0f4db7cadafbd21717cd090f29dba29cd63\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/64/ac/de1dd54f9a6e48b846e9cb5e4176d6f063380e7f83d69807ad\n",
            "Successfully built gym crowdai-api timeout-decorator\n",
            "Installing collected packages: requests, requests-toolbelt, platformdirs, distlib, deprecated, backports.entry-points-selectable, virtualenv, redis, python-gitlab, pyglet, pluggy, msgpack, cloudpickle, tox, timeout-decorator, svgutils, recordtype, pytest-runner, pytest, msgpack-numpy, ipycanvas, importlib-resources, gym, dataclasses, crowdai-api, flatland-rl\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyglet\n",
            "    Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.3\n",
            "    Uninstalling msgpack-1.0.3:\n",
            "      Successfully uninstalled msgpack-1.0.3\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: importlib-resources\n",
            "    Found existing installation: importlib-resources 5.4.0\n",
            "    Uninstalling importlib-resources-5.4.0:\n",
            "      Successfully uninstalled importlib-resources-5.4.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires cloudpickle>=1.3, but you have cloudpickle 1.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed backports.entry-points-selectable-1.1.1 cloudpickle-1.2.2 crowdai-api-0.1.22 dataclasses-0.6 deprecated-1.2.13 distlib-0.3.4 flatland-rl-3.0.8 gym-0.14.0 importlib-resources-1.5.0 ipycanvas-0.10.2 msgpack-0.6.1 msgpack-numpy-0.4.7.1 platformdirs-2.4.0 pluggy-0.13.1 pyglet-1.3.2 pytest-4.6.11 pytest-runner-5.3.1 python-gitlab-2.10.1 recordtype-1.3 redis-4.0.2 requests-2.26.0 requests-toolbelt-0.9.1 svgutils-0.3.4 timeout-decorator-0.5.0 tox-3.24.4 virtualenv-20.10.0\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    # Clone GitHub repository\n",
        "    !git clone --single-branch --branch flatland_v_3_deterministic https://github.com/flatlandLucaDando/Flatland.git\n",
        "    # Copy files required to run the code\n",
        "    !pip install cloudpickle\n",
        "    !pip install flatland-rl\n",
        "\n",
        "    # Restart Runtime\n",
        "    import os\n",
        "    os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0SHU5OFSwlp"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "import random\n",
        "import sys\n",
        "from argparse import ArgumentParser, Namespace\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "import psutil\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch\n",
        "from typing import Callable, Tuple, Optional, Dict, List\n",
        "from numpy.random.mtrand import RandomState"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e5ILy1PYV9o"
      },
      "source": [
        "# Structure Rail\n",
        "Contein the basilar structure of the rail, with the high velocity rails and the right, left, nord or sud rails\n",
        "\n",
        "With i_flag you can select the different rails configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8M6jhCIYvPL"
      },
      "outputs": [],
      "source": [
        "i = 3\n",
        "\n",
        "if i == 1:\n",
        "\t# One rail, so no right or left rails  \n",
        "\tright_rails = [(0,0)]\n",
        "\tleft_rails = [(0,0)]\n",
        "\tdown_rails = [(0,0)]\n",
        "\tup_rails = [(0,0)]\n",
        "\n",
        "\tav_line = [(0,0)]\n",
        "\n",
        "if i ==2:\n",
        "\t# Rails where the direction is right\n",
        "\tright_rails = []\n",
        "\tfor i in range(8):\n",
        "\t\tright_rails.append((5,i+6))\n",
        "\t# Rails where the direction is left\n",
        "\tleft_rails = []\n",
        "\tfor i in range(8):\n",
        "\t\tleft_rails.append((6,i+6))\n",
        "\n",
        "\tdown_rails = [(0,0)]\n",
        "\tup_rails = [(0,0)]\n",
        "\n",
        "\tav_line = [(0,0)]\n",
        "\n",
        "if i == 3:\n",
        "\t# One rail, so no right or left rails  \n",
        "\tright_rails = [(0,0)]\n",
        "\tleft_rails = [(0,0)]\n",
        "\tdown_rails = [(0,0)]\n",
        "\tup_rails = [(0,0)]\n",
        "\n",
        "\tav_line = [(0,0)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25VWq_QpYWH0"
      },
      "source": [
        "# Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZmMdgAZO5Nc"
      },
      "outputs": [],
      "source": [
        "from flatland.core.grid.rail_env_grid import RailEnvTransitions\n",
        "from flatland.core.transition_map import GridTransitionMap\n",
        "\n",
        "'''\n",
        "###############################################################\n",
        "######################   EXAMPLE LUCA  #########################\n",
        "###############################################################\n",
        "'''\n",
        "\n",
        "# Example generate a rail given a manual specification,\n",
        "# a map of tuples (cell_type, rotation)\n",
        "\n",
        "# Example 2 simple railway with 2 stations and two rails and multiple rails in the stations\n",
        "railway_example = [[(0,0)] * 25,\n",
        "\t\t\t\t   [(0,0)] * 6 + [(9,270)] +[(1,90)]*13 + [(8,90)]  +[(0,0)] *4,\n",
        "\t\t\t\t   [(0,0)] * 6 +[(1,0)]+ [(9,270)] + [(1,90)]*10 + [(8,90)]  + [(0,0)]+ [(1,0)] +[(0,0)] *4,\n",
        "\t\t\t\t   [(0,0)] * 6 +[(1,0)]*2 +  [(0,0)] * 10+ [(1,0)] + [(0,0)]+ [(1,0)]  + [(0,0)] *4,\n",
        "\t\t\t\t   [(7, 270)] + [(1,90)] * 3 + [(8,90)] + [(0,0)] + [(1,0)]*2 +[(0,0)] *2 + [(8,0)] +  [(1,90)] * 3+ [(8,90)]+ [(0,0)] *3 + [(1,0)] +[(0,0)]+  [(1,0)] +[(0,0)]+ [(8,0)]+   [(1,90)] + [(7, 90)] ,\n",
        "\t\t\t\t   [(7, 270)] + [(1,90)] * 3 + [(5,270)] + [(2,270)] + [(5,0)] + [(2,90)] + [(10,90)] + [(2,270)]+ [(2,90)]  +[(1,90)] * 3+ [(10,270)] + [(10,90)]  + [(2,270)] + [(1,90)] + [(5,180)] + [(1,90)] + [(5,270)] + [(1,90)]+  [(5,180)] +[(1,90)]  + [(7, 90)] ,\n",
        "\t\t\t\t   [(7, 270)] + [(1,90)] * 3 + [(10,270)] + [(2,90)] +[(2,90)] +[(1,90)] + [(10,270)] + [(2,90)] + [(1,90)] *5+ [(10,270)] + [(2,90)]+ [(1,90)] + [(10,270)]+ [(1,90)] + [(10,270)]  +[(1,90)] + [(10,270)] +[(1,90)] + [(7, 90)],\n",
        "\t\t\t\t   [(0,0)] * 25,\n",
        "\t\t\t\t   [(0,0)] * 25]\n",
        "\n",
        "# wheight and height of the grid\n",
        "height = len(railway_example)\n",
        "width = len(railway_example[0])\n",
        "\n",
        "# creating the transition map\n",
        "rail_env_transitions = RailEnvTransitions()\n",
        "rail = GridTransitionMap(width=width, height=height, transitions=rail_env_transitions)\n",
        "\n",
        "for r in range(height):\n",
        "\tfor c in range(width):\n",
        "\t\trail_spec_of_cell = railway_example[r][c]\n",
        "\t\tindex_basic_type_of_cell_ = rail_spec_of_cell[0]\n",
        "\t\trotation_cell_ = rail_spec_of_cell[1]\n",
        "\t\tif index_basic_type_of_cell_ < 0 or index_basic_type_of_cell_ >= len(rail_env_transitions.transitions):\n",
        "\t\t\tprint(\"ERROR - invalid rail_spec_of_cell type=\", index_basic_type_of_cell_)\n",
        "\t\tbasic_type_of_cell_ = rail_env_transitions.transitions[index_basic_type_of_cell_]\n",
        "\t\teffective_transition_cell = rail_env_transitions.rotate_transition(basic_type_of_cell_, rotation_cell_)\n",
        "\t\trail.set_transitions((r, c), effective_transition_cell)\n",
        "\n",
        "# No high velocity lines, so make a (0,0) position\n",
        "\tav_line = (0,0)\n",
        "\t\n",
        "\t# TODO sistema i binari destra e sinistra e su e giù\n",
        "\t# Rails where the direction is right\n",
        "\tright_rails = [(0,0)]\n",
        "\t# Rails where the direction is left\n",
        "\tleft_rails = [(0,0)]\n",
        "\tdown_rails = [(0,0)]\n",
        "\tup_rails = [(0,0)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEEkAbhEXvTb"
      },
      "source": [
        "# Data Structures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tCkoOAPX3WZ"
      },
      "source": [
        "## Convoy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH2WxoxeXyDg"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "import itertools\n",
        "\n",
        "# Type of a convoy, can be high velocity or regional\n",
        "# The velocity are given by default depending on the type of convoy, 360 for HV, 180 for IC, 120 for Regional\n",
        "class Type_of_convoy(Enum):\n",
        "\tHIGH_VELOCITY = 1\n",
        "\tINTERCITY = 2\n",
        "\tREGIONAL = 3\n",
        "\n",
        "# A convoy is a locomotive + wagons.\n",
        "class Convoy:\n",
        "\n",
        "\t# For the id\n",
        "\tid_iter = itertools.count()\n",
        "\n",
        "\tdef __init__(self, train_type, schedule = []):\n",
        "\n",
        "\t\t# identifier of the train\n",
        "\t\tself.id = next(Convoy.id_iter)\n",
        "\t\t# type of train (High velocity, Intercity, regional)\n",
        "\t\tself.train_type = train_type\n",
        "\t\t# schedule of the train\n",
        "\t\tself.schedule = []\n",
        "\n",
        "\t\tif train_type == Type_of_convoy.HIGH_VELOCITY:\n",
        "\t\t\tself.maximum_velocity = 1\n",
        "\t\tif train_type == Type_of_convoy.INTERCITY:\n",
        "\t\t\tself.maximum_velocity = 1/2\n",
        "\t\tif train_type == Type_of_convoy.REGIONAL:\n",
        "\t\t\tself.maximum_velocity = 1/3\n",
        "\n",
        "\tdef add_train_run(self, train_run):\n",
        "\t\tself.schedule.append(train_run)\n",
        "\n",
        "\t# Discover the starting time of a certain run\n",
        "\tdef starting_time(self, run_number):\n",
        "\t\treturn self.schedule[run_number][0]\n",
        "\n",
        "\t# Convert velocity (maximum possible velocity is 360)\n",
        "\tdef velocity_conversion(self):\n",
        "\t\tprint(self.maximum_velocity * 360)\n",
        "\n",
        "\t# Verificate that a schedule is possible (if someone want to write manually)\n",
        "\tdef schedule_verification(self, schedule, num_trains_run):\n",
        "\t\tif type(schedule) == list:\n",
        "\t\t\trow_num = len(schedule)\n",
        "\t\t\tcolumn_num = len(schedule[0])\n",
        "\t\t\tif row_num >  1:\n",
        "\t\t\t\tfor num_of_runs in range(num_trains_run - 1):\n",
        "\t\t\t\t\tfor steps in range(len(schedule) - 1):\n",
        "\t\t\t\t\t\tif schedule[num_of_runs][step + 1] <= schedule[num_of_runs][step]:\n",
        "\t\t\t\t\t\t\tprint('==========================================================')\n",
        "\t\t\t\t\t\t\tprint('The time to connect stations',step,'and',step + 1,'have to be > 0')\n",
        "\n",
        "\t\t\telse:\n",
        "\t\t\t\tfor steps in range(len(schedule) - 1):\n",
        "\t\t\t\t\tif schedule[num_of_runs][step + 1] <= schedule[num_of_runs][step]:\n",
        "\t\t\t\t\t\tprint('==========================================================')\n",
        "\t\t\t\t\t\tprint('The time to connect stations',step,'and',step + 1,'have to be > 0')\n",
        "\t\telse:\n",
        "\t\t\tprint('A schedule should comprend different stations')\n",
        "\t\treturn True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q80GIJJEX8Yk"
      },
      "source": [
        "## Line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gG_B-nASX-r1"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "# A line is considered from a city to another, tipically joining several cities\n",
        "class Line:\n",
        "\n",
        "\t# For the id\n",
        "\tid_iter = itertools.count()\n",
        "\n",
        "\tdef __init__(self, type_line, stations, stops):\n",
        "\t\t# ID of the line\n",
        "\t\tself.id = next(Line.id_iter)\n",
        "\t\t# type of line (High velocity or regional)\n",
        "\t\tself.type_line = type_line\n",
        "\t\t# Stations where the line pass from\n",
        "\t\tself.stations = stations\n",
        "\t\t# Stops are stations where the train have to stop\n",
        "\t\t# Is an array with 0 where not stop and 1 where train stops\n",
        "\t\tself.stops = stops\n",
        "\n",
        "\t\tif type(stations) == int or type(stops) == int:\n",
        "\t\t\tprint('The stations of a line should be more than one, and the dimension of the stops should be the same of the stations')\n",
        "\t\telse:\n",
        "\t\t\tif(len(stations)) != (len(stops)):\n",
        "\t\t\t\tprint('Stations and Stops have to be the same lenght')\n",
        "\n",
        "\n",
        "\tdef inversion_of_line(self):\n",
        "\t\tself.direction = self.direction * -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcqtL8kcYBb3"
      },
      "source": [
        "## Rail Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZXAlq4oYFw6"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "import itertools\n",
        "\n",
        "# A connection can be: High velocity or normal\n",
        "# The velocity are given by default depending on the type of connection, 360 for HV and 120 for normal\n",
        "class Connection_type(Enum):\n",
        "\tHIGH_VELOCITY_RAIL = 1\n",
        "\tNORMAL_RAIL = 2\n",
        "\n",
        "\n",
        "# A physical connection between two stations\n",
        "class Rail_connection:\n",
        "\n",
        "\t# For the id\n",
        "\tid_iter = itertools.count()\n",
        "\n",
        "\tdef __init__(self, station_a, station_b, rail_connection_type, additional_runtime_percent, max_speed_usable: int = 1/2):\n",
        "\t\t# each railway section has an id\n",
        "\t\tself.id = next(Rail_connection.id_iter)\n",
        "\t\t# Station A and B are the two connected stations\n",
        "\t\tself.station_a = station_a\n",
        "\t\tself.station_b = station_b\n",
        "\t\t# A connection can be: High velocity or normal\n",
        "\t\tself.rail_connection_type = rail_connection_type\n",
        "\t\t# Maximum speed usable in the rails\n",
        "\t\tself.max_speed_usable = max_speed_usable\n",
        "\t\t# Additional Runtime Percent is the percent [0-1] of the min run time that is added to the min run time, if the train is on schedule.\n",
        "\t\t# In general, he actual run time is computed as min run time + max(0, (min run time*additionalRuntimePercent)-actual_delay).\n",
        "\t\tself.additional_runtime_percent = additional_runtime_percent\n",
        "\n",
        "\t\tif rail_connection_type == Connection_type.HIGH_VELOCITY_RAIL:\n",
        "\t\t\tself.max_speed_usable = 1\n",
        "\t\tif rail_connection_type == Connection_type.NORMAL_RAIL:\n",
        "\t\t\tself.max_speed_usable = 1 / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDV9yKClYIy_"
      },
      "source": [
        "## Station"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8gBNXfkYMss"
      },
      "outputs": [],
      "source": [
        "from flatland.core.grid.grid_utils import Vec2dOperations as Vec2d\n",
        "\n",
        "# Station\n",
        "class Station:\n",
        "\n",
        "\t# TODO metti valori precisi per min wait time (lis)\n",
        "\tdef __init__(self, name, position, capacity, min_wait_time, additional_wait_percent, importance, railway_topology):\n",
        "\t\t# Name of the station (e.g. Milano, Torino etc etc)\n",
        "\t\tself.name = name\n",
        "\t\t# Position (y,x) of the station in the railway\n",
        "\t\tself.position = position\n",
        "\t\t# Capacity of the station, num of rails in the station\n",
        "\t\tself.capacity = capacity\n",
        "\t\t# Minimum wait time for the trains, a train can't stop less than the min wait time\n",
        "\t\tself.min_wait_time = min_wait_time\n",
        "\t\t# Additional wait percent is the percent [0-1] of the minWaitTime that is added to the minWait at each stop, if the train is on schedule. \n",
        "\t\t# In general, the actual (runtime) stopping time is computed as minWaitTime + max(0, (minWaitTime*additionalWaitTimePercent)-actual_delay).\n",
        "\t\tself.additional_wait_percent = additional_wait_percent\n",
        "\t\t# Stations have different importance depending on how much they are big and how much people they transport depending on the time\n",
        "\t\tself.importance = importance\n",
        "\t\t\t\t# Rails of the station\n",
        "\t\tself.rails = self.calculate_rails(railway_topology)\n",
        "\t\treturn\n",
        "\n",
        "\n",
        "\tdef time_in_station(self, train_velocity):\n",
        "\t\t# The len of the rails is given by the station\n",
        "\t\tlen_rails = len(self.rails_in_station[0])\n",
        "\t\t# The time needed is given by the formula (len * 1/velocity + waiting time + 10% of time)\n",
        "\t\ttime_needed =  len_rails * int(pow(train_velocity, -1)) + self.min_wait_time[0]\n",
        "\t\ttime_needed += int(time_needed/10)\n",
        "\t\treturn time_needed\n",
        "\n",
        "\tdef calculate_rails(self, railway_topology):\n",
        "\t\t# Number of rails of the station\n",
        "\t\tnum_of_rails = self.capacity\n",
        "\t\tcenter_of_station = self.position \n",
        "\t\trail_shape = railway_topology.grid.shape\n",
        "\n",
        "\t\t#Flag\n",
        "\t\tleft = True  # Flag to understand where to go right or left\n",
        "\t\tnorth = True    # Flag to understand where to go right or left\n",
        "\n",
        "\t\t# Indicating the incrementing number north or sud (in case of horizontal station), east ovest (in case of vertical stations)\n",
        "\t\tdifference_from_original = 0 \n",
        "\n",
        "\t\t# Counter\n",
        "\t\tcounter_of_rails = 1\n",
        "\t\t# Rails of the station, has the position of the rails. Each row is a rail\n",
        "\t\tself.rails = []\n",
        "  \n",
        "\t\t# Counter to check the station is well positioned, to avoid the while goes for eternity\n",
        "\t\tcounter = 0\n",
        "\n",
        "\t\t# Starting position the center of station\n",
        "\t\tcurrent_position = (self.position[0], self.position[1])\n",
        "  \n",
        "\t\t# The first rail coincide with the position of the station\n",
        "\t\tself.rails.append(current_position)\n",
        "\n",
        "\t\twhile counter_of_rails < num_of_rails:\n",
        "\n",
        "\t\t\tcounter += 1\n",
        "\n",
        "\t\t\tif counter > 500:\n",
        "\t\t\t\traise ImportError('The position of the station, or the capacity should be different, check for the right position or capacity, cant calculate the rails')\n",
        "\n",
        "\t\t\t# Horizontal rail\n",
        "\t\t\t# is position inside the grid?\n",
        "\t\t\telif current_position[0] >= rail_shape[0] or current_position[0] < 0 or current_position[1] >= rail_shape[1] or current_position[1] < 0:\n",
        "\t\t\t\tcontinue \n",
        "\t\t\t\n",
        "\t\t\t# Starting going up to check the rails\n",
        "\t\t\telif railway_topology.grid[current_position] == 1025 and north:\n",
        "\t\t\t\t# Going to up\n",
        "\t\t\t\tnew_pos = (-1, 0)\n",
        "\t\t\t\t# Update the position to left or right\n",
        "\t\t\t\tcurrent_position = Vec2d.add(current_position, new_pos)\n",
        "\t\t\t\t# If not 0 the rail is in the station\n",
        "\t\t\t\tif railway_topology.grid[current_position] != 0:\n",
        "\t\t\t\t\tself.rails.append(current_position)\n",
        "\t\t\t\t\tcounter_of_rails += 1\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tcurrent_position = (self.position[0], self.position[1])\n",
        "\t\t\t\t\tnorth = False\n",
        "\t\t\t\t\tcontinue\t\t\t\n",
        "\n",
        "\t\t\telif railway_topology.grid[current_position] == 1025 and not north:\n",
        "\t\t\t\t# Going to up\n",
        "\t\t\t\tnew_pos = (1, 0)\n",
        "\t\t\t\t# Update the position to left or right\n",
        "\t\t\t\tcurrent_position = Vec2d.add(current_position, new_pos)\n",
        "\t\t\t\t# If not 0 the rail is in the station\n",
        "\t\t\t\tif railway_topology.grid[current_position] != 0:\n",
        "\t\t\t\t\tself.rails.append(current_position)\n",
        "\t\t\t\t\tcounter_of_rails += 1\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tcontinue\n",
        " \n",
        "\t\t\t# Vertical rail same as for horizontal, but starting from south and north, and then left and right\n",
        "\t\t\telif railway_topology.grid[current_position] == 32800 and left:\n",
        "\t\t\t\t# Going to up\n",
        "\t\t\t\tnew_pos = (0, -1)\n",
        "\t\t\t\t# Update the position to left or right\n",
        "\t\t\t\tcurrent_position = Vec2d.add(current_position, new_pos)\n",
        "\t\t\t\t# If not 0 the rail is in the station\n",
        "\t\t\t\tif railway_topology.grid[current_position] != 0:\n",
        "\t\t\t\t\tself.rails.append(current_position)\n",
        "\t\t\t\t\tcounter_of_rails += 1\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tcurrent_position = (self.position[0], self.position[1])\n",
        "\t\t\t\t\tleft = False\n",
        "\t\t\t\t\tcontinue\t\t\t\n",
        "\n",
        "\t\t\telif railway_topology.grid[current_position] == 32800 and not left:\n",
        "\t\t\t\t# Going to up\n",
        "\t\t\t\tnew_pos = (0, 1)\n",
        "\t\t\t\t# Update the position to left or right\n",
        "\t\t\t\tcurrent_position = Vec2d.add(current_position, new_pos)\n",
        "\t\t\t\t# If not 0 the rail is in the station\n",
        "\t\t\t\tif railway_topology.grid[current_position] != 0:\n",
        "\t\t\t\t\tself.rails.append(current_position)\n",
        "\t\t\t\t\tcounter_of_rails += 1\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t# Eliminate duplicates\n",
        "\t\trails_position = []\n",
        "\t\trails_position_single = []\n",
        "\t\tfor i in range(len(self.rails)):\n",
        "\t\t\tfor j in range(len(self.rails[i])):\n",
        "\t\t\t\tif self.rails[i][j] not in rails_position_single:\n",
        "\t\t\t\t\trails_position_single.append(self.rails[i][j])\n",
        "\t\t\trails_position.append(rails_position_single)\n",
        "\t\t\trails_position_single = []\n",
        "\t\tself.rails = rails_position"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B01cYfcYNyt"
      },
      "source": [
        "## Train Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdHNpaAeYQjE"
      },
      "outputs": [],
      "source": [
        "# A train run is the run on a line for a train (e.g. Genova-Milano --- Milano-Genova)\n",
        "# The train run consider each intermediate station the train has to pass between the two \"principal\" stations\n",
        "class Train_run:\n",
        "\n",
        "\tdef __init__(self, line_belongin, starting_time, from_depot: bool = False, to_depot: bool = False, inverse_train_direction: bool = False):\n",
        "\t\t# Line in which the train run is, so it contein informations about the stations to stop and etc etc\n",
        "\t\tself.line_belongin = line_belongin\n",
        "\t\t# Starting time of the run\n",
        "\t\tself.starting_time = starting_time\n",
        "\t\t# FromDepot indicates whether this run starts from a depot. Similar for ToDepot.\n",
        "\t\tself.from_depot = from_depot\n",
        "\t\tself.to_depot = to_depot\n",
        "\t\t# If inverse line direction \n",
        "\t\tself.inverse_train_direction = inverse_train_direction\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7kzefAwQidY"
      },
      "source": [
        "# Utils function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSx1S5lWQ2de"
      },
      "outputs": [],
      "source": [
        "from enum import IntEnum\n",
        "from typing import NamedTuple\n",
        "from flatland.core.grid.grid4 import Grid4TransitionsEnum\n",
        "\n",
        "class RailEnvActions(IntEnum):\n",
        "    DO_NOTHING = 0  # implies change of direction in a dead-end!\n",
        "    MOVE_LEFT = 1\n",
        "    MOVE_FORWARD = 2\n",
        "    MOVE_RIGHT = 3\n",
        "    STOP_MOVING = 4\n",
        "    REVERSE = 5\n",
        "\n",
        "    @staticmethod\n",
        "    def to_char(a: int):\n",
        "        return {\n",
        "            0: 'B',\n",
        "            1: 'L',\n",
        "            2: 'F',\n",
        "            3: 'R',\n",
        "            4: 'S',\n",
        "            5: 'I',\n",
        "        }[a]\n",
        "\n",
        "    @classmethod\n",
        "    def is_action_valid(cls, action):\n",
        "        return action in cls._value2member_map_\n",
        "\n",
        "    def is_moving_action(self):\n",
        "        return self.value in [self.MOVE_RIGHT, self.MOVE_LEFT, self.MOVE_FORWARD, self.REVERSE]\n",
        "\n",
        "\n",
        "RailEnvGridPos = NamedTuple('RailEnvGridPos', [('r', int), ('c', int)])\n",
        "RailEnvNextAction = NamedTuple('RailEnvNextAction', [('action', RailEnvActions), ('next_position', RailEnvGridPos),\n",
        "                                                     ('next_direction', Grid4TransitionsEnum)])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from flatland.core.grid.grid_utils import IntVector2D, IntVector2DDistance\n",
        "from flatland.core.grid.grid_utils import IntVector2DArray\n",
        "from flatland.core.grid.grid_utils import Vec2dOperations as Vec2d\n",
        "from flatland.core.transition_map import GridTransitionMap\n",
        "from flatland.utils.ordered_set import OrderedSet\n",
        "\n",
        "\n",
        "class AStarNode:\n",
        "    \"\"\"A node class for A* Pathfinding\"\"\"\n",
        "\n",
        "    def __init__(self, pos: IntVector2D, parent=None):\n",
        "        self.parent = parent\n",
        "        self.pos: IntVector2D = pos\n",
        "        self.g = 0.0\n",
        "        self.h = 0.0\n",
        "        self.f = 0.0\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        other : AStarNode\n",
        "        \"\"\"\n",
        "        return self.pos == other.pos\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.pos)\n",
        "\n",
        "    def update_if_better(self, other):\n",
        "        if other.g < self.g:\n",
        "            self.parent = other.parent\n",
        "            self.g = other.g\n",
        "            self.h = other.h\n",
        "            self.f = other.f\n",
        "\n",
        "\n",
        "def a_star(grid_map: GridTransitionMap, start: IntVector2D, end: IntVector2D,\n",
        "           a_star_distance_function: IntVector2DDistance = Vec2d.get_manhattan_distance, avoid_rails=False,\n",
        "           respect_transition_validity=True, forbidden_cells: IntVector2DArray = None) -> IntVector2DArray:\n",
        "    \"\"\"\n",
        "\n",
        "    :param avoid_rails:\n",
        "    :param grid_map: Grid Map where the path is found in\n",
        "    :param start: Start positions as (row,column)\n",
        "    :param end:  End position as (row,column)\n",
        "    :param a_star_distance_function: Define the distance function to use as heuristc:\n",
        "            -get_euclidean_distance\n",
        "            -get_manhattan_distance\n",
        "            -get_chebyshev_distance\n",
        "    :param respect_transition_validity: Whether or not a-star respect allowed transitions on the grid map.\n",
        "            - True: Respects the validity of transition. This generates valid paths, of no path if it cannot be found\n",
        "            - False: This always finds a path, but the path might be illegal and thus needs to be fixed afterwards\n",
        "    :param forbidden_cells: List of cells where the path cannot pass through. Used to avoid certain areas of Grid map\n",
        "    :return: IF a path is found a ordered list of al cells in path is returned\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    Returns a list of tuples as a path from the given start to end.\n",
        "    If no path is found, returns path to closest point to end.\n",
        "    \"\"\"\n",
        "    rail_shape = grid_map.grid.shape\n",
        "\n",
        "    start_node = AStarNode(start, None)\n",
        "    end_node = AStarNode(end, None)\n",
        "    open_nodes = OrderedSet()\n",
        "    #print('open nodes all inizio',open_nodes)\n",
        "    closed_nodes = OrderedSet()\n",
        "    open_nodes.add(start_node)\n",
        "\n",
        "    while len(open_nodes) > 0:\n",
        "        # get node with current shortest est. path (lowest f)\n",
        "        current_node = None\n",
        "        for item in open_nodes:\n",
        "            if current_node is None:\n",
        "                current_node = item\n",
        "                #print('Current node all inizio',current_node)\n",
        "                continue\n",
        "            if item.f < current_node.f:\n",
        "                current_node = item\n",
        "                #print('Current node in generale',current_node.pos, current_node.parent.pos, current_node.f)\n",
        "\n",
        "            #print('open nodes nel ciclo ', open_nodes.pos)\n",
        "\n",
        "        # pop current off open list, add to closed list\n",
        "        open_nodes.remove(current_node)\n",
        "        closed_nodes.add(current_node)\n",
        "\n",
        "        # found the goal\n",
        "        if current_node == end_node:\n",
        "            path = []\n",
        "            current = current_node\n",
        "            while current is not None:\n",
        "                path.append(current.pos)\n",
        "                current = current.parent\n",
        "\n",
        "                #print(path)\n",
        "\n",
        "            # return reversed path\n",
        "            return path[::-1]\n",
        "\n",
        "        # generate children\n",
        "        children = []\n",
        "        if current_node.parent is not None:\n",
        "            prev_pos = current_node.parent.pos\n",
        "        else:\n",
        "            prev_pos = None\n",
        "\n",
        "        for new_pos in [(0, -1), (0, 1), (-1, 0), (1, 0)]:\n",
        "            # update the \"current\" pos\n",
        "            node_pos: IntVector2D = Vec2d.add(current_node.pos, new_pos)\n",
        "\n",
        "            # is node_pos inside the grid?\n",
        "            if node_pos[0] >= rail_shape[0] or node_pos[0] < 0 or node_pos[1] >= rail_shape[1] or node_pos[1] < 0:\n",
        "                continue\n",
        "\n",
        "            # validate positions\n",
        "            #\n",
        "\n",
        "            if not grid_map.check_transition_is_possible(prev_pos, current_node.pos, node_pos) \\\n",
        "             and respect_transition_validity:\n",
        "                continue\n",
        "\n",
        "            '''\n",
        "            if grid_map.validate_new_transition(prev_pos, current_node.pos, node_pos, end_node.pos) and respect_transition_validity:\n",
        "                   # and grid_map.check_direction_of_railroad(prev_pos, current_node.pos, node_pos):\n",
        "                print('=========================================')\n",
        "                print(prev_pos, current_node.pos, node_pos)\n",
        "                continue\n",
        "            '''\n",
        "\n",
        "\n",
        "            # create new node\n",
        "\n",
        "            new_node = AStarNode(node_pos, current_node)\n",
        "            #print(new_node.pos)\n",
        "\n",
        "            # Skip paths through forbidden regions if they are provided\n",
        "            if forbidden_cells is not None:\n",
        "                if node_pos in forbidden_cells and new_node != start_node and new_node != end_node:\n",
        "                    continue\n",
        "\n",
        "            children.append(new_node)\n",
        "\n",
        "        # loop through children\n",
        "        for child in children:\n",
        "            # already in closed list?\n",
        "            if child in closed_nodes:\n",
        "                continue\n",
        "\n",
        "            # create the f, g, and h values\n",
        "            child.g = current_node.g + 1.0\n",
        "            # this heuristic avoids diagonal paths\n",
        "            if avoid_rails:\n",
        "                child.h = a_star_distance_function(child.pos, end_node.pos) + np.clip(grid_map.grid[child.pos], 0, 1)\n",
        "            else:\n",
        "                child.h = a_star_distance_function(child.pos, end_node.pos)\n",
        "            child.f = child.g + child.h\n",
        "\n",
        "            # already in the open list?\n",
        "            if child in open_nodes:\n",
        "                continue\n",
        "\n",
        "            # add the child to the open list\n",
        "            open_nodes.add(child)\n",
        "\n",
        "        # no full path found\n",
        "        if len(open_nodes) == 0:\n",
        "            return []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKFkmlccTHt9"
      },
      "source": [
        "# Flatland Custom Rail Generator\n",
        "\n",
        "--- \n",
        "A custom rail is a rail defined by a matrix. Each cell of the matrix define the type of cell in the 2-D grid of the flatland environment\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SSP2ltVXxHv"
      },
      "source": [
        "## Different type of cell\n",
        "\n",
        "<img src=\"https://i.imgur.com/ruiRuep.jpg\" width=\"500\"/> <img src=\"https://i.imgur.com/sABiSuc.jpg\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecRto8qiVvXz"
      },
      "source": [
        "* This is the function to create a custom rail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlyvYqEJViux"
      },
      "outputs": [],
      "source": [
        "\"\"\"Rail generators (infrastructure manager, \"Infrastrukturbetreiber\").\"\"\"\n",
        "from typing import Callable, Tuple, Optional, Dict, List\n",
        "\n",
        "from numpy.random.mtrand import RandomState\n",
        "\n",
        "from flatland.core.grid.grid4 import Grid4TransitionsEnum\n",
        "from flatland.core.grid.rail_env_grid import RailEnvTransitions\n",
        "from flatland.core.transition_map import GridTransitionMap\n",
        "\n",
        "\n",
        "RailGeneratorProduct = Tuple[GridTransitionMap, Optional[Dict]]\n",
        "\"\"\" A rail generator returns a RailGenerator Product, which is just\n",
        "    a GridTransitionMap followed by an (optional) dict/\n",
        "\"\"\"\n",
        "\n",
        "RailGenerator = Callable[[int, int, int, int], RailGeneratorProduct]\n",
        "\n",
        "# Number of agents are given by timetables (the num of the rows), target stations are also given by timetable \n",
        "def rail_custom_generator(rail_spec, train_stations_position: list = None, timetable: list = None):\n",
        "\n",
        "    \"\"\"\n",
        "    Utility to convert a rail given by manual specification as a map of tuples\n",
        "    (cell_type, rotation), to a transition map with the correct 16-bit\n",
        "    transitions specifications.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    rail_spec : list of list of tuples\n",
        "        List (rows) of lists (columns) of tuples, each specifying a rail_spec_of_cell for\n",
        "        the RailEnv environment as (cell_type, rotation), with rotation being\n",
        "        clock-wise and in [0, 90, 180, 270].\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    function\n",
        "        Generator function that always returns a GridTransitionMap object with\n",
        "        the matrix of correct 16-bit bitmaps for each rail_spec_of_cell.\n",
        "\n",
        "    New features:\n",
        "    -------------\n",
        "        Train station poition: to define the position of the station\n",
        "        Target station: Define the target of the different agents\n",
        "        Timetable: timetable contein the intermediate station and the time at which pass across them\n",
        "    \"\"\"\n",
        "\n",
        "    def custom_generator(width: int, height: int, num_agents: int, num_resets: int = 0,\n",
        "                  np_random: RandomState = None) -> RailGenerator:\n",
        "\n",
        "        # All the cities are oriented in the same way in my model\n",
        "        city_orientations = 1\n",
        "\n",
        "        # Taking the number of agents from timetable\n",
        "        num_of_agents = len(timetable)\n",
        "\n",
        "        # Taking the target stations from timetable\n",
        "        target_stations = []\n",
        "\n",
        "        for agent in range(num_agents):\n",
        "            target_stations.append(timetable[agent][-1])\n",
        "      \n",
        "        rail_env_transitions = RailEnvTransitions()\n",
        "\n",
        "        height = len(rail_spec)\n",
        "        width = len(rail_spec[0])\n",
        "        rail = GridTransitionMap(width=width, height=height, transitions=rail_env_transitions)\n",
        "\n",
        "        for r in range(height):\n",
        "            for c in range(width):\n",
        "                rail_spec_of_cell = rail_spec[r][c]\n",
        "                index_basic_type_of_cell_ = rail_spec_of_cell[0]\n",
        "                rotation_cell_ = rail_spec_of_cell[1]\n",
        "                if index_basic_type_of_cell_ < 0 or index_basic_type_of_cell_ >= len(rail_env_transitions.transitions):\n",
        "                    print(\"ERROR - invalid rail_spec_of_cell type=\", index_basic_type_of_cell_)\n",
        "                    return []\n",
        "                basic_type_of_cell_ = rail_env_transitions.transitions[index_basic_type_of_cell_]\n",
        "                effective_transition_cell = rail_env_transitions.rotate_transition(basic_type_of_cell_, rotation_cell_)\n",
        "                rail.set_transitions((r, c), effective_transition_cell)\n",
        "\n",
        "        return rail,  {'agents_hints': {\n",
        "            'num_agents': num_of_agents,            \n",
        "            'city_positions': train_stations_position,\n",
        "            'train_stations': train_stations_position,\n",
        "            'city_orientations': city_orientations,\n",
        "            'targets' : target_stations,\n",
        "            'timetable' : timetable \n",
        "        }}\n",
        "\n",
        "    return custom_generator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBH5g0GFWHld"
      },
      "source": [
        "* these are the utilities for the environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-PIRK0HWP_t"
      },
      "outputs": [],
      "source": [
        "from flatland.core.env_observation_builder import ObservationBuilder\n",
        "from flatland.envs.observations import TreeObsForRailEnv\n",
        "from flatland.envs.predictions import ShortestPathPredictorForRailEnv\n",
        "from flatland.envs.rail_env import RailEnv\n",
        "from flatland.envs.rail_generators import rail_from_file\n",
        "from flatland.envs.line_generators import line_from_file\n",
        "from flatland.envs.step_utils.states import TrainState\n",
        "\n",
        "\n",
        "def load_flatland_environment_from_file(file_name: str,\n",
        "                                        load_from_package: str = None,\n",
        "                                        obs_builder_object: ObservationBuilder = None,\n",
        "                                        record_steps = False,\n",
        "                                        ) -> RailEnv:\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    file_name : str\n",
        "        The pickle file.\n",
        "    load_from_package : str\n",
        "        The python module to import from. Example: 'env_data.tests'\n",
        "        This requires that there are `__init__.py` files in the folder structure we load the file from.\n",
        "    obs_builder_object: ObservationBuilder\n",
        "        The obs builder for the `RailEnv` that is created.\n",
        "\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    RailEnv\n",
        "        The environment loaded from the pickle file.\n",
        "    \"\"\"\n",
        "    if obs_builder_object is None:\n",
        "        obs_builder_object = TreeObsForRailEnv(\n",
        "            max_depth=2,\n",
        "            predictor=ShortestPathPredictorForRailEnv(max_depth=10))\n",
        "    environment = RailEnv(width=1, height=1, rail_generator=rail_from_file(file_name, load_from_package),\n",
        "                          line_generator=line_from_file(file_name, load_from_package),\n",
        "                          number_of_agents=1,\n",
        "                          obs_builder_object=obs_builder_object,\n",
        "                          record_steps=record_steps,\n",
        "                          )\n",
        "    return environment\n",
        "\n",
        "# TODO riferisciti a un agente (EnvAgent)\n",
        "# Usa le azioni dell'agente specifico\n",
        "def delay_a_train(delay: int, delay_time: int, time_of_train_generation: int, actions, train):\n",
        "    \n",
        "    i_agent = train.handle\n",
        "    train_velocity = train.speed_counter.speed\n",
        "\n",
        "    \n",
        "    actions_scheduled = [0] * (len(actions[i_agent]) + delay)\n",
        "    \n",
        "    # Copy the actions scheduled for the train before the delay\n",
        "    for i in range(delay_time - time_of_train_generation):\n",
        "        actions_scheduled[i] = actions[i_agent][i]\n",
        "    # Delay the train (STOP)  \n",
        "    for i in range(delay):\n",
        "        if (i + delay_time - time_of_train_generation) < 0 or (delay_time - time_of_train_generation) > len(actions[i_agent]):\n",
        "            raise ImportError('The train is not present in the environment, check the delay time')\n",
        "        actions_scheduled[i + delay_time - time_of_train_generation] = RailEnvActions.STOP_MOVING\n",
        "    # Copy the actions scheduled for the train after the delay\n",
        "    for i in range(len(actions[i_agent]) - (delay_time - time_of_train_generation)):\n",
        "        actions_scheduled[i + delay_time - time_of_train_generation + delay] = actions[i_agent][i + delay_time - time_of_train_generation]\n",
        "    \n",
        "    actions[i_agent] = actions_scheduled\n",
        "    return \n",
        "\n",
        "\n",
        "# Function to convert decimal number to base number\n",
        "def actions_decimal_to_base(base, number_to_convert, num_agents):\n",
        "    division = number_to_convert\n",
        "    result = []\n",
        "    while division != 0:\n",
        "        result.append(division % base)\n",
        "        division = int(division / base)\n",
        "    actions_to_perform = result[::-1]\n",
        "    if len(actions_to_perform) < num_agents:\n",
        "        zero_to_add = num_agents - len(actions_to_perform)\n",
        "        for i in range(zero_to_add):\n",
        "            actions_to_perform.insert(0,0)\n",
        "    return actions_to_perform\n",
        "\n",
        "\n",
        "def make_a_deterministic_interruption(agent_to_interrupt, interruption_time):\n",
        "    if agent_to_interrupt.state.is_on_map_state():\n",
        "        agent_to_interrupt.malfunction_handler.malfunction_down_counter = interruption_time\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hRGASyFWbbg"
      },
      "source": [
        "# Custom schedule generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyOVeCkwWi3y"
      },
      "outputs": [],
      "source": [
        "\"\"\"Schedule generators (railway undertaking, \"EVU\").\"\"\"\n",
        "from typing import Tuple, List, Callable, Mapping, Optional, Any\n",
        "\n",
        "from enum import IntEnum\n",
        "from numpy.random.mtrand import RandomState\n",
        " \n",
        "from flatland.core.transition_map import GridTransitionMap\n",
        "from typing import List, NamedTuple, Callable\n",
        "\n",
        "from flatland.core.grid.grid4 import Grid4TransitionsEnum\n",
        "from flatland.core.grid.grid_utils import IntVector2DArray\n",
        "\n",
        "\n",
        "Schedule = NamedTuple('Schedule', [('agent_positions', IntVector2DArray),\n",
        "                                   ('agent_directions', List[Grid4TransitionsEnum]),\n",
        "                                   ('agent_targets', IntVector2DArray),\n",
        "                                   ('agent_speeds', List[float]),\n",
        "                                   ('agent_malfunction_rates', List[int]),\n",
        "                                   ('max_episode_steps', int)]) \n",
        "\n",
        "def check_rail_road_direction(rail: GridTransitionMap, timetable):\n",
        "    # To establish the direction of trains in the railroas I define a simple law, as for the cars, each trains has to \n",
        "    # go the direction that let them to have the right free\n",
        "\n",
        "    agents_direction = [0]*len(timetable)\n",
        "    path_result = [0]*len(timetable)\n",
        "\n",
        "    #print(rail.grid[7 ,13],rail.grid[7 ,12],rail.grid[7 ,11],rail.grid[7 ,10],rail.grid[7 ,9],rail.grid[7 ,8],rail.grid[7 ,7],rail.grid[7 ,6], rail.grid[7 ,5])\n",
        "    \n",
        "    for i in range (len(timetable)):\n",
        "        # Consider the a_star result to calculate the direction\n",
        "        path_result[i] = (a_star(rail,timetable[i][0][0],timetable[i][0][1]))\n",
        "        if path_result[i] == []:\n",
        "            agents_direction[i] = 1\n",
        "            continue\n",
        "        if len(path_result[i]) == 1:\n",
        "            agents_direction[i] = 1\n",
        "            continue\n",
        "        difference_x = path_result[i][0][1] - path_result[i][1][1]\n",
        "        difference_y = path_result[i][0][0] - path_result[i][1][0]\n",
        "        if difference_y == 1:\n",
        "            agents_direction[i] = 0\n",
        "        if difference_x ==  -1:\n",
        "            agents_direction[i] = 1\n",
        "        if difference_y == -1:\n",
        "            agents_direction[i] = 2\n",
        "        if difference_x == 1:\n",
        "            agents_direction[i] = 3\n",
        "\n",
        "    return agents_direction\n",
        "\n",
        "AgentPosition = Tuple[int, int]\n",
        "ScheduleGenerator = Callable[[GridTransitionMap, int, Optional[Any], Optional[int]], Schedule]\n",
        "\n",
        "\n",
        "def custom_schedule_generator(timetable, speed_ratio_map: Mapping[float, float] = None, seed: int = 1) -> ScheduleGenerator:\n",
        "\n",
        "#class Custom_schedule_generator(BaseSchedGen):\n",
        "\t\"\"\"\n",
        "\n",
        "\tThis is a custom schedule generator, create a schedule with the timetable, and the station where the trains should pass\n",
        "\t\"\"\"\n",
        "\n",
        "\tdef generate_custom(rail: GridTransitionMap, num_agents: int, hints: Any = None, num_resets: int = 0,\n",
        "\t\t\t\t  np_random: RandomState = None) -> Schedule:\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tThe generator that assigns tasks to all the agents\n",
        "\t\t:param rail: Rail infrastructure given by the rail_generator\n",
        "\t\t:param num_agents: Number of agents to include in the schedule\n",
        "\t\t:param hints: Hints provided by the rail_generator These include positions of start/target positions\n",
        "\t\t:param num_resets: How often the generator has been reset.\n",
        "\t\t:return: Returns the generator to the rail constructor\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\ttrain_stations = hints['train_stations']\n",
        "\t\tcity_positions = hints['city_positions']\n",
        "\t\tcity_orientation = hints['city_orientations']\n",
        "\t\tmax_num_agents = hints['num_agents']\n",
        "\n",
        "\t\tif num_agents > max_num_agents:\n",
        "\t\t\tnum_agents = max_num_agents\n",
        "\t\t\twarnings.warn(\"Too many agents! Changes number of agents.\")\n",
        "\t\t# Place agents and targets within available train stations\n",
        "\t\tagents_position = []\n",
        "\t\tagents_target = []\n",
        "\t\tagents_direction = []\n",
        "\n",
        "\t\t# Define the agent positions\n",
        "\t\t# TODO capisci se così va bene o no\n",
        "\t\tfor agent_i in range (len(timetable)):\n",
        "\t\t\tagents_position.append(timetable[agent_i][0][0])\n",
        "\t\t\tagents_target.append(timetable[agent_i][0][-1])\n",
        "\n",
        "\n",
        "\t\t# Define the direction of the trains based on the rail they occupy\n",
        "\t\t# Input --> the topology of the network, the position of the trains\n",
        "\t\t# Output --> an array with the directions of the trains\n",
        "\t\t# DIRECTIONS: 0 = UP, 1 = RIGHT, 2 = DOWN, 3 = LEFT\n",
        "\n",
        "\t\tagents_direction = check_rail_road_direction(rail, timetable)\n",
        "\n",
        "\n",
        "\t\t_runtime_seed = seed + num_resets\n",
        "\n",
        "\t\tif speed_ratio_map:\n",
        "\t\t\tspeeds = speed_initialization_helper(num_agents, speed_ratio_map, seed=_runtime_seed, np_random=np_random)\n",
        "\t\telse:\n",
        "\t\t\tspeeds = [1.0] * len(agents_position)\n",
        "\n",
        "\t\t# We add multiply factors to the max number of time steps to simplify task in Flatland challenge.\n",
        "\t\t# These factors might change in the future.\n",
        "\t\ttimedelay_factor = 4\n",
        "\t\talpha = 2\n",
        "\t\tmax_episode_steps = 1000\n",
        "\n",
        "\t\t#print(agents_position, agents_target, agents_direction)\n",
        "\n",
        "\t\treturn Schedule(agent_positions=agents_position, agent_directions=agents_direction,\n",
        "\t\t\t\t\t\tagent_targets=agents_target, agent_speeds=speeds, agent_malfunction_rates=None,\n",
        "\t\t\t\t\t\tmax_episode_steps=max_episode_steps)\n",
        "\n",
        "\treturn generate_custom  #(station_to_traverse = [(21, 37), (15, 51)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11emYfouXAL5"
      },
      "source": [
        "* These are the plan to follow utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKROm4gyXOr6"
      },
      "outputs": [],
      "source": [
        "# import chain\n",
        "from itertools import chain\n",
        "from enum import IntEnum\n",
        "import random\n",
        "# This is to test if the timetable is valid or not\n",
        "from flatland.core.grid.grid4_astar import a_star\n",
        "\n",
        "class RailEnvActions(IntEnum):\n",
        "    DO_NOTHING = 0  # implies change of direction in a dead-end!\n",
        "    MOVE_LEFT = 1\n",
        "    MOVE_FORWARD = 2\n",
        "    MOVE_RIGHT = 3\n",
        "    STOP_MOVING = 4\n",
        "    REVERSE = 5\n",
        "\n",
        "    @staticmethod\n",
        "    def to_char(a: int):\n",
        "        return {\n",
        "            0: 'B',\n",
        "            1: 'L',\n",
        "            2: 'F',\n",
        "            3: 'R',\n",
        "            4: 'S',\n",
        "            5: 'I'\n",
        "        }[a]\n",
        "\n",
        "# Check if the timetable is feaseble or not\n",
        "def control_timetable(timetable, railway_topology):\n",
        "    # Check for all the trains\n",
        "    for trains in range (len(timetable)):       \n",
        "        # Check for all the stations\n",
        "        # Calculate the difference of two different times, so i don't need the last term to cycle          \n",
        "        for stations in range (len(timetable[trains][1]) - 1):   \n",
        "            if (timetable[trains][1][stations] - timetable[trains][1][stations + 1]) >= 0:\n",
        "                print('===================================================================================================================================')\n",
        "                print('Attention!!! The agent number', trains, 'has a problem in the timetable, times to reach stations', stations, 'and', (stations+1), 'are not right')\n",
        "                print('The time to reach the successive station SHOULD BE > 0, pay attenction to the timetable')\n",
        "                # Function that check if the time to reach a station defined by the timetable are possible or not,\n",
        "                # Return the time minimum time to reach two different stations depending on the distance and on the line type (high velocity, regional...)\n",
        "            time_to_next_station = time_to_reach_next_station(timetable[trains][0][stations], timetable[trains][0][stations + 1], railway_topology, timetable, trains)\n",
        "            # Control if the time to reach the next station is possible (considering maximum velocities of lines and the distances between two stations)\n",
        "            if time_to_next_station > (timetable[trains][1][stations+1]- timetable[trains][1][stations]):\n",
        "                print('===================================================================================================================================')\n",
        "                print('Attention!!! Agent number', trains, 'has a problem in the timetable, times to reach stations', stations, 'and', (stations+1), 'are not right')\n",
        "                print('The time to reach the next station SHOULD BE HIGHER. The minimum time to reach the station should be:', time_to_next_station)\n",
        "    return\n",
        "\n",
        "# TODO aggiungere dei controlli \n",
        "# - controllare che la posizione in cui si mette il goal del secondo treno sia possibile\n",
        "# - controllare il tempo necessario nella stazione (in base anche alla rialzatura in cui si mette il treno \n",
        "#   e.g. treno spostato su di due caselle, tempo necessario + 4 * velocità alla meno uno)\n",
        "\n",
        "def divide_trains_in_station_rails(timetable, railway_topology):\n",
        "    # The number of different stations presented in the timetable\n",
        "    different_stations = 0\n",
        "    # The position of different stations presented in the timetable\n",
        "    station_positions = []\n",
        "    # Check how many different stations are in the timetable\n",
        "    for i in range(len(timetable)): # for all the trains\n",
        "        for k in range(len(timetable[i][0])): # for all the stations\n",
        "            if timetable[i][0][k] not in station_positions:\n",
        "                station_positions.append(timetable[i][0][k])\n",
        "                different_stations += 1\n",
        "\n",
        "    # Indexes contein the indexes of the station like this\n",
        "    # 0 for the first station in station position \n",
        "    # 1 for the second and so on\n",
        "    indexes = []\n",
        "    # Local variable for the loop\n",
        "    single_index = []\n",
        "\n",
        "    for j in range(len(timetable)): # for all the trains\n",
        "        single_index = [0]*len(timetable[j][0])\n",
        "        for k in range(len(timetable[j][0])): # for all the stations\n",
        "            for i in range(len(station_positions)): # for all the different stations discovered\n",
        "                if station_positions[i] == timetable[j][0][k]:\n",
        "                    single_index[k] = i\n",
        "        indexes.append(single_index)\n",
        "    \n",
        "    # Stations have a capacity, if more trains with respect to the capacity\n",
        "    # of the station are present there is a problem\n",
        "    counter_of_trains = [0] * different_stations  # counter of trains in a certain station\n",
        "    \n",
        "    # TODO fai un ciclo for che cicli gli step nella tabella oraria per aggiornare il counter trains\n",
        "    # quando più treni sono nella stessa stazione aumenta, quando un treno esce dalla stazione diminuisce\n",
        "    # aggiungi una lettera che cicli sulle due stazioni\t(ad ora le stazioni girano su tutta la timetable)\n",
        "    # Calculating the maximum time the agents have to stay in env \n",
        "    \n",
        "     # Here controll if two or more trains have to reach the same station at the same time\n",
        "    for m in range(len(timetable)):  # for all the trains m\n",
        "        for n in range(len(timetable)): # for all the trains n with m!=n\n",
        "            for k in range(len(timetable[m][1])): # for all the stations of m\n",
        "                for l in range(len(timetable[n][1])): # for all the stations of n\n",
        "                    if m!=n and m<n:\n",
        "                        # time at which the trains have to reach the stations\n",
        "                        time_train_a = timetable[m][1][k]\n",
        "                        time_train_b = timetable[n][1][l]\n",
        "                        # if they have to reach the same stations\n",
        "                        if indexes[m][k] == indexes[n][l]: \n",
        "                            threshold_time = calculate_time_in_station(timetable,m,n,k,l)\n",
        "                            # if the time at which they have to reach the station is similar (calculated the time needed in the stations for the trains)\n",
        "                            if time_train_a - time_train_b < threshold_time and time_train_a - time_train_b > -threshold_time:\n",
        "                                # I change the goal of the convoy that first reach the station\n",
        "                                timetable[n][0][l] = (station_positions[indexes[n][l]][0] - 1, station_positions[indexes[n][l]][1])\n",
        "                            \n",
        "\n",
        "\n",
        "# Define the scheduled actions the agents have to do\n",
        "def action_to_do(timetable, railway_topology):\n",
        "    # Path to do to arrive to the right station\n",
        "\n",
        "    # L'idea vuole essere quella di avere un tempo necessario per stare in stazione\n",
        "    # Se due treni nell'intorno di tempo devono stare nella stessa stazione bisogna indirizzarli \n",
        "    # in binari liberi diversi, quindi il passaggio diventa diverso.\n",
        "\n",
        "    path_result = []\n",
        "    # Calculate the path for all the trains\n",
        "    for train_i in range (len(timetable)):\n",
        "        # Number of stations in the train i\n",
        "        num_of_stations = len(timetable[train_i][0])\n",
        "        # The partial result a train run\n",
        "        path_partial_result = []\n",
        "        for station in range(num_of_stations - 1): \n",
        "            path_partial_result.append(a_star(railway_topology,timetable[train_i][0][station],timetable[train_i][0][station + 1]))\n",
        "            if path_partial_result == []:\n",
        "                raise ImportError('There s not a path between station', station, 'and station', station + 1 )\n",
        "\n",
        "        # Final result for all the trains and train runs\n",
        "        path_result.append(path_partial_result)\n",
        "\n",
        "    # Calculate the actions that have to be done\n",
        "    actions_to_do = []\n",
        "    for train_i in range (len(timetable)):\n",
        "        # Number of stations in the train i\n",
        "        num_of_stations = len(timetable[train_i][0])\n",
        "        # Flag that tells me that the next step is particular\n",
        "        next = False\n",
        "        # Each train occupy a row in the action_to_do matrix \n",
        "        actions_single_train = []\n",
        "        # I need the direction of the last run for the reverse action\n",
        "        direction_last_run = 0\n",
        "        for station in range (num_of_stations - 1):\n",
        "            # Each train occupy a row in the action_to_do matrix \n",
        "            actions_single_train_run = []\n",
        "            for step in range (len(path_result[train_i][station])):\n",
        "                # If i'm restarting from the final station of the train run, i have to wait till is the time to restart\n",
        "                if len(path_result[train_i][station]) == 1:\n",
        "                    time_to_wait = timetable[train_i][1][station + 1] - timetable[train_i][1][station]\n",
        "                    for i in range(time_to_wait):\n",
        "                        actions_single_train_run.append(RailEnvActions.STOP_MOVING)\n",
        "                    continue\n",
        "                # Calculate the direction of the trains at each step\n",
        "                if step == 0:\n",
        "                    difference_y = path_result[train_i][station][step][0] - path_result[train_i][station][step + 1][0]\n",
        "                    difference_x = path_result[train_i][station][step][1] - path_result[train_i][station][step + 1][1]\n",
        "                    if difference_y == 1:\n",
        "                        direction = 0\n",
        "                    if difference_x ==  -1:\n",
        "                        direction = 1\n",
        "                    if difference_y == -1:\n",
        "                        direction = 2\n",
        "                    if difference_x == 1:\n",
        "                        direction = 3 \n",
        "                else:\n",
        "                    difference_y = path_result[train_i][station][step - 1][0] - path_result[train_i][station][step][0]\n",
        "                    difference_x = path_result[train_i][station][step - 1][1] - path_result[train_i][station][step][1]\n",
        "                    if difference_y == 1:\n",
        "                        direction = 0\n",
        "                    if difference_x ==  -1:\n",
        "                        direction = 1\n",
        "                    if difference_y == -1:\n",
        "                        direction = 2\n",
        "                    if difference_x == 1:\n",
        "                        direction = 3 \n",
        "                # Variable to count the number of possible path at each cell, is an int with the number of possible path\n",
        "                if not step == 0:\n",
        "                    # Specific case, a train is at the boarder of two different lines, \n",
        "                    # if this appen I have to consider the previous transition at the next time stamp due to the fact the velocity changes\n",
        "                    if next:\n",
        "                        multiple_path = railway_topology.get_transitions(path_result[train_i][station][step-1][0],path_result[train_i][station][step-1][1],prev_direction).count(1)\n",
        "                        next = False\n",
        "                    elif (path_result[train_i][station][step] in av_line) and not (path_result[train_i][station][step - 1] in av_line):\n",
        "                        multiple_path = railway_topology.get_transitions(path_result[train_i][station][step][0],path_result[train_i][station][step][1],prev_direction).count(1)\n",
        "                        next = True\n",
        "                    else:\n",
        "                        multiple_path = railway_topology.get_transitions(path_result[train_i][station][step-1][0],path_result[train_i][station][step-1][1],prev_direction).count(1)\n",
        "                # Starting with a move forward direction for the train\n",
        "                if step == 0:\n",
        "                    #actions_single_train.append(RailEnvActions.MOVE_FORWARD)\n",
        "                    prev_direction = direction\n",
        "                # If I'm not at the start of the train \n",
        "                else:\n",
        "                    # The direction doesn't change\n",
        "                    if num_of_stations > 1 and station >= 1 and step <= 1:\n",
        "                        if (direction - direction_last_run == 2 or direction - direction_last_run == -2):\n",
        "                            # If I'm in an hig velocity line velocity is define only by the type of train\n",
        "                            actions_single_train_run.append(RailEnvActions.REVERSE)\n",
        "                            prev_direction = direction\n",
        "                            continue\n",
        "\n",
        "                    if direction - prev_direction == 0:\n",
        "                        # If I'm in an hig velocity line velocity is define only by the type of train\n",
        "                        if path_result[train_i][station][step - 1] in av_line:\n",
        "                            velocity = timetable[train_i][2]\n",
        "                        # If I'm in other line velocity is the minimum between 1/2 (the velocity of the line) and the type of train velocity\n",
        "                        else:\n",
        "                            velocity = min(timetable[train_i][2], 1/2)\n",
        "                        for i in range(int(pow(velocity, -1))):\n",
        "                            #print('Test per capire come varia',i, 'Treno numero', train_i)\n",
        "                            actions_single_train_run.append(RailEnvActions.MOVE_FORWARD)\n",
        "                        # I'm arrived at the station?\n",
        "                        if step == (len(path_result[train_i][station]) - 1):\n",
        "                            # If the next station is the last one of the train run I don't have to stop for the min wait time\n",
        "                            if station != (num_of_stations - 2):\n",
        "                                if len(path_result[train_i][station + 1]) == 1:\n",
        "                                    continue\n",
        "                            # If is an intermediate station I need to stop the min wait time\n",
        "                            for i in range(3):   # TODO ADD THE WAITING TIMES OF THE STATIONS\n",
        "                                actions_single_train_run.append(RailEnvActions.STOP_MOVING)\n",
        "\n",
        "                        prev_direction = direction\n",
        "                    # I have to reverse the train direction when I arrive at the ending station\n",
        "                    elif ((direction - prev_direction) == -2) or ((direction - prev_direction) == 2):\n",
        "                        # If I'm in an hig velocity line velocity is define only by the type of train\n",
        "                        if path_result[train_i][station][step - 1] in av_line:\n",
        "                            velocity = timetable[train_i][2]\n",
        "                        else:\n",
        "                            velocity = min(timetable[train_i][2], 1/2)\n",
        "                        for i in range(int(pow(velocity, -1))):\n",
        "                            actions_single_train_run.append(RailEnvActions.REVERSE)\n",
        "                        prev_direction = direction\n",
        "                    # I have to move to left \n",
        "                    # and I have more then one possible path, so I go left at the deviation\n",
        "                    # Depending on the direction of march the results can be -1 or -3\n",
        "                    elif ((direction - prev_direction == -1) and (multiple_path > 1)) or ((direction - prev_direction == +3)):\n",
        "                        # If I'm in an hig velocity line velocity is define only by the type of train\n",
        "                        if path_result[train_i][station][step - 1] in av_line:\n",
        "                            velocity = timetable[train_i][2]\n",
        "                        # If I'm in other line velocity is the minimum between 1/2 (the velocity of the line) and the type of train velocity\n",
        "                        else:\n",
        "                            velocity = min(timetable[train_i][2], 1/2)\n",
        "                        for i in range(int(pow(velocity, -1))):\n",
        "                            actions_single_train_run.append(RailEnvActions.MOVE_LEFT)\n",
        "                        prev_direction = direction\n",
        "                    # I have to move right \n",
        "                    # and I have more then one possible path, so I go left at the deviation \n",
        "                    # Depending on the direction of march the results can be +1 or -3\n",
        "                    elif ((direction - prev_direction == 1) and (multiple_path > 1)) or ((direction - prev_direction == -3) ):\n",
        "                        # If I'm in an hig velocity line velocity is define only by the type of train\n",
        "                        if path_result[train_i][station][step - 1] in av_line:\n",
        "                            velocity = timetable[train_i][2]\n",
        "                        # If I'm in other line velocity is the minimum between 1/2 (the velocity of the line) and the type of train velocity\n",
        "                        else:\n",
        "                            velocity = min(timetable[train_i][2], 1/2)\n",
        "                        for i in range(int(pow(velocity, -1))):\n",
        "                            actions_single_train_run.append(RailEnvActions.MOVE_RIGHT)\n",
        "                        prev_direction = direction\n",
        "                    else:\n",
        "                        if path_result[train_i][station][step - 1] in av_line:\n",
        "                            velocity = timetable[train_i][2]\n",
        "                        else:\n",
        "                            velocity = min(timetable[train_i][2], 1/2)\n",
        "                        for i in range(int(pow(velocity, -1))):\n",
        "                            actions_single_train_run.append(RailEnvActions.MOVE_FORWARD)\n",
        "                        # I'm arrived at the station?\n",
        "                        if step == (len(path_result[train_i][station]) - 1):\n",
        "                            for i in range(3):   # TODO ADD THE WAITING TIMES OF THE STATIONS\n",
        "                                actions_single_train_run.append(RailEnvActions.STOP_MOVING)\n",
        "                        prev_direction = direction\n",
        "            direction_last_run = direction\n",
        "\n",
        "            actions_single_train.append(actions_single_train_run)\n",
        " \n",
        "        if isinstance(actions_single_train[0], list):\n",
        "            len(actions_single_train)\n",
        "            actions_single_train = list(chain.from_iterable(actions_single_train))\n",
        "        actions_to_do.append(actions_single_train)\n",
        "\n",
        "    return actions_to_do\n",
        "\n",
        "# Calculate the time to reach the stations to understand if timetable is right\n",
        "def time_to_reach_next_station(departure_station_position, arrival_station_position, railway_topology, schedule, train_number):\n",
        "    # First thing check the distance between two stations \n",
        "    result = a_star(railway_topology, departure_station_position, arrival_station_position)\n",
        "    # Maximum velocity a train can achieve\n",
        "    train_velocity = schedule[train_number][2]\n",
        "\n",
        "    lenght_path = len(result)  # distance between stations\n",
        "\n",
        "    # Array when I put at each step the time needed to make the path\n",
        "    # The total time is the sum of the numbers\n",
        "    time_array = []\n",
        "    # Check the at each step which train i am and which line im in\n",
        "    for step in range(lenght_path):\n",
        "        if (result[step]) in av_line:\n",
        "            time_array.append(pow(train_velocity,-1))\n",
        "        else:\n",
        "            time_array.append(pow(min(train_velocity, 1/2), -1))\n",
        "    time_needed = sum(time_array)\n",
        "\n",
        "    #print((time_needed + int(time_needed/10))) DEBUG\n",
        "\n",
        "    # Adding to the time a 10% to face with problems in case it's neaded\n",
        "    return (time_needed + int(time_needed/10))\n",
        "\n",
        "# TODO calculate the av_rails, in order to distinguish them\n",
        "# TODO calculate the right,left,up,down rails, in order to distinguish them\n",
        "# TODO understad if the velocities are realistic or not (360 km for high velocity, 180 and 120 is realistic or not?)\n",
        "\n",
        "def calculate_timetable(convoys, railway_topology):\n",
        "    # The timetable that should be returned\n",
        "    timetable = []\n",
        "    # For each convoy\n",
        "    for convoy_i in range(len(convoys)):\n",
        "        # For each train run defined\n",
        "        single_convoy_schedule = convoys[convoy_i].schedule\n",
        "        single_convoy_schedule_len = len(convoys[convoy_i].schedule)\n",
        "        single_convoy = []\n",
        "        for num_of_runs in range(single_convoy_schedule_len):\n",
        "            # The single train run\n",
        "            single_train_run = []\n",
        "            # The number of station to pass\n",
        "            num_of_stations = len(single_convoy_schedule[num_of_runs].line_belongin.stations)\n",
        "            # The station to stop\n",
        "            stations_to_stop_position = []\n",
        "            # Direction not inverted?\n",
        "            if not single_convoy_schedule[num_of_runs].inverse_train_direction:\n",
        "                for i in range(num_of_stations):\n",
        "                    # append the station position in the right order\n",
        "                    stations_to_stop_position.append(single_convoy_schedule[num_of_runs].line_belongin.stations[i].position)\n",
        "            # Direction inverdet?\n",
        "            else:\n",
        "                for i in range(num_of_stations):\n",
        "                    # append the station position in inverted order\n",
        "                    stations_to_stop_position.append(single_convoy_schedule[num_of_runs].line_belongin.stations[num_of_stations - 1 - i].position)\n",
        "            # Adding the starting time\n",
        "            single_train_run.append(single_convoy_schedule[num_of_runs].starting_time)\n",
        "\n",
        "            for stations in range(num_of_stations -1):\n",
        "                departure_station_position = stations_to_stop_position[stations]\n",
        "                arrival_station_position = stations_to_stop_position[stations + 1]\n",
        "                # First thing check the distance between two stations\n",
        "                result = a_star(railway_topology, departure_station_position, arrival_station_position)\n",
        "                # Maximum velocity a train can achieve\n",
        "                train_velocity = convoys[convoy_i].maximum_velocity \n",
        "\n",
        "                lenght_path = len(result)  # distance between stations\n",
        "\n",
        "                # Array when I put at each step the time needed to make the path\n",
        "                # The total time is the sum of the numbers\n",
        "                time_array = []\n",
        "\n",
        "                # Check the at each step which train i am and which line im in\n",
        "                # Train should be in the middle of two line type\n",
        "                for step in range(lenght_path):\n",
        "                    if (result[step]) in av_line:\n",
        "                        time_array.append(pow(train_velocity,-1))\n",
        "                    else:\n",
        "                        time_array.append(pow(min(train_velocity, 1/2), -1))\n",
        "                time_needed = sum(time_array)\n",
        "                # Adding to the time a 10% to face with problems in case it's neaded\n",
        "                time_needed = time_needed + int(time_needed/10)\n",
        "\n",
        "                # Adding the precedence time \n",
        "                if stations != (num_of_stations - 1):\n",
        "                    if len(single_train_run) == 1 and type(single_convoy_schedule[num_of_runs].line_belongin.stations[stations].min_wait_time) == int:\n",
        "                        single_train_run.append(int(time_needed + single_train_run[0] + single_convoy_schedule[num_of_runs].line_belongin.stations[stations].min_wait_time))\n",
        "                    else:\n",
        "                        # sum of time needed, the precedence time and the waiting time at the station\n",
        "                        single_train_run.append(int(time_needed + single_train_run[stations] + single_convoy_schedule[num_of_runs].line_belongin.stations[stations].min_wait_time[0]))\n",
        "\n",
        "            single_convoy.append(stations_to_stop_position)\n",
        "            single_convoy.append(single_train_run)\n",
        "            \n",
        "        timetable.append(single_convoy)\n",
        "\n",
        "    # This is needed in order to obtein the timetable-standard structure\n",
        "    final_timetable = [] # The final timetable\n",
        "    timetable_single_convoy = [] # Timetable of a single convoy\n",
        "    timetable_position_example = [] # Partial timetable with the position of the stations to pass\n",
        "    timetable_time_example = []  # Partial timetable with the time at which reach the stations\n",
        "    single_position_timetable = []  # position and time of a single train run\n",
        "    single_time_timetable = []\n",
        "\n",
        "    for i in range(len(timetable)):\n",
        "        for j in range(len(timetable[i])):\n",
        "            if j % 2 == 0:\n",
        "                timetable_position_example.append(timetable[i][j])\n",
        "            else:\n",
        "                timetable_time_example.append(timetable[i][j])\n",
        "        for k in range(len(timetable_position_example)):\n",
        "            single_position_timetable += (timetable_position_example[k])\n",
        "        for k in range(len(timetable_time_example)):\n",
        "            single_time_timetable += timetable_time_example[k]\n",
        "        # The standard timetable form is (positions, time, train velocity)\n",
        "        timetable_single_convoy.append(single_position_timetable)\n",
        "        timetable_single_convoy.append(single_time_timetable)\n",
        "        timetable_single_convoy.append(convoys[i].maximum_velocity)\n",
        "        # Final timetable\n",
        "        final_timetable.append(timetable_single_convoy)\n",
        "        # Restart the partial results\n",
        "        single_position_timetable = []\n",
        "        timetable_position_example = []\n",
        "        single_time_timetable = []\n",
        "        timetable_time_example = []\n",
        "        timetable_single_convoy = []\n",
        "\n",
        "    return final_timetable\n",
        "\n",
        "def calculate_time_in_station(timetable,train_a,train_b,index_a,index_b):\n",
        "    time_a = 15\n",
        "    time_b = 15\n",
        "    if index_a != 0:\n",
        "        time_a = timetable[train_a][1][index_a] - timetable[train_a][1][index_a - 1] + 15\n",
        "    if index_b != 0:\n",
        "        time_b = timetable[train_b][1][index_b] - timetable[train_b][1][index_b - 1] + 15\n",
        "    return max(time_a,time_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNlNKBMYZgVW"
      },
      "source": [
        "# Rail Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hNWqYVGZmPi"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT5xWtspZlzI"
      },
      "outputs": [],
      "source": [
        "from flatland.envs.rail_env import RailEnvActions\n",
        "\n",
        "# Import your own Agent or use RLlib to train agents on Flatland\n",
        "# As an example we use a random agent instead\n",
        "class RandomAgent:\n",
        "\n",
        "\tdef __init__(self, state_size, action_size):\n",
        "\t\tself.state_size = state_size\n",
        "\t\tself.action_size = action_size\n",
        "\n",
        "\n",
        "\t# HERE DEFINE THE ACTIONS TO DO IN CASE THE AGENT IS NOT IN THE DETERMINISTIC PART \n",
        "\t# For now the agents can only move forward (for DEBUG)\n",
        "\tdef act(self, state):\n",
        "\t\treturn RailEnvActions.MOVE_FORWARD\n",
        "\n",
        "\tdef step(self, memories):\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tStep function to improve agent by adjusting policy given the observations\n",
        "\n",
        "\t\t:param memories: SARS Tuple to be\n",
        "\t\t:return:\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\treturn\n",
        "\n",
        "\tdef save(self, filename):\n",
        "\t\t# Store the current policy\n",
        "\t\treturn\n",
        "\n",
        "\tdef load(self, filename):\n",
        "\t\t# Load a policy\n",
        "\t\treturn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqtaVQZNZ39v"
      },
      "source": [
        "## Environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXdkQKaRadDL"
      },
      "source": [
        "### Rewards and Penalities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImedOM4oaKbh"
      },
      "source": [
        "Here define the penalities and rewards for the agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4zDuy13aJVH"
      },
      "outputs": [],
      "source": [
        "# Penalities \n",
        "step_penality = - 0.01               # a step is time passing, so a penality for each step is needed\n",
        "stop_penality = -0.05                # penalty for stopping a moving agent\n",
        "reverse_penality = -0.07            # penalty for reversing the march of an agent\n",
        "skip_penality = 0                   # penalty for skipping a station\n",
        "target_not_reached_penalty = -20     # penalty for not reaching the final target (depot)\n",
        "default_skip_penalty = 30\n",
        "cancellation_factor = 1\n",
        "cancellation_time_buffer = 0\n",
        "\n",
        "target_reward = 30         # reward for an agent reaching his final target\n",
        "station_passage_reward = 10 # reward for an agent reaching intermediate station, the reward is wheighted with the delay of the agent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVWfJEALailv"
      },
      "source": [
        "### Training Flag\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afVzyw0Pak3a"
      },
      "outputs": [],
      "source": [
        "example_training = 'training0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9B5UGAXYgJq"
      },
      "source": [
        "### Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_86tpr-Z7Au"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Definition of the RailEnv environment.\n",
        "\"\"\"\n",
        "import random\n",
        "from random import *\n",
        "\n",
        "from typing import List, Optional, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "from gym.utils import seeding\n",
        "\n",
        "from flatland.utils.rendertools import RenderTool, AgentRenderVariant\n",
        "from flatland.core.env import Environment\n",
        "from flatland.core.env_observation_builder import ObservationBuilder\n",
        "from flatland.core.grid.grid4 import Grid4Transitions\n",
        "from flatland.core.transition_map import GridTransitionMap\n",
        "from flatland.envs.agent_utils import EnvAgent\n",
        "from flatland.envs.distance_map import DistanceMap\n",
        "\n",
        "from flatland.envs import malfunction_generators as mal_gen\n",
        "from flatland.envs import rail_generators as rail_gen\n",
        "from flatland.envs import line_generators as line_gen\n",
        "from flatland.envs.timetable_generators import timetable_generator\n",
        "from flatland.envs import persistence\n",
        "from flatland.envs import agent_chains as ac\n",
        "\n",
        "from flatland.envs.observations import GlobalObsForRailEnv\n",
        "\n",
        "from flatland.envs.timetable_generators import timetable_generator\n",
        "from flatland.envs.step_utils.states import TrainState, StateTransitionSignals\n",
        "from flatland.envs.step_utils.transition_utils import check_valid_action\n",
        "from flatland.envs.step_utils import action_preprocessing\n",
        "from flatland.envs.step_utils import env_utils\n",
        "\n",
        "training = example_training\n",
        "\n",
        "class RailEnv(Environment):\n",
        "    \"\"\"\n",
        "    RailEnv environment class.\n",
        "\n",
        "    RailEnv is an environment inspired by a (simplified version of) a rail\n",
        "    network, in which agents (trains) have to navigate to their target\n",
        "    locations in the shortest time possible, while at the same time cooperating\n",
        "    to avoid bottlenecks.\n",
        "\n",
        "    The valid actions in the environment are:\n",
        "\n",
        "     -   0: do nothing (continue moving or stay still)\n",
        "     -   1: turn left at switch and move to the next cell; if the agent was not moving, movement is started\n",
        "     -   2: move to the next cell in front of the agent; if the agent was not moving, movement is started\n",
        "     -   3: turn right at switch and move to the next cell; if the agent was not moving, movement is started\n",
        "     -   4: stop moving\n",
        "     -   5: invert the direction of march\n",
        "\n",
        "    Moving forward in a dead-end cell makes the agent turn 180 degrees and step\n",
        "    to the cell it came from.\n",
        "\n",
        "    The actions of the agents are executed in order of their handle to prevent\n",
        "    deadlocks and to allow them to learn relative priorities.\n",
        "\n",
        "    Reward Function:\n",
        "\n",
        "    It costs each agent a step_penalty for every time-step taken in the environment. Independent of the movement\n",
        "    of the agent. Currently all other penalties such as penalty for stopping, starting and invalid actions are set to 0.\n",
        "\n",
        "    alpha = 1\n",
        "    beta = 1\n",
        "    Reward function parameters:\n",
        "\n",
        "    - invalid_action_penalty = 0\n",
        "    - step_penalty = -alpha\n",
        "    - global_reward = beta\n",
        "    - epsilon = avoid rounding errors\n",
        "    - stop_penalty = 0  # penalty for stopping a moving agent\n",
        "    - start_penalty = 0  # penalty for starting a stopped agent\n",
        "\n",
        "    Stochastic malfunctioning of trains:\n",
        "    Trains in RailEnv can malfunction if they are halted too often (either by their own choice or because an invalid\n",
        "    action or cell is selected.\n",
        "\n",
        "    Every time an agent stops, an agent has a certain probability of malfunctioning. Malfunctions of trains follow a\n",
        "    poisson process with a certain rate. Not all trains will be affected by malfunctions during episodes to keep\n",
        "    complexity managable.\n",
        "\n",
        "    TODO: currently, the parameters that control the stochasticity of the environment are hard-coded in init().\n",
        "    For Round 2, they will be passed to the constructor as arguments, to allow for more flexibility.\n",
        "\n",
        "    \"\"\"\n",
        "    cancellation_factor = 1\n",
        "    cancellation_time_buffer = 0\n",
        "\n",
        "    def __init__(self,\n",
        "                 width,\n",
        "                 height,\n",
        "                 max_episode_steps,\n",
        "                 rail_generator=None,\n",
        "                 line_generator=None,  # : line_gen.LineGenerator = line_gen.random_line_generator(),\n",
        "                 number_of_agents=2,\n",
        "                 obs_builder_object: ObservationBuilder = GlobalObsForRailEnv(),\n",
        "                 malfunction_generator_and_process_data=None,  # mal_gen.no_malfunction_generator(),\n",
        "                 malfunction_generator=None,\n",
        "                 remove_agents_at_target=True,\n",
        "                 random_seed=None,\n",
        "                 record_steps=False,\n",
        "                 close_following=True,\n",
        "                 ):\n",
        "        \"\"\"\n",
        "        Environment init.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        rail_generator : function\n",
        "            The rail_generator function is a function that takes the width,\n",
        "            height and agents handles of a  rail environment, along with the number of times\n",
        "            the env has been reset, and returns a GridTransitionMap object and a list of\n",
        "            starting positions, targets, and initial orientations for agent handle.\n",
        "            The rail_generator can pass a distance map in the hints or information for specific line_generators.\n",
        "            Implementations can be found in flatland/envs/rail_generators.py\n",
        "        line_generator : function\n",
        "            The line_generator function is a function that takes the grid, the number of agents and optional hints\n",
        "            and returns a list of starting positions, targets, initial orientations and speed for all agent handles.\n",
        "            Implementations can be found in flatland/envs/line_generators.py\n",
        "        width : int\n",
        "            The width of the rail map. Potentially in the future,\n",
        "            a range of widths to sample from.\n",
        "        height : int\n",
        "            The height of the rail map. Potentially in the future,\n",
        "            a range of heights to sample from.\n",
        "        number_of_agents : int\n",
        "            Number of agents to spawn on the map. Potentially in the future,\n",
        "            a range of number of agents to sample from.\n",
        "        obs_builder_object: ObservationBuilder object\n",
        "            ObservationBuilder-derived object that takes builds observation\n",
        "            vectors for each agent.\n",
        "        remove_agents_at_target : bool\n",
        "            If remove_agents_at_target is set to true then the agents will be removed by placing to\n",
        "            RailEnv.DEPOT_POSITION when the agent has reach it's target position.\n",
        "        random_seed : int or None\n",
        "            if None, then its ignored, else the random generators are seeded with this number to ensure\n",
        "            that stochastic operations are replicable across multiple operations\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        if malfunction_generator_and_process_data is not None:\n",
        "            print(\"DEPRECATED - RailEnv arg: malfunction_and_process_data - use malfunction_generator\")\n",
        "            self.malfunction_generator, self.malfunction_process_data = malfunction_generator_and_process_data\n",
        "        elif malfunction_generator is not None:\n",
        "            self.malfunction_generator = malfunction_generator\n",
        "            # malfunction_process_data is not used\n",
        "            # self.malfunction_generator, self.malfunction_process_data = malfunction_generator_and_process_data\n",
        "            self.malfunction_process_data = self.malfunction_generator.get_process_data()\n",
        "        # replace default values here because we can't use default args values because of cyclic imports\n",
        "        else:\n",
        "            self.malfunction_generator = mal_gen.NoMalfunctionGen()\n",
        "            self.malfunction_process_data = self.malfunction_generator.get_process_data()\n",
        "        \n",
        "        self.number_of_agents = number_of_agents\n",
        "\n",
        "        if rail_generator is None:\n",
        "            rail_generator = rail_gen.sparse_rail_generator()\n",
        "        self.rail_generator = rail_generator\n",
        "        if line_generator is None:\n",
        "            line_generator = line_gen.sparse_line_generator()\n",
        "        self.line_generator = line_generator\n",
        "\n",
        "        self.rail: Optional[GridTransitionMap] = None\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "\n",
        "        self.remove_agents_at_target = remove_agents_at_target\n",
        "\n",
        "        self.obs_builder = obs_builder_object\n",
        "        self.obs_builder.set_env(self)\n",
        "\n",
        "        self._max_episode_steps: Optional[int] = max_episode_steps\n",
        "        self._elapsed_steps = 0\n",
        "\n",
        "        self.obs_dict = {}\n",
        "        self.rewards_dict = {}\n",
        "        self.dev_obs_dict = {}\n",
        "        self.dev_pred_dict = {}\n",
        "\n",
        "        self.agents: List[EnvAgent] = []\n",
        "        self.num_resets = 0\n",
        "        self.distance_map = DistanceMap(self.agents, self.height, self.width)\n",
        "\n",
        "        self.action_space = [6]\n",
        "        \n",
        "        self.previous_station = [[(-1,0)]] * number_of_agents\n",
        "        \n",
        "        self.dones_for_position = [False] * number_of_agents\n",
        "        \n",
        "\n",
        "        self._seed()\n",
        "        if random_seed:\n",
        "            self._seed(seed=random_seed)\n",
        "\n",
        "        self.agent_positions = None\n",
        "\n",
        "        self.run_once = [0]*(self.number_of_agents)   # Flag to check when a train has started   \n",
        "\n",
        "        # save episode timesteps ie agent positions, orientations.  (not yet actions / observations)\n",
        "        self.record_steps = record_steps  # whether to save timesteps\n",
        "        # save timesteps in here: [[[row, col, dir, malfunction],...nAgents], ...nSteps]\n",
        "        self.cur_episode = []\n",
        "        self.list_actions = []  # save actions in here\n",
        "\n",
        "        self.motionCheck = ac.MotionCheck()\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        random.seed(seed)\n",
        "        self.random_seed = seed\n",
        "\n",
        "        # Keep track of all the seeds in order\n",
        "        if not hasattr(self, 'seed_history'):\n",
        "            self.seed_history = [seed]\n",
        "        if self.seed_history[-1] != seed:\n",
        "            self.seed_history.append(seed)\n",
        "\n",
        "        return [seed]\n",
        "\n",
        "    def find_indices(self, array, index_to_find):\n",
        "        indeces = []\n",
        "        for i in range(len(array)):\n",
        "            if array[i] == index_to_find:\n",
        "                indeces.append(i)\n",
        "        return (indeces)\n",
        "\n",
        "    # no more agent_handles\n",
        "    def get_agent_handles(self):\n",
        "        return range(self.get_num_agents())\n",
        "    \n",
        "    def get_num_agents(self) -> int:\n",
        "        return len(self.agents)\n",
        "\n",
        "    def add_agent(self, agent):\n",
        "        \"\"\" Add static info for a single agent.\n",
        "            Returns the index of the new agent.\n",
        "        \"\"\"\n",
        "        self.agents.append(agent)\n",
        "        return len(self.agents) - 1\n",
        "\n",
        "    def reset_agents(self):\n",
        "        \"\"\" Reset the agents to their starting positions\n",
        "        \"\"\"\n",
        "        for agent in self.agents:\n",
        "            agent.reset()\n",
        "        self.active_agents = [i for i in range(len(self.agents))]\n",
        "\n",
        "    def action_required(self, agent):\n",
        "        \"\"\"\n",
        "        Check if an agent needs to provide an action\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        agent: RailEnvAgent\n",
        "        Agent we want to check\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        True: Agent needs to provide an action\n",
        "        False: Agent cannot provide an action\n",
        "        \"\"\"\n",
        "        return agent.state == TrainState.READY_TO_DEPART or \\\n",
        "               ( agent.state.is_on_map_state() and agent.speed_counter.is_cell_entry )\n",
        "\n",
        "    def reset(self, regenerate_rail: bool = True, regenerate_schedule: bool = True, *,\n",
        "              random_seed: int = None) -> Tuple[Dict, Dict]:\n",
        "        \"\"\"\n",
        "        reset(regenerate_rail, regenerate_schedule, activate_agents, random_seed)\n",
        "\n",
        "        The method resets the rail environment\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        regenerate_rail : bool, optional\n",
        "            regenerate the rails\n",
        "        regenerate_schedule : bool, optional\n",
        "            regenerate the schedule and the static agents\n",
        "        random_seed : int, optional\n",
        "            random seed for environment\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        observation_dict: Dict\n",
        "            Dictionary with an observation for each agent\n",
        "        info_dict: Dict with agent specific information\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if random_seed:\n",
        "            self._seed(random_seed)\n",
        "\n",
        "        optionals = {}\n",
        "        if regenerate_rail or self.rail is None:\n",
        "\n",
        "            if \"__call__\" in dir(self.rail_generator):\n",
        "                rail, optionals = self.rail_generator(\n",
        "                    self.width, self.height, self.number_of_agents, self.num_resets, self.np_random)\n",
        "            elif \"generate\" in dir(self.rail_generator):\n",
        "                rail, optionals = self.rail_generator.generate(\n",
        "                    self.width, self.height, self.number_of_agents, self.num_resets, self.np_random)\n",
        "            else:\n",
        "                raise ValueError(\"Could not invoke __call__ or generate on rail_generator\")\n",
        "\n",
        "            self.rail = rail\n",
        "            self.height, self.width = self.rail.grid.shape\n",
        "\n",
        "            # Do a new set_env call on the obs_builder to ensure\n",
        "            # that obs_builder specific instantiations are made according to the\n",
        "            # specifications of the current environment : like width, height, etc\n",
        "            self.obs_builder.set_env(self)\n",
        "\n",
        "        if optionals and 'distance_map' in optionals:\n",
        "            self.distance_map.set(optionals['distance_map'])\n",
        "\n",
        "        if regenerate_schedule or regenerate_rail or self.get_num_agents() == 0:\n",
        "            agents_hints = None\n",
        "            if optionals and 'agents_hints' in optionals:\n",
        "                agents_hints = optionals['agents_hints']\n",
        "\n",
        "            line = self.line_generator(self.rail, self.number_of_agents, agents_hints, \n",
        "                                               self.num_resets, self.np_random)\n",
        "            self.agents = EnvAgent.from_line(line)\n",
        "\n",
        "            # Reset distance map - basically initializing\n",
        "            self.distance_map.reset(self.agents, self.rail)\n",
        "\n",
        "            # NEW : Time Schedule Generation\n",
        "            timetable = timetable_generator(self.agents, self.distance_map, \n",
        "                                               agents_hints, self.np_random)\n",
        "\n",
        "            #self._max_episode_steps = 250\n",
        "\n",
        "            for agent_i, agent in enumerate(self.agents):\n",
        "                agent.earliest_departure = timetable.earliest_departures[agent_i]         \n",
        "                agent.latest_arrival = timetable.latest_arrivals[agent_i]\n",
        "        else:\n",
        "            self.distance_map.reset(self.agents, self.rail)\n",
        "        \n",
        "        # Reset agents to initial states\n",
        "        self.reset_agents()\n",
        "\n",
        "        self.run_once = [0]*(self.number_of_agents)   # Flag to check when a train has started\n",
        "\n",
        "        self.num_resets += 1\n",
        "        self._elapsed_steps = 0\n",
        "        \n",
        "        self.previous_station = [[(-1,0)]] * self.number_of_agents\n",
        "        \n",
        "        self.dones_for_position = [False] * self.number_of_agents\n",
        "        \n",
        "\n",
        "        # Agent positions map\n",
        "        self.agent_positions = np.zeros((self.height, self.width), dtype=int) - 1\n",
        "        self._update_agent_positions_map(ignore_old_positions=False)\n",
        "\n",
        "        self.dones = dict.fromkeys(list(range(self.get_num_agents())) + [\"__all__\"], False)\n",
        "\n",
        "        # Reset the state of the observation builder with the new environment\n",
        "        self.obs_builder.reset()\n",
        "\n",
        "        # Empty the episode store of agent positions\n",
        "        self.cur_episode = []\n",
        "\n",
        "        info_dict = self.get_info_dict()\n",
        "        # Return the new observation vectors for each agent\n",
        "        observation_dict: Dict = self._get_observations()\n",
        "        if hasattr(self, \"renderer\") and self.renderer is not None:\n",
        "            self.renderer = None\n",
        "        return observation_dict, info_dict\n",
        "\n",
        "\n",
        "    def _update_agent_positions_map(self, ignore_old_positions=True):\n",
        "        \"\"\" Update the agent_positions array for agents that changed positions \"\"\"\n",
        "        for agent in self.agents:\n",
        "            if not ignore_old_positions or agent.old_position != agent.position:\n",
        "                if agent.position is not None:\n",
        "                    self.agent_positions[agent.position] = agent.handle\n",
        "                if agent.old_position is not None:\n",
        "                    self.agent_positions[agent.old_position] = -1\n",
        "    \n",
        "    def generate_state_transition_signals(self, agent, preprocessed_action, movement_allowed, target_time):\n",
        "        \"\"\" Generate State Transitions Signals used in the state machine \"\"\"\n",
        "        st_signals = StateTransitionSignals()\n",
        "        \n",
        "        # Malfunction starts when in_malfunction is set to true\n",
        "        st_signals.in_malfunction = agent.malfunction_handler.in_malfunction\n",
        "\n",
        "        # Malfunction counter complete - Malfunction ends next timestep\n",
        "        st_signals.malfunction_counter_complete = agent.malfunction_handler.malfunction_counter_complete\n",
        "\n",
        "        # Earliest departure reached - Train is allowed to move now\n",
        "        st_signals.earliest_departure_reached = self._elapsed_steps >= agent.earliest_departure\n",
        "\n",
        "        # Stop Action Given\n",
        "        st_signals.stop_action_given = (preprocessed_action == RailEnvActions.STOP_MOVING)\n",
        "\n",
        "        # Valid Movement action Given\n",
        "        st_signals.valid_movement_action_given = preprocessed_action.is_moving_action() and movement_allowed\n",
        "\n",
        "        # Target Reached\n",
        "        if self._elapsed_steps >= target_time:\n",
        "            # agent.target = [agent.target[0] - 1, agent.target[1]]\n",
        "            st_signals.target_reached = env_utils.fast_position_equal(agent.position, agent.target)\n",
        "        else:\n",
        "            st_signals.target_reached = False\n",
        "\n",
        "        # Movement conflict - Multiple trains trying to move into same cell\n",
        "        # If speed counter is not in cell exit, the train can enter the cell\n",
        "        st_signals.movement_conflict = (not movement_allowed) and agent.speed_counter.is_cell_exit\n",
        "\n",
        "        return st_signals\n",
        "\n",
        "    def _handle_end_reward(self, agent: EnvAgent, timetable) -> int:\n",
        "        '''\n",
        "        Handles end-of-episode reward for a particular agent.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        agent : EnvAgent\n",
        "        '''\n",
        "        i_agent = agent.handle\n",
        "\n",
        "        if training == 'training0' and i_agent != 0:\n",
        "            reward = 0\n",
        "            return reward\n",
        "        if (training == 'training1' or training == 'training1.1') and i_agent > 1:\n",
        "            reward = 0\n",
        "            return reward\n",
        "\n",
        "        reward = 0\n",
        "\n",
        "        # Reached intermediated stations?\n",
        "        #reward = self.intermediate_station_reward(i_agent, timetable)\n",
        "\n",
        "        # agent done? (arrival_time is not None)\n",
        "        if agent.state == TrainState.DONE:\n",
        "            # if agent arrived earlier or on time = 0\n",
        "            # if agent arrived later = -ve reward based on how late\n",
        "            reward += target_reward\n",
        "            i_agent = agent.handle\n",
        "            self.dones[i_agent] = True\n",
        "            # DELAY\n",
        "            delay = min(agent.latest_arrival - agent.arrival_time, 0)\n",
        "            delay_penalty = delay * 0.7 * 0.7/3 # FORMULA DATA DAL PROF DA AGGIUSTARE\n",
        "            reward += delay_penalty\n",
        "            #reward = min(agent.latest_arrival - agent.arrival_time, 0)\n",
        "\n",
        "        # Agents not done (arrival_time is None)\n",
        "        else:\n",
        "            # CANCELLED check (never departed)\n",
        "            if (agent.state.is_off_map_state()):\n",
        "                reward += -1 * self.cancellation_factor * \\\n",
        "                    (agent.get_travel_time_on_shortest_path(self.distance_map) + self.cancellation_time_buffer)\n",
        "\n",
        "            # Departed but never reached\n",
        "            if (agent.state.is_on_map_state()):\n",
        "                reward += target_not_reached_penalty\n",
        "                \n",
        "                pasted_agent_positions = self.cur_episode\n",
        "                if pasted_agent_positions == []:\n",
        "                    reward += default_skip_penalty\n",
        "                    return reward\n",
        "                \n",
        "                stations_to_pass = timetable[i_agent][0]\n",
        "                \n",
        "                for positions in range (len(pasted_agent_positions)):\n",
        "                    # If the agent is passed in at least one station (different from the starting one) no problems\n",
        "                    if pasted_agent_positions[positions][i_agent] in stations_to_pass[1:]:\n",
        "                        return reward\n",
        "                    \n",
        "                # else, I have to give a skip penalty for all the skipped stations, for now simplified\n",
        "                # I give an high penalty\n",
        "                reward += - default_skip_penalty\n",
        "                return reward\n",
        "        \n",
        "        return reward\n",
        "\n",
        "    def preprocess_action(self, action, agent):\n",
        "        \"\"\"\n",
        "        Preprocess the provided action\n",
        "            * Change to DO_NOTHING if illegal action\n",
        "            * Block all actions when in waiting state\n",
        "            * Check MOVE_LEFT/MOVE_RIGHT actions on current position else try MOVE_FORWARD\n",
        "        \"\"\"\n",
        "        action = action_preprocessing.preprocess_raw_action(action, agent.state, agent.action_saver.saved_action)\n",
        "        action = action_preprocessing.preprocess_action_when_waiting(action, agent.state)\n",
        "\n",
        "        # Try moving actions on current position\n",
        "        current_position, current_direction = agent.position, agent.direction\n",
        "        if current_position is None: # Agent not added on map yet\n",
        "            current_position, current_direction = agent.initial_position, agent.initial_direction\n",
        "        \n",
        "        action = action_preprocessing.preprocess_moving_action(action, self.rail, current_position, current_direction)\n",
        "\n",
        "        # Check transitions, bounts for executing the action in the given position and directon\n",
        "        if action.is_moving_action() and not check_valid_action(action, self.rail, current_position, current_direction):\n",
        "            action = RailEnvActions.STOP_MOVING\n",
        "\n",
        "        return action\n",
        "    \n",
        "    def clear_rewards_dict(self):\n",
        "        \"\"\" Reset the rewards dictionary \"\"\"\n",
        "        self.rewards_dict = {i_agent: 0 for i_agent in range(len(self.agents))}\n",
        "\n",
        "    def get_info_dict(self):\n",
        "        \"\"\" \n",
        "        Returns dictionary of infos for all agents \n",
        "        dict_keys : action_required - \n",
        "                    malfunction - Counter value for malfunction > 0 means train is in malfunction\n",
        "                    speed - Speed of the train\n",
        "                    state - State from the trains's state machine\n",
        "        \"\"\"\n",
        "        info_dict = {\n",
        "            'action_required': {i: self.action_required(agent) for i, agent in enumerate(self.agents)},\n",
        "            'malfunction': {\n",
        "                i: agent.malfunction_handler.malfunction_down_counter for i, agent in enumerate(self.agents)\n",
        "            },\n",
        "            'speed': {i: agent.speed_counter.speed for i, agent in enumerate(self.agents)},\n",
        "            'state': {i: agent.state for i, agent in enumerate(self.agents)}\n",
        "        }\n",
        "        return info_dict\n",
        "    \n",
        "    def update_step_rewards(self, i_agent):\n",
        "        \"\"\"\n",
        "        Update the rewards dict for agent id i_agent for every timestep\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        action = self.agents[i_agent].action_saver.saved_action\n",
        "        moving = self.agents[i_agent].moving\n",
        "        state = self.agents[i_agent].state\n",
        "        \"\"\"\n",
        "        reward = None\n",
        "\n",
        "        reward = step_penality\n",
        "        \"\"\"\n",
        "        if action == RailEnvActions.REVERSE:\n",
        "            reward += reverse_penality\n",
        "        if not moving or state == TrainState.STOPPED:\n",
        "            reward += stop_penality\n",
        "        \"\"\"\n",
        "        self.rewards_dict[i_agent] += reward\n",
        "        \n",
        "    def calculate_train_run(self, timetable, i_agent, specific_station_index):\n",
        "        \"\"\"[Function to calculate a specific train run for a specific agent]\n",
        "\n",
        "        Args:\n",
        "            timetable ([list]): [Timetable]\n",
        "            i_agent ([int]): [i_agent]\n",
        "            specific_station_index ([int]): [Index of the station I want to calculate the train run in which is]\n",
        "        \"\"\"\n",
        "        all_train_run = timetable[i_agent][0]\n",
        "        all_times = timetable[i_agent][1]\n",
        "\n",
        "        previous_station = all_train_run[specific_station_index]\n",
        "        \n",
        "        specific_train_run_stations = []\n",
        "        specific_train_run_times = []\n",
        "        specific_train_run = []\n",
        "        train_run_initial_index = 0\n",
        "        \n",
        "        # Starting finding the first station\n",
        "        if specific_station_index != 0:\n",
        "            for station_reversed in range(specific_station_index + 1):                    \n",
        "                if all_train_run[specific_station_index - station_reversed - 1] == previous_station:\n",
        "                    initial_train_run_station = previous_station\n",
        "                    if station_reversed == 0:\n",
        "                        train_run_initial_index = specific_station_index\n",
        "                        initial_time = all_times[train_run_initial_index]\n",
        "                    else:\n",
        "                        train_run_initial_index = specific_station_index - station_reversed\n",
        "                        initial_time = all_times[train_run_initial_index]\n",
        "                    break\n",
        "                elif station_reversed == specific_station_index:\n",
        "                    initial_train_run_station = previous_station\n",
        "                    train_run_initial_index = specific_station_index - station_reversed\n",
        "                    initial_time = all_times[train_run_initial_index]\n",
        "                    break\n",
        "                else:\n",
        "                    previous_station = all_train_run[specific_station_index - station_reversed - 1] \n",
        "        # If I'm the first station...\n",
        "        else:\n",
        "            initial_train_run_station = previous_station\n",
        "            initial_time = all_times[0]\n",
        "        \n",
        "        previous_station = initial_train_run_station\n",
        "        previous_time = initial_time   \n",
        "        \n",
        "        for stations in range(1 , len(all_train_run)):\n",
        "            if previous_station == all_train_run[train_run_initial_index + stations]:\n",
        "                ending_train_run_station = previous_station\n",
        "                specific_train_run_stations.append(ending_train_run_station)\n",
        "                specific_train_run_times.append(all_times[train_run_initial_index + stations])\n",
        "                break\n",
        "            elif train_run_initial_index + stations == len(all_train_run):\n",
        "                ending_train_run_station = previous_station\n",
        "                specific_train_run_stations.append(ending_train_run_station)\n",
        "                specific_train_run_times.append(all_times[train_run_initial_index + stations])\n",
        "                break\n",
        "            else:\n",
        "                specific_train_run_stations.append(previous_station)\n",
        "                specific_train_run_times.append(previous_time)\n",
        "                previous_station = all_train_run[train_run_initial_index + stations]\n",
        "                previous_time = all_times[train_run_initial_index + stations]\n",
        "                if train_run_initial_index + stations == len(all_train_run) - 1:\n",
        "                    specific_train_run_stations.append(previous_station)\n",
        "                    specific_train_run_times.append(all_times[train_run_initial_index + stations])\n",
        "                    break\n",
        "        specific_train_run.append(specific_train_run_stations)\n",
        "        specific_train_run.append(specific_train_run_times)\n",
        "                \n",
        "        return specific_train_run\n",
        "    \n",
        "    def calculate_skip_penalty(self, timetable, index_of_station_skipped, station_skipped, time_scheduled,\n",
        "                               i_agent, station, train_type, specific_train_run):\n",
        "        \n",
        "        train_importance = train_type\n",
        "        station_importance = 0.7\n",
        "        #station_importance = station.importance   # TODO modificare !!!!\n",
        "        number_of_station_to_pass = len(specific_train_run)\n",
        "        \n",
        "        # array that have to contein all the possible passages from the skipped station for other agents (convoys)\n",
        "        possible_train_passage = []\n",
        "        \n",
        "        for i in range(len(timetable)):\n",
        "            if i != i_agent:\n",
        "                num_of_stations = len(timetable[i_agent][0])\n",
        "                for stations in range(num_of_stations - 1):\n",
        "                    if timetable[i][0][stations] == station_skipped:        # same station\n",
        "                        if timetable[i][1][stations] > time_scheduled:      # greater time, so the successive agent\n",
        "                            if timetable[i][0][stations + 1] == timetable[i_agent][0][index_of_station_skipped + 1]:   # same direction\n",
        "                                possible_train_passage.append(timetable[i][1][stations] - time_scheduled)\n",
        "        \n",
        "        if possible_train_passage == []:\n",
        "            penalty = - default_skip_penalty\n",
        "            return penalty\n",
        "            \n",
        "        else:\n",
        "            for i in range(len(possible_train_passage)):\n",
        "                delay = min(possible_train_passage)\n",
        "                \n",
        "            \n",
        "        penalty = - (delay*train_importance*station_importance)/number_of_station_to_pass\n",
        "        \n",
        "        return penalty\n",
        "    \n",
        "    def calculate_delay_penalty(self, delay, train_run, station, train_type):\n",
        "        \"\"\"[Calculate the penalty of the agent based on the delay, and weighted on the type of train, on the importance of the station and \n",
        "        on the number of stations reached by the train]\n",
        "\n",
        "        Args:\n",
        "            delay ([int]): [delay of the train in a specific station]\n",
        "            train_run ([list]): [specific train run i'm doing with my train]\n",
        "            station ([Station]): [station reached]\n",
        "            train_type ([convoy.type]): [type of the convoy (regional, intercity, high velocity)]\n",
        "        \"\"\"\n",
        "        number_of_station_to_pass = len(train_run) + 1     \n",
        "        \n",
        "        train_importance = train_type\n",
        "        #station_importance = station.importance\n",
        "        station_importance = 0.7  # TODO modificalo !!!!!\n",
        "        \n",
        "        penalty = - (delay*train_importance*station_importance)/number_of_station_to_pass\n",
        "        \n",
        "        return penalty\n",
        "\n",
        "    def end_of_episode_update(self, have_all_agents_ended, timetable):\n",
        "        \"\"\" \n",
        "        Updates made when episode ends\n",
        "        Parameters: have_all_agents_ended - Indicates if all agents have reached done state\n",
        "        \"\"\"\n",
        "        if have_all_agents_ended or \\\n",
        "           ( (self._max_episode_steps is not None) and (self._elapsed_steps >= self._max_episode_steps)):\n",
        "\n",
        "            for i_agent, agent in enumerate(self.agents):\n",
        "                \n",
        "                reward = self._handle_end_reward(agent, timetable)\n",
        "                self.rewards_dict[i_agent] += reward\n",
        "                \n",
        "                #self.dones[i_agent] = True\n",
        "\n",
        "            #self.dones[\"__all__\"] = True\n",
        "\n",
        "    def handle_done_state(self, agent):\n",
        "        \"\"\" Any updates to agent to be made in Done state \"\"\"\n",
        "        if agent.state == TrainState.DONE and agent.arrival_time is None:\n",
        "            agent.arrival_time = self._elapsed_steps\n",
        "            if self.remove_agents_at_target:\n",
        "                agent.position = None\n",
        "\n",
        "    def check_intermediate_station_passage(self, step, i_agent, timetable):\n",
        "            from operator import itemgetter\n",
        "            positions = self.cur_episode\n",
        "            if positions == []:\n",
        "                return\n",
        "            reward = 0\n",
        "            stations_to_pass = timetable[i_agent][0]\n",
        "\n",
        "            if positions[step - 1][i_agent] in stations_to_pass and positions[step - 1][i_agent] not in self.previous_station[i_agent]:\n",
        "\n",
        "                self.previous_station[i_agent].append(positions[step - 1][i_agent])\n",
        "                \n",
        "                reward += station_passage_reward\n",
        "\n",
        "                station_in_which_i_am = positions[step - 1][i_agent]\n",
        "\n",
        "                index = self.find_indices(timetable[i_agent][0], positions[step - 1][i_agent])\n",
        "                difference = []\n",
        "                for num_station in range(len(index)):\n",
        "                    difference.append(step - timetable[i_agent][1][index[num_station]])\n",
        "\n",
        "                index_of_min, value_of_min = min(enumerate(difference), key=itemgetter(1))\n",
        "                index_of_my_station = index[index_of_min]\n",
        "                \n",
        "                station = timetable[i_agent][0][index_of_my_station]\n",
        "                train_type = timetable[i_agent][2]\n",
        "                \n",
        "                specific_train_run = self.calculate_train_run(timetable, i_agent, index_of_my_station)\n",
        "                \n",
        "                index_of_my_station_for_my_train_run = specific_train_run[0].index(station)\n",
        "                \n",
        "                reward += self.calculate_delay_penalty(value_of_min, specific_train_run, station, train_type)\n",
        "\n",
        "                if index_of_my_station > 1:\n",
        "                    previous_stations = specific_train_run[0][0:index_of_my_station_for_my_train_run]\n",
        "                    flag_station_passed = [False] * (len(previous_stations) - 1)\n",
        "                    for past_positions in range(len(positions)):\n",
        "                        for i_previous_station in range(1, index_of_my_station):\n",
        "                            if positions[past_positions][i_agent] == timetable[i_agent][0][i_previous_station - 1]:\n",
        "                                self.rewards_dict[i_agent] += 0 \n",
        "                                flag_station_passed[i_previous_station - 1] = True\n",
        "                    \n",
        "                    for i_previous_station in range(len(flag_station_passed)):\n",
        "                        if not flag_station_passed[i_previous_station]: \n",
        "                            station_skipped = previous_stations[0][i_previous_station]\n",
        "                            time_scheduled_for_station = previous_stations[1][i_previous_station] \n",
        "                            reward += self.calculate_skip_penalty(timetable, index_of_my_station, station_skipped, \n",
        "                                                             time_scheduled_for_station, i_agent, station, train_type, specific_train_run)\n",
        "                    self.rewards_dict[i_agent] += reward\n",
        "                    return\n",
        "    \"\"\"\n",
        "    def intermediate_station_reward(self, convoy_i, timetable):\n",
        "        reward = 0\n",
        "        positions = self.cur_episode\n",
        "        passed_positions_convoy_i = [row[convoy_i] for row in positions]\n",
        "        i = 0\n",
        "        initial_station = timetable[convoy_i][0][0]\n",
        "        for station_i in timetable[convoy_i][0]:\n",
        "            if station_i == initial_station:\n",
        "                continue\n",
        "            for positions in passed_positions_convoy_i:\n",
        "                if station_i == positions:\n",
        "                    index = self.find_indices(timetable[convoy_i][0], station_i)\n",
        "                    for time_index in index: \n",
        "                        time_scheduled = timetable[convoy_i][1][time_index]\n",
        "                        time_difference = (time_scheduled - i)**2\n",
        "                        if time_difference == 0:\n",
        "                            time_difference = 1\n",
        "                        reward += station_passage_reward/time_difference\n",
        "                i += 1\n",
        "        return reward      \"\"\" \n",
        "\n",
        "    def step(self, action_dict_: Dict[int, RailEnvActions]):\n",
        "        \"\"\"\n",
        "        Updates rewards for the agents at a step.\n",
        "        \"\"\"\n",
        "        self._elapsed_steps += 1\n",
        "\n",
        "        # Not allowed to step further once done\n",
        "        if self.dones[\"__all__\"]:\n",
        "            raise Exception(\"Episode is done, cannot call step()\")\n",
        "\n",
        "        self.clear_rewards_dict()\n",
        "\n",
        "        have_all_agents_ended = True # Boolean flag to check if all agents are done\n",
        "\n",
        "        self.motionCheck = ac.MotionCheck()  # reset the motion check\n",
        "\n",
        "        temp_transition_data = {}\n",
        "        \n",
        "        for agent in self.agents:\n",
        "            i_agent = agent.handle\n",
        "\n",
        "            # Build info dict\n",
        "            rail, optionals = self.rail_generator(\n",
        "                self.width, self.height, self.number_of_agents, self.num_resets, self.np_random)\n",
        "\n",
        "            agent = self.agents[i_agent]\n",
        "\n",
        "            # Calculate velocities that the agents have to mantein\n",
        "            velocities = self.check_speed(optionals['agents_hints'])   # TODO variare velocità in base alla stazione da raggiungere     \n",
        "\n",
        "            agent.speed_counter.speed = velocities[i_agent]\n",
        "\n",
        "            # Starting time of the agent\n",
        "            starting_time = optionals['agents_hints']['timetable'][i_agent][1][0]\n",
        "            ending_time = optionals['agents_hints']['timetable'][i_agent][1][-1]\n",
        "\n",
        "            agent.earliest_departure = starting_time\n",
        "            agent.latest_arrival = ending_time\n",
        "\n",
        "            agent.old_position = agent.position\n",
        "            agent.old_direction = agent.direction\n",
        "            # Generate malfunction\n",
        "            agent.malfunction_handler.generate_malfunction(self.malfunction_generator, self.np_random)\n",
        "\n",
        "            # Get action for the agent\n",
        "            action = action_dict_.get(i_agent, RailEnvActions.DO_NOTHING)\n",
        "\n",
        "            preprocessed_action = self.preprocess_action(action, agent)\n",
        "\n",
        "            # Save moving actions in not already saved\n",
        "            agent.action_saver.save_action_if_allowed(preprocessed_action, agent.state)\n",
        "\n",
        "            # Train's next position can change if current stopped in a fractional speed or train is at cell's exit\n",
        "\n",
        "            position_update_allowed = agent.speed_counter.is_cell_exit and \\\n",
        "                        not agent.malfunction_handler.malfunction_down_counter > 0 and \\\n",
        "                        not preprocessed_action == RailEnvActions.STOP_MOVING                            \n",
        "\n",
        "            #position_update_allowed = (agent.speed_counter.is_cell_exit or agent.state == TrainState.STOPPED)\n",
        "\n",
        "            # Calculate new position\n",
        "            # Keep agent in same place if already done\n",
        "            if agent.state == TrainState.DONE:\n",
        "                new_position, new_direction = agent.position, agent.direction\n",
        "            elif agent.state == TrainState.MALFUNCTION:\n",
        "                new_position, new_direction = agent.position, agent.direction\n",
        "            # Add agent to the map if not on it yet\n",
        "            elif agent.position is None and agent.action_saver.is_action_saved:\n",
        "                new_position = agent.initial_position\n",
        "                new_direction = agent.initial_direction       \n",
        "            # If movement is allowed apply saved action independent of other agents\n",
        "            elif agent.action_saver.is_action_saved and position_update_allowed:\n",
        "                saved_action = agent.action_saver.saved_action\n",
        "                # Apply action independent of other agents and get temporary new position and direction\n",
        "                new_position, new_direction  = env_utils.apply_action_independent(saved_action, \n",
        "                                                                             self.rail, \n",
        "                                                                             agent.position, \n",
        "                                                                             agent.direction)\n",
        "                preprocessed_action = saved_action\n",
        "            else:\n",
        "                new_position, new_direction = agent.position, agent.direction\n",
        "\n",
        "            temp_transition_data[i_agent] = env_utils.AgentTransitionData(position=new_position,\n",
        "                                                                direction=new_direction,\n",
        "                                                                preprocessed_action=preprocessed_action)\n",
        "            \n",
        "            # This is for storing and later checking for conflicts of agents trying to occupy same cell                                                    \n",
        "            self.motionCheck.addAgent(i_agent, agent.position, new_position)\n",
        "\n",
        "        # Find conflicts between trains trying to occupy same cell  TODO controlla i bug\n",
        "        self.motionCheck.find_conflicts()\n",
        "        \n",
        "        for agent in self.agents:\n",
        "            i_agent = agent.handle\n",
        "\n",
        "            ## Update positions\n",
        "            if agent.malfunction_handler.in_malfunction:\n",
        "                movement_allowed = False\n",
        "            else:\n",
        "                # TODO check how the check motion is gestito, fai si che una reverse action sia sempre \n",
        "                # possibile ma attenzione quando c'è un treno vicino\n",
        "                movement_allowed = self.motionCheck.check_motion(i_agent, agent.position) \n",
        "\n",
        "\n",
        "            movement_inside_cell = agent.state == TrainState.STOPPED and not agent.speed_counter.is_cell_exit\n",
        "            movement_allowed = movement_allowed or movement_inside_cell\n",
        "\n",
        "            # Fetch the saved transition data\n",
        "            agent_transition_data = temp_transition_data[i_agent]\n",
        "            preprocessed_action = agent_transition_data.preprocessed_action\n",
        "\n",
        "            ## Update states\n",
        "            state_transition_signals = self.generate_state_transition_signals(agent, preprocessed_action, movement_allowed, ending_time)\n",
        "            agent.state_machine.set_transition_signals(state_transition_signals)\n",
        "            agent.state_machine.step()\n",
        "\n",
        "            # Needed when not removing agents at target\n",
        "            movement_allowed = movement_allowed and agent.state != TrainState.DONE\n",
        "\n",
        "            # Agent is being added to map\n",
        "            if agent.state.is_on_map_state():\n",
        "                if agent.state_machine.previous_state.is_off_map_state():\n",
        "                    agent.position = agent.initial_position\n",
        "                    agent.direction = agent.initial_direction\n",
        "            # Speed counter completes\n",
        "                elif movement_allowed and (agent.speed_counter.is_cell_exit):\n",
        "                    agent.position = agent_transition_data.position\n",
        "                    agent.direction = agent_transition_data.direction\n",
        "                    agent.state_machine.update_if_reached(agent.position, agent.target)\n",
        "\n",
        "            # Off map or on map state and position should match\n",
        "            env_utils.state_position_sync_check(agent.state, agent.position, agent.handle)\n",
        "                \n",
        "        self._update_agent_positions_map()\n",
        "        if self.record_steps:\n",
        "            self.record_timestep(action_dict_)\n",
        "            \n",
        "        for agent in self.agents:\n",
        "            \n",
        "            i_agent = agent.handle\n",
        "\n",
        "            ## Update rewards \n",
        "            if agent.state != TrainState.MALFUNCTION and agent.state.is_on_map_state:                           \n",
        "                self.update_step_rewards(i_agent)\n",
        "\n",
        "            # The if condition is important to avoid multiple penalties due to malfunctions occurred in stations\n",
        "            if agent.state != TrainState.MALFUNCTION and agent.state.is_on_map_state:\n",
        "                self.check_intermediate_station_passage(self._elapsed_steps, i_agent, optionals['agents_hints']['timetable'])\n",
        "                \n",
        "            # Handle done state actions, optionally remove agents\n",
        "            self.handle_done_state(agent)\n",
        "            \n",
        "            if training == 'training0':\n",
        "                if i_agent == 0:\n",
        "                    have_all_agents_ended &= (agent.state == TrainState.DONE)\n",
        "\n",
        "            elif training == 'training1' or training == 'training1.1':\n",
        "                if i_agent < 2:\n",
        "                    have_all_agents_ended &= (agent.state == TrainState.DONE)\n",
        "\n",
        "            else:\n",
        "                have_all_agents_ended &= (agent.state == TrainState.DONE)\n",
        "\n",
        "            ## Update counters (malfunction and speed)\n",
        "            agent.speed_counter.update_counter(agent.state, agent.old_position)\n",
        "                                            #    agent.state_machine.previous_state)\n",
        "            agent.malfunction_handler.update_counter()\n",
        "\n",
        "            # Clear old action when starting in new cell\n",
        "            if agent.speed_counter.is_cell_entry and agent.position is not None:\n",
        "                agent.action_saver.clear_saved_action()\n",
        "        \n",
        "        # Check if episode has ended and update rewards and dones\n",
        "        self.end_of_episode_update(have_all_agents_ended, optionals['agents_hints']['timetable'])\n",
        "\n",
        "        return self._get_observations(), self.rewards_dict, self.dones, self.get_info_dict() \n",
        "    \n",
        "\n",
        "\n",
        "    '''def record_timestep(self, dActions):\n",
        "                    \"\"\" \n",
        "                    Record the positions and orientations of all agents in memory, in the cur_episode\n",
        "                    \"\"\"\n",
        "                    list_agents_state = []\n",
        "                    for i_agent in range(self.get_num_agents()):\n",
        "                        agent = self.agents[i_agent]\n",
        "                        # the int cast is to avoid numpy types which may cause problems with msgpack\n",
        "                        # in env v2, agents may have position None, before starting\n",
        "                        if agent.position is None:\n",
        "                            pos = (0, 0)\n",
        "                        else:\n",
        "                            pos = (int(agent.position[0]), int(agent.position[1]))\n",
        "                        # print(\"pos:\", pos, type(pos[0]))\n",
        "                        list_agents_state.append([\n",
        "                                *pos, int(agent.direction), \n",
        "                                agent.malfunction_handler.malfunction_down_counter,  \n",
        "                                int(agent.state),\n",
        "                                int(agent.position in self.motionCheck.svDeadlocked)\n",
        "                                ])\n",
        "            \n",
        "                    self.cur_episode.append(list_agents_state)\n",
        "                    self.list_actions.append(dActions)'''\n",
        "\n",
        "    def record_timestep(self, dActions):\n",
        "        \"\"\" \n",
        "        Record the positions and orientations of all agents in memory, in the cur_episode\n",
        "        \"\"\"\n",
        "        list_agents_state = []\n",
        "        for i_agent in range(self.get_num_agents()):\n",
        "            agent = self.agents[i_agent]\n",
        "            # the int cast is to avoid numpy types which may cause problems with msgpack\n",
        "            # in env v2, agents may have position None, before starting\n",
        "            if agent.state == TrainState.DONE and not self.dones_for_position[i_agent]:\n",
        "                pos = agent.target\n",
        "                self.dones_for_position[i_agent] = True\n",
        "                \n",
        "            elif agent.state.is_off_map_state():\n",
        "                pos = (-1, 0) \n",
        "                \n",
        "            elif agent.position == None: \n",
        "                pos = (-1, 0)\n",
        "            else:\n",
        "                pos = (int(agent.position[0]), int(agent.position[1]))\n",
        "                \n",
        "            # print(\"pos:\", pos, type(pos[0]))\n",
        "            list_agents_state.append(pos)\n",
        "\n",
        "        self.cur_episode.append(list_agents_state)\n",
        "        self.list_actions.append(dActions)\n",
        "\n",
        "    def _get_observations(self):\n",
        "        \"\"\"\n",
        "        Utility which returns the dictionary of observations for an agent with respect to environment\n",
        "        \"\"\"\n",
        "        # print(f\"_get_obs - num agents: {self.get_num_agents()} {list(range(self.get_num_agents()))}\")\n",
        "        self.obs_dict = self.obs_builder.get_many(list(range(self.get_num_agents())))\n",
        "        return self.obs_dict\n",
        "\n",
        "    def get_valid_directions_on_grid(self, row: int, col: int) -> List[int]:\n",
        "        \"\"\"\n",
        "        Returns directions in which the agent can move\n",
        "        \"\"\"\n",
        "        return Grid4Transitions.get_entry_directions(self.rail.get_full_transitions(row, col))\n",
        "\n",
        "    def _exp_distirbution_synced(self, rate: float) -> float:\n",
        "        \"\"\"\n",
        "        Generates sample from exponential distribution\n",
        "        We need this to guarantee synchronity between different instances with same seed.\n",
        "        :param rate:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        u = self.np_random.rand()\n",
        "        x = - np.log(1 - u) * rate\n",
        "        return x\n",
        "\n",
        "    def _is_agent_ok(self, agent: EnvAgent) -> bool:\n",
        "        \"\"\"\n",
        "        Check if an agent is ok, meaning it can move and is not malfuncitoinig\n",
        "        Parameters\n",
        "        ----------\n",
        "        agent\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        True if agent is ok, False otherwise\n",
        "\n",
        "        \"\"\"\n",
        "        return agent.malfunction_handler.in_malfunction\n",
        "        \n",
        "\n",
        "    def save(self, filename):\n",
        "        print(\"DEPRECATED call to env.save() - pls call RailEnvPersister.save()\")\n",
        "        persistence.RailEnvPersister.save(self, filename)\n",
        "\n",
        "    def render(self, mode=\"rgb_array\", gl=\"PGL\", agent_render_variant=AgentRenderVariant.ONE_STEP_BEHIND,\n",
        "            show_debug=False, clear_debug_text=True, show=False,\n",
        "            screen_height=600, screen_width=800,\n",
        "            show_observations=False, show_predictions=False,\n",
        "            show_rowcols=False, return_image=True):\n",
        "        \"\"\"\n",
        "        This methods provides the option to render the\n",
        "        environment's behavior as an image or to a window.\n",
        "        Parameters\n",
        "        ----------\n",
        "        mode\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Image if mode is rgb_array, opens a window otherwise\n",
        "        \"\"\"\n",
        "        if not hasattr(self, \"renderer\") or self.renderer is None:\n",
        "            self.initialize_renderer(mode=mode, gl=gl,  # gl=\"TKPILSVG\",\n",
        "                                    agent_render_variant=agent_render_variant,\n",
        "                                    show_debug=show_debug,\n",
        "                                    clear_debug_text=clear_debug_text,\n",
        "                                    show=show,\n",
        "                                    screen_height=screen_height,  # Adjust these parameters to fit your resolution\n",
        "                                    screen_width=screen_width)\n",
        "        return self.update_renderer(mode=mode, show=show, show_observations=show_observations,\n",
        "                                    show_predictions=show_predictions,\n",
        "                                    show_rowcols=show_rowcols, return_image=return_image)\n",
        "\n",
        "    def initialize_renderer(self, mode, gl,\n",
        "                agent_render_variant,\n",
        "                show_debug,\n",
        "                clear_debug_text,\n",
        "                show,\n",
        "                screen_height,\n",
        "                screen_width):\n",
        "        # Initiate the renderer\n",
        "        self.renderer = RenderTool(self, gl=gl,  # gl=\"TKPILSVG\",\n",
        "                                agent_render_variant=agent_render_variant,\n",
        "                                show_debug=show_debug,\n",
        "                                clear_debug_text=clear_debug_text,\n",
        "                                screen_height=screen_height,  # Adjust these parameters to fit your resolution\n",
        "                                screen_width=screen_width)  # Adjust these parameters to fit your resolution\n",
        "        self.renderer.show = show\n",
        "        self.renderer.reset()\n",
        "\n",
        "    def update_renderer(self, mode, show, show_observations, show_predictions,\n",
        "                    show_rowcols, return_image):\n",
        "        \"\"\"\n",
        "        This method updates the render.\n",
        "        Parameters\n",
        "        ----------\n",
        "        mode\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Image if mode is rgb_array, None otherwise\n",
        "        \"\"\"\n",
        "        image = self.renderer.render_env(show=show, show_observations=show_observations,\n",
        "                                show_predictions=show_predictions,\n",
        "                                show_rowcols=show_rowcols, return_image=return_image)\n",
        "        if mode == 'rgb_array':\n",
        "            return image[:, :, :3]\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"\n",
        "        This methods closes any renderer window.\n",
        "        \"\"\"\n",
        "        if hasattr(self, \"renderer\") and self.renderer is not None:\n",
        "            try:\n",
        "                if self.renderer.show:\n",
        "                    self.renderer.close_window()\n",
        "            except Exception as e:\n",
        "                print(\"Could Not close window due to:\",e)\n",
        "            self.renderer = None\n",
        "\n",
        "\n",
        "    def check_speed(self, agents_hints):\n",
        "\n",
        "    # Velocity depending on the train type and on the line (Take the minimum between the two possible velocities)\n",
        "        train_velocities = [0]*self.number_of_agents\n",
        "\n",
        "        # Check for all the agents\n",
        "        for i_agent, agent in enumerate(self.agents):\n",
        "\n",
        "            # the i_agent\n",
        "            agent = self.agents[i_agent]\n",
        "\n",
        "            # Check if the agent is in the environment or not\n",
        "            if agent.position != None:\n",
        "\n",
        "                # If the agent is in the line i the max velocity is x\n",
        "\n",
        "                # High velocity line case\n",
        "                if (agent.position in av_line):  \n",
        "                    train_velocities[i_agent] = min(1, agents_hints['timetable'][i_agent][2])                \n",
        "                # Regional line case\n",
        "                else:\n",
        "                    train_velocities[i_agent] = min(1/2, agents_hints['timetable'][i_agent][2])\n",
        "\n",
        "            # If agent is not in the environment deafault velocity is 1/2\n",
        "            else:\n",
        "                train_velocities[i_agent] = 1/2\n",
        "\n",
        "        return train_velocities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_SDC43AZXBw"
      },
      "source": [
        "# Simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HpZdeKva-43"
      },
      "source": [
        "Timer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yjH2BFlbAHQ"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer\n",
        "\n",
        "\n",
        "class Timer(object):\n",
        "    \"\"\"\n",
        "    Utility to measure times.\n",
        "\n",
        "    TODO:\n",
        "    - add \"lap\" method to make it easier to measure average time (+std) when measuring the same thing multiple times.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.total_time = 0.0\n",
        "        self.start_time = 0.0\n",
        "        self.end_time = 0.0\n",
        "\n",
        "    def start(self):\n",
        "        self.start_time = default_timer()\n",
        "\n",
        "    def end(self):\n",
        "        self.total_time += default_timer() - self.start_time\n",
        "\n",
        "    def get(self):\n",
        "        return self.total_time\n",
        "\n",
        "    def get_current(self):\n",
        "        return default_timer() - self.start_time\n",
        "\n",
        "    def reset(self):\n",
        "        self.__init__()\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.get()\n",
        "\n",
        "import numpy as np\n",
        "from flatland.envs.observations import TreeObsForRailEnv\n",
        "\n",
        "def max_lt(seq, val):\n",
        "    \"\"\"\n",
        "    Return greatest item in seq for which item < val applies.\n",
        "    None is returned if seq was empty or all items in seq were >= val.\n",
        "    \"\"\"\n",
        "    max = 0\n",
        "    idx = len(seq) - 1\n",
        "    while idx >= 0:\n",
        "        if seq[idx] < val and seq[idx] >= 0 and seq[idx] > max:\n",
        "            max = seq[idx]\n",
        "        idx -= 1\n",
        "    return max\n",
        "\n",
        "\n",
        "def min_gt(seq, val):\n",
        "    \"\"\"\n",
        "    Return smallest item in seq for which item > val applies.\n",
        "    None is returned if seq was empty or all items in seq were >= val.\n",
        "    \"\"\"\n",
        "    min = np.inf\n",
        "    idx = len(seq) - 1\n",
        "    while idx >= 0:\n",
        "        if seq[idx] >= val and seq[idx] < min:\n",
        "            min = seq[idx]\n",
        "        idx -= 1\n",
        "    return min\n",
        "\n",
        "\n",
        "def norm_obs_clip(obs, clip_min=-1, clip_max=1, fixed_radius=0, normalize_to_range=False):\n",
        "    \"\"\"\n",
        "    This function returns the difference between min and max value of an observation\n",
        "    :param obs: Observation that should be normalized\n",
        "    :param clip_min: min value where observation will be clipped\n",
        "    :param clip_max: max value where observation will be clipped\n",
        "    :return: returnes normalized and clipped observatoin\n",
        "    \"\"\"\n",
        "    if fixed_radius > 0:\n",
        "        max_obs = fixed_radius\n",
        "    else:\n",
        "        max_obs = max(1, max_lt(obs, 1000)) + 1\n",
        "\n",
        "    min_obs = 0  # min(max_obs, min_gt(obs, 0))\n",
        "    if normalize_to_range:\n",
        "        min_obs = min_gt(obs, 0)\n",
        "    if min_obs > max_obs:\n",
        "        min_obs = max_obs\n",
        "    if max_obs == min_obs:\n",
        "        return np.clip(np.array(obs) / max_obs, clip_min, clip_max)\n",
        "    norm = np.abs(max_obs - min_obs)\n",
        "    return np.clip((np.array(obs) - min_obs) / norm, clip_min, clip_max)\n",
        "\n",
        "\n",
        "def _split_node_into_feature_groups(node) -> (np.ndarray, np.ndarray, np.ndarray):\n",
        "    data = np.zeros(6)\n",
        "    distance = np.zeros(1)\n",
        "    agent_data = np.zeros(4)\n",
        "\n",
        "    data[0] = node.dist_own_target_encountered\n",
        "    data[1] = node.dist_other_target_encountered\n",
        "    data[2] = node.dist_other_agent_encountered\n",
        "    data[3] = node.dist_potential_conflict\n",
        "    data[4] = node.dist_unusable_switch\n",
        "    data[5] = node.dist_to_next_branch\n",
        "\n",
        "    distance[0] = node.dist_min_to_target\n",
        "\n",
        "    agent_data[0] = node.num_agents_same_direction\n",
        "    agent_data[1] = node.num_agents_opposite_direction\n",
        "    agent_data[2] = node.num_agents_malfunctioning\n",
        "    agent_data[3] = node.speed_min_fractional\n",
        "\n",
        "    return data, distance, agent_data\n",
        "\n",
        "\n",
        "def _split_subtree_into_feature_groups(node, current_tree_depth: int, max_tree_depth: int) -> (np.ndarray, np.ndarray, np.ndarray):\n",
        "    if node == -np.inf:\n",
        "        remaining_depth = max_tree_depth - current_tree_depth\n",
        "        # reference: https://stackoverflow.com/questions/515214/total-number-of-nodes-in-a-tree-data-structure\n",
        "        num_remaining_nodes = int((4 ** (remaining_depth + 1) - 1) / (4 - 1))\n",
        "        return [-np.inf] * num_remaining_nodes * 6, [-np.inf] * num_remaining_nodes, [-np.inf] * num_remaining_nodes * 4\n",
        "\n",
        "    data, distance, agent_data = _split_node_into_feature_groups(node)\n",
        "\n",
        "    if not node.childs:\n",
        "        return data, distance, agent_data\n",
        "\n",
        "    for direction in TreeObsForRailEnv.tree_explored_actions_char:\n",
        "        sub_data, sub_distance, sub_agent_data = _split_subtree_into_feature_groups(node.childs[direction], current_tree_depth + 1, max_tree_depth)\n",
        "        data = np.concatenate((data, sub_data))\n",
        "        distance = np.concatenate((distance, sub_distance))\n",
        "        agent_data = np.concatenate((agent_data, sub_agent_data))\n",
        "\n",
        "    return data, distance, agent_data\n",
        "\n",
        "\n",
        "def split_tree_into_feature_groups(tree, max_tree_depth: int) -> (np.ndarray, np.ndarray, np.ndarray):\n",
        "    \"\"\"\n",
        "    This function splits the tree into three difference arrays of values\n",
        "    \"\"\"\n",
        "    data, distance, agent_data = _split_node_into_feature_groups(tree)\n",
        "\n",
        "    for direction in TreeObsForRailEnv.tree_explored_actions_char:\n",
        "        sub_data, sub_distance, sub_agent_data = _split_subtree_into_feature_groups(tree.childs[direction], 1, max_tree_depth)\n",
        "        data = np.concatenate((data, sub_data))\n",
        "        distance = np.concatenate((distance, sub_distance))\n",
        "        agent_data = np.concatenate((agent_data, sub_agent_data))\n",
        "\n",
        "    return data, distance, agent_data\n",
        "\n",
        "\n",
        "def normalize_observation(observation, tree_depth: int, observation_radius=0):\n",
        "    \"\"\"\n",
        "    This function normalizes the observation used by the RL algorithm\n",
        "    \"\"\"\n",
        "    data, distance, agent_data = split_tree_into_feature_groups(observation, tree_depth)\n",
        "\n",
        "    data = norm_obs_clip(data, fixed_radius=observation_radius)\n",
        "    distance = norm_obs_clip(distance, normalize_to_range=True)\n",
        "    agent_data = np.clip(agent_data, -1, 1)\n",
        "    normalized_obs = np.concatenate((np.concatenate((data, distance)), agent_data))\n",
        "    return normalized_obs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuASmxBLbk1K"
      },
      "source": [
        "## RL Utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLEtssE_rVNF",
        "outputId": "70a266ce-9354-41fc-b7bb-bd5fb2d177cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: torch-0.4.1-cp36-cp36m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n",
            "\u001b[31mERROR: torch-0.4.0-{platform}-linux_x86_64.whl is not a valid wheel filename.\u001b[0m\n",
            "Torch 1.10.0+cu111 CUDA 11.1\n",
            "Device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# http://pytorch.org/\n",
        "from os import path\n",
        "!pip3 install http://download.pytorch.org/whl/cu92/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "\n",
        "!pip install --upgrade --force-reinstall -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "\n",
        "import torch\n",
        "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
        "print('Device:', torch.device('cuda:0'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZVhjovKbnwa",
        "outputId": "c06a1f7c-9441-4c0e-dc5c-cb194e2d8e26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  \"\"\"\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "from collections import namedtuple, deque, Iterable\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DuelingQNetwork(nn.Module):\n",
        "    \"\"\"Dueling Q-network (https://arxiv.org/abs/1511.06581)\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, hidsize1=128, hidsize2=128):\n",
        "        super(DuelingQNetwork, self).__init__()\n",
        "\n",
        "        # value network\n",
        "        self.fc1_val = nn.Linear(state_size, hidsize1)\n",
        "        self.fc2_val = nn.Linear(hidsize1, hidsize2)\n",
        "        self.fc4_val = nn.Linear(hidsize2, 1)\n",
        "\n",
        "        # advantage network\n",
        "        self.fc1_adv = nn.Linear(state_size, hidsize1)\n",
        "        self.fc2_adv = nn.Linear(hidsize1, hidsize2)\n",
        "        self.fc4_adv = nn.Linear(hidsize2, action_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        val = F.relu(self.fc1_val(x))\n",
        "        val = F.relu(self.fc2_val(val))\n",
        "        val = self.fc4_val(val)\n",
        "\n",
        "        # advantage calculation\n",
        "        adv = F.relu(self.fc1_adv(x))\n",
        "        adv = F.relu(self.fc2_adv(adv))\n",
        "        adv = self.fc4_adv(adv)\n",
        "\n",
        "        return val + adv - adv.mean()\n",
        "\n",
        "class Policy:\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def save(self, filename):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def load(self, filename):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class DDDQNPolicy(Policy):\n",
        "    \"\"\"Dueling Double DQN policy\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, action_size, parameters, evaluation_mode=False):\n",
        "        self.evaluation_mode = evaluation_mode\n",
        "\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.double_dqn = True\n",
        "        self.hidsize = 1\n",
        "\n",
        "        if not evaluation_mode:\n",
        "            self.hidsize = parameters.hidden_size\n",
        "            self.buffer_size = parameters.buffer_size\n",
        "            self.batch_size = parameters.batch_size\n",
        "            self.update_every = parameters.update_every\n",
        "            self.learning_rate = parameters.learning_rate\n",
        "            self.tau = parameters.tau\n",
        "            self.gamma = parameters.gamma\n",
        "            self.buffer_min_size = parameters.buffer_min_size\n",
        "\n",
        "        # Device\n",
        "        if parameters.use_gpu and torch.cuda.is_available():\n",
        "            self.device = torch.device(\"cuda:0\")\n",
        "            # print(\"🐇 Using GPU\")\n",
        "        else:\n",
        "            self.device = torch.device(\"cpu\")\n",
        "            # print(\"🐢 Using CPU\")\n",
        "\n",
        "        # Q-Network\n",
        "        self.qnetwork_local = DuelingQNetwork(state_size, action_size, hidsize1=self.hidsize, hidsize2=self.hidsize).to(self.device)\n",
        "\n",
        "        if not evaluation_mode:\n",
        "            self.qnetwork_target = copy.deepcopy(self.qnetwork_local)\n",
        "            self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=self.learning_rate)\n",
        "            self.memory = ReplayBuffer(action_size, self.buffer_size, self.batch_size, self.device)\n",
        "\n",
        "            self.t_step = 0\n",
        "            self.loss = 0.0\n",
        "\n",
        "    def act(self, state, eps=0.):\n",
        "        state = torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
        "        self.qnetwork_local.eval()\n",
        "        with torch.no_grad():\n",
        "            action_values = self.qnetwork_local(state)\n",
        "        self.qnetwork_local.train()\n",
        "\n",
        "        # Epsilon-greedy action selection\n",
        "        if random.random() > eps:\n",
        "            return np.argmax(action_values.cpu().data.numpy())\n",
        "        else:\n",
        "            return random.choice(np.arange(self.action_size))\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        assert not self.evaluation_mode, \"Policy has been initialized for evaluation only.\"\n",
        "\n",
        "        # Save experience in replay memory\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "\n",
        "        # Learn every UPDATE_EVERY time steps.\n",
        "        self.t_step = (self.t_step + 1) % self.update_every\n",
        "        if self.t_step == 0:\n",
        "            # If enough samples are available in memory, get random subset and learn\n",
        "            if len(self.memory) > self.buffer_min_size and len(self.memory) > self.batch_size:\n",
        "                self._learn()\n",
        "\n",
        "    def _learn(self):\n",
        "        experiences = self.memory.sample()\n",
        "        states, actions, rewards, next_states, dones = experiences\n",
        "\n",
        "        # Get expected Q values from local model\n",
        "        q_expected = self.qnetwork_local(states).gather(1, actions)\n",
        "\n",
        "        if self.double_dqn:\n",
        "            # Double DQN\n",
        "            q_best_action = self.qnetwork_local(next_states).max(1)[1]\n",
        "            q_targets_next = self.qnetwork_target(next_states).gather(1, q_best_action.unsqueeze(-1))\n",
        "        else:\n",
        "            # DQN\n",
        "            q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(-1)\n",
        "\n",
        "        # Compute Q targets for current states\n",
        "        q_targets = rewards + (self.gamma * q_targets_next * (1 - dones))\n",
        "\n",
        "        # Compute loss\n",
        "        self.loss = F.mse_loss(q_expected, q_targets)\n",
        "\n",
        "        # Minimize the loss\n",
        "        self.optimizer.zero_grad()\n",
        "        self.loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Update target network\n",
        "        self._soft_update(self.qnetwork_local, self.qnetwork_target, self.tau)\n",
        "\n",
        "    def _soft_update(self, local_model, target_model, tau):\n",
        "        # Soft update model parameters.\n",
        "        # θ_target = τ*θ_local + (1 - τ)*θ_target\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)\n",
        "\n",
        "    def save(self, filename):\n",
        "        torch.save(self.qnetwork_local.state_dict(), filename + \".local\")\n",
        "        torch.save(self.qnetwork_target.state_dict(), filename + \".target\")\n",
        "\n",
        "    def load(self, filename):\n",
        "        if os.path.exists(filename + \".local\"):\n",
        "            self.qnetwork_local.load_state_dict(torch.load(filename + \".local\"))\n",
        "        if os.path.exists(filename + \".target\"):\n",
        "            self.qnetwork_target.load_state_dict(torch.load(filename + \".target\"))\n",
        "\n",
        "    def save_replay_buffer(self, filename):\n",
        "        memory = self.memory.memory\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(list(memory)[-500000:], f)\n",
        "\n",
        "    def load_replay_buffer(self, filename):\n",
        "        with open(filename, 'rb') as f:\n",
        "            self.memory.memory = pickle.load(f)\n",
        "\n",
        "    def test(self):\n",
        "        self.act(np.array([[0] * self.state_size]))\n",
        "        self._learn()\n",
        "\n",
        "\n",
        "Experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
        "\n",
        "    def __init__(self, action_size, buffer_size, batch_size, device):\n",
        "        \"\"\"Initialize a ReplayBuffer object.\n",
        "\n",
        "        Params\n",
        "        ======\n",
        "            action_size (int): dimension of each action\n",
        "            buffer_size (int): maximum size of buffer\n",
        "            batch_size (int): size of each training batch\n",
        "        \"\"\"\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=buffer_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        \"\"\"Add a new experience to memory.\"\"\"\n",
        "        e = Experience(np.expand_dims(state, 0), action, reward, np.expand_dims(next_state, 0), done)\n",
        "        self.memory.append(e)\n",
        "\n",
        "    def sample(self):\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "\n",
        "        states = torch.from_numpy(self.__v_stack_impr([e.state for e in experiences if e is not None])) \\\n",
        "            .float().to(self.device)\n",
        "        actions = torch.from_numpy(self.__v_stack_impr([e.action for e in experiences if e is not None])) \\\n",
        "            .long().to(self.device)\n",
        "        rewards = torch.from_numpy(self.__v_stack_impr([e.reward for e in experiences if e is not None])) \\\n",
        "            .float().to(self.device)\n",
        "        next_states = torch.from_numpy(self.__v_stack_impr([e.next_state for e in experiences if e is not None])) \\\n",
        "            .float().to(self.device)\n",
        "        dones = torch.from_numpy(self.__v_stack_impr([e.done for e in experiences if e is not None]).astype(np.uint8)) \\\n",
        "            .float().to(self.device)\n",
        "\n",
        "        return states, actions, rewards, next_states, dones\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the current size of internal memory.\"\"\"\n",
        "        return len(self.memory)\n",
        "\n",
        "    def __v_stack_impr(self, states):\n",
        "        sub_dim = len(states[0][0]) if isinstance(states[0], Iterable) else 1\n",
        "        np_states = np.reshape(np.array(states), (len(states), sub_dim))\n",
        "        return np_states\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMZuh-ENcPpx"
      },
      "source": [
        "## Network Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JIixnrEcK7i"
      },
      "outputs": [],
      "source": [
        "\n",
        "from argparse import ArgumentParser, Namespace\n",
        "import sys\n",
        "sys.argv=['']\n",
        "del sys\n",
        "\n",
        "\n",
        "parser = ArgumentParser()\n",
        "parser.add_argument(\"-n\", \"--n_episodes\", help=\"number of episodes to run\", default=2500, type=int)\n",
        "parser.add_argument(\"-t\", \"--training_env_config\", help=\"training config id (eg 0 for Test_0)\", default=0, type=int)\n",
        "parser.add_argument(\"-e\", \"--evaluation_env_config\", help=\"evaluation config id (eg 0 for Test_0)\", default=0, type=int)\n",
        "parser.add_argument(\"--n_evaluation_episodes\", help=\"number of evaluation episodes\", default=25, type=int)\n",
        "parser.add_argument(\"--checkpoint_interval\", help=\"checkpoint interval\", default=100, type=int)\n",
        "parser.add_argument(\"--eps_start\", help=\"max exploration\", default=1.0, type=float)\n",
        "parser.add_argument(\"--eps_end\", help=\"min exploration\", default=0.01, type=float)\n",
        "parser.add_argument(\"--eps_decay\", help=\"exploration decay\", default=0.99, type=float)\n",
        "parser.add_argument(\"--buffer_size\", help=\"replay buffer size\", default=int(1e5), type=int)\n",
        "parser.add_argument(\"--buffer_min_size\", help=\"min buffer size to start training\", default=0, type=int)\n",
        "parser.add_argument(\"--restore_replay_buffer\", help=\"replay buffer to restore\", default=\"\", type=str)\n",
        "parser.add_argument(\"--save_replay_buffer\", help=\"save replay buffer at each evaluation interval\", default=False, type=bool)\n",
        "parser.add_argument(\"--batch_size\", help=\"minibatch size\", default=128, type=int)\n",
        "parser.add_argument(\"--gamma\", help=\"discount factor\", default=0.99, type=float)\n",
        "parser.add_argument(\"--tau\", help=\"soft update of target parameters\", default=1e-3, type=float)\n",
        "parser.add_argument(\"--learning_rate\", help=\"learning rate\", default=0.5e-4, type=float)\n",
        "parser.add_argument(\"--hidden_size\", help=\"hidden size (2 fc layers)\", default=128, type=int)\n",
        "parser.add_argument(\"--update_every\", help=\"how often to update the network\", default=8, type=int)\n",
        "parser.add_argument(\"--use_gpu\", help=\"use GPU if available\", default=True, type=bool)\n",
        "parser.add_argument(\"--num_threads\", help=\"number of threads PyTorch can use\", default=1, type=int)\n",
        "parser.add_argument(\"--render\", help=\"render 1 episode in 100\", default=False, type=bool)\n",
        "parser.add_argument(\"--track\", help=\"whether to track using wandb\", default=False, type=bool)\n",
        "training_params = parser.parse_args()\n",
        "\n",
        "\n",
        "obs_params = {\n",
        "    \"observation_tree_depth\": 2,\n",
        "    \"observation_radius\": 10,\n",
        "    \"observation_max_path_depth\": 30\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsKfoyboORdc"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0uJ7VZYOUTA"
      },
      "outputs": [],
      "source": [
        "from typing import Type\n",
        "import numpy as np\n",
        "import os\n",
        "# Import the structures\n",
        "\n",
        "\n",
        "example_training = 'training0'\n",
        "'''\n",
        "###############################################################\n",
        "######################   EXAMPLE 1  #########################\n",
        "###############################################################\n",
        "'''\n",
        "\n",
        "if example_training == 1:\n",
        "\t# Import the examples\n",
        "\tfrom examples.new_example_1 import rail, railway_example, av_line\n",
        "\t# Define the stations\n",
        "\tquarto_station = Station('Quarto', position = (3, 2), capacity = 2, min_wait_time = [2, 2, 1], \n",
        "\t\tadditional_wait_percent = [0.5, 1, 1.5], importance = 80, railway_topology = rail)\n",
        "\tquinto_station = Station('Quinto', position = (3, 9), capacity = 2, min_wait_time = [2, 2, 1], \n",
        "\t\tadditional_wait_percent = [0.5, 1, 1.5], importance = 80, railway_topology = rail)\n",
        "\n",
        "\t# Define the rail connection beetween the two stations\n",
        "\tconnection_quarto_quinto = Rail_connection(station_a = quarto_station, \n",
        "\t\tstation_b = quinto_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\t# Define the lines\n",
        "\tgenova_urbana = Line(type_line = Connection_type.NORMAL_RAIL, \n",
        "\t\tstations = (quarto_station, quinto_station), stops = (1, 1))\n",
        "\n",
        "\tstations = []\n",
        "\tstations.append([quarto_station.position, 0.5])\n",
        "\tstations.append([quinto_station.position, 0.5])\n",
        "\n",
        "\tstations_objects = [quarto_station, quinto_station]\n",
        "\n",
        "\t# Define the train runs\n",
        "\ttrain_run_0 = Train_run(genova_urbana, starting_time = 3, from_depot = True)\n",
        "\ttrain_run_1 = Train_run(genova_urbana, starting_time = 10, from_depot = True, inverse_train_direction = True)\n",
        "\ttrain_run_2 = Train_run(genova_urbana, starting_time = 40, inverse_train_direction = True)\n",
        "\ttrain_run_3 = Train_run(genova_urbana, starting_time = 70)\n",
        "\n",
        "\t# Define the convoys\n",
        "\tR1079_convoy = Convoy( Type_of_convoy.INTERCITY)\n",
        "\tR1078_convoy = Convoy( Type_of_convoy.INTERCITY)\n",
        "\n",
        "\tconvoys = [R1079_convoy, R1078_convoy]\n",
        "\n",
        "\t# Adding the train runs to the convoys\n",
        "\tR1079_convoy.add_train_run(train_run_0)\n",
        "\tR1079_convoy.add_train_run(train_run_2)\n",
        "\tR1078_convoy.add_train_run(train_run_1)\n",
        "\tR1078_convoy.add_train_run(train_run_3)\n",
        "\n",
        "\t# Generating the timetable\n",
        "\t# The timetable is composed by (station positions, time at which reach the stations, maximum train velocity)\n",
        "\ttimetable_example = calculate_timetable(convoys, rail)\n",
        "\"\"\" \n",
        "\t# TODO crea una funzione (per ora non è una funzione, serve quella) per esportare le timetable come excel\n",
        "\tfrom pandas import DataFrame\n",
        "\timport pandas as pd\n",
        "\n",
        "\tdf_quarto = [0]* len(convoys)\n",
        "\tdf_quinto = [0]* len(convoys)\n",
        "\tdf = [0]* len(convoys)\n",
        "\tquarto = []\n",
        "\tquinto = []\n",
        "\tfor i in range(len(convoys)):\n",
        "\t\tfor j in range(len(stations_objects)):\n",
        "\t\t\tfor k in range(len(timetable_example[i][0])):\n",
        "\t\t\t\tif j == 0:\n",
        "\t\t\t\t\tif timetable_example[i][0][k] == stations_objects[j].position:\n",
        "\t\t\t\t\t\tquarto.append(timetable_example[i][1][k])\n",
        "\t\t\t\tif j == 1:\n",
        "\t\t\t\t\tif timetable_example[i][0][k] == stations_objects[j].position:\n",
        "\t\t\t\t\t\tquinto.append(timetable_example[i][1][k])\n",
        "\t\tdf_quarto[i] = DataFrame({stations_objects[0].name : quarto})\n",
        "\t\tdf_quinto[i]  = DataFrame({stations_objects[1].name : quinto})\n",
        "\t\tframes = [df_quarto[i], df_quinto[i]]\n",
        "\t\tdf[i] = pd.concat(frames, axis=1)\n",
        "\t\tquarto = []\n",
        "\t\tquinto = []\n",
        "\n",
        "\t\t# funtion\n",
        "\tdef multiple_dfs(df_list, sheets, file_name, spaces):\n",
        "\t    writer = pd.ExcelWriter(file_name, engine='xlsxwriter')   \n",
        "\t    row = 0\n",
        "\t    for dataframe in df_list:\n",
        "\t        dataframe.to_excel(writer,sheet_name=sheets,startrow=row , startcol=0)   \n",
        "\t        row = row + len(dataframe.index) + spaces + 1\n",
        "\t    writer.save()\n",
        "\n",
        "\t# run function\n",
        "\tos.makedirs(\"output/timetables\", exist_ok=True)\n",
        "\tmultiple_dfs(df, 'Validation', 'output/timetables/timetable_test_1.xlsx', 1)\"\"\"\n",
        "\n",
        "if example_training == 2:\n",
        "\t# Import the examples\n",
        "\tfrom examples.new_example_2 import rail, railway_example, av_line\n",
        "\n",
        "\t# Define the stations\n",
        "\t# TODO raagiona sul come definire meglio la capacità delle stazioni e gestire i binari....\n",
        "\tquarto_station = Station('Quarto', position = (6, 2), capacity = 5, min_wait_time = [2, 2, 1], \n",
        "\t\tadditional_wait_percent = [0.5, 1, 1.5], importance = 80, railway_topology = rail)\n",
        "\tquinto_station = Station('Quinto', position = (6, 17), capacity = 5, min_wait_time = [2, 2, 1], \n",
        "\t\tadditional_wait_percent = [0.5, 1, 1.5], importance = 80, railway_topology = rail)\n",
        "\n",
        "\n",
        "\t# Define the rail connection beetween the two stations\n",
        "\tconnection_quarto_quinto = Rail_connection(station_a = quarto_station, \n",
        "\t\tstation_b = quinto_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\n",
        "\t# Define the lines\n",
        "\tgenova_urbana = Line(type_line = Connection_type.NORMAL_RAIL, \n",
        "\t\tstations = (quarto_station, quinto_station), stops = (1, 1))\n",
        "\n",
        "\tstations = []\n",
        "\tstations.append([quarto_station.position, 0.5])\n",
        "\tstations.append([quinto_station.position, 0.5])\n",
        "\tstations_objects = [quarto_station, quinto_station]\n",
        "\n",
        "\t# Define the train runs\n",
        "\ttrain_run_0 = Train_run(genova_urbana, starting_time = 3, from_depot = True)\n",
        "\ttrain_run_1 = Train_run(genova_urbana, starting_time = 40, from_depot = True, inverse_train_direction = True)\n",
        " \n",
        "\ttrain_run_2 = Train_run(genova_urbana, starting_time = 55, inverse_train_direction = True)\n",
        " \n",
        "\ttrain_run_3 = Train_run(genova_urbana, starting_time = 20, from_depot = True)\n",
        "\ttrain_run_5 = Train_run(genova_urbana, starting_time = 70, inverse_train_direction = True, to_depot = True)\n",
        " \n",
        "\ttrain_run_4 = Train_run(genova_urbana, starting_time = 20, from_depot = True)\n",
        "\ttrain_run_6 = Train_run(genova_urbana, starting_time = 75, inverse_train_direction = True, to_depot = True)\n",
        "\n",
        "\t# Define the convoys\n",
        "\tR1079_convoy = Convoy( Type_of_convoy.INTERCITY)\n",
        "\tR1078_convoy = Convoy( Type_of_convoy.INTERCITY)\n",
        "\tR1077_convoy = Convoy( Type_of_convoy.INTERCITY)\n",
        "\n",
        "\t# SOME MODIFICATION TO STUDY TRAINING\n",
        "\t#R1076_convoy = Convoy( Type_of_convoy.INTERCITY)\n",
        "\n",
        "\tconvoys = [R1079_convoy, R1078_convoy, R1077_convoy] #, R1076_convoy]\n",
        "\n",
        "\t# Adding the train runs to the convoys\n",
        "\t# R1079\n",
        "\tR1079_convoy.add_train_run(train_run_0)\n",
        "\tR1079_convoy.add_train_run(train_run_2)\n",
        "\t# R1078\n",
        "\tR1078_convoy.add_train_run(train_run_1)\n",
        "\t# R1077\n",
        "\tR1077_convoy.add_train_run(train_run_3)\n",
        "\tR1077_convoy.add_train_run(train_run_5)\n",
        "\t# R1076\n",
        "\t#R1076_convoy.add_train_run(train_run_4)\n",
        "\n",
        "\t# Generating the timetable\n",
        "\t# The timetable is composed by (station positions, time at which reach the stations, maximum train velocity)\n",
        "\ttimetable_example = calculate_timetable(convoys, rail)\n",
        "\n",
        "'''\n",
        "###############################################################\n",
        "######################   EXAMPLE 3  #########################\n",
        "###############################################################\n",
        "'''\n",
        "\n",
        "if example_training == 3:\n",
        "\t# Import the examples\n",
        "\tfrom examples.new_example_3 import rail, railway_example, av_line\n",
        "\n",
        "\t# Define the stations\n",
        "\tgenova_station = Station('Genova', position = (21,2), capacity = 2, min_wait_time = [2, 2, 1], \n",
        "\t\tadditional_wait_percent = [0.5, 1, 1.5], importance = 80, railway_topology = rail)\n",
        "\tpavia_station = Station('Pavia', position = (21,18), capacity = 2, min_wait_time = [2, 2, 1],\n",
        "\t\tadditional_wait_percent = [0.5, 1, 1.5], importance = 80, railway_topology = rail)\n",
        "\tmilano_station = Station('Milano', position = (15,49), capacity = 2, min_wait_time = [2, 2, 1],\n",
        "\t\tadditional_wait_percent = [0.5, 1, 1.5], importance = 80, railway_topology = rail)\n",
        "\ttorino_station = Station('Torino', position = (9,1), capacity = 2, min_wait_time = [2, 2, 1],\n",
        "\t\tadditional_wait_percent = [0.5, 1, 1.5], importance = 80, railway_topology = rail)\n",
        "\tnovara_station = Station('Novara', position = (3,40), capacity = 2, min_wait_time = [2, 2, 1],\n",
        "\t\tadditional_wait_percent = [0.5, 1, 1.5], importance = 80, railway_topology = rail)\n",
        "\n",
        "\t# Define the connections between station\n",
        "\tconnection_genova_pavia = Rail_connection(station_a = genova_station, \n",
        "\t\tstation_b = pavia_station, rail_connection_type = Connection_type.HIGH_VELOCITY_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\tconnection_pavia_milano = Rail_connection(station_a = pavia_station, \n",
        "\t\tstation_b = milano_station, rail_connection_type = Connection_type.HIGH_VELOCITY_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\tconnection_genova_torino = Rail_connection(station_a = pavia_station, \n",
        "\t\tstation_b = milano_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\tconnection_torino_novara = Rail_connection(station_a = torino_station, \n",
        "\t\tstation_b = novara_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\tconnection_novara_pavia = Rail_connection(station_a = novara_station, \n",
        "\t\tstation_b = pavia_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\tconnection_torino_pavia = Rail_connection(station_a = torino_station, \n",
        "\t\tstation_b = pavia_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\t# Define the lines\n",
        "\tgenova_milano = Line(type_line = Connection_type.HIGH_VELOCITY_RAIL, \n",
        "\t\tstations = (genova_station, pavia_station, milano_station), stops = (1, 1, 1))\n",
        "\ttorino_milano = Line(type_line = Connection_type.NORMAL_RAIL, \n",
        "\t\tstations = (torino_station, novara_station, milano_station), stops = (1, 1, 1))\n",
        "\tgenova_torino = Line(type_line = Connection_type.NORMAL_RAIL, \n",
        "\t\tstations = (genova_station, torino_station), stops = (1, 1))\n",
        "\n",
        "\tstations = []\n",
        "\tstations.append([genova_station.position, 1])\n",
        "\tstations.append([pavia_station.position, 1])\n",
        "\tstations.append([milano_station.position, 1])\n",
        "\tstations.append([torino_station.position, 0.5])\n",
        "\tstations.append([novara_station.position, 0.5])\n",
        "\n",
        "\tstations_objects = [genova_station, pavia_station, milano_station, torino_station, novara_station]\n",
        "\n",
        "\t# Defining the train runs\n",
        "\t# convoy 1\n",
        "\ttrain_run_0 = Train_run(genova_milano, starting_time = 5, from_depot = True)\n",
        "\t# convoy 2\n",
        "\ttrain_run_1 = Train_run(genova_milano, starting_time = 7, from_depot = True, inverse_train_direction = True)\n",
        "\t# convoy 3\n",
        "\ttrain_run_2 = Train_run(torino_milano, starting_time = 12, from_depot = True)\n",
        "\t# convoy 4\n",
        "\ttrain_run_3 = Train_run(torino_milano, starting_time = 3, from_depot = True, inverse_train_direction = True)\n",
        "\t# convoy 5\n",
        "\ttrain_run_4 = Train_run(genova_torino, starting_time = 11, from_depot = True)\n",
        "\t# convoy 6\n",
        "\ttrain_run_5 = Train_run(genova_torino, starting_time = 20, from_depot = True, inverse_train_direction = True)\n",
        "\n",
        "\t# Define the convoysss\n",
        "\tFR1001_convoy = Convoy( Type_of_convoy.HIGH_VELOCITY)\n",
        "\tR1002_convoy = Convoy( Type_of_convoy.INTERCITY)\t\n",
        "\tR1003_convoy = Convoy( Type_of_convoy.INTERCITY)\n",
        "\tFR1004_convoy = Convoy( Type_of_convoy.HIGH_VELOCITY)\n",
        "\tR1005_convoy = Convoy( Type_of_convoy.INTERCITY)\n",
        "\tR1006_convoy = Convoy( Type_of_convoy.INTERCITY)\n",
        "\n",
        "\tconvoys = [FR1001_convoy, R1002_convoy, R1003_convoy, FR1004_convoy, R1005_convoy, R1006_convoy]\n",
        "\n",
        "\t# Add the train runs to convoys\n",
        "\tFR1001_convoy.add_train_run(train_run_0)\n",
        "\n",
        "\tR1002_convoy.add_train_run(train_run_1)\n",
        "\n",
        "\tR1003_convoy.add_train_run(train_run_2)\n",
        "\n",
        "\tFR1004_convoy.add_train_run(train_run_3)\n",
        "\n",
        "\tR1005_convoy.add_train_run(train_run_4)\n",
        "\n",
        "\tR1006_convoy.add_train_run(train_run_5)\n",
        "\n",
        "\t#Calculate plan to do\n",
        "\n",
        "\ttimetable_example = calculate_timetable(convoys, rail)\n",
        "\n",
        "'''\n",
        "###############################################################\n",
        "######################   EXAMPLE 0  #########################\n",
        "###############################################################\n",
        "'''\n",
        "\n",
        "if example_training == 0:\n",
        "\n",
        "\t# Import the examples\n",
        "\tfrom examples.esempio_prova import rail, railway_example, av_line\n",
        "\n",
        "\tstazione_prova = Station('Prova', position = (3,2), capacity = 1, min_wait_time = 1, additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\tstazione_prova_2 = Station('Prova 2', position = (3, 9), capacity = 1, min_wait_time = 1, additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\n",
        "\tconnection_prova = Rail_connection(station_a = stazione_prova, \n",
        "\t\tstation_b = stazione_prova_2, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\tlinea_prova = Line(type_line = Connection_type.NORMAL_RAIL, \n",
        "\t\tstations = (stazione_prova, stazione_prova_2), stops = (1, 1))\n",
        "\n",
        "\tstations = []\n",
        "\tstations.append([stazione_prova.position, 0.5])\n",
        "\tstations.append([stazione_prova_2.position, 0.5])\n",
        "\n",
        "\t# Define the train runs\n",
        "\ttrain_run_0 = Train_run(linea_prova, starting_time = 3, from_depot = True)\n",
        "\ttrain_run_1 = Train_run(linea_prova, starting_time = 40, from_depot = True, inverse_train_direction = True)\n",
        "\n",
        "\t# Define the convoys\n",
        "\tR1079_convoy = Convoy( Type_of_convoy.INTERCITY)\n",
        "\tR1078_convoy = Convoy( Type_of_convoy.INTERCITY)\n",
        "\n",
        "\tconvoys = [R1079_convoy, R1078_convoy]\n",
        "\n",
        "\t# Adding the train runs to the convoys\n",
        "\tR1079_convoy.add_train_run(train_run_0)\n",
        "\tR1078_convoy.add_train_run(train_run_1)\n",
        "\n",
        "\t# Generating the timetable\n",
        "\t# The timetable is composed by (station positions, time at which reach the stations, maximum train velocity)\n",
        "\ttimetable_example = calculate_timetable(convoys, rail)\n",
        "\n",
        "'''\n",
        "###############################################################\n",
        "######################   Training 0  #########################\n",
        "###############################################################\n",
        "'''\n",
        "\n",
        "if example_training == 'training0':\n",
        "\t# Import the examples\n",
        "\n",
        "\tgenova_station = Station('Genova', position = (6,2), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\trecco_station = Station('Recco', position = (6,13), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\tchiavari_station = Station('Chiavari', position = (6,23), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\n",
        "\tconnection_genova_recco = Rail_connection(station_a = genova_station, \n",
        "\t\tstation_b = recco_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\tconnection_recco_chiavari = Rail_connection(station_a = recco_station, \n",
        "\t\tstation_b = chiavari_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\tlinea_genova_levante = Line(type_line = Connection_type.NORMAL_RAIL, \n",
        "\t\tstations = (genova_station, recco_station, chiavari_station), stops = (1, 1, 1))\n",
        "\n",
        "\tstations = []\n",
        "\n",
        "\tstations.append([genova_station.position, 0.5])\n",
        "\tstations.append([recco_station.position, 0.5])\n",
        "\tstations.append([chiavari_station, 0.5])\n",
        "\n",
        "\ttrain_run_0 = Train_run(linea_genova_levante, starting_time = 3, from_depot = True)\n",
        "\n",
        "\tR102_convoy = Convoy(Type_of_convoy.INTERCITY)\n",
        "\n",
        "\tconvoys = [R102_convoy]\n",
        "\n",
        "\tR102_convoy.add_train_run(train_run_0)\n",
        "\n",
        "\ttimetable_example = calculate_timetable(convoys, rail)\n",
        "\n",
        "\t# Interruption\n",
        "\ttimetable_example.append([[(6,8), (6,13)],[1, 13], 0.5])\n",
        "\ttimetable_example.append([[(5,8), (5,13)],[1, 13], 0.5])\n",
        "\n",
        "\n",
        "'''\n",
        "###############################################################\n",
        "######################   Training 0.1 (FOUR STATIONS)  #########################\n",
        "###############################################################\n",
        "'''\n",
        "\n",
        "if example_training == 'training0.1':\n",
        "\t# Import the examples\n",
        "\tfrom examples.four_stations import rail, railway_example, av_line\n",
        "\n",
        "\tgenova_station = Station('Genova', position = (6,2), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\trecco_station = Station('Recco', position = (6,13), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\tchiavari_station = Station('Chiavari', position = (6,23), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "   \n",
        "\tspezia_station = Station('Spezia', position = (6,32),capacity=3, min_wait_time=[1,1,1],additional_wait_percent=1,importance=1, railway_topology = rail)\n",
        "\n",
        "\n",
        "\tconnection_genova_recco = Rail_connection(station_a = genova_station, \n",
        "\t\tstation_b = recco_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\tconnection_recco_chiavari = Rail_connection(station_a = recco_station, \n",
        "\t\tstation_b = chiavari_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\tconnection_chiavari_spezia = Rail_connection(station_a = chiavari_station,\n",
        "\t\tstation_b = spezia_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable=[0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\tlinea_genova_levante = Line(type_line = Connection_type.NORMAL_RAIL, \n",
        "\t\tstations = (genova_station, recco_station, chiavari_station, spezia_station), stops = (1, 1, 1, 1))\n",
        "\n",
        "\tstations = []\n",
        "\n",
        "\tstations.append([genova_station.position, 0.5])\n",
        "\tstations.append([recco_station.position, 0.5])\n",
        "\tstations.append([chiavari_station, 0.5])\n",
        "\n",
        "\tstations.append([spezia_station, 0.5])\t\n",
        "\n",
        "\ttrain_run_0 = Train_run(linea_genova_levante, starting_time = 3, from_depot = True)\n",
        "\n",
        "\tR102_convoy = Convoy(Type_of_convoy.INTERCITY)\n",
        "\n",
        "\tconvoys = [R102_convoy]\n",
        "\n",
        "\tR102_convoy.add_train_run(train_run_0)\n",
        "\n",
        "\ttimetable_example = calculate_timetable(convoys, rail)\n",
        "\n",
        "\t# Interruption\n",
        "\ttimetable_example.append([[(6,8), (6,11)],[1, 225], 0.5])\n",
        "\ttimetable_example.append([[(5,8), (5,11)],[1, 225], 0.5])\n",
        "\n",
        "\n",
        "'''\n",
        "###############################################################\n",
        "######################   Training 1  #########################\n",
        "###############################################################\n",
        "'''\n",
        "\n",
        "if example_training == 'training1':\n",
        "\t# Import the examples\n",
        "\tfrom examples.ferrovia_luca import rail, railway_example, av_line\n",
        "\n",
        "\tgenova_station = Station('Genova', position = (6,2), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\trecco_station = Station('Recco', position = (6,13), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\tchiavari_station = Station('Chiavari', position = (6,23), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\n",
        "\tconnection_genova_recco = Rail_connection(station_a = genova_station, \n",
        "\t\tstation_b = recco_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\tconnection_recco_chiavari = Rail_connection(station_a = recco_station, \n",
        "\t\tstation_b = chiavari_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\tlinea_genova_levante = Line(type_line = Connection_type.NORMAL_RAIL, \n",
        "\t\tstations = (genova_station, recco_station, chiavari_station), stops = (1, 1, 1))\n",
        "\n",
        "\tstations = []\n",
        "\n",
        "\tstations.append([genova_station.position, 0.5])\n",
        "\tstations.append([recco_station.position, 0.5])\n",
        "\tstations.append([chiavari_station, 0.5])\n",
        "\n",
        "\ttrain_run_0 = Train_run(linea_genova_levante, starting_time = 3, from_depot = True)\n",
        "\n",
        "\ttrain_run_1 = Train_run(linea_genova_levante, starting_time = 3, from_depot = True, inverse_train_direction = True)\n",
        "\n",
        "\tR102_convoy = Convoy(Type_of_convoy.INTERCITY)\n",
        "\tR103_convoy = Convoy(Type_of_convoy.INTERCITY)\n",
        "\n",
        "\tconvoys = [R102_convoy, R103_convoy]\n",
        "\n",
        "\tR102_convoy.add_train_run(train_run_0)\n",
        "\n",
        "\tR103_convoy.add_train_run(train_run_1)\n",
        "\n",
        "\ttimetable_example = calculate_timetable(convoys, rail)\n",
        "\n",
        "\t# Interruption\n",
        "\ttimetable_example.append([[(6,8), (6,11)],[1, 225], 0.5])\n",
        "\ttimetable_example.append([[(5,8), (5,11)],[1, 225], 0.5])\n",
        "\n",
        "\n",
        "'''\n",
        "###############################################################\n",
        "######################   Training 1.1  #########################\n",
        "###############################################################\n",
        "'''\n",
        "\n",
        "if example_training == 'training1.1':\n",
        "\t# Import the examples\n",
        "\tfrom examples.ferrovia_luca import rail, railway_example, av_line\n",
        "\n",
        "\tgenova_station = Station('Genova', position = (6,2), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\trecco_station = Station('Recco', position = (6,13), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\tchiavari_station = Station('Chiavari', position = (6,23), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\n",
        "\tconnection_genova_recco = Rail_connection(station_a = genova_station, \n",
        "\t\tstation_b = recco_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\tconnection_recco_chiavari = Rail_connection(station_a = recco_station, \n",
        "\t\tstation_b = chiavari_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\tlinea_genova_levante = Line(type_line = Connection_type.NORMAL_RAIL, \n",
        "\t\tstations = (genova_station, recco_station, chiavari_station), stops = (1, 1, 1))\n",
        "\n",
        "\tstations = []\n",
        "\n",
        "\tstations.append([genova_station.position, 0.5])\n",
        "\tstations.append([recco_station.position, 0.5])\n",
        "\tstations.append([chiavari_station, 0.5])\n",
        "\n",
        "\ttrain_run_0 = Train_run(linea_genova_levante, starting_time = 3, from_depot = True)\n",
        "\n",
        "\ttrain_run_1 = Train_run(linea_genova_levante, starting_time = 3, from_depot = True, inverse_train_direction = True)\n",
        "\n",
        "\tR102_convoy = Convoy(Type_of_convoy.INTERCITY)\n",
        "\tR103_convoy = Convoy(Type_of_convoy.INTERCITY)\n",
        "\n",
        "\tconvoys = [R102_convoy, R103_convoy]\n",
        "\n",
        "\tR102_convoy.add_train_run(train_run_0)\n",
        "\n",
        "\tR103_convoy.add_train_run(train_run_1)\n",
        "\n",
        "\ttimetable_example = calculate_timetable(convoys, rail)\n",
        "\n",
        "\t# Interruption\n",
        "\ttimetable_example.append([[(6,8), (6,11)],[1, 225], 0.5])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t'''\n",
        "###############################################################\n",
        "######################      DEBUG     #########################\n",
        "###############################################################\n",
        "'''\n",
        "\n",
        "if example_training == 'debug':\n",
        "\t# Import the examples\n",
        "\tfrom examples.ferrovia_luca import rail, railway_example, av_line\n",
        "\n",
        "\tgenova_station = Station('Genova', position = (6,2), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\trecco_station = Station('Recco', position = (6,13), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\tchiavari_station = Station('Chiavari', position = (6,23), capacity = 3, min_wait_time = [1, 1, 1], additional_wait_percent =1, importance = 1, railway_topology = rail)\n",
        "\n",
        "\tconnection_genova_recco = Rail_connection(station_a = genova_station, \n",
        "\t\tstation_b = recco_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\tconnection_recco_chiavari = Rail_connection(station_a = recco_station, \n",
        "\t\tstation_b = chiavari_station, rail_connection_type = Connection_type.NORMAL_RAIL,\n",
        "\t\tmax_speed_usable = [0.9, 0.6, 0.3], additional_runtime_percent = [0.1, 0.1, 0.1])\n",
        "\n",
        "\tlinea_genova_levante = Line(type_line = Connection_type.NORMAL_RAIL, \n",
        "\t\tstations = (genova_station, recco_station, chiavari_station), stops = (1, 1, 1))\n",
        "\n",
        "\tstations = []\n",
        "\n",
        "\tstations.append([genova_station.position, 0.5])\n",
        "\tstations.append([recco_station.position, 0.5])\n",
        "\tstations.append([chiavari_station, 0.5])\n",
        "\n",
        "\ttrain_run_0 = Train_run(linea_genova_levante, starting_time = 3, from_depot = True)\n",
        "\n",
        "\tR102_convoy = Convoy(Type_of_convoy.INTERCITY)\n",
        "\n",
        "\tconvoys = [R102_convoy]\n",
        "\n",
        "\tR102_convoy.add_train_run(train_run_0)\n",
        "\n",
        "\ttimetable_example = calculate_timetable(convoys, rail)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbIzu6GJhDLn"
      },
      "source": [
        "## Modified Files\n",
        "These files are modified from the real Flatland, so it's important to execute them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HCQuF5nhSGw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from flatland.envs.step_utils.states import TrainState\n",
        "\n",
        "class SpeedCounter:\n",
        "    def __init__(self, speed):\n",
        "        self._speed = speed\n",
        "        self.counter = None\n",
        "        self.reset_counter()\n",
        "\n",
        "    def update_counter(self, state, old_position):\n",
        "        # Can't start counting when adding train to the map\n",
        "        if state == TrainState.MOVING and old_position is not None:\n",
        "            self.counter += 1\n",
        "            self.counter = self.counter % (self.max_count + 1)\n",
        "\n",
        "            \n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"speed: {self.speed} \\\n",
        "                 max_count: {self.max_count} \\\n",
        "                 is_cell_entry: {self.is_cell_entry} \\\n",
        "                 is_cell_exit: {self.is_cell_exit} \\\n",
        "                 counter: {self.counter}\"\n",
        "\n",
        "    def reset_counter(self):\n",
        "        self.counter = 0\n",
        "\n",
        "    @property\n",
        "    def is_cell_entry(self):\n",
        "        return self.counter == 0\n",
        "\n",
        "    @property\n",
        "    def is_cell_exit(self):\n",
        "        return self.counter == self.max_count\n",
        "\n",
        "    @property\n",
        "    def speed(self):\n",
        "        return self._speed\n",
        "\n",
        "    @speed.setter\n",
        "    def speed(self, value):\n",
        "        self._speed = value\n",
        "\n",
        "    @property\n",
        "    def max_count(self):\n",
        "        return int(1/self._speed) - 1\n",
        "\n",
        "    def to_dict(self):\n",
        "        return {\"speed\": self._speed,\n",
        "                \"counter\": self.counter}\n",
        "    \n",
        "    def from_dict(self, load_dict):\n",
        "        self._speed = load_dict['speed']\n",
        "        self.counter = load_dict['counter']\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self._speed == other._speed and self.counter == other.counter\n",
        "\n",
        "class RailEnvActions(IntEnum):\n",
        "    DO_NOTHING = 0  # implies change of direction in a dead-end!\n",
        "    MOVE_LEFT = 1\n",
        "    MOVE_FORWARD = 2\n",
        "    MOVE_RIGHT = 3\n",
        "    STOP_MOVING = 4\n",
        "    REVERSE = 5\n",
        "\n",
        "    @staticmethod\n",
        "    def to_char(a: int):\n",
        "        return {\n",
        "            0: 'B',\n",
        "            1: 'L',\n",
        "            2: 'F',\n",
        "            3: 'R',\n",
        "            4: 'S',\n",
        "            5: 'I',\n",
        "        }[a]\n",
        "\n",
        "    @classmethod\n",
        "    def is_action_valid(cls, action):\n",
        "        return action in cls._value2member_map_\n",
        "\n",
        "    def is_moving_action(self):\n",
        "        return self.value in [self.MOVE_RIGHT, self.MOVE_LEFT, self.MOVE_FORWARD, self.REVERSE]\n",
        "\n",
        "\n",
        "from flatland.envs.rail_trainrun_data_structures import Waypoint\n",
        "import numpy as np\n",
        "import warnings\n",
        "\n",
        "from typing import Tuple, Optional, NamedTuple, List\n",
        "\n",
        "from attr import attr, attrs, attrib, Factory\n",
        "\n",
        "from flatland.core.grid.grid4 import Grid4TransitionsEnum\n",
        "from flatland.envs.timetable_utils import Line\n",
        "\n",
        "from flatland.envs.step_utils.action_saver import ActionSaver\n",
        "from flatland.envs.step_utils.state_machine import TrainStateMachine\n",
        "from flatland.envs.step_utils.states import TrainState\n",
        "from flatland.envs.step_utils.malfunction_handler import MalfunctionHandler\n",
        "\n",
        "Agent = NamedTuple('Agent', [('initial_position', Tuple[int, int]),\n",
        "                             ('initial_direction', Grid4TransitionsEnum),\n",
        "                             ('direction', Grid4TransitionsEnum),\n",
        "                             ('target', Tuple[int, int]),\n",
        "                             ('moving', bool),\n",
        "                             ('earliest_departure', int),\n",
        "                             ('latest_arrival', int),\n",
        "                             ('handle', int),\n",
        "                             ('position', Tuple[int, int]),\n",
        "                             ('arrival_time', int),\n",
        "                             ('old_direction', Grid4TransitionsEnum),\n",
        "                             ('old_position', Tuple[int, int]),\n",
        "                             ('speed_counter', SpeedCounter),\n",
        "                             ('action_saver', ActionSaver),\n",
        "                             ('state_machine', TrainStateMachine),\n",
        "                             ('malfunction_handler', MalfunctionHandler),\n",
        "                             ])\n",
        "\n",
        "\n",
        "def load_env_agent(agent_tuple: Agent):\n",
        "     return EnvAgent(\n",
        "                        initial_position = agent_tuple.initial_position,\n",
        "                        initial_direction = agent_tuple.initial_direction,\n",
        "                        direction = agent_tuple.direction,\n",
        "                        target = agent_tuple.target,\n",
        "                        moving = agent_tuple.moving,\n",
        "                        earliest_departure = agent_tuple.earliest_departure,\n",
        "                        latest_arrival = agent_tuple.latest_arrival,\n",
        "                        handle = agent_tuple.handle,\n",
        "                        position = agent_tuple.position,\n",
        "                        arrival_time = agent_tuple.arrival_time,\n",
        "                        old_direction = agent_tuple.old_direction,\n",
        "                        old_position = agent_tuple.old_position,\n",
        "                        speed_counter = agent_tuple.speed_counter,\n",
        "                        action_saver = agent_tuple.action_saver,\n",
        "                        state_machine = agent_tuple.state_machine,\n",
        "                        malfunction_handler = agent_tuple.malfunction_handler,\n",
        "                    )\n",
        "\n",
        "@attrs\n",
        "class EnvAgent:\n",
        "    # INIT FROM HERE IN _from_line()\n",
        "    initial_position = attrib(type=Tuple[int, int])\n",
        "    initial_direction = attrib(type=Grid4TransitionsEnum)\n",
        "    direction = attrib(type=Grid4TransitionsEnum)\n",
        "    target = attrib(type=Tuple[int, int])\n",
        "    moving = attrib(default=False, type=bool)\n",
        "\n",
        "    # NEW : EnvAgent - Schedule properties\n",
        "    earliest_departure = attrib(default=None, type=int)  # default None during _from_line()\n",
        "    latest_arrival = attrib(default=None, type=int)  # default None during _from_line()\n",
        "\n",
        "    handle = attrib(default=None)\n",
        "    # INIT TILL HERE IN _from_line()\n",
        "\n",
        "    # Env step facelift\n",
        "    speed_counter = attrib(default = Factory(lambda: SpeedCounter(1.0)), type=SpeedCounter)\n",
        "    action_saver = attrib(default = Factory(lambda: ActionSaver()), type=ActionSaver)\n",
        "    state_machine = attrib(default= Factory(lambda: TrainStateMachine(initial_state=TrainState.WAITING)) , \n",
        "                           type=TrainStateMachine)\n",
        "    malfunction_handler = attrib(default = Factory(lambda: MalfunctionHandler()), type=MalfunctionHandler)\n",
        "\n",
        "    position = attrib(default=None, type=Optional[Tuple[int, int]])\n",
        "\n",
        "    # NEW : EnvAgent Reward Handling\n",
        "    arrival_time = attrib(default=None, type=int)\n",
        "\n",
        "    # used in rendering\n",
        "    old_direction = attrib(default=None)\n",
        "    old_position = attrib(default=None)\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Resets the agents to their initial values of the episode. Called after ScheduleTime generation.\n",
        "        \"\"\"\n",
        "        self.position = None\n",
        "        # TODO: set direction to None: https://gitlab.aicrowd.com/flatland/flatland/issues/280\n",
        "        self.direction = self.initial_direction\n",
        "        self.old_position = None\n",
        "        self.old_direction = None\n",
        "        self.moving = False\n",
        "\n",
        "        self.malfunction_handler.reset()\n",
        "\n",
        "        self.action_saver.clear_saved_action()\n",
        "        self.speed_counter.reset_counter()\n",
        "        self.state_machine.reset()\n",
        "\n",
        "    def to_agent(self) -> Agent:\n",
        "        return Agent(initial_position=self.initial_position, \n",
        "                     initial_direction=self.initial_direction,\n",
        "                     direction=self.direction,\n",
        "                     target=self.target,\n",
        "                     moving=self.moving,\n",
        "                     earliest_departure=self.earliest_departure, \n",
        "                     latest_arrival=self.latest_arrival, \n",
        "                     handle=self.handle,\n",
        "                     position=self.position, \n",
        "                     old_direction=self.old_direction, \n",
        "                     old_position=self.old_position,\n",
        "                     speed_counter=self.speed_counter,\n",
        "                     action_saver=self.action_saver,\n",
        "                     arrival_time=self.arrival_time,\n",
        "                     state_machine=self.state_machine,\n",
        "                     malfunction_handler=self.malfunction_handler)\n",
        "\n",
        "    def get_shortest_path(self, distance_map) -> List[Waypoint]:\n",
        "        from flatland.envs.rail_env_shortest_paths import get_shortest_paths # Circular dep fix\n",
        "        return get_shortest_paths(distance_map=distance_map, agent_handle=self.handle)[self.handle]\n",
        "        \n",
        "    def get_travel_time_on_shortest_path(self, distance_map) -> int:\n",
        "        shortest_path = self.get_shortest_path(distance_map)\n",
        "        if shortest_path is not None:\n",
        "            distance = len(shortest_path)\n",
        "        else:\n",
        "            distance = 0\n",
        "        speed = self.speed_counter.speed\n",
        "        return int(np.ceil(distance / speed))\n",
        "\n",
        "    def get_time_remaining_until_latest_arrival(self, elapsed_steps: int) -> int:\n",
        "        return self.latest_arrival - elapsed_steps\n",
        "\n",
        "    def get_current_delay(self, elapsed_steps: int, distance_map) -> int:\n",
        "        '''\n",
        "        +ve if arrival time is projected before latest arrival\n",
        "        -ve if arrival time is projected after latest arrival\n",
        "        '''\n",
        "        return self.get_time_remaining_until_latest_arrival(elapsed_steps) - \\\n",
        "               self.get_travel_time_on_shortest_path(distance_map)\n",
        "\n",
        "\n",
        "    @classmethod\n",
        "    def from_line(cls, line: Line):\n",
        "        \"\"\" Create a list of EnvAgent from lists of positions, directions and targets\n",
        "        \"\"\"\n",
        "\n",
        "        #print(line.agent_directions)\n",
        "\n",
        "        num_agents = len(line.agent_positions)\n",
        "        \n",
        "        agent_list = []\n",
        "        for i_agent in range(num_agents):\n",
        "            speed = line.agent_speeds[i_agent] if line.agent_speeds is not None else 1.0\n",
        "            \n",
        "            agent = EnvAgent(initial_position = line.agent_positions[i_agent],\n",
        "                            initial_direction = line.agent_directions[i_agent],\n",
        "                            direction = line.agent_directions[i_agent],\n",
        "                            target = line.agent_targets[i_agent], \n",
        "                            moving = False, \n",
        "                            earliest_departure = None,\n",
        "                            latest_arrival = None,\n",
        "                            handle = i_agent,\n",
        "                            speed_counter = SpeedCounter(speed=speed))\n",
        "            agent_list.append(agent)\n",
        "\n",
        "        return agent_list\n",
        "\n",
        "    @classmethod\n",
        "    def load_legacy_static_agent(cls, static_agents_data: Tuple):\n",
        "        agents = []\n",
        "        for i, static_agent in enumerate(static_agents_data):\n",
        "            if len(static_agent) >= 6:\n",
        "                agent = EnvAgent(initial_position=static_agent[0], initial_direction=static_agent[1],\n",
        "                                direction=static_agent[1], target=static_agent[2], moving=static_agent[3],\n",
        "                                speed_counter=SpeedCounter(static_agent[4]['speed']), handle=i)\n",
        "            else:\n",
        "                agent = EnvAgent(initial_position=static_agent[0], initial_direction=static_agent[1],\n",
        "                                direction=static_agent[1], target=static_agent[2], \n",
        "                                moving=False,\n",
        "                                speed_counter=SpeedCounter(1.0),\n",
        "                                handle=i)\n",
        "            agents.append(agent)\n",
        "        return agents\n",
        "    \n",
        "    def __str__(self):\n",
        "        return f\"\\n \\\n",
        "                 handle(agent index): {self.handle} \\n \\\n",
        "                 initial_position: {self.initial_position}  \\n \\\n",
        "                 initial_direction: {self.initial_direction} \\n \\\n",
        "                 position: {self.position}  \\n \\\n",
        "                 direction: {self.direction}  \\n \\\n",
        "                 target: {self.target} \\n \\\n",
        "                 old_position: {self.old_position} \\n \\\n",
        "                 old_direction {self.old_direction} \\n \\\n",
        "                 earliest_departure: {self.earliest_departure}  \\n \\\n",
        "                 latest_arrival: {self.latest_arrival} \\n \\\n",
        "                 state: {str(self.state)} \\n \\\n",
        "                 malfunction_handler: {self.malfunction_handler} \\n \\\n",
        "                 action_saver: {self.action_saver} \\n \\\n",
        "                 speed_counter: {self.speed_counter}\"\n",
        "\n",
        "    @property\n",
        "    def state(self):\n",
        "        return self.state_machine.state\n",
        "\n",
        "    @state.setter\n",
        "    def state(self, state):\n",
        "        self._set_state(state)\n",
        "    \n",
        "    def _set_state(self, state):\n",
        "        warnings.warn(\"Not recommended to set the state with this function unless completely required\")\n",
        "        self.state_machine.set_state(state)\n",
        "\n",
        "    @property\n",
        "    def malfunction_data(self):\n",
        "        raise ValueError(\"agent.malunction_data is deprecated, please use agent.malfunction_hander instead\")\n",
        "\n",
        "    @property\n",
        "    def speed_data(self):\n",
        "        raise ValueError(\"agent.speed_data is deprecated, please use agent.speed_counter instead\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "TransitionMap and derived classes.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from importlib_resources import path\n",
        "from numpy import array\n",
        "\n",
        "from flatland.core.grid.grid4 import Grid4Transitions\n",
        "from flatland.core.grid.grid4_utils import get_new_position, get_direction\n",
        "from flatland.core.grid.grid_utils import IntVector2DArray, IntVector2D\n",
        "from flatland.core.grid.grid_utils import Vec2dOperations as Vec2d\n",
        "from flatland.core.grid.rail_env_grid import RailEnvTransitions\n",
        "from flatland.core.transitions import Transitions\n",
        "from flatland.utils.ordered_set import OrderedSet\n",
        "from flatland.core.grid.grid4 import Grid4TransitionsEnum\n",
        "\n",
        "\n",
        "# TODO are these general classes or for grid4 only?\n",
        "class TransitionMap:\n",
        "    \"\"\"\n",
        "    Base TransitionMap class.\n",
        "\n",
        "    Generic class that implements a collection of transitions over a set of\n",
        "    cells.\n",
        "    \"\"\"\n",
        "\n",
        "    def get_transitions(self, cell_id):\n",
        "        \"\"\"\n",
        "        Return a tuple of transitions available in a cell specified by\n",
        "        `cell_id` (e.g., a tuple of size of the maximum number of transitions,\n",
        "        with values 0 or 1, or potentially in between,\n",
        "        for stochastic transitions).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cell_id : [cell identifier]\n",
        "            The cell_id object depends on the specific implementation.\n",
        "            It generally is an int (e.g., an index) or a tuple of indices.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple\n",
        "            List of the validity of transitions in the cell.\n",
        "\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def set_transitions(self, cell_id, new_transitions):\n",
        "        \"\"\"\n",
        "        Replaces the available transitions in cell `cell_id` with the tuple\n",
        "        `new_transitions'. `new_transitions` must have\n",
        "        one element for each possible transition.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cell_id : [cell identifier]\n",
        "            The cell_id object depends on the specific implementation.\n",
        "            It generally is an int (e.g., an index) or a tuple of indices.\n",
        "        new_transitions : tuple\n",
        "            Tuple of new transitions validitiy for the cell.\n",
        "\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_transition(self, cell_id, transition_index):\n",
        "        \"\"\"\n",
        "        Return the status of whether an agent in cell `cell_id` can perform a\n",
        "        movement along transition `transition_index` (e.g., the NESW direction\n",
        "        of movement, for agents on a grid).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cell_id : [cell identifier]\n",
        "            The cell_id object depends on the specific implementation.\n",
        "            It generally is an int (e.g., an index) or a tuple of indices.\n",
        "        transition_index : int\n",
        "            Index of the transition to probe, as index in the tuple returned by\n",
        "            get_transitions(). e.g., the NESW direction of movement, for agents\n",
        "            on a grid.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        int or float (depending on Transitions used)\n",
        "            Validity of the requested transition (e.g.,\n",
        "            0/1 allowed/not allowed, a probability in [0,1], etc...)\n",
        "\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def set_transition(self, cell_id, transition_index, new_transition):\n",
        "        \"\"\"\n",
        "        Replaces the validity of transition to `transition_index` in cell\n",
        "        `cell_id' with the new `new_transition`.\n",
        "\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cell_id : [cell identifier]\n",
        "            The cell_id object depends on the specific implementation.\n",
        "            It generally is an int (e.g., an index) or a tuple of indices.\n",
        "        transition_index : int\n",
        "            Index of the transition to probe, as index in the tuple returned by\n",
        "            get_transitions(). e.g., the NESW direction of movement, for agents\n",
        "            on a grid.\n",
        "        new_transition : int or float (depending on Transitions used)\n",
        "            Validity of the requested transition (e.g.,\n",
        "            0/1 allowed/not allowed, a probability in [0,1], etc...)\n",
        "\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class GridTransitionMap(TransitionMap):\n",
        "    \"\"\"\n",
        "    Implements a TransitionMap over a 2D grid.\n",
        "\n",
        "    GridTransitionMap implements utility functions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, width, height, transitions: Transitions = Grid4Transitions([]), random_seed=None):\n",
        "        \"\"\"\n",
        "        Builder for GridTransitionMap object.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        width : int\n",
        "            Width of the grid.\n",
        "        height : int\n",
        "            Height of the grid.\n",
        "        transitions : Transitions object\n",
        "            The Transitions object to use to encode/decode transitions over the\n",
        "            grid.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.transitions = transitions\n",
        "        self.random_generator = np.random.RandomState()\n",
        "        if random_seed is None:\n",
        "            self.random_generator.seed(12)\n",
        "        else:\n",
        "            self.random_generator.seed(random_seed)\n",
        "        self.grid = np.zeros((height, width), dtype=self.transitions.get_type())\n",
        "\n",
        "    def get_full_transitions(self, row, column):\n",
        "        \"\"\"\n",
        "        Returns the full transitions for the cell at (row, column) in the format transition_map's transitions.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        row: int\n",
        "        column: int\n",
        "            (row,column) specifies the cell in this transition map.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self.transitions.get_type()\n",
        "            The cell content int the format of this map's Transitions.\n",
        "\n",
        "        \"\"\"\n",
        "        return self.grid[row][column]\n",
        "\n",
        "    def get_transitions(self, row, column, orientation):\n",
        "        \"\"\"\n",
        "        Return a tuple of transitions available in a cell specified by\n",
        "        `cell_id` (e.g., a tuple of size of the maximum number of transitions,\n",
        "        with values 0 or 1, or potentially in between,\n",
        "        for stochastic transitions).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cell_id : tuple\n",
        "            The cell_id indices a cell as (column, row, orientation),\n",
        "            where orientation is the direction an agent is facing within a cell.\n",
        "            Alternatively, it can be accessed as (column, row) to return the\n",
        "            full cell content.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple\n",
        "            List of the validity of transitions in the cell as given by the maps transitions.\n",
        "\n",
        "        \"\"\"\n",
        "        return self.transitions.get_transitions(self.grid[row][column], orientation)\n",
        "\n",
        "    def set_transitions(self, cell_id, new_transitions):\n",
        "        \"\"\"\n",
        "        Replaces the available transitions in cell `cell_id` with the tuple\n",
        "        `new_transitions'. `new_transitions` must have\n",
        "        one element for each possible transition.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cell_id : tuple\n",
        "            The cell_id indices a cell as (column, row, orientation),\n",
        "            where orientation is the direction an agent is facing within a cell.\n",
        "            Alternatively, it can be accessed as (column, row) to replace the\n",
        "            full cell content.\n",
        "        new_transitions : tuple\n",
        "            Tuple of new transitions validitiy for the cell.\n",
        "\n",
        "        \"\"\"\n",
        "        assert len(cell_id) in (2, 3), \\\n",
        "            'GridTransitionMap.set_transitions() ERROR: cell_id tuple must have length 2 or 3.'\n",
        "        if len(cell_id) == 3:\n",
        "            self.grid[cell_id[0]][cell_id[1]] = self.transitions.set_transitions(self.grid[cell_id[0]][cell_id[1]],\n",
        "                                                                                 cell_id[2],\n",
        "                                                                                 new_transitions)\n",
        "        elif len(cell_id) == 2:\n",
        "            self.grid[cell_id[0]][cell_id[1]] = new_transitions\n",
        "\n",
        "    def get_transition(self, cell_id, transition_index):\n",
        "        \"\"\"\n",
        "        Return the status of whether an agent in cell `cell_id` can perform a\n",
        "        movement along transition `transition_index` (e.g., the NESW direction\n",
        "        of movement, for agents on a grid).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cell_id : tuple\n",
        "            The cell_id indices a cell as (column, row, orientation),\n",
        "            where orientation is the direction an agent is facing within a cell.\n",
        "        transition_index : int\n",
        "            Index of the transition to probe, as index in the tuple returned by\n",
        "            get_transitions(). e.g., the NESW direction of movement, for agents\n",
        "            on a grid.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        int or float (depending on Transitions used in the )\n",
        "            Validity of the requested transition (e.g.,\n",
        "            0/1 allowed/not allowed, a probability in [0,1], etc...)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        assert len(cell_id) == 3, \\\n",
        "            'GridTransitionMap.get_transition() ERROR: cell_id tuple must have length 2 or 3.'\n",
        "        return self.transitions.get_transition(self.grid[cell_id[0]][cell_id[1]], cell_id[2], transition_index)\n",
        "\n",
        "    def set_transition(self, cell_id, transition_index, new_transition, remove_deadends=False):\n",
        "        \"\"\"\n",
        "        Replaces the validity of transition to `transition_index` in cell\n",
        "        `cell_id' with the new `new_transition`.\n",
        "\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cell_id : tuple\n",
        "            The cell_id indices a cell as (column, row, orientation),\n",
        "            where orientation is the direction an agent is facing within a cell.\n",
        "        transition_index : int\n",
        "            Index of the transition to probe, as index in the tuple returned by\n",
        "            get_transitions(). e.g., the NESW direction of movement, for agents\n",
        "            on a grid.\n",
        "        new_transition : int or float (depending on Transitions used in the map.)\n",
        "            Validity of the requested transition (e.g.,\n",
        "            0/1 allowed/not allowed, a probability in [0,1], etc...)\n",
        "\n",
        "        \"\"\"\n",
        "        assert len(cell_id) == 3, \\\n",
        "            'GridTransitionMap.set_transition() ERROR: cell_id tuple must have length 3.'\n",
        "        self.grid[cell_id[0]][cell_id[1]] = self.transitions.set_transition(\n",
        "            self.grid[cell_id[0]][cell_id[1]],\n",
        "            cell_id[2],\n",
        "            transition_index,\n",
        "            new_transition,\n",
        "            remove_deadends)\n",
        "\n",
        "    def save_transition_map(self, filename):\n",
        "        \"\"\"\n",
        "        Save the transitions grid as `filename`, in npy format.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        filename : string\n",
        "            Name of the file to which to save the transitions grid.\n",
        "\n",
        "        \"\"\"\n",
        "        np.save(filename, self.grid)\n",
        "\n",
        "    def load_transition_map(self, package, resource):\n",
        "        \"\"\"\n",
        "        Load the transitions grid from `filename` (npy format).\n",
        "        The load function only updates the transitions grid, and possibly width and height, but the object has to be\n",
        "        initialized with the correct `transitions` object anyway.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        package : string\n",
        "            Name of the package from which to load the transitions grid.\n",
        "        resource : string\n",
        "            Name of the file from which to load the transitions grid within the package.\n",
        "        override_gridsize : bool\n",
        "            If override_gridsize=True, the width and height of the GridTransitionMap object are replaced with the size\n",
        "            of the map loaded from `filename`. If override_gridsize=False, the transitions grid is either cropped (if\n",
        "            the grid size is larger than (height,width) ) or padded with zeros (if the grid size is smaller than\n",
        "            (height,width) )\n",
        "\n",
        "        \"\"\"\n",
        "        with path(package, resource) as file_in:\n",
        "            new_grid = np.load(file_in)\n",
        "\n",
        "        new_height = new_grid.shape[0]\n",
        "        new_width = new_grid.shape[1]\n",
        "\n",
        "        self.width = new_width\n",
        "        self.height = new_height\n",
        "        self.grid = new_grid\n",
        "\n",
        "    def is_dead_end(self, rcPos: IntVector2DArray):\n",
        "        \"\"\"\n",
        "        Check if the cell is a dead-end.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        rcPos: Tuple[int,int]\n",
        "            tuple(row, column) with grid coordinate\n",
        "        Returns\n",
        "        -------\n",
        "        boolean\n",
        "            True if and only if the cell is a dead-end.\n",
        "        \"\"\"\n",
        "        nbits = 0\n",
        "        tmp = self.get_full_transitions(rcPos[0], rcPos[1])\n",
        "        while tmp > 0:\n",
        "            nbits += (tmp & 1)\n",
        "            tmp = tmp >> 1\n",
        "        return nbits == 1\n",
        "\n",
        "    def is_simple_turn(self, rcPos: IntVector2DArray):\n",
        "        \"\"\"\n",
        "        Check if the cell is a left/right simple turn\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            rcPos: Tuple[int,int]\n",
        "                tuple(row, column) with grid coordinate\n",
        "        Returns\n",
        "        -------\n",
        "            boolean\n",
        "                True if and only if the cell is a left/right simple turn.\n",
        "        \"\"\"\n",
        "        tmp = self.get_full_transitions(rcPos[0], rcPos[1])\n",
        "\n",
        "        def is_simple_turn(trans):\n",
        "            all_simple_turns = OrderedSet()\n",
        "            for trans in [int('0100000000000010', 2),  # Case 1b (8)  - simple turn right\n",
        "                          int('0001001000000000', 2)  # Case 1c (9)  - simple turn left]:\n",
        "                          ]:\n",
        "                for _ in range(3):\n",
        "                    trans = self.transitions.rotate_transition(trans, rotation=90)\n",
        "                    all_simple_turns.add(trans)\n",
        "            return trans in all_simple_turns\n",
        "\n",
        "        return is_simple_turn(tmp)\n",
        "\n",
        "    def check_path_exists(self, start: IntVector2DArray, direction: int, end: IntVector2DArray):\n",
        "        \"\"\"\n",
        "        Breath first search for a possible path from one node with a certain orientation to a target node.\n",
        "        :param start: Start cell rom where we want to check the path\n",
        "        :param direction: Start direction for the path we are testing\n",
        "        :param end: Cell that we try to reach from the start cell\n",
        "        :return: True if a path exists, False otherwise\n",
        "        \"\"\"\n",
        "        visited = OrderedSet()\n",
        "        stack = [(start, direction)]\n",
        "        while stack:\n",
        "            node = stack.pop()\n",
        "            node_position = node[0]\n",
        "            node_direction = node[1]\n",
        "\n",
        "            if Vec2d.is_equal(node_position, end):\n",
        "                return True\n",
        "            if node not in visited:\n",
        "                visited.add(node)\n",
        "\n",
        "                moves = self.get_transitions(node_position[0], node_position[1], node_direction)\n",
        "                for move_index in range(4):\n",
        "                    if moves[move_index]:\n",
        "                        stack.append((get_new_position(node_position, move_index),\n",
        "                                      move_index))\n",
        "\n",
        "        return False\n",
        "\n",
        "    def cell_neighbours_valid(self, rcPos: IntVector2DArray, check_this_cell=False):\n",
        "        \"\"\"\n",
        "        Check validity of cell at rcPos = tuple(row, column)\n",
        "        Checks that:\n",
        "        - surrounding cells have inbound transitions for all the outbound transitions of this cell.\n",
        "\n",
        "        These are NOT checked - see transition.is_valid:\n",
        "        - all transitions have the mirror transitions (N->E <=> W->S)\n",
        "        - Reverse transitions (N -> S) only exist for a dead-end\n",
        "        - a cell contains either no dead-ends or exactly one\n",
        "\n",
        "        Returns: True (valid) or False (invalid)\n",
        "        \"\"\"\n",
        "        cell_transition = self.grid[tuple(rcPos)]\n",
        "\n",
        "        if check_this_cell:\n",
        "            if not self.transitions.is_valid(cell_transition):\n",
        "                return False\n",
        "\n",
        "        gDir2dRC = self.transitions.gDir2dRC  # [[-1,0] = N, [0,1]=E, etc]\n",
        "        grcPos = array(rcPos)\n",
        "        grcMax = self.grid.shape\n",
        "\n",
        "        binTrans = self.get_full_transitions(*rcPos)  # 16bit integer - all trans in/out\n",
        "        lnBinTrans = array([binTrans >> 8, binTrans & 0xff], dtype=np.uint8)  # 2 x uint8\n",
        "        g2binTrans = np.unpackbits(lnBinTrans).reshape(4, 4)  # 4x4 x uint8 binary(0,1)\n",
        "        gDirOut = g2binTrans.any(axis=0)  # outbound directions as boolean array (4)\n",
        "        giDirOut = np.argwhere(gDirOut)[:, 0]  # valid outbound directions as array of int\n",
        "\n",
        "        # loop over available outbound directions (indices) for rcPos\n",
        "        for iDirOut in giDirOut:\n",
        "            gdRC = gDir2dRC[iDirOut]  # row,col increment\n",
        "            gPos2 = grcPos + gdRC  # next cell in that direction\n",
        "\n",
        "            # Check the adjacent cell is within bounds\n",
        "            # if not, then this transition is invalid!\n",
        "            if np.any(gPos2 < 0):\n",
        "                return False\n",
        "            if np.any(gPos2 >= grcMax):\n",
        "                return False\n",
        "\n",
        "            # Get the transitions out of gPos2, using iDirOut as the inbound direction\n",
        "            # if there are no available transitions, ie (0,0,0,0), then rcPos is invalid\n",
        "            t4Trans2 = self.get_transitions(*gPos2, iDirOut)\n",
        "            if any(t4Trans2):\n",
        "                continue\n",
        "            else:\n",
        "                return False\n",
        "        # If the cell is empty but has incoming connections we return false\n",
        "        if binTrans < 1:\n",
        "            connected = 0\n",
        "\n",
        "            for iDirOut in np.arange(4):\n",
        "                gdRC = gDir2dRC[iDirOut]  # row,col increment\n",
        "                gPos2 = grcPos + gdRC  # next cell in that direction\n",
        "\n",
        "                # Check the adjacent cell is within bounds\n",
        "                # if not, then ignore it for the count of incoming connections\n",
        "                if np.any(gPos2 < 0):\n",
        "                    continue\n",
        "                if np.any(gPos2 >= grcMax):\n",
        "                    continue\n",
        "\n",
        "                # Get the transitions out of gPos2, using iDirOut as the inbound direction\n",
        "                # if there are no available transitions, ie (0,0,0,0), then rcPos is invalid\n",
        "\n",
        "                for orientation in range(4):\n",
        "                    connected += self.get_transition((gPos2[0], gPos2[1], orientation), mirror(iDirOut))\n",
        "            if connected > 0:\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def fix_neighbours(self, rcPos: IntVector2DArray, check_this_cell=False):\n",
        "        \"\"\"\n",
        "        Check validity of cell at rcPos = tuple(row, column)\n",
        "        Checks that:\n",
        "        - surrounding cells have inbound transitions for all the outbound transitions of this cell.\n",
        "\n",
        "        These are NOT checked - see transition.is_valid:\n",
        "        - all transitions have the mirror transitions (N->E <=> W->S)\n",
        "        - Reverse transitions (N -> S) only exist for a dead-end\n",
        "        - a cell contains either no dead-ends or exactly one\n",
        "\n",
        "        Returns: True (valid) or False (invalid)\n",
        "        \"\"\"\n",
        "        cell_transition = self.grid[tuple(rcPos)]\n",
        "\n",
        "        if check_this_cell:\n",
        "            if not self.transitions.is_valid(cell_transition):\n",
        "                return False\n",
        "\n",
        "        gDir2dRC = self.transitions.gDir2dRC  # [[-1,0] = N, [0,1]=E, etc]\n",
        "        grcPos = array(rcPos)\n",
        "        grcMax = self.grid.shape\n",
        "\n",
        "        binTrans = self.get_full_transitions(*rcPos)  # 16bit integer - all trans in/out\n",
        "        lnBinTrans = array([binTrans >> 8, binTrans & 0xff], dtype=np.uint8)  # 2 x uint8\n",
        "        g2binTrans = np.unpackbits(lnBinTrans).reshape(4, 4)  # 4x4 x uint8 binary(0,1)\n",
        "        gDirOut = g2binTrans.any(axis=0)  # outbound directions as boolean array (4)\n",
        "        giDirOut = np.argwhere(gDirOut)[:, 0]  # valid outbound directions as array of int\n",
        "\n",
        "        # loop over available outbound directions (indices) for rcPos\n",
        "        for iDirOut in giDirOut:\n",
        "            gdRC = gDir2dRC[iDirOut]  # row,col increment\n",
        "            gPos2 = grcPos + gdRC  # next cell in that direction\n",
        "\n",
        "            # Check the adjacent cell is within bounds\n",
        "            # if not, then this transition is invalid!\n",
        "            if np.any(gPos2 < 0):\n",
        "                return False\n",
        "            if np.any(gPos2 >= grcMax):\n",
        "                return False\n",
        "\n",
        "            # Get the transitions out of gPos2, using iDirOut as the inbound direction\n",
        "            # if there are no available transitions, ie (0,0,0,0), then rcPos is invalid\n",
        "            t4Trans2 = self.get_transitions(*gPos2, iDirOut)\n",
        "            if any(t4Trans2):\n",
        "                continue\n",
        "            else:\n",
        "                self.set_transition((gPos2[0], gPos2[1], iDirOut), mirror(iDirOut), 1)\n",
        "                return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    def fix_transitions(self, rcPos: IntVector2DArray, direction: IntVector2D = -1):\n",
        "        \"\"\"\n",
        "        Fixes broken transitions\n",
        "        \"\"\"\n",
        "        gDir2dRC = self.transitions.gDir2dRC  # [[-1,0] = N, [0,1]=E, etc]\n",
        "        grcPos = array(rcPos)\n",
        "        grcMax = self.grid.shape\n",
        "        # Transition elements\n",
        "        transitions = RailEnvTransitions()\n",
        "        cells = transitions.transition_list\n",
        "        simple_switch_east_south = transitions.rotate_transition(cells[10], 90)\n",
        "        simple_switch_west_south = transitions.rotate_transition(cells[2], 270)\n",
        "        symmetrical = cells[6]\n",
        "        double_slip = cells[5]\n",
        "        three_way_transitions = [simple_switch_east_south, simple_switch_west_south]\n",
        "        # loop over available outbound directions (indices) for rcPos\n",
        "\n",
        "        incoming_connections = np.zeros(4)\n",
        "        for iDirOut in np.arange(4):\n",
        "            gdRC = gDir2dRC[iDirOut]  # row,col increment\n",
        "            gPos2 = grcPos + gdRC  # next cell in that direction\n",
        "\n",
        "            # Check the adjacent cell is within bounds\n",
        "            # if not, then ignore it for the count of incoming connections\n",
        "            if np.any(gPos2 < 0):\n",
        "                continue\n",
        "            if np.any(gPos2 >= grcMax):\n",
        "                continue\n",
        "\n",
        "            # Get the transitions out of gPos2, using iDirOut as the inbound direction\n",
        "            # if there are no available transitions, ie (0,0,0,0), then rcPos is invalid\n",
        "            connected = 0\n",
        "            for orientation in range(4):\n",
        "                connected += self.get_transition((gPos2[0], gPos2[1], orientation), mirror(iDirOut))\n",
        "            if connected > 0:\n",
        "                incoming_connections[iDirOut] = 1\n",
        "\n",
        "        number_of_incoming = np.sum(incoming_connections)\n",
        "        # Only one incoming direction --> Straight line set deadend\n",
        "        if number_of_incoming == 1:\n",
        "            if self.get_full_transitions(*rcPos) == 0:\n",
        "                self.set_transitions(rcPos, 0)\n",
        "            else:\n",
        "                self.set_transitions(rcPos, 0)\n",
        "\n",
        "                for direction in range(4):\n",
        "                    if incoming_connections[direction] > 0:\n",
        "                        self.set_transition((rcPos[0], rcPos[1], mirror(direction)), direction, 1)\n",
        "        # Connect all incoming connections\n",
        "        if number_of_incoming == 2:\n",
        "            self.set_transitions(rcPos, 0)\n",
        "\n",
        "            connect_directions = np.argwhere(incoming_connections > 0)\n",
        "            self.set_transition((rcPos[0], rcPos[1], mirror(connect_directions[0])), connect_directions[1], 1)\n",
        "            self.set_transition((rcPos[0], rcPos[1], mirror(connect_directions[1])), connect_directions[0], 1)\n",
        "\n",
        "        # Find feasible connection for three entries\n",
        "        if number_of_incoming == 3:\n",
        "            self.set_transitions(rcPos, 0)\n",
        "            hole = np.argwhere(incoming_connections < 1)[0][0]\n",
        "            if direction >= 0:\n",
        "                switch_type_idx = (direction - hole + 3) % 4\n",
        "                if switch_type_idx == 0:\n",
        "                    transition = simple_switch_west_south\n",
        "                elif switch_type_idx == 2:\n",
        "                    transition = simple_switch_east_south\n",
        "                else:\n",
        "                    transition = self.random_generator.choice(three_way_transitions, 1)\n",
        "            else:\n",
        "                transition = self.random_generator.choice(three_way_transitions, 1)\n",
        "            transition = transitions.rotate_transition(transition, int(hole * 90))\n",
        "            self.set_transitions((rcPos[0], rcPos[1]), transition)\n",
        "\n",
        "        # Make a double slip switch\n",
        "        if number_of_incoming == 4:\n",
        "            rotation = self.random_generator.randint(2)\n",
        "            transition = transitions.rotate_transition(double_slip, int(rotation * 90))\n",
        "            self.set_transitions((rcPos[0], rcPos[1]), transition)\n",
        "        return True\n",
        "\n",
        "    def validate_new_transition(self, prev_pos: IntVector2D, current_pos: IntVector2D,\n",
        "                                new_pos: IntVector2D, end_pos: IntVector2D):\n",
        "        \"\"\"\n",
        "        Utility function to test that a path drawn by a-start algorithm uses valid transition objects.\n",
        "        We us this to quide a-star as there are many transition elements that are not allowed in RailEnv\n",
        "\n",
        "        :param prev_pos: The previous position we were checking\n",
        "        :param current_pos: The current position we are checking\n",
        "        :param new_pos: Possible child position we move into\n",
        "        :param end_pos: End cell of path we are drawing\n",
        "        :return: True if the transition is valid, False if transition element is illegal\n",
        "        \"\"\"\n",
        "        # start by getting direction used to get to current node\n",
        "        # and direction from current node to possible child node\n",
        "        new_dir = get_direction(current_pos, new_pos)\n",
        "        if prev_pos is not None:\n",
        "            current_dir = get_direction(prev_pos, current_pos)\n",
        "        else:\n",
        "            current_dir = new_dir\n",
        "        # create new transition that would go to child\n",
        "        new_trans = self.grid[current_pos]\n",
        "        if prev_pos is None:\n",
        "            if new_trans == 0:\n",
        "                # need to flip direction because of how end points are defined\n",
        "                new_trans = self.transitions.set_transition(new_trans, mirror(current_dir), new_dir, 1)\n",
        "            else:\n",
        "                # check if matches existing layout\n",
        "                new_trans = self.transitions.set_transition(new_trans, current_dir, new_dir, 1)\n",
        "        else:\n",
        "            # set the forward path\n",
        "            new_trans = self.transitions.set_transition(new_trans, current_dir, new_dir, 1)\n",
        "            # set the backwards path\n",
        "            new_trans = self.transitions.set_transition(new_trans, mirror(new_dir), mirror(current_dir), 1)\n",
        "        if Vec2d.is_equal(new_pos, end_pos):\n",
        "            # need to validate end pos setup as well\n",
        "            new_trans_e = self.grid[end_pos]\n",
        "            if new_trans_e == 0:\n",
        "                # need to flip direction because of how end points are defined\n",
        "                new_trans_e = self.transitions.set_transition(new_trans_e, new_dir, mirror(new_dir), 1)\n",
        "            else:\n",
        "                # check if matches existing layout\n",
        "                new_trans_e = self.transitions.set_transition(new_trans_e, new_dir, new_dir, 1)\n",
        "\n",
        "            if not self.transitions.is_valid(new_trans_e):\n",
        "                return False\n",
        "\n",
        "        # is transition is valid?\n",
        "        return self.transitions.is_valid(new_trans)\n",
        "\n",
        "    # Function to check if a transition is possible/valide or the train/agent can't go there\n",
        "    def check_transition_is_possible(self, previous_position, current_position, new_position):\n",
        "        # Finding direction of the agent\n",
        "\n",
        "        #print(left_rails, right_rails)\n",
        "\n",
        "        new_dir = get_direction(current_position, new_position)\n",
        "        if previous_position is not None:\n",
        "            current_dir = get_direction(previous_position, current_position)\n",
        "        else:\n",
        "            current_dir = new_dir\n",
        "\n",
        "        # checking the possible transitions\n",
        "        # EXAMPLE OF RESULT OF THE FUNCTION\n",
        "        # \n",
        "        #  [0, 1, 1, 0]   \n",
        "        #   N  E  S  W\n",
        "        transitions = self.get_transitions(current_position[0], current_position[1], current_dir)\n",
        "        #print(previous_position, current_position, transitions,)\n",
        "        \n",
        "        # Transition to NORD valid?\n",
        "        if (new_position[0] == (current_position[0] - 1)) and (transitions[0] == 1):\n",
        "            if new_dir  == Grid4TransitionsEnum.NORTH:\n",
        "                if new_position in down_rails:\n",
        "                    return False\n",
        "            return True\n",
        "        # Transition to EAST valid?\n",
        "        if (new_position[1] == (current_position[1] + 1)) and (transitions[1] == 1):\n",
        "            if new_dir  == Grid4TransitionsEnum.EAST:\n",
        "                if new_position in left_rails:\n",
        "                    return False\n",
        "            return True\n",
        "        # Transition to SUD valid?\n",
        "        if (new_position[0] == (current_position[0] + 1)) and (transitions[2] == 1):\n",
        "            if new_dir  == Grid4TransitionsEnum.SOUTH:\n",
        "                if new_position in up_rails:\n",
        "                    return False\n",
        "            return True\n",
        "        # Transition to WEST valid?\n",
        "        if (new_position[1] == (current_position[1] - 1)) and (transitions[3] == 1):\n",
        "            if new_dir  == Grid4TransitionsEnum.WEST:\n",
        "                if new_position in right_rails:\n",
        "                    return False\n",
        "            return True\n",
        "        else:\n",
        "            return False \n",
        "\n",
        "def mirror(dir):\n",
        "    return (dir + 2) % 4\n",
        "# TODO: improvement override __getitem__ and __setitem__ (cell contents, not transitions?)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1G5loAfPIi_"
      },
      "source": [
        "\n",
        "## Simulation import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi0nPdXHZzXU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# In Flatland you can use custom observation builders and predicitors\n",
        "# Observation builders generate the observation needed by the controller\n",
        "# Preditctors can be used to do short time prediction which can help in avoiding conflicts in the network\n",
        "from flatland.envs.malfunction_generators import malfunction_from_params, MalfunctionParameters, ParamMalfunctionGen\n",
        "from flatland.envs.observations import TreeObsForRailEnv, GlobalObsForRailEnv\n",
        "# Import the railway generators\n",
        "from flatland.utils.rendertools import RenderTool, AgentRenderVariant\n",
        "# Import the agent class\n",
        "from flatland.envs.step_utils.states import TrainState\n",
        "from flatland.envs.predictions import ShortestPathPredictorForRailEnv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D9FmbZM78L3"
      },
      "source": [
        "## Simulation Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9biEfh5q8AVd"
      },
      "outputs": [],
      "source": [
        "obs_params = {\n",
        "    \"observation_tree_depth\": 2,\n",
        "    \"observation_radius\": 10,\n",
        "    \"observation_max_path_depth\": 30\n",
        "}\n",
        "\n",
        "training_flag = example_training\n",
        "\n",
        "###### TRAINING PARAMETERS #######\n",
        "n_episodes = 20000\n",
        "eps_start = 1\n",
        "eps_end = 0.01\n",
        "eps_decay = 0.99\n",
        "max_steps = 250     # 1440 one day\n",
        "checkpoint_interval = 100\n",
        "training_id = '0' \n",
        "render = False\n",
        "\n",
        "######### FLAGS ##########\n",
        "# Flag for the first training\n",
        "training_flag = example_training\n",
        "# Flag active in case of interruptions\n",
        "interruption = True\n",
        "# Flag to select the agent ----> multi agent or external controller\n",
        "multi_agent = True\n",
        "# Flag to save the video or not\n",
        "video_save = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai4RdjiP8NHB"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmxJfjM2qTJH"
      },
      "outputs": [],
      "source": [
        "# Check the maximum possible delay...180 not good for now\n",
        "def calculate_metric(env, timetable):\n",
        "    positions = env.cur_episode\n",
        "    prev_station = 0\n",
        "    delta = 400 \n",
        "    metric_result = []\n",
        "    for i_agent in range(env.get_num_agents()):\n",
        "        if not env.agents[i_agent].state == TrainState.MALFUNCTION:\n",
        "            station_vector = [delta] * len(timetable[i_agent][0])\n",
        "            for i_station in range(len(timetable[i_agent][0])):\n",
        "                for step in range(len(positions)):\n",
        "                    if positions[step][i_agent] == timetable[i_agent][0][i_station] and positions[step][i_agent] != prev_station:\n",
        "                        prev_station = positions[step][i_agent]\n",
        "                        distance_delay = ((step - timetable[i_agent][1][i_station])**2)**(1/2)\n",
        "                        station_vector[i_station] = distance_delay\n",
        "            metric_result.append(station_vector)\n",
        "    metric_sum = sum(sum(x) for x in metric_result)\n",
        "    dimension = 0\n",
        "    for i in range(len(metric_result)):\n",
        "        for j in range(len(metric_result[i])):\n",
        "            dimension += 1\n",
        "    metric_normalized = 1 - (metric_sum / (delta*dimension))\n",
        "    return metric_normalized\n",
        "\n",
        "def choose_a_random_training_configuration(env, max_steps):\n",
        "    case = 0\n",
        "    if case == 0:\n",
        "        make_a_deterministic_interruption(env.agents[1], max_steps)\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "        return    \n",
        "    elif case == 1:\n",
        "        env.agents[1].initial_position = (6,15)\n",
        "        env.agents[2].initial_position = (5,15)\n",
        "        make_a_deterministic_interruption(env.agents[1], max_steps)\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "        return\n",
        "    elif case == 2:\n",
        "        make_a_deterministic_interruption(env.agents[1], max_steps)\n",
        "        env.agents[2].malfunction_handler.malfunction_down_counter = max_steps\n",
        "        return       \n",
        "    elif case == 3:\n",
        "        env.agents[1].malfunction_handler.malfunction_down_counter = max_steps\n",
        "        env.agents[2].initial_position = (5,15)\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "        return\n",
        "\n",
        "def format_action_prob(action_probs):\n",
        "    action_probs = np.round(action_probs, 3)\n",
        "    actions = [\"↻\", \"←\", \"↑\", \"→\", \"◼\", \"↓\"]\n",
        "\n",
        "    buffer = \"\"\n",
        "    for action, action_prob in zip(actions, action_probs):\n",
        "        buffer += action + \" \" + \"{:.3f}\".format(action_prob) + \" \"\n",
        "\n",
        "    return buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c5rkMFTPLg4",
        "outputId": "6406de0f-9536-4765-a61e-a3420e2028f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "🚂 Episode 2083\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 20.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.237 → 0.250 ◼ 0.395 ↓ 0.079 \t Metric 0.5965 \n",
            "Episode Nr. 2084\t Score = -105.01999999999994\n",
            "🚂 Episode 2084\t 🏆 Score: -0.140 Avg: -0.038\t 💯 Done: 0.00% Avg: 19.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.705 ← 0.008 ↑ 0.019 → 0.011 ◼ 0.004 ↓ 0.253 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2085\t Score = -45.01999999999994\n",
            "🚂 Episode 2085\t 🏆 Score: -0.060 Avg: -0.038\t 💯 Done: 0.00% Avg: 19.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.224 ← 0.011 ↑ 0.015 → 0.037 ◼ 0.705 ↓ 0.007 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2086\t Score = 10.11\n",
            "🚂 Episode 2086\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 19.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.014 ↑ 0.271 → 0.229 ◼ 0.429 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 2087\t Score = 9.563333333333334\n",
            "🚂 Episode 2087\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 19.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.263 → 0.263 ◼ 0.395 ↓ 0.039 \t Metric 0.5965 \n",
            "Episode Nr. 2088\t Score = 9.563333333333334\n",
            "🚂 Episode 2088\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 20.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.197 → 0.289 ◼ 0.395 ↓ 0.079 \t Metric 0.5965 \n",
            "Episode Nr. 2089\t Score = -105.01999999999994\n",
            "🚂 Episode 2089\t 🏆 Score: -0.140 Avg: -0.038\t 💯 Done: 0.00% Avg: 19.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.609 ← 0.008 ↑ 0.341 → 0.023 ◼ 0.008 ↓ 0.011 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2090\t Score = 9.563333333333334\n",
            "🚂 Episode 2090\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 20.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.105 ↑ 0.211 → 0.171 ◼ 0.368 ↓ 0.132 \t Metric 0.5965 \n",
            "Episode Nr. 2091\t Score = 8.643333333333333\n",
            "🚂 Episode 2091\t 🏆 Score: 0.012 Avg: -0.037\t 💯 Done: 33.33% Avg: 20.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2092\t Score = 8.79\n",
            "🚂 Episode 2092\t 🏆 Score: 0.012 Avg: -0.036\t 💯 Done: 33.33% Avg: 20.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2093\t Score = 8.643333333333333\n",
            "🚂 Episode 2093\t 🏆 Score: 0.012 Avg: -0.036\t 💯 Done: 33.33% Avg: 20.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2094\t Score = 9.563333333333334\n",
            "🚂 Episode 2094\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.197 → 0.276 ◼ 0.395 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2095\t Score = 8.79\n",
            "🚂 Episode 2095\t 🏆 Score: 0.012 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2096\t Score = -45.01999999999994\n",
            "🚂 Episode 2096\t 🏆 Score: -0.060 Avg: -0.035\t 💯 Done: 0.00% Avg: 20.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.310 ← 0.011 ↑ 0.011 → 0.250 ◼ 0.407 ↓ 0.011 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2097\t Score = 9.563333333333334\n",
            "🚂 Episode 2097\t 🏆 Score: 0.013 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.632 → 0.276 ◼ 0.013 ↓ 0.039 \t Metric 0.5965 \n",
            "Episode Nr. 2098\t Score = -42.53999999999999\n",
            "🚂 Episode 2098\t 🏆 Score: -0.057 Avg: -0.035\t 💯 Done: 0.00% Avg: 20.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.478 ← 0.008 ↑ 0.107 → 0.033 ◼ 0.132 ↓ 0.243 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2099\t Score = -42.53999999999999\n",
            "🚂 Episode 2099\t 🏆 Score: -0.057 Avg: -0.035\t 💯 Done: 0.00% Avg: 20.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.303 ← 0.021 ↑ 0.177 → 0.315 ◼ 0.179 ↓ 0.006 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2100\t Score = -105.01999999999994\n",
            "🚂 Episode 2100\t 🏆 Score: -0.140 Avg: -0.036\t 💯 Done: 0.00% Avg: 20.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.011 ↑ 0.954 → 0.011 ◼ 0.004 ↓ 0.011 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2101\t Score = 8.79\n",
            "🚂 Episode 2101\t 🏆 Score: 0.012 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2102\t Score = 8.79\n",
            "🚂 Episode 2102\t 🏆 Score: 0.012 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2103\t Score = 9.563333333333334\n",
            "🚂 Episode 2103\t 🏆 Score: 0.013 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.711 → 0.224 ◼ 0.013 ↓ 0.013 \t Metric 0.5965 \n",
            "Episode Nr. 2104\t Score = -42.53999999999999\n",
            "🚂 Episode 2104\t 🏆 Score: -0.057 Avg: -0.035\t 💯 Done: 0.00% Avg: 20.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.002 ← 0.497 ↑ 0.023 → 0.245 ◼ 0.194 ↓ 0.039 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2105\t Score = -105.01999999999994\n",
            "🚂 Episode 2105\t 🏆 Score: -0.140 Avg: -0.036\t 💯 Done: 0.00% Avg: 20.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.008 ↑ 0.023 → 0.958 ◼ 0.004 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2106\t Score = 8.79\n",
            "🚂 Episode 2106\t 🏆 Score: 0.012 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.14%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2107\t Score = 9.563333333333334\n",
            "🚂 Episode 2107\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.329 → 0.211 ◼ 0.395 ↓ 0.026 \t Metric 0.5965 \n",
            "Episode Nr. 2108\t Score = 8.79\n",
            "🚂 Episode 2108\t 🏆 Score: 0.012 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2109\t Score = -105.01999999999994\n",
            "🚂 Episode 2109\t 🏆 Score: -0.140 Avg: -0.035\t 💯 Done: 0.00% Avg: 20.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.498 ← 0.008 ↑ 0.019 → 0.100 ◼ 0.004 ↓ 0.372 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2110\t Score = 9.563333333333334\n",
            "🚂 Episode 2110\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.276 → 0.211 ◼ 0.395 ↓ 0.079 \t Metric 0.5965 \n",
            "Episode Nr. 2111\t Score = 9.563333333333334\n",
            "🚂 Episode 2111\t 🏆 Score: 0.013 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.039 ↑ 0.263 → 0.211 ◼ 0.395 ↓ 0.079 \t Metric 0.5965 \n",
            "Episode Nr. 2112\t Score = -42.53999999999999\n",
            "🚂 Episode 2112\t 🏆 Score: -0.057 Avg: -0.035\t 💯 Done: 0.00% Avg: 20.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.365 ← 0.029 ↑ 0.394 → 0.031 ◼ 0.169 ↓ 0.012 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2113\t Score = -45.01999999999994\n",
            "🚂 Episode 2113\t 🏆 Score: -0.060 Avg: -0.035\t 💯 Done: 0.00% Avg: 20.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.243 ← 0.011 ↑ 0.022 → 0.034 ◼ 0.683 ↓ 0.007 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2114\t Score = -45.01999999999994\n",
            "🚂 Episode 2114\t 🏆 Score: -0.060 Avg: -0.035\t 💯 Done: 0.00% Avg: 19.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.041 ← 0.015 ↑ 0.022 → 0.037 ◼ 0.877 ↓ 0.007 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2115\t Score = -45.01999999999994\n",
            "🚂 Episode 2115\t 🏆 Score: -0.060 Avg: -0.035\t 💯 Done: 0.00% Avg: 19.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.918 ← 0.011 ↑ 0.022 → 0.037 ◼ 0.004 ↓ 0.007 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2116\t Score = -42.53999999999999\n",
            "🚂 Episode 2116\t 🏆 Score: -0.057 Avg: -0.036\t 💯 Done: 0.00% Avg: 19.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.598 ← 0.010 ↑ 0.056 → 0.016 ◼ 0.315 ↓ 0.006 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2117\t Score = 8.79\n",
            "🚂 Episode 2117\t 🏆 Score: 0.012 Avg: -0.035\t 💯 Done: 33.33% Avg: 19.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2118\t Score = -42.53999999999999\n",
            "🚂 Episode 2118\t 🏆 Score: -0.057 Avg: -0.035\t 💯 Done: 0.00% Avg: 19.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.431 ← 0.006 ↑ 0.010 → 0.025 ◼ 0.518 ↓ 0.010 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2119\t Score = 9.563333333333334\n",
            "🚂 Episode 2119\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 19.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.053 ↑ 0.250 → 0.211 ◼ 0.382 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2120\t Score = 9.563333333333334\n",
            "🚂 Episode 2120\t 🏆 Score: 0.013 Avg: -0.034\t 💯 Done: 33.33% Avg: 19.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.053 ↑ 0.237 → 0.224 ◼ 0.382 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2121\t Score = 9.563333333333334\n",
            "🚂 Episode 2121\t 🏆 Score: 0.013 Avg: -0.034\t 💯 Done: 33.33% Avg: 19.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.039 ↑ 0.250 → 0.211 ◼ 0.395 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2122\t Score = 9.563333333333334\n",
            "🚂 Episode 2122\t 🏆 Score: 0.013 Avg: -0.033\t 💯 Done: 33.33% Avg: 19.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.039 ↑ 0.250 → 0.211 ◼ 0.395 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2123\t Score = 9.563333333333334\n",
            "🚂 Episode 2123\t 🏆 Score: 0.013 Avg: -0.033\t 💯 Done: 33.33% Avg: 20.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.039 ↑ 0.237 → 0.237 ◼ 0.395 ↓ 0.079 \t Metric 0.5965 \n",
            "Episode Nr. 2124\t Score = 8.79\n",
            "🚂 Episode 2124\t 🏆 Score: 0.012 Avg: -0.033\t 💯 Done: 33.33% Avg: 20.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2125\t Score = 9.563333333333334\n",
            "🚂 Episode 2125\t 🏆 Score: 0.013 Avg: -0.032\t 💯 Done: 33.33% Avg: 20.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.039 ↑ 0.276 → 0.224 ◼ 0.395 ↓ 0.053 \t Metric 0.5965 \n",
            "Episode Nr. 2126\t Score = -105.01999999999994\n",
            "🚂 Episode 2126\t 🏆 Score: -0.140 Avg: -0.033\t 💯 Done: 0.00% Avg: 20.14%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.943 ← 0.008 ↑ 0.015 → 0.011 ◼ 0.008 ↓ 0.015 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2127\t Score = -102.53999999999999\n",
            "🚂 Episode 2127\t 🏆 Score: -0.137 Avg: -0.034\t 💯 Done: 0.00% Avg: 19.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.323 ← 0.410 ↑ 0.245 → 0.008 ◼ 0.008 ↓ 0.006 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2128\t Score = -105.01999999999994\n",
            "🚂 Episode 2128\t 🏆 Score: -0.140 Avg: -0.035\t 💯 Done: 0.00% Avg: 19.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.241 ← 0.015 ↑ 0.414 → 0.015 ◼ 0.004 ↓ 0.310 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2129\t Score = 9.563333333333334\n",
            "🚂 Episode 2129\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 19.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.237 ↑ 0.645 → 0.053 ◼ 0.013 ↓ 0.039 \t Metric 0.5965 \n",
            "Episode Nr. 2130\t Score = -102.53999999999999\n",
            "🚂 Episode 2130\t 🏆 Score: -0.137 Avg: -0.036\t 💯 Done: 0.00% Avg: 19.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.467 ↑ 0.148 → 0.276 ◼ 0.002 ↓ 0.099 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2131\t Score = 9.563333333333334\n",
            "🚂 Episode 2131\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 19.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.303 → 0.605 ◼ 0.039 ↓ 0.013 \t Metric 0.5965 \n",
            "Episode Nr. 2132\t Score = -102.53999999999999\n",
            "🚂 Episode 2132\t 🏆 Score: -0.137 Avg: -0.036\t 💯 Done: 0.00% Avg: 19.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.217 ← 0.004 ↑ 0.014 → 0.004 ◼ 0.061 ↓ 0.700 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2133\t Score = 9.563333333333334\n",
            "🚂 Episode 2133\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 19.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.039 ↑ 0.632 → 0.132 ◼ 0.158 ↓ 0.026 \t Metric 0.5965 \n",
            "Episode Nr. 2134\t Score = -42.53999999999999\n",
            "🚂 Episode 2134\t 🏆 Score: -0.057 Avg: -0.036\t 💯 Done: 0.00% Avg: 19.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.450 ← 0.012 ↑ 0.033 → 0.021 ◼ 0.478 ↓ 0.006 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2135\t Score = 9.563333333333334\n",
            "🚂 Episode 2135\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 19.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.066 ← 0.408 ↑ 0.197 → 0.092 ◼ 0.053 ↓ 0.184 \t Metric 0.5965 \n",
            "Episode Nr. 2136\t Score = -42.53999999999999\n",
            "🚂 Episode 2136\t 🏆 Score: -0.057 Avg: -0.036\t 💯 Done: 0.00% Avg: 19.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.087 ↑ 0.311 → 0.241 ◼ 0.285 ↓ 0.066 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2137\t Score = -102.53999999999999\n",
            "🚂 Episode 2137\t 🏆 Score: -0.137 Avg: -0.037\t 💯 Done: 0.00% Avg: 19.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.239 ← 0.420 ↑ 0.199 → 0.006 ◼ 0.002 ↓ 0.134 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2138\t Score = -45.01999999999994\n",
            "🚂 Episode 2138\t 🏆 Score: -0.060 Avg: -0.037\t 💯 Done: 0.00% Avg: 19.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.007 ↑ 0.026 → 0.037 ◼ 0.918 ↓ 0.004 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2139\t Score = 9.563333333333334\n",
            "🚂 Episode 2139\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 19.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.303 → 0.618 ◼ 0.013 ↓ 0.026 \t Metric 0.5965 \n",
            "Episode Nr. 2140\t Score = -42.53999999999999\n",
            "🚂 Episode 2140\t 🏆 Score: -0.057 Avg: -0.037\t 💯 Done: 0.00% Avg: 19.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.196 ← 0.006 ↑ 0.012 → 0.198 ◼ 0.462 ↓ 0.126 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2141\t Score = -42.53999999999999\n",
            "🚂 Episode 2141\t 🏆 Score: -0.057 Avg: -0.037\t 💯 Done: 0.00% Avg: 18.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.016 ← 0.357 ↑ 0.190 → 0.346 ◼ 0.085 ↓ 0.006 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2142\t Score = 9.563333333333334\n",
            "🚂 Episode 2142\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 19.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.026 ↑ 0.263 → 0.224 ◼ 0.368 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2143\t Score = 8.79\n",
            "🚂 Episode 2143\t 🏆 Score: 0.012 Avg: -0.036\t 💯 Done: 33.33% Avg: 19.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2144\t Score = -45.01999999999994\n",
            "🚂 Episode 2144\t 🏆 Score: -0.060 Avg: -0.036\t 💯 Done: 0.00% Avg: 18.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.754 ↑ 0.209 → 0.022 ◼ 0.004 ↓ 0.004 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2145\t Score = -42.53999999999999\n",
            "🚂 Episode 2145\t 🏆 Score: -0.057 Avg: -0.036\t 💯 Done: 0.00% Avg: 18.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.006 ← 0.045 ↑ 0.021 → 0.493 ◼ 0.155 ↓ 0.280 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2146\t Score = 9.563333333333334\n",
            "🚂 Episode 2146\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 18.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.408 → 0.092 ◼ 0.395 ↓ 0.066 \t Metric 0.5965 \n",
            "Episode Nr. 2147\t Score = -42.53999999999999\n",
            "🚂 Episode 2147\t 🏆 Score: -0.057 Avg: -0.036\t 💯 Done: 0.00% Avg: 18.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.472 ← 0.006 ↑ 0.008 → 0.021 ◼ 0.482 ↓ 0.012 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2148\t Score = -105.01999999999994\n",
            "🚂 Episode 2148\t 🏆 Score: -0.140 Avg: -0.037\t 💯 Done: 0.00% Avg: 18.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.008 ↑ 0.904 → 0.015 ◼ 0.008 ↓ 0.061 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2149\t Score = -105.01999999999994\n",
            "🚂 Episode 2149\t 🏆 Score: -0.140 Avg: -0.038\t 💯 Done: 0.00% Avg: 18.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.008 ↑ 0.050 → 0.920 ◼ 0.008 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2150\t Score = 9.563333333333334\n",
            "🚂 Episode 2150\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 18.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.053 ↑ 0.263 → 0.421 ◼ 0.184 ↓ 0.066 \t Metric 0.5965 \n",
            "Episode Nr. 2151\t Score = -105.01999999999994\n",
            "🚂 Episode 2151\t 🏆 Score: -0.140 Avg: -0.039\t 💯 Done: 0.00% Avg: 18.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.008 ↑ 0.023 → 0.433 ◼ 0.464 ↓ 0.069 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2152\t Score = 9.563333333333334\n",
            "🚂 Episode 2152\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 18.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.421 → 0.066 ◼ 0.013 ↓ 0.461 \t Metric 0.5965 \n",
            "Episode Nr. 2153\t Score = -42.53999999999999\n",
            "🚂 Episode 2153\t 🏆 Score: -0.057 Avg: -0.038\t 💯 Done: 0.00% Avg: 18.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.449 ← 0.027 ↑ 0.012 → 0.019 ◼ 0.482 ↓ 0.012 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2154\t Score = -105.01999999999994\n",
            "🚂 Episode 2154\t 🏆 Score: -0.140 Avg: -0.039\t 💯 Done: 0.00% Avg: 18.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.008 ↑ 0.019 → 0.015 ◼ 0.617 ↓ 0.333 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2155\t Score = 9.563333333333334\n",
            "🚂 Episode 2155\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 18.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.263 → 0.224 ◼ 0.013 ↓ 0.461 \t Metric 0.5965 \n",
            "Episode Nr. 2156\t Score = -42.53999999999999\n",
            "🚂 Episode 2156\t 🏆 Score: -0.057 Avg: -0.039\t 💯 Done: 0.00% Avg: 18.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.330 ← 0.241 ↑ 0.012 → 0.025 ◼ 0.386 ↓ 0.006 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2157\t Score = -45.01999999999994\n",
            "🚂 Episode 2157\t 🏆 Score: -0.060 Avg: -0.039\t 💯 Done: 0.00% Avg: 17.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.097 ↑ 0.541 → 0.030 ◼ 0.321 ↓ 0.007 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2158\t Score = -105.01999999999994\n",
            "🚂 Episode 2158\t 🏆 Score: -0.140 Avg: -0.040\t 💯 Done: 0.00% Avg: 17.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.464 ← 0.008 ↑ 0.199 → 0.015 ◼ 0.008 ↓ 0.307 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2159\t Score = 9.563333333333334\n",
            "🚂 Episode 2159\t 🏆 Score: 0.013 Avg: -0.040\t 💯 Done: 33.33% Avg: 17.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.039 ↑ 0.750 → 0.066 ◼ 0.026 ↓ 0.105 \t Metric 0.5965 \n",
            "Episode Nr. 2160\t Score = -102.53999999999999\n",
            "🚂 Episode 2160\t 🏆 Score: -0.137 Avg: -0.041\t 💯 Done: 0.00% Avg: 17.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.552 ← 0.004 ↑ 0.179 → 0.006 ◼ 0.004 ↓ 0.254 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2161\t Score = -45.01999999999994\n",
            "🚂 Episode 2161\t 🏆 Score: -0.060 Avg: -0.041\t 💯 Done: 0.00% Avg: 17.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.007 ↑ 0.019 → 0.187 ◼ 0.772 ↓ 0.007 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2162\t Score = -45.01999999999994\n",
            "🚂 Episode 2162\t 🏆 Score: -0.060 Avg: -0.041\t 💯 Done: 0.00% Avg: 17.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.821 ↑ 0.015 → 0.041 ◼ 0.108 ↓ 0.007 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2163\t Score = 9.563333333333334\n",
            "🚂 Episode 2163\t 🏆 Score: 0.013 Avg: -0.041\t 💯 Done: 33.33% Avg: 17.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.368 → 0.053 ◼ 0.382 ↓ 0.158 \t Metric 0.5965 \n",
            "Episode Nr. 2164\t Score = -42.53999999999999\n",
            "🚂 Episode 2164\t 🏆 Score: -0.057 Avg: -0.041\t 💯 Done: 0.00% Avg: 17.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.412 ↑ 0.237 → 0.161 ◼ 0.173 ↓ 0.014 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2165\t Score = -20.436666666666664\n",
            "🚂 Episode 2165\t 🏆 Score: -0.027 Avg: -0.041\t 💯 Done: 33.33% Avg: 17.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.329 → 0.605 ◼ 0.013 ↓ 0.013 \t Metric 0.397 \n",
            "Episode Nr. 2166\t Score = -20.436666666666664\n",
            "🚂 Episode 2166\t 🏆 Score: -0.027 Avg: -0.040\t 💯 Done: 33.33% Avg: 17.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.026 ↑ 0.303 → 0.605 ◼ 0.013 ↓ 0.013 \t Metric 0.397 \n",
            "Episode Nr. 2167\t Score = 8.643333333333333\n",
            "🚂 Episode 2167\t 🏆 Score: 0.012 Avg: -0.040\t 💯 Done: 33.33% Avg: 17.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2168\t Score = -42.53999999999999\n",
            "🚂 Episode 2168\t 🏆 Score: -0.057 Avg: -0.040\t 💯 Done: 0.00% Avg: 17.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.060 ← 0.476 ↑ 0.021 → 0.425 ◼ 0.016 ↓ 0.002 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2169\t Score = -42.53999999999999\n",
            "🚂 Episode 2169\t 🏆 Score: -0.057 Avg: -0.040\t 💯 Done: 0.00% Avg: 17.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.449 ← 0.468 ↑ 0.023 → 0.033 ◼ 0.021 ↓ 0.006 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2170\t Score = 8.79\n",
            "🚂 Episode 2170\t 🏆 Score: 0.012 Avg: -0.040\t 💯 Done: 33.33% Avg: 17.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2171\t Score = 9.563333333333334\n",
            "🚂 Episode 2171\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 17.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.434 ↑ 0.224 → 0.092 ◼ 0.145 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2172\t Score = 9.563333333333334\n",
            "🚂 Episode 2172\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 17.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.539 ↑ 0.237 → 0.079 ◼ 0.039 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2173\t Score = 8.79\n",
            "🚂 Episode 2173\t 🏆 Score: 0.012 Avg: -0.038\t 💯 Done: 33.33% Avg: 18.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2174\t Score = -42.53999999999999\n",
            "🚂 Episode 2174\t 🏆 Score: -0.057 Avg: -0.038\t 💯 Done: 0.00% Avg: 17.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.483 ← 0.468 ↑ 0.017 → 0.021 ◼ 0.004 ↓ 0.006 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2175\t Score = 9.563333333333334\n",
            "🚂 Episode 2175\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 18.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.342 → 0.066 ◼ 0.368 ↓ 0.184 \t Metric 0.5965 \n",
            "Episode Nr. 2176\t Score = -105.01999999999994\n",
            "🚂 Episode 2176\t 🏆 Score: -0.140 Avg: -0.039\t 💯 Done: 0.00% Avg: 17.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.935 ← 0.011 ↑ 0.015 → 0.027 ◼ 0.004 ↓ 0.008 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2177\t Score = -102.53999999999999\n",
            "🚂 Episode 2177\t 🏆 Score: -0.137 Avg: -0.040\t 💯 Done: 0.00% Avg: 17.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.716 ← 0.103 ↑ 0.160 → 0.008 ◼ 0.002 ↓ 0.012 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2178\t Score = 8.79\n",
            "🚂 Episode 2178\t 🏆 Score: 0.012 Avg: -0.039\t 💯 Done: 33.33% Avg: 17.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2179\t Score = -42.53999999999999\n",
            "🚂 Episode 2179\t 🏆 Score: -0.057 Avg: -0.040\t 💯 Done: 0.00% Avg: 17.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.419 ↑ 0.012 → 0.299 ◼ 0.043 ↓ 0.184 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2180\t Score = -105.01999999999994\n",
            "🚂 Episode 2180\t 🏆 Score: -0.140 Avg: -0.041\t 💯 Done: 0.00% Avg: 17.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.900 ← 0.008 ↑ 0.019 → 0.011 ◼ 0.054 ↓ 0.008 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2181\t Score = 9.563333333333334\n",
            "🚂 Episode 2181\t 🏆 Score: 0.013 Avg: -0.040\t 💯 Done: 33.33% Avg: 17.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.132 ↑ 0.276 → 0.079 ◼ 0.368 ↓ 0.118 \t Metric 0.5965 \n",
            "Episode Nr. 2182\t Score = -42.53999999999999\n",
            "🚂 Episode 2182\t 🏆 Score: -0.057 Avg: -0.040\t 💯 Done: 0.00% Avg: 17.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.155 ← 0.322 ↑ 0.219 → 0.179 ◼ 0.045 ↓ 0.080 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2183\t Score = -42.53999999999999\n",
            "🚂 Episode 2183\t 🏆 Score: -0.057 Avg: -0.040\t 💯 Done: 0.00% Avg: 17.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.113 ← 0.177 ↑ 0.023 → 0.381 ◼ 0.006 ↓ 0.301 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2184\t Score = -42.53999999999999\n",
            "🚂 Episode 2184\t 🏆 Score: -0.057 Avg: -0.040\t 💯 Done: 0.00% Avg: 17.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.280 ← 0.357 ↑ 0.083 → 0.074 ◼ 0.041 ↓ 0.165 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2185\t Score = -105.01999999999994\n",
            "🚂 Episode 2185\t 🏆 Score: -0.140 Avg: -0.041\t 💯 Done: 0.00% Avg: 16.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.008 ↑ 0.019 → 0.011 ◼ 0.946 ↓ 0.011 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2186\t Score = -45.01999999999994\n",
            "🚂 Episode 2186\t 🏆 Score: -0.060 Avg: -0.042\t 💯 Done: 0.00% Avg: 16.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.026 ↑ 0.026 → 0.914 ◼ 0.007 ↓ 0.019 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2187\t Score = -45.01999999999994\n",
            "🚂 Episode 2187\t 🏆 Score: -0.060 Avg: -0.042\t 💯 Done: 0.00% Avg: 16.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.112 ← 0.030 ↑ 0.287 → 0.560 ◼ 0.004 ↓ 0.007 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2188\t Score = -42.53999999999999\n",
            "🚂 Episode 2188\t 🏆 Score: -0.057 Avg: -0.042\t 💯 Done: 0.00% Avg: 16.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.421 ← 0.115 ↑ 0.144 → 0.072 ◼ 0.002 ↓ 0.247 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2189\t Score = 8.79\n",
            "🚂 Episode 2189\t 🏆 Score: 0.012 Avg: -0.041\t 💯 Done: 33.33% Avg: 16.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2190\t Score = -22.619999999999997\n",
            "🚂 Episode 2190\t 🏆 Score: -0.030 Avg: -0.041\t 💯 Done: 33.33% Avg: 16.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.144 ← 0.098 ↑ 0.275 → 0.105 ◼ 0.170 ↓ 0.209 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2191\t Score = -42.53999999999999\n",
            "🚂 Episode 2191\t 🏆 Score: -0.057 Avg: -0.042\t 💯 Done: 0.00% Avg: 16.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.087 ← 0.557 ↑ 0.089 → 0.258 ◼ 0.004 ↓ 0.004 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2192\t Score = 9.563333333333334\n",
            "🚂 Episode 2192\t 🏆 Score: 0.013 Avg: -0.041\t 💯 Done: 33.33% Avg: 16.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.197 → 0.434 ◼ 0.132 ↓ 0.197 \t Metric 0.5965 \n",
            "Episode Nr. 2193\t Score = 8.79\n",
            "🚂 Episode 2193\t 🏆 Score: 0.012 Avg: -0.040\t 💯 Done: 33.33% Avg: 16.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2194\t Score = 9.563333333333334\n",
            "🚂 Episode 2194\t 🏆 Score: 0.013 Avg: -0.040\t 💯 Done: 33.33% Avg: 17.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.184 ↑ 0.171 → 0.066 ◼ 0.395 ↓ 0.171 \t Metric 0.5965 \n",
            "Episode Nr. 2195\t Score = 8.79\n",
            "🚂 Episode 2195\t 🏆 Score: 0.012 Avg: -0.039\t 💯 Done: 33.33% Avg: 17.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2196\t Score = -105.01999999999994\n",
            "🚂 Episode 2196\t 🏆 Score: -0.140 Avg: -0.040\t 💯 Done: 0.00% Avg: 17.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.935 ← 0.015 ↑ 0.015 → 0.015 ◼ 0.011 ↓ 0.008 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2197\t Score = -42.53999999999999\n",
            "🚂 Episode 2197\t 🏆 Score: -0.057 Avg: -0.041\t 💯 Done: 0.00% Avg: 16.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.878 ← 0.027 ↑ 0.012 → 0.014 ◼ 0.056 ↓ 0.014 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2198\t Score = 9.563333333333334\n",
            "🚂 Episode 2198\t 🏆 Score: 0.013 Avg: -0.040\t 💯 Done: 33.33% Avg: 17.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.276 → 0.171 ◼ 0.395 ↓ 0.118 \t Metric 0.5965 \n",
            "Episode Nr. 2199\t Score = 9.563333333333334\n",
            "🚂 Episode 2199\t 🏆 Score: 0.013 Avg: -0.040\t 💯 Done: 33.33% Avg: 17.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.092 ↑ 0.237 → 0.145 ◼ 0.395 ↓ 0.118 \t Metric 0.5965 \n",
            "Episode Nr. 2200\t Score = 9.563333333333334\n",
            "🚂 Episode 2200\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 17.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.066 ↑ 0.171 → 0.197 ◼ 0.395 ↓ 0.158 \t Metric 0.5965 \n",
            "Episode Nr. 2201\t Score = -42.53999999999999\n",
            "🚂 Episode 2201\t 🏆 Score: -0.057 Avg: -0.039\t 💯 Done: 0.00% Avg: 17.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.132 ↑ 0.388 → 0.237 ◼ 0.155 ↓ 0.014 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2202\t Score = 9.563333333333334\n",
            "🚂 Episode 2202\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 17.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.026 ↑ 0.276 → 0.632 ◼ 0.013 ↓ 0.013 \t Metric 0.5965 \n",
            "Episode Nr. 2203\t Score = -20.436666666666664\n",
            "🚂 Episode 2203\t 🏆 Score: -0.027 Avg: -0.039\t 💯 Done: 33.33% Avg: 17.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.737 → 0.053 ◼ 0.013 ↓ 0.158 \t Metric 0.397 \n",
            "Episode Nr. 2204\t Score = -20.436666666666664\n",
            "🚂 Episode 2204\t 🏆 Score: -0.027 Avg: -0.038\t 💯 Done: 33.33% Avg: 17.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.105 ↑ 0.803 → 0.053 ◼ 0.013 ↓ 0.013 \t Metric 0.397 \n",
            "Episode Nr. 2205\t Score = -45.01999999999994\n",
            "🚂 Episode 2205\t 🏆 Score: -0.060 Avg: -0.039\t 💯 Done: 0.00% Avg: 17.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.373 ↑ 0.034 → 0.011 ◼ 0.571 ↓ 0.004 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2206\t Score = -42.53999999999999\n",
            "🚂 Episode 2206\t 🏆 Score: -0.057 Avg: -0.039\t 💯 Done: 0.00% Avg: 17.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.134 ← 0.239 ↑ 0.025 → 0.386 ◼ 0.210 ↓ 0.006 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2207\t Score = 9.563333333333334\n",
            "🚂 Episode 2207\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 17.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.197 ↑ 0.263 → 0.066 ◼ 0.368 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2208\t Score = 8.79\n",
            "🚂 Episode 2208\t 🏆 Score: 0.012 Avg: -0.038\t 💯 Done: 33.33% Avg: 17.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2209\t Score = -42.53999999999999\n",
            "🚂 Episode 2209\t 🏆 Score: -0.057 Avg: -0.038\t 💯 Done: 0.00% Avg: 17.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.157 ← 0.054 ↑ 0.008 → 0.144 ◼ 0.280 ↓ 0.357 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2210\t Score = 9.563333333333334\n",
            "🚂 Episode 2210\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 17.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.303 → 0.197 ◼ 0.368 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2211\t Score = -22.619999999999997\n",
            "🚂 Episode 2211\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 17.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.654 ← 0.020 ↑ 0.092 → 0.098 ◼ 0.131 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2212\t Score = 9.563333333333334\n",
            "🚂 Episode 2212\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 17.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.237 → 0.263 ◼ 0.395 ↓ 0.066 \t Metric 0.5965 \n",
            "Episode Nr. 2213\t Score = 9.563333333333334\n",
            "🚂 Episode 2213\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 18.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.224 → 0.276 ◼ 0.395 ↓ 0.066 \t Metric 0.5965 \n",
            "Episode Nr. 2214\t Score = 9.563333333333334\n",
            "🚂 Episode 2214\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 18.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.224 → 0.276 ◼ 0.395 ↓ 0.066 \t Metric 0.5965 \n",
            "Episode Nr. 2215\t Score = -42.53999999999999\n",
            "🚂 Episode 2215\t 🏆 Score: -0.057 Avg: -0.036\t 💯 Done: 0.00% Avg: 18.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.724 ← 0.010 ↑ 0.010 → 0.235 ◼ 0.006 ↓ 0.016 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2216\t Score = 9.563333333333334\n",
            "🚂 Episode 2216\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 18.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.645 → 0.092 ◼ 0.105 ↓ 0.118 \t Metric 0.5965 \n",
            "Episode Nr. 2217\t Score = 9.426666666666666\n",
            "🚂 Episode 2217\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 18.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.333 → 0.090 ◼ 0.397 ↓ 0.141 \t Metric 0.5974999999999999 \n",
            "Episode Nr. 2218\t Score = -105.01999999999994\n",
            "🚂 Episode 2218\t 🏆 Score: -0.140 Avg: -0.036\t 💯 Done: 0.00% Avg: 18.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.900 ← 0.008 ↑ 0.015 → 0.023 ◼ 0.050 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2219\t Score = -105.01999999999994\n",
            "🚂 Episode 2219\t 🏆 Score: -0.140 Avg: -0.037\t 💯 Done: 0.00% Avg: 18.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.069 ↑ 0.023 → 0.011 ◼ 0.885 ↓ 0.008 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2220\t Score = -22.619999999999997\n",
            "🚂 Episode 2220\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 18.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.209 ← 0.536 ↑ 0.078 → 0.118 ◼ 0.013 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2221\t Score = -22.619999999999997\n",
            "🚂 Episode 2221\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 18.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.392 ← 0.405 ↑ 0.033 → 0.118 ◼ 0.007 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2222\t Score = -42.53999999999999\n",
            "🚂 Episode 2222\t 🏆 Score: -0.057 Avg: -0.037\t 💯 Done: 0.00% Avg: 18.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.128 ← 0.482 ↑ 0.283 → 0.014 ◼ 0.072 ↓ 0.020 \t Metric 0.635 \n",
            "Episode Nr. 2223\t Score = -42.53999999999999\n",
            "🚂 Episode 2223\t 🏆 Score: -0.057 Avg: -0.037\t 💯 Done: 0.00% Avg: 17.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.282 ↑ 0.103 → 0.435 ◼ 0.056 ↓ 0.120 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2224\t Score = -42.53999999999999\n",
            "🚂 Episode 2224\t 🏆 Score: -0.057 Avg: -0.038\t 💯 Done: 0.00% Avg: 17.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.317 ← 0.101 ↑ 0.085 → 0.439 ◼ 0.056 ↓ 0.002 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2225\t Score = -22.619999999999997\n",
            "🚂 Episode 2225\t 🏆 Score: -0.030 Avg: -0.038\t 💯 Done: 33.33% Avg: 17.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.386 ← 0.092 ↑ 0.098 → 0.405 ◼ 0.007 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2226\t Score = -42.53999999999999\n",
            "🚂 Episode 2226\t 🏆 Score: -0.057 Avg: -0.038\t 💯 Done: 0.00% Avg: 17.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.002 ← 0.159 ↑ 0.049 → 0.107 ◼ 0.359 ↓ 0.324 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2227\t Score = 8.79\n",
            "🚂 Episode 2227\t 🏆 Score: 0.012 Avg: -0.037\t 💯 Done: 33.33% Avg: 17.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2228\t Score = 9.563333333333334\n",
            "🚂 Episode 2228\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 18.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.829 → 0.066 ◼ 0.039 ↓ 0.026 \t Metric 0.5965 \n",
            "Episode Nr. 2229\t Score = -105.01999999999994\n",
            "🚂 Episode 2229\t 🏆 Score: -0.140 Avg: -0.038\t 💯 Done: 0.00% Avg: 17.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.008 ↑ 0.027 → 0.594 ◼ 0.364 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2230\t Score = 9.563333333333334\n",
            "🚂 Episode 2230\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 18.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.171 → 0.250 ◼ 0.382 ↓ 0.158 \t Metric 0.5965 \n",
            "Episode Nr. 2231\t Score = 8.643333333333333\n",
            "🚂 Episode 2231\t 🏆 Score: 0.012 Avg: -0.037\t 💯 Done: 33.33% Avg: 18.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2232\t Score = 9.563333333333334\n",
            "🚂 Episode 2232\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 18.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.171 → 0.250 ◼ 0.395 ↓ 0.145 \t Metric 0.5965 \n",
            "Episode Nr. 2233\t Score = -105.01999999999994\n",
            "🚂 Episode 2233\t 🏆 Score: -0.140 Avg: -0.037\t 💯 Done: 0.00% Avg: 18.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.015 ← 0.008 ↑ 0.015 → 0.023 ◼ 0.720 ↓ 0.218 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2234\t Score = -23.779999999999998\n",
            "🚂 Episode 2234\t 🏆 Score: -0.032 Avg: -0.037\t 💯 Done: 33.33% Avg: 18.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.031 ← 0.141 ↑ 0.804 → 0.012 ◼ 0.006 ↓ 0.006 \t Metric 0.6583333333333333 \n",
            "Episode Nr. 2235\t Score = -24.419999999999998\n",
            "🚂 Episode 2235\t 🏆 Score: -0.033 Avg: -0.037\t 💯 Done: 33.33% Avg: 18.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.530 ↑ 0.110 → 0.290 ◼ 0.050 ↓ 0.010 \t Metric 0.395 \n",
            "Episode Nr. 2236\t Score = -23.22\n",
            "🚂 Episode 2236\t 🏆 Score: -0.031 Avg: -0.037\t 💯 Done: 33.33% Avg: 18.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.234 → 0.021 ◼ 0.011 ↓ 0.553 \t Metric 0.397 \n",
            "Episode Nr. 2237\t Score = 9.563333333333334\n",
            "🚂 Episode 2237\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 18.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.553 → 0.053 ◼ 0.263 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2238\t Score = -23.22\n",
            "🚂 Episode 2238\t 🏆 Score: -0.031 Avg: -0.037\t 💯 Done: 33.33% Avg: 18.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.457 ← 0.170 ↑ 0.149 → 0.021 ◼ 0.191 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2239\t Score = -23.22\n",
            "🚂 Episode 2239\t 🏆 Score: -0.031 Avg: -0.037\t 💯 Done: 33.33% Avg: 19.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.734 → 0.064 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2240\t Score = -23.22\n",
            "🚂 Episode 2240\t 🏆 Score: -0.031 Avg: -0.037\t 💯 Done: 33.33% Avg: 19.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.713 ↑ 0.138 → 0.021 ◼ 0.096 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2241\t Score = -22.619999999999997\n",
            "🚂 Episode 2241\t 🏆 Score: -0.030 Avg: -0.036\t 💯 Done: 33.33% Avg: 19.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.294 ↑ 0.163 → 0.137 ◼ 0.203 ↓ 0.196 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2242\t Score = 8.79\n",
            "🚂 Episode 2242\t 🏆 Score: 0.012 Avg: -0.036\t 💯 Done: 33.33% Avg: 19.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2243\t Score = -42.53999999999999\n",
            "🚂 Episode 2243\t 🏆 Score: -0.057 Avg: -0.036\t 💯 Done: 0.00% Avg: 19.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.002 ← 0.068 ↑ 0.039 → 0.016 ◼ 0.483 ↓ 0.392 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2244\t Score = -45.01999999999994\n",
            "🚂 Episode 2244\t 🏆 Score: -0.060 Avg: -0.036\t 💯 Done: 0.00% Avg: 19.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.015 ↑ 0.022 → 0.041 ◼ 0.907 ↓ 0.007 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2245\t Score = 8.79\n",
            "🚂 Episode 2245\t 🏆 Score: 0.012 Avg: -0.036\t 💯 Done: 33.33% Avg: 19.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2246\t Score = -20.436666666666664\n",
            "🚂 Episode 2246\t 🏆 Score: -0.027 Avg: -0.036\t 💯 Done: 33.33% Avg: 19.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.763 → 0.105 ◼ 0.066 ↓ 0.026 \t Metric 0.397 \n",
            "Episode Nr. 2247\t Score = 8.79\n",
            "🚂 Episode 2247\t 🏆 Score: 0.012 Avg: -0.035\t 💯 Done: 33.33% Avg: 19.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2248\t Score = 9.563333333333334\n",
            "🚂 Episode 2248\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 19.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.171 ↑ 0.224 → 0.105 ◼ 0.079 ↓ 0.408 \t Metric 0.5965 \n",
            "Episode Nr. 2249\t Score = -105.01999999999994\n",
            "🚂 Episode 2249\t 🏆 Score: -0.140 Avg: -0.036\t 💯 Done: 0.00% Avg: 19.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.015 ↑ 0.015 → 0.019 ◼ 0.935 ↓ 0.008 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2250\t Score = -105.01999999999994\n",
            "🚂 Episode 2250\t 🏆 Score: -0.140 Avg: -0.037\t 💯 Done: 0.00% Avg: 19.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.038 ← 0.011 ↑ 0.015 → 0.023 ◼ 0.839 ↓ 0.073 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2251\t Score = -45.01999999999994\n",
            "🚂 Episode 2251\t 🏆 Score: -0.060 Avg: -0.037\t 💯 Done: 0.00% Avg: 19.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.313 ↑ 0.631 → 0.034 ◼ 0.007 ↓ 0.007 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2252\t Score = 8.79\n",
            "🚂 Episode 2252\t 🏆 Score: 0.012 Avg: -0.037\t 💯 Done: 33.33% Avg: 19.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2253\t Score = -22.619999999999997\n",
            "🚂 Episode 2253\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 19.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.523 ↑ 0.444 → 0.013 ◼ 0.007 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2254\t Score = -23.22\n",
            "🚂 Episode 2254\t 🏆 Score: -0.031 Avg: -0.037\t 💯 Done: 33.33% Avg: 19.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.564 ↑ 0.138 → 0.128 ◼ 0.149 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2255\t Score = -23.22\n",
            "🚂 Episode 2255\t 🏆 Score: -0.031 Avg: -0.037\t 💯 Done: 33.33% Avg: 19.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.138 ↑ 0.181 → 0.021 ◼ 0.638 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2256\t Score = -22.619999999999997\n",
            "🚂 Episode 2256\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 19.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.392 ← 0.072 ↑ 0.131 → 0.013 ◼ 0.386 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2257\t Score = -22.619999999999997\n",
            "🚂 Episode 2257\t 🏆 Score: -0.030 Avg: -0.036\t 💯 Done: 33.33% Avg: 19.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.392 ← 0.118 ↑ 0.078 → 0.013 ◼ 0.392 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2258\t Score = 8.79\n",
            "🚂 Episode 2258\t 🏆 Score: 0.012 Avg: -0.036\t 💯 Done: 33.33% Avg: 20.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2259\t Score = -42.53999999999999\n",
            "🚂 Episode 2259\t 🏆 Score: -0.057 Avg: -0.036\t 💯 Done: 0.00% Avg: 19.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.105 ← 0.452 ↑ 0.021 → 0.041 ◼ 0.377 ↓ 0.004 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2260\t Score = -22.619999999999997\n",
            "🚂 Episode 2260\t 🏆 Score: -0.030 Avg: -0.036\t 💯 Done: 33.33% Avg: 19.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.386 ← 0.131 ↑ 0.059 → 0.020 ◼ 0.386 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2261\t Score = -105.01999999999994\n",
            "🚂 Episode 2261\t 🏆 Score: -0.140 Avg: -0.037\t 💯 Done: 0.00% Avg: 19.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.008 ↑ 0.015 → 0.019 ◼ 0.678 ↓ 0.272 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2262\t Score = 9.563333333333334\n",
            "🚂 Episode 2262\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 19.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.237 ↑ 0.658 → 0.053 ◼ 0.013 ↓ 0.026 \t Metric 0.5965 \n",
            "Episode Nr. 2263\t Score = 9.563333333333334\n",
            "🚂 Episode 2263\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 20.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.132 ↑ 0.763 → 0.053 ◼ 0.013 ↓ 0.013 \t Metric 0.5965 \n",
            "Episode Nr. 2264\t Score = 9.563333333333334\n",
            "🚂 Episode 2264\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 20.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.579 ↑ 0.303 → 0.053 ◼ 0.026 ↓ 0.026 \t Metric 0.5965 \n",
            "Episode Nr. 2265\t Score = 9.563333333333334\n",
            "🚂 Episode 2265\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.276 → 0.579 ◼ 0.039 ↓ 0.066 \t Metric 0.5965 \n",
            "Episode Nr. 2266\t Score = -42.53999999999999\n",
            "🚂 Episode 2266\t 🏆 Score: -0.057 Avg: -0.035\t 💯 Done: 0.00% Avg: 20.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.097 ← 0.091 ↑ 0.017 → 0.386 ◼ 0.396 ↓ 0.012 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2267\t Score = 9.563333333333334\n",
            "🚂 Episode 2267\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.447 → 0.487 ◼ 0.013 ↓ 0.013 \t Metric 0.5965 \n",
            "Episode Nr. 2268\t Score = -22.619999999999997\n",
            "🚂 Episode 2268\t 🏆 Score: -0.030 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.673 ← 0.098 ↑ 0.098 → 0.013 ◼ 0.007 ↓ 0.111 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2269\t Score = 9.563333333333334\n",
            "🚂 Episode 2269\t 🏆 Score: 0.013 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.461 → 0.079 ◼ 0.368 ↓ 0.053 \t Metric 0.5965 \n",
            "Episode Nr. 2270\t Score = -42.53999999999999\n",
            "🚂 Episode 2270\t 🏆 Score: -0.057 Avg: -0.035\t 💯 Done: 0.00% Avg: 20.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.454 ← 0.204 ↑ 0.093 → 0.225 ◼ 0.004 ↓ 0.019 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2271\t Score = -105.01999999999994\n",
            "🚂 Episode 2271\t 🏆 Score: -0.140 Avg: -0.036\t 💯 Done: 0.00% Avg: 20.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.858 ← 0.008 ↑ 0.019 → 0.015 ◼ 0.096 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2272\t Score = 8.79\n",
            "🚂 Episode 2272\t 🏆 Score: 0.012 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2273\t Score = 8.79\n",
            "🚂 Episode 2273\t 🏆 Score: 0.012 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2274\t Score = 8.79\n",
            "🚂 Episode 2274\t 🏆 Score: 0.012 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2275\t Score = 8.79\n",
            "🚂 Episode 2275\t 🏆 Score: 0.012 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2276\t Score = -42.53999999999999\n",
            "🚂 Episode 2276\t 🏆 Score: -0.057 Avg: -0.034\t 💯 Done: 0.00% Avg: 20.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.311 ← 0.188 ↑ 0.025 → 0.019 ◼ 0.043 ↓ 0.414 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2277\t Score = -105.01999999999994\n",
            "🚂 Episode 2277\t 🏆 Score: -0.140 Avg: -0.035\t 💯 Done: 0.00% Avg: 20.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.207 ← 0.008 ↑ 0.027 → 0.015 ◼ 0.736 ↓ 0.008 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2278\t Score = 9.563333333333334\n",
            "🚂 Episode 2278\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.026 ↑ 0.855 → 0.053 ◼ 0.013 ↓ 0.026 \t Metric 0.5965 \n",
            "Episode Nr. 2279\t Score = -42.53999999999999\n",
            "🚂 Episode 2279\t 🏆 Score: -0.057 Avg: -0.035\t 💯 Done: 0.00% Avg: 20.14%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.041 ← 0.285 ↑ 0.146 → 0.254 ◼ 0.041 ↓ 0.233 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2280\t Score = -45.01999999999994\n",
            "🚂 Episode 2280\t 🏆 Score: -0.060 Avg: -0.035\t 💯 Done: 0.00% Avg: 19.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.183 ← 0.086 ↑ 0.448 → 0.045 ◼ 0.231 ↓ 0.007 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2281\t Score = 9.563333333333334\n",
            "🚂 Episode 2281\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 20.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.487 → 0.053 ◼ 0.395 ↓ 0.026 \t Metric 0.5965 \n",
            "Episode Nr. 2282\t Score = -42.53999999999999\n",
            "🚂 Episode 2282\t 🏆 Score: -0.057 Avg: -0.035\t 💯 Done: 0.00% Avg: 19.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.324 ← 0.142 ↑ 0.089 → 0.076 ◼ 0.008 ↓ 0.361 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2283\t Score = 8.79\n",
            "🚂 Episode 2283\t 🏆 Score: 0.012 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2284\t Score = -22.619999999999997\n",
            "🚂 Episode 2284\t 🏆 Score: -0.030 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.14%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.405 ← 0.026 ↑ 0.163 → 0.020 ◼ 0.098 ↓ 0.288 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2285\t Score = -23.22\n",
            "🚂 Episode 2285\t 🏆 Score: -0.031 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.585 ↑ 0.266 → 0.021 ◼ 0.096 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2286\t Score = -22.619999999999997\n",
            "🚂 Episode 2286\t 🏆 Score: -0.030 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.242 ← 0.248 ↑ 0.288 → 0.033 ◼ 0.059 ↓ 0.131 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2287\t Score = 8.643333333333333\n",
            "🚂 Episode 2287\t 🏆 Score: 0.012 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2288\t Score = -45.01999999999994\n",
            "🚂 Episode 2288\t 🏆 Score: -0.060 Avg: -0.034\t 💯 Done: 0.00% Avg: 20.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.896 ← 0.011 ↑ 0.041 → 0.045 ◼ 0.004 ↓ 0.004 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2289\t Score = 9.563333333333334\n",
            "🚂 Episode 2289\t 🏆 Score: 0.013 Avg: -0.034\t 💯 Done: 33.33% Avg: 20.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.053 ↑ 0.395 → 0.053 ◼ 0.368 ↓ 0.118 \t Metric 0.5965 \n",
            "Episode Nr. 2290\t Score = 9.563333333333334\n",
            "🚂 Episode 2290\t 🏆 Score: 0.013 Avg: -0.033\t 💯 Done: 33.33% Avg: 20.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.158 ↑ 0.316 → 0.039 ◼ 0.368 ↓ 0.105 \t Metric 0.5965 \n",
            "Episode Nr. 2291\t Score = 9.563333333333334\n",
            "🚂 Episode 2291\t 🏆 Score: 0.013 Avg: -0.033\t 💯 Done: 33.33% Avg: 20.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.434 → 0.053 ◼ 0.368 ↓ 0.105 \t Metric 0.5965 \n",
            "Episode Nr. 2292\t Score = 9.563333333333334\n",
            "🚂 Episode 2292\t 🏆 Score: 0.013 Avg: -0.032\t 💯 Done: 33.33% Avg: 20.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.434 → 0.053 ◼ 0.368 ↓ 0.105 \t Metric 0.5965 \n",
            "Episode Nr. 2293\t Score = -42.53999999999999\n",
            "🚂 Episode 2293\t 🏆 Score: -0.057 Avg: -0.032\t 💯 Done: 0.00% Avg: 20.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.214 ← 0.398 ↑ 0.170 → 0.060 ◼ 0.004 ↓ 0.154 \t Metric 0.6625 \n",
            "Episode Nr. 2294\t Score = 9.563333333333334\n",
            "🚂 Episode 2294\t 🏆 Score: 0.013 Avg: -0.032\t 💯 Done: 33.33% Avg: 20.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.447 → 0.039 ◼ 0.395 ↓ 0.079 \t Metric 0.5965 \n",
            "Episode Nr. 2295\t Score = -42.53999999999999\n",
            "🚂 Episode 2295\t 🏆 Score: -0.057 Avg: -0.032\t 💯 Done: 0.00% Avg: 20.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.173 ← 0.291 ↑ 0.068 → 0.274 ◼ 0.002 ↓ 0.192 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2296\t Score = 9.563333333333334\n",
            "🚂 Episode 2296\t 🏆 Score: 0.013 Avg: -0.032\t 💯 Done: 33.33% Avg: 20.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.026 ↑ 0.447 → 0.039 ◼ 0.355 ↓ 0.105 \t Metric 0.5965 \n",
            "Episode Nr. 2297\t Score = -22.619999999999997\n",
            "🚂 Episode 2297\t 🏆 Score: -0.030 Avg: -0.032\t 💯 Done: 33.33% Avg: 20.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.386 ← 0.092 ↑ 0.098 → 0.020 ◼ 0.013 ↓ 0.392 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2298\t Score = -23.22\n",
            "🚂 Episode 2298\t 🏆 Score: -0.031 Avg: -0.032\t 💯 Done: 33.33% Avg: 20.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.574 ← 0.096 ↑ 0.202 → 0.032 ◼ 0.011 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 2299\t Score = 9.563333333333334\n",
            "🚂 Episode 2299\t 🏆 Score: 0.013 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.171 ↑ 0.250 → 0.066 ◼ 0.395 ↓ 0.105 \t Metric 0.5965 \n",
            "Episode Nr. 2300\t Score = -22.619999999999997\n",
            "🚂 Episode 2300\t 🏆 Score: -0.030 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.503 ← 0.092 ↑ 0.085 → 0.020 ◼ 0.281 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2301\t Score = -24.419999999999998\n",
            "🚂 Episode 2301\t 🏆 Score: -0.033 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.030 ↑ 0.160 → 0.170 ◼ 0.560 ↓ 0.070 \t Metric 0.395 \n",
            "Episode Nr. 2302\t Score = -22.619999999999997\n",
            "🚂 Episode 2302\t 🏆 Score: -0.030 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.333 ← 0.176 ↑ 0.052 → 0.033 ◼ 0.392 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2303\t Score = -23.22\n",
            "🚂 Episode 2303\t 🏆 Score: -0.031 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.255 ↑ 0.117 → 0.032 ◼ 0.128 ↓ 0.457 \t Metric 0.397 \n",
            "Episode Nr. 2304\t Score = 9.563333333333334\n",
            "🚂 Episode 2304\t 🏆 Score: 0.013 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.132 ↑ 0.329 → 0.039 ◼ 0.368 ↓ 0.118 \t Metric 0.5965 \n",
            "Episode Nr. 2305\t Score = -22.619999999999997\n",
            "🚂 Episode 2305\t 🏆 Score: -0.030 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.536 ← 0.092 ↑ 0.078 → 0.026 ◼ 0.248 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2306\t Score = -22.619999999999997\n",
            "🚂 Episode 2306\t 🏆 Score: -0.030 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.301 ← 0.235 ↑ 0.333 → 0.039 ◼ 0.059 ↓ 0.033 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2307\t Score = -42.53999999999999\n",
            "🚂 Episode 2307\t 🏆 Score: -0.057 Avg: -0.031\t 💯 Done: 0.00% Avg: 21.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.198 ← 0.052 ↑ 0.173 → 0.326 ◼ 0.047 ↓ 0.204 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2308\t Score = -23.22\n",
            "🚂 Episode 2308\t 🏆 Score: -0.031 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.117 → 0.021 ◼ 0.436 ↓ 0.223 \t Metric 0.397 \n",
            "Episode Nr. 2309\t Score = -23.22\n",
            "🚂 Episode 2309\t 🏆 Score: -0.031 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.074 ↑ 0.415 → 0.032 ◼ 0.128 ↓ 0.340 \t Metric 0.397 \n",
            "Episode Nr. 2310\t Score = -42.53999999999999\n",
            "🚂 Episode 2310\t 🏆 Score: -0.057 Avg: -0.031\t 💯 Done: 0.00% Avg: 21.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.258 ← 0.144 ↑ 0.216 → 0.111 ◼ 0.035 ↓ 0.237 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2311\t Score = -22.619999999999997\n",
            "🚂 Episode 2311\t 🏆 Score: -0.030 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.392 ← 0.020 ↑ 0.118 → 0.059 ◼ 0.176 ↓ 0.235 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2312\t Score = -42.53999999999999\n",
            "🚂 Episode 2312\t 🏆 Score: -0.057 Avg: -0.032\t 💯 Done: 0.00% Avg: 21.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.130 ← 0.177 ↑ 0.181 → 0.301 ◼ 0.064 ↓ 0.148 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2313\t Score = -102.53999999999999\n",
            "🚂 Episode 2313\t 🏆 Score: -0.137 Avg: -0.033\t 💯 Done: 0.00% Avg: 21.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.654 ← 0.067 ↑ 0.014 → 0.057 ◼ 0.103 ↓ 0.105 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2314\t Score = 9.563333333333334\n",
            "🚂 Episode 2314\t 🏆 Score: 0.013 Avg: -0.032\t 💯 Done: 33.33% Avg: 21.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.026 ↑ 0.408 → 0.053 ◼ 0.395 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2315\t Score = -23.22\n",
            "🚂 Episode 2315\t 🏆 Score: -0.031 Avg: -0.032\t 💯 Done: 33.33% Avg: 21.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.032 ↑ 0.160 → 0.128 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2316\t Score = 8.79\n",
            "🚂 Episode 2316\t 🏆 Score: 0.012 Avg: -0.032\t 💯 Done: 33.33% Avg: 21.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2317\t Score = 9.563333333333334\n",
            "🚂 Episode 2317\t 🏆 Score: 0.013 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.184 ↑ 0.263 → 0.066 ◼ 0.342 ↓ 0.118 \t Metric 0.5965 \n",
            "Episode Nr. 2318\t Score = 9.563333333333334\n",
            "🚂 Episode 2318\t 🏆 Score: 0.013 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.434 → 0.039 ◼ 0.368 ↓ 0.118 \t Metric 0.5965 \n",
            "Episode Nr. 2319\t Score = -42.53999999999999\n",
            "🚂 Episode 2319\t 🏆 Score: -0.057 Avg: -0.031\t 💯 Done: 0.00% Avg: 21.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.214 ← 0.134 ↑ 0.117 → 0.330 ◼ 0.016 ↓ 0.190 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2320\t Score = -42.53999999999999\n",
            "🚂 Episode 2320\t 🏆 Score: -0.057 Avg: -0.031\t 💯 Done: 0.00% Avg: 21.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.002 ← 0.227 ↑ 0.340 → 0.272 ◼ 0.014 ↓ 0.146 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2321\t Score = -42.53999999999999\n",
            "🚂 Episode 2321\t 🏆 Score: -0.057 Avg: -0.032\t 💯 Done: 0.00% Avg: 21.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.023 ← 0.482 ↑ 0.060 → 0.064 ◼ 0.179 ↓ 0.192 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2322\t Score = 9.563333333333334\n",
            "🚂 Episode 2322\t 🏆 Score: 0.013 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.382 → 0.092 ◼ 0.368 ↓ 0.118 \t Metric 0.5965 \n",
            "Episode Nr. 2323\t Score = -42.53999999999999\n",
            "🚂 Episode 2323\t 🏆 Score: -0.057 Avg: -0.031\t 💯 Done: 0.00% Avg: 21.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.122 ← 0.136 ↑ 0.256 → 0.183 ◼ 0.124 ↓ 0.179 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2324\t Score = 9.563333333333334\n",
            "🚂 Episode 2324\t 🏆 Score: 0.013 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.487 → 0.092 ◼ 0.237 ↓ 0.145 \t Metric 0.5965 \n",
            "Episode Nr. 2325\t Score = -45.01999999999994\n",
            "🚂 Episode 2325\t 🏆 Score: -0.060 Avg: -0.031\t 💯 Done: 0.00% Avg: 21.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.123 ← 0.007 ↑ 0.619 → 0.243 ◼ 0.004 ↓ 0.004 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2326\t Score = 8.79\n",
            "🚂 Episode 2326\t 🏆 Score: 0.012 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2327\t Score = -45.01999999999994\n",
            "🚂 Episode 2327\t 🏆 Score: -0.060 Avg: -0.031\t 💯 Done: 0.00% Avg: 21.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.616 ↑ 0.343 → 0.030 ◼ 0.004 ↓ 0.004 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2328\t Score = -23.22\n",
            "🚂 Episode 2328\t 🏆 Score: -0.031 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.14%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.532 ↑ 0.106 → 0.032 ◼ 0.287 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2329\t Score = 8.643333333333333\n",
            "🚂 Episode 2329\t 🏆 Score: 0.012 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2330\t Score = -23.22\n",
            "🚂 Episode 2330\t 🏆 Score: -0.031 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.511 ← 0.085 ↑ 0.096 → 0.128 ◼ 0.138 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2331\t Score = -23.22\n",
            "🚂 Episode 2331\t 🏆 Score: -0.031 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.181 ← 0.096 ↑ 0.106 → 0.117 ◼ 0.468 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2332\t Score = -22.619999999999997\n",
            "🚂 Episode 2332\t 🏆 Score: -0.030 Avg: -0.031\t 💯 Done: 33.33% Avg: 21.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.046 ↑ 0.190 → 0.176 ◼ 0.248 ↓ 0.320 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2333\t Score = 9.563333333333334\n",
            "🚂 Episode 2333\t 🏆 Score: 0.013 Avg: -0.030\t 💯 Done: 33.33% Avg: 21.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.829 → 0.066 ◼ 0.013 ↓ 0.053 \t Metric 0.5965 \n",
            "Episode Nr. 2334\t Score = 9.563333333333334\n",
            "🚂 Episode 2334\t 🏆 Score: 0.013 Avg: -0.030\t 💯 Done: 33.33% Avg: 21.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.408 ↑ 0.382 → 0.079 ◼ 0.079 ↓ 0.039 \t Metric 0.5965 \n",
            "Episode Nr. 2335\t Score = -42.53999999999999\n",
            "🚂 Episode 2335\t 🏆 Score: -0.057 Avg: -0.030\t 💯 Done: 0.00% Avg: 21.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.136 ← 0.260 ↑ 0.235 → 0.056 ◼ 0.019 ↓ 0.293 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2336\t Score = 9.563333333333334\n",
            "🚂 Episode 2336\t 🏆 Score: 0.013 Avg: -0.030\t 💯 Done: 33.33% Avg: 21.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.171 → 0.632 ◼ 0.039 ↓ 0.118 \t Metric 0.5965 \n",
            "Episode Nr. 2337\t Score = 9.563333333333334\n",
            "🚂 Episode 2337\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 21.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.039 ↑ 0.382 → 0.434 ◼ 0.066 ↓ 0.066 \t Metric 0.5965 \n",
            "Episode Nr. 2338\t Score = -42.53999999999999\n",
            "🚂 Episode 2338\t 🏆 Score: -0.057 Avg: -0.030\t 💯 Done: 0.00% Avg: 21.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.058 ← 0.130 ↑ 0.264 → 0.243 ◼ 0.285 ↓ 0.019 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2339\t Score = -23.22\n",
            "🚂 Episode 2339\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 21.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.032 ↑ 0.128 → 0.138 ◼ 0.628 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 2340\t Score = 9.563333333333334\n",
            "🚂 Episode 2340\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 21.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.026 ↑ 0.618 → 0.184 ◼ 0.013 ↓ 0.132 \t Metric 0.5965 \n",
            "Episode Nr. 2341\t Score = 9.563333333333334\n",
            "🚂 Episode 2341\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 22.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.026 ↑ 0.789 → 0.053 ◼ 0.013 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2342\t Score = 9.563333333333334\n",
            "🚂 Episode 2342\t 🏆 Score: 0.013 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.539 ↑ 0.197 → 0.053 ◼ 0.039 ↓ 0.158 \t Metric 0.5965 \n",
            "Episode Nr. 2343\t Score = 9.563333333333334\n",
            "🚂 Episode 2343\t 🏆 Score: 0.013 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.434 → 0.066 ◼ 0.355 ↓ 0.105 \t Metric 0.5965 \n",
            "Episode Nr. 2344\t Score = -42.53999999999999\n",
            "🚂 Episode 2344\t 🏆 Score: -0.057 Avg: -0.028\t 💯 Done: 0.00% Avg: 22.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.155 ← 0.260 ↑ 0.480 → 0.039 ◼ 0.006 ↓ 0.060 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2345\t Score = -45.01999999999994\n",
            "🚂 Episode 2345\t 🏆 Score: -0.060 Avg: -0.029\t 💯 Done: 0.00% Avg: 21.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.080 ← 0.305 ↑ 0.271 → 0.019 ◼ 0.156 ↓ 0.170 \t Metric 0.346 \n",
            "Episode Nr. 2346\t Score = -23.22\n",
            "🚂 Episode 2346\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 21.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.532 → 0.160 ◼ 0.011 ↓ 0.223 \t Metric 0.397 \n",
            "Episode Nr. 2347\t Score = -22.619999999999997\n",
            "🚂 Episode 2347\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 22.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.209 ← 0.059 ↑ 0.431 → 0.124 ◼ 0.033 ↓ 0.144 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2348\t Score = 8.643333333333333\n",
            "🚂 Episode 2348\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2349\t Score = 9.563333333333334\n",
            "🚂 Episode 2349\t 🏆 Score: 0.013 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.474 → 0.039 ◼ 0.368 ↓ 0.079 \t Metric 0.5965 \n",
            "Episode Nr. 2350\t Score = -42.53999999999999\n",
            "🚂 Episode 2350\t 🏆 Score: -0.057 Avg: -0.028\t 💯 Done: 0.00% Avg: 22.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.313 ↑ 0.165 → 0.311 ◼ 0.004 ↓ 0.144 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2351\t Score = 8.79\n",
            "🚂 Episode 2351\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2352\t Score = -23.22\n",
            "🚂 Episode 2352\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.106 ↑ 0.181 → 0.128 ◼ 0.128 ↓ 0.447 \t Metric 0.397 \n",
            "Episode Nr. 2353\t Score = -22.91\n",
            "🚂 Episode 2353\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.590 ← 0.051 ↑ 0.071 → 0.071 ◼ 0.199 ↓ 0.019 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 2354\t Score = -42.53999999999999\n",
            "🚂 Episode 2354\t 🏆 Score: -0.057 Avg: -0.028\t 💯 Done: 0.00% Avg: 22.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.128 ← 0.334 ↑ 0.227 → 0.159 ◼ 0.060 ↓ 0.091 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2355\t Score = 9.563333333333334\n",
            "🚂 Episode 2355\t 🏆 Score: 0.013 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.803 → 0.118 ◼ 0.013 ↓ 0.026 \t Metric 0.5965 \n",
            "Episode Nr. 2356\t Score = -23.22\n",
            "🚂 Episode 2356\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.628 ← 0.032 ↑ 0.181 → 0.128 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2357\t Score = -23.22\n",
            "🚂 Episode 2357\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.096 ↑ 0.202 → 0.202 ◼ 0.064 ↓ 0.426 \t Metric 0.397 \n",
            "Episode Nr. 2358\t Score = -23.22\n",
            "🚂 Episode 2358\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.287 → 0.138 ◼ 0.128 ↓ 0.372 \t Metric 0.397 \n",
            "Episode Nr. 2359\t Score = 8.79\n",
            "🚂 Episode 2359\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 22.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2360\t Score = -42.53999999999999\n",
            "🚂 Episode 2360\t 🏆 Score: -0.057 Avg: -0.028\t 💯 Done: 0.00% Avg: 22.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.118 ← 0.070 ↑ 0.412 → 0.202 ◼ 0.023 ↓ 0.175 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2361\t Score = -23.22\n",
            "🚂 Episode 2361\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.649 ↑ 0.181 → 0.043 ◼ 0.021 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 2362\t Score = -23.520000000000003\n",
            "🚂 Episode 2362\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.156 ← 0.156 ↑ 0.500 → 0.052 ◼ 0.031 ↓ 0.104 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2363\t Score = -23.22\n",
            "🚂 Episode 2363\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.096 ↑ 0.117 → 0.117 ◼ 0.606 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2364\t Score = -23.22\n",
            "🚂 Episode 2364\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 22.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.064 ↑ 0.713 → 0.117 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 2365\t Score = 9.563333333333334\n",
            "🚂 Episode 2365\t 🏆 Score: 0.013 Avg: -0.027\t 💯 Done: 33.33% Avg: 22.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.487 → 0.039 ◼ 0.382 ↓ 0.053 \t Metric 0.5965 \n",
            "Episode Nr. 2366\t Score = -23.520000000000003\n",
            "🚂 Episode 2366\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 23.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.031 ↑ 0.271 → 0.396 ◼ 0.271 ↓ 0.021 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2367\t Score = -22.619999999999997\n",
            "🚂 Episode 2367\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 23.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.248 ↑ 0.209 → 0.190 ◼ 0.007 ↓ 0.340 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2368\t Score = 9.563333333333334\n",
            "🚂 Episode 2368\t 🏆 Score: 0.013 Avg: -0.027\t 💯 Done: 33.33% Avg: 23.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.211 ↑ 0.289 → 0.053 ◼ 0.342 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2369\t Score = -45.01999999999994\n",
            "🚂 Episode 2369\t 🏆 Score: -0.060 Avg: -0.027\t 💯 Done: 0.00% Avg: 23.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.123 ← 0.362 ↑ 0.381 → 0.026 ◼ 0.093 ↓ 0.015 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2370\t Score = -22.619999999999997\n",
            "🚂 Episode 2370\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 23.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.235 ↑ 0.490 → 0.111 ◼ 0.046 ↓ 0.105 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2371\t Score = -22.619999999999997\n",
            "🚂 Episode 2371\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 23.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.386 ← 0.124 ↑ 0.137 → 0.013 ◼ 0.209 ↓ 0.131 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2372\t Score = -22.619999999999997\n",
            "🚂 Episode 2372\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 23.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.137 ↑ 0.516 → 0.059 ◼ 0.059 ↓ 0.144 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2373\t Score = -23.22\n",
            "🚂 Episode 2373\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 23.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.202 ↑ 0.096 → 0.457 ◼ 0.011 ↓ 0.213 \t Metric 0.397 \n",
            "Episode Nr. 2374\t Score = -23.22\n",
            "🚂 Episode 2374\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 23.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.223 ↑ 0.160 → 0.021 ◼ 0.245 ↓ 0.340 \t Metric 0.397 \n",
            "Episode Nr. 2375\t Score = -42.53999999999999\n",
            "🚂 Episode 2375\t 🏆 Score: -0.057 Avg: -0.028\t 💯 Done: 0.00% Avg: 23.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.056 ← 0.332 ↑ 0.334 → 0.183 ◼ 0.058 ↓ 0.037 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2376\t Score = -23.22\n",
            "🚂 Episode 2376\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 23.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.351 → 0.096 ◼ 0.011 ↓ 0.330 \t Metric 0.397 \n",
            "Episode Nr. 2377\t Score = -23.22\n",
            "🚂 Episode 2377\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 23.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.319 → 0.138 ◼ 0.011 ↓ 0.330 \t Metric 0.397 \n",
            "Episode Nr. 2378\t Score = 8.643333333333333\n",
            "🚂 Episode 2378\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 23.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2379\t Score = -23.22\n",
            "🚂 Episode 2379\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 23.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.096 → 0.053 ◼ 0.617 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2380\t Score = -23.779999999999998\n",
            "🚂 Episode 2380\t 🏆 Score: -0.032 Avg: -0.028\t 💯 Done: 33.33% Avg: 23.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.025 ← 0.074 ↑ 0.399 → 0.110 ◼ 0.337 ↓ 0.055 \t Metric 0.6583333333333333 \n",
            "Episode Nr. 2381\t Score = -23.22\n",
            "🚂 Episode 2381\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 23.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.287 ← 0.032 ↑ 0.585 → 0.043 ◼ 0.021 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2382\t Score = 8.643333333333333\n",
            "🚂 Episode 2382\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 24.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2383\t Score = -42.53999999999999\n",
            "🚂 Episode 2383\t 🏆 Score: -0.057 Avg: -0.027\t 💯 Done: 0.00% Avg: 23.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.134 ← 0.212 ↑ 0.223 → 0.262 ◼ 0.047 ↓ 0.122 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2384\t Score = -23.22\n",
            "🚂 Episode 2384\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 23.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.053 ↑ 0.447 → 0.149 ◼ 0.011 ↓ 0.330 \t Metric 0.397 \n",
            "Episode Nr. 2385\t Score = -23.22\n",
            "🚂 Episode 2385\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 23.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.032 ↑ 0.266 → 0.032 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2386\t Score = 9.563333333333334\n",
            "🚂 Episode 2386\t 🏆 Score: 0.013 Avg: -0.027\t 💯 Done: 33.33% Avg: 24.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.855 → 0.066 ◼ 0.013 ↓ 0.026 \t Metric 0.5965 \n",
            "Episode Nr. 2387\t Score = -42.53999999999999\n",
            "🚂 Episode 2387\t 🏆 Score: -0.057 Avg: -0.027\t 💯 Done: 0.00% Avg: 23.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.175 ↑ 0.443 → 0.171 ◼ 0.058 ↓ 0.111 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2388\t Score = -23.22\n",
            "🚂 Episode 2388\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 23.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.160 ↑ 0.191 → 0.160 ◼ 0.043 ↓ 0.436 \t Metric 0.397 \n",
            "Episode Nr. 2389\t Score = -23.22\n",
            "🚂 Episode 2389\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 24.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.181 ↑ 0.096 → 0.245 ◼ 0.011 ↓ 0.447 \t Metric 0.397 \n",
            "Episode Nr. 2390\t Score = -23.22\n",
            "🚂 Episode 2390\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 24.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.096 ↑ 0.404 → 0.149 ◼ 0.011 ↓ 0.330 \t Metric 0.397 \n",
            "Episode Nr. 2391\t Score = -22.619999999999997\n",
            "🚂 Episode 2391\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 24.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.124 ← 0.235 ↑ 0.203 → 0.092 ◼ 0.007 ↓ 0.340 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2392\t Score = -45.01999999999994\n",
            "🚂 Episode 2392\t 🏆 Score: -0.060 Avg: -0.028\t 💯 Done: 0.00% Avg: 23.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.168 ← 0.190 ↑ 0.597 → 0.030 ◼ 0.004 ↓ 0.011 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2393\t Score = -22.91\n",
            "🚂 Episode 2393\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 24.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.045 ← 0.282 ↑ 0.269 → 0.160 ◼ 0.013 ↓ 0.231 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 2394\t Score = -22.619999999999997\n",
            "🚂 Episode 2394\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 24.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.131 ← 0.163 ↑ 0.144 → 0.209 ◼ 0.007 ↓ 0.346 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2395\t Score = -23.22\n",
            "🚂 Episode 2395\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 24.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.223 → 0.021 ◼ 0.011 ↓ 0.532 \t Metric 0.397 \n",
            "Episode Nr. 2396\t Score = 8.79\n",
            "🚂 Episode 2396\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 24.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2397\t Score = 8.79\n",
            "🚂 Episode 2397\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 24.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2398\t Score = 8.79\n",
            "🚂 Episode 2398\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 24.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2399\t Score = -23.22\n",
            "🚂 Episode 2399\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 24.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.191 → 0.032 ◼ 0.011 ↓ 0.553 \t Metric 0.397 \n",
            "Episode Nr. 2400\t Score = -23.22\n",
            "🚂 Episode 2400\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 24.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.585 ↑ 0.096 → 0.021 ◼ 0.234 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2401\t Score = -23.22\n",
            "🚂 Episode 2401\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 24.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.117 → 0.043 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2402\t Score = -23.22\n",
            "🚂 Episode 2402\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 24.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.298 ↑ 0.074 → 0.021 ◼ 0.383 ↓ 0.213 \t Metric 0.397 \n",
            "Episode Nr. 2403\t Score = -23.22\n",
            "🚂 Episode 2403\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 24.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.298 → 0.043 ◼ 0.011 ↓ 0.457 \t Metric 0.397 \n",
            "Episode Nr. 2404\t Score = -23.22\n",
            "🚂 Episode 2404\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 25.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.628 ↑ 0.191 → 0.043 ◼ 0.011 ↓ 0.117 \t Metric 0.397 \n",
            "Episode Nr. 2405\t Score = -23.22\n",
            "🚂 Episode 2405\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 25.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.298 ↑ 0.500 → 0.043 ◼ 0.011 ↓ 0.117 \t Metric 0.397 \n",
            "Episode Nr. 2406\t Score = -23.22\n",
            "🚂 Episode 2406\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 25.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.064 → 0.223 ◼ 0.128 ↓ 0.394 \t Metric 0.397 \n",
            "Episode Nr. 2407\t Score = 9.563333333333334\n",
            "🚂 Episode 2407\t 🏆 Score: 0.013 Avg: -0.027\t 💯 Done: 33.33% Avg: 25.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.276 → 0.566 ◼ 0.013 ↓ 0.105 \t Metric 0.5965 \n",
            "Episode Nr. 2408\t Score = 9.563333333333334\n",
            "🚂 Episode 2408\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 25.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.184 ↑ 0.158 → 0.487 ◼ 0.066 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2409\t Score = -23.22\n",
            "🚂 Episode 2409\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 25.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.053 ↑ 0.255 → 0.202 ◼ 0.011 ↓ 0.426 \t Metric 0.397 \n",
            "Episode Nr. 2410\t Score = -20.436666666666664\n",
            "🚂 Episode 2410\t 🏆 Score: -0.027 Avg: -0.026\t 💯 Done: 33.33% Avg: 25.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.197 ↑ 0.566 → 0.092 ◼ 0.013 ↓ 0.105 \t Metric 0.397 \n",
            "Episode Nr. 2411\t Score = 8.79\n",
            "🚂 Episode 2411\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 25.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2412\t Score = -22.619999999999997\n",
            "🚂 Episode 2412\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 25.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.288 ← 0.124 ↑ 0.085 → 0.072 ◼ 0.392 ↓ 0.039 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2413\t Score = -23.22\n",
            "🚂 Episode 2413\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 25.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.500 ← 0.032 ↑ 0.234 → 0.032 ◼ 0.011 ↓ 0.191 \t Metric 0.397 \n",
            "Episode Nr. 2414\t Score = -42.53999999999999\n",
            "🚂 Episode 2414\t 🏆 Score: -0.057 Avg: -0.026\t 💯 Done: 0.00% Avg: 25.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.282 ← 0.194 ↑ 0.133 → 0.190 ◼ 0.122 ↓ 0.079 \t Metric 0.6325000000000001 \n",
            "Episode Nr. 2415\t Score = -23.22\n",
            "🚂 Episode 2415\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 25.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.106 → 0.021 ◼ 0.351 ↓ 0.340 \t Metric 0.397 \n",
            "Episode Nr. 2416\t Score = 9.563333333333334\n",
            "🚂 Episode 2416\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 25.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.066 ↑ 0.289 → 0.184 ◼ 0.276 ↓ 0.171 \t Metric 0.5965 \n",
            "Episode Nr. 2417\t Score = 9.563333333333334\n",
            "🚂 Episode 2417\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 25.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.368 → 0.079 ◼ 0.395 ↓ 0.118 \t Metric 0.5965 \n",
            "Episode Nr. 2418\t Score = -105.01999999999994\n",
            "🚂 Episode 2418\t 🏆 Score: -0.140 Avg: -0.027\t 💯 Done: 0.00% Avg: 25.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.368 ← 0.011 ↑ 0.023 → 0.042 ◼ 0.552 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2419\t Score = -42.53999999999999\n",
            "🚂 Episode 2419\t 🏆 Score: -0.057 Avg: -0.027\t 💯 Done: 0.00% Avg: 25.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.002 ← 0.164 ↑ 0.393 → 0.184 ◼ 0.014 ↓ 0.244 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2420\t Score = -22.619999999999997\n",
            "🚂 Episode 2420\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 25.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.072 ← 0.163 ↑ 0.582 → 0.046 ◼ 0.052 ↓ 0.085 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2421\t Score = -23.22\n",
            "🚂 Episode 2421\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 25.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.043 ↑ 0.266 → 0.213 ◼ 0.011 ↓ 0.362 \t Metric 0.397 \n",
            "Episode Nr. 2422\t Score = -45.01999999999994\n",
            "🚂 Episode 2422\t 🏆 Score: -0.060 Avg: -0.027\t 💯 Done: 0.00% Avg: 25.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.213 ← 0.007 ↑ 0.265 → 0.496 ◼ 0.007 ↓ 0.011 \t Metric 0.39949999999999997 \n",
            "Episode Nr. 2423\t Score = 9.563333333333334\n",
            "🚂 Episode 2423\t 🏆 Score: 0.013 Avg: -0.027\t 💯 Done: 33.33% Avg: 25.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.197 ↑ 0.658 → 0.092 ◼ 0.013 ↓ 0.026 \t Metric 0.5965 \n",
            "Episode Nr. 2424\t Score = -105.01999999999994\n",
            "🚂 Episode 2424\t 🏆 Score: -0.140 Avg: -0.028\t 💯 Done: 0.00% Avg: 24.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.034 ↑ 0.019 → 0.575 ◼ 0.356 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2425\t Score = 10.11\n",
            "🚂 Episode 2425\t 🏆 Score: 0.013 Avg: -0.028\t 💯 Done: 33.33% Avg: 25.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.886 → 0.029 ◼ 0.014 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 2426\t Score = -45.01999999999994\n",
            "🚂 Episode 2426\t 🏆 Score: -0.060 Avg: -0.028\t 💯 Done: 0.00% Avg: 24.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.050 ← 0.094 ↑ 0.292 → 0.443 ◼ 0.097 ↓ 0.023 \t Metric 0.38549999999999995 \n",
            "Episode Nr. 2427\t Score = -102.53999999999999\n",
            "🚂 Episode 2427\t 🏆 Score: -0.137 Avg: -0.029\t 💯 Done: 0.00% Avg: 24.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.120 ← 0.182 ↑ 0.473 → 0.143 ◼ 0.004 ↓ 0.078 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2428\t Score = -23.22\n",
            "🚂 Episode 2428\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.149 ← 0.181 ↑ 0.138 → 0.309 ◼ 0.138 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 2429\t Score = -22.619999999999997\n",
            "🚂 Episode 2429\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.340 ← 0.137 ↑ 0.092 → 0.072 ◼ 0.235 ↓ 0.124 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2430\t Score = -42.53999999999999\n",
            "🚂 Episode 2430\t 🏆 Score: -0.057 Avg: -0.029\t 💯 Done: 0.00% Avg: 24.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.037 ← 0.124 ↑ 0.351 → 0.198 ◼ 0.062 ↓ 0.227 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2431\t Score = -42.53999999999999\n",
            "🚂 Episode 2431\t 🏆 Score: -0.057 Avg: -0.030\t 💯 Done: 0.00% Avg: 24.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.068 ← 0.266 ↑ 0.462 → 0.056 ◼ 0.010 ↓ 0.138 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2432\t Score = -105.01999999999994\n",
            "🚂 Episode 2432\t 🏆 Score: -0.140 Avg: -0.031\t 💯 Done: 0.00% Avg: 23.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.406 ↑ 0.019 → 0.533 ◼ 0.027 ↓ 0.011 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2433\t Score = -42.53999999999999\n",
            "🚂 Episode 2433\t 🏆 Score: -0.057 Avg: -0.031\t 💯 Done: 0.00% Avg: 23.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.271 ↑ 0.361 → 0.089 ◼ 0.193 ↓ 0.077 \t Metric 0.5791666666666666 \n",
            "Episode Nr. 2434\t Score = -23.22\n",
            "🚂 Episode 2434\t 🏆 Score: -0.031 Avg: -0.031\t 💯 Done: 33.33% Avg: 23.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.181 ← 0.181 ↑ 0.117 → 0.032 ◼ 0.468 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2435\t Score = -22.91\n",
            "🚂 Episode 2435\t 🏆 Score: -0.031 Avg: -0.031\t 💯 Done: 33.33% Avg: 23.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.019 ← 0.205 ↑ 0.103 → 0.269 ◼ 0.026 ↓ 0.378 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 2436\t Score = 8.79\n",
            "🚂 Episode 2436\t 🏆 Score: 0.012 Avg: -0.031\t 💯 Done: 33.33% Avg: 24.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2437\t Score = -23.22\n",
            "🚂 Episode 2437\t 🏆 Score: -0.031 Avg: -0.031\t 💯 Done: 33.33% Avg: 24.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.043 ↑ 0.160 → 0.032 ◼ 0.532 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2438\t Score = 8.79\n",
            "🚂 Episode 2438\t 🏆 Score: 0.012 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2439\t Score = 9.563333333333334\n",
            "🚂 Episode 2439\t 🏆 Score: 0.013 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.303 ↑ 0.408 → 0.066 ◼ 0.013 ↓ 0.197 \t Metric 0.5965 \n",
            "Episode Nr. 2440\t Score = 9.563333333333334\n",
            "🚂 Episode 2440\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.408 → 0.500 ◼ 0.013 ↓ 0.039 \t Metric 0.5965 \n",
            "Episode Nr. 2441\t Score = -20.436666666666664\n",
            "🚂 Episode 2441\t 🏆 Score: -0.027 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.039 ↑ 0.671 → 0.079 ◼ 0.013 ↓ 0.105 \t Metric 0.397 \n",
            "Episode Nr. 2442\t Score = -23.22\n",
            "🚂 Episode 2442\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.117 ← 0.064 ↑ 0.106 → 0.032 ◼ 0.638 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2443\t Score = -23.22\n",
            "🚂 Episode 2443\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.032 ↑ 0.213 → 0.032 ◼ 0.638 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2444\t Score = -23.22\n",
            "🚂 Episode 2444\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.085 ↑ 0.170 → 0.032 ◼ 0.628 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2445\t Score = 9.563333333333334\n",
            "🚂 Episode 2445\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.053 ↑ 0.395 → 0.250 ◼ 0.184 ↓ 0.105 \t Metric 0.5965 \n",
            "Episode Nr. 2446\t Score = 8.79\n",
            "🚂 Episode 2446\t 🏆 Score: 0.012 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2447\t Score = 9.563333333333334\n",
            "🚂 Episode 2447\t 🏆 Score: 0.013 Avg: -0.028\t 💯 Done: 33.33% Avg: 24.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.250 → 0.592 ◼ 0.013 ↓ 0.105 \t Metric 0.5965 \n",
            "Episode Nr. 2448\t Score = -105.01999999999994\n",
            "🚂 Episode 2448\t 🏆 Score: -0.140 Avg: -0.029\t 💯 Done: 0.00% Avg: 24.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.165 ← 0.284 ↑ 0.019 → 0.310 ◼ 0.218 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2449\t Score = -105.01999999999994\n",
            "🚂 Episode 2449\t 🏆 Score: -0.140 Avg: -0.030\t 💯 Done: 0.00% Avg: 24.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.352 ← 0.161 ↑ 0.019 → 0.092 ◼ 0.372 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2450\t Score = -102.53999999999999\n",
            "🚂 Episode 2450\t 🏆 Score: -0.137 Avg: -0.031\t 💯 Done: 0.00% Avg: 24.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.016 ← 0.079 ↑ 0.249 → 0.169 ◼ 0.366 ↓ 0.121 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2451\t Score = -42.53999999999999\n",
            "🚂 Episode 2451\t 🏆 Score: -0.057 Avg: -0.032\t 💯 Done: 0.00% Avg: 24.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.268 ↑ 0.188 → 0.121 ◼ 0.257 ↓ 0.135 \t Metric 0.5516666666666667 \n",
            "Episode Nr. 2452\t Score = 8.643333333333333\n",
            "🚂 Episode 2452\t 🏆 Score: 0.012 Avg: -0.031\t 💯 Done: 33.33% Avg: 24.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2453\t Score = -23.22\n",
            "🚂 Episode 2453\t 🏆 Score: -0.031 Avg: -0.031\t 💯 Done: 33.33% Avg: 24.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.043 ↑ 0.170 → 0.032 ◼ 0.628 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2454\t Score = 10.11\n",
            "🚂 Episode 2454\t 🏆 Score: 0.013 Avg: -0.031\t 💯 Done: 33.33% Avg: 24.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.171 ↑ 0.186 → 0.429 ◼ 0.043 ↓ 0.157 \t Metric 0.5925 \n",
            "Episode Nr. 2455\t Score = 8.79\n",
            "🚂 Episode 2455\t 🏆 Score: 0.012 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2456\t Score = 9.563333333333334\n",
            "🚂 Episode 2456\t 🏆 Score: 0.013 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.895 → 0.039 ◼ 0.013 ↓ 0.013 \t Metric 0.5965 \n",
            "Episode Nr. 2457\t Score = 9.563333333333334\n",
            "🚂 Episode 2457\t 🏆 Score: 0.013 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.342 → 0.579 ◼ 0.013 ↓ 0.026 \t Metric 0.5965 \n",
            "Episode Nr. 2458\t Score = 9.426666666666666\n",
            "🚂 Episode 2458\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.026 ↑ 0.192 → 0.603 ◼ 0.026 ↓ 0.128 \t Metric 0.5974999999999999 \n",
            "Episode Nr. 2459\t Score = -42.53999999999999\n",
            "🚂 Episode 2459\t 🏆 Score: -0.057 Avg: -0.029\t 💯 Done: 0.00% Avg: 24.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.002 ← 0.035 ↑ 0.219 → 0.029 ◼ 0.600 ↓ 0.115 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2460\t Score = 9.563333333333334\n",
            "🚂 Episode 2460\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.039 ↑ 0.184 → 0.553 ◼ 0.013 ↓ 0.197 \t Metric 0.5965 \n",
            "Episode Nr. 2461\t Score = -22.91\n",
            "🚂 Episode 2461\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.006 ← 0.218 ↑ 0.179 → 0.013 ◼ 0.301 ↓ 0.282 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 2462\t Score = 9.563333333333334\n",
            "🚂 Episode 2462\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.526 → 0.303 ◼ 0.013 ↓ 0.118 \t Metric 0.5965 \n",
            "Episode Nr. 2463\t Score = -105.01999999999994\n",
            "🚂 Episode 2463\t 🏆 Score: -0.140 Avg: -0.030\t 💯 Done: 0.00% Avg: 24.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.220 ↑ 0.403 → 0.015 ◼ 0.343 ↓ 0.015 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2464\t Score = 8.79\n",
            "🚂 Episode 2464\t 🏆 Score: 0.012 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2465\t Score = 9.563333333333334\n",
            "🚂 Episode 2465\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 24.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.026 ↑ 0.342 → 0.053 ◼ 0.224 ↓ 0.316 \t Metric 0.5965 \n",
            "Episode Nr. 2466\t Score = -105.01999999999994\n",
            "🚂 Episode 2466\t 🏆 Score: -0.140 Avg: -0.030\t 💯 Done: 0.00% Avg: 24.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.037 ↑ 0.735 → 0.201 ◼ 0.004 ↓ 0.015 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2467\t Score = -23.22\n",
            "🚂 Episode 2467\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.702 ↑ 0.106 → 0.117 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2468\t Score = -42.53999999999999\n",
            "🚂 Episode 2468\t 🏆 Score: -0.057 Avg: -0.030\t 💯 Done: 0.00% Avg: 24.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.392 ← 0.113 ↑ 0.365 → 0.016 ◼ 0.095 ↓ 0.019 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2469\t Score = -23.22\n",
            "🚂 Episode 2469\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.117 ↑ 0.181 → 0.053 ◼ 0.128 ↓ 0.447 \t Metric 0.397 \n",
            "Episode Nr. 2470\t Score = -22.619999999999997\n",
            "🚂 Episode 2470\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.235 ← 0.608 ↑ 0.052 → 0.052 ◼ 0.007 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2471\t Score = -23.22\n",
            "🚂 Episode 2471\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.660 ↑ 0.266 → 0.021 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2472\t Score = -42.53999999999999\n",
            "🚂 Episode 2472\t 🏆 Score: -0.057 Avg: -0.031\t 💯 Done: 0.00% Avg: 24.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.353 ← 0.204 ↑ 0.287 → 0.080 ◼ 0.010 ↓ 0.066 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2473\t Score = -42.53999999999999\n",
            "🚂 Episode 2473\t 🏆 Score: -0.057 Avg: -0.031\t 💯 Done: 0.00% Avg: 23.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.120 ← 0.045 ↑ 0.491 → 0.204 ◼ 0.041 ↓ 0.099 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2474\t Score = 8.79\n",
            "🚂 Episode 2474\t 🏆 Score: 0.012 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2475\t Score = -23.22\n",
            "🚂 Episode 2475\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.660 ↑ 0.213 → 0.021 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2476\t Score = -23.22\n",
            "🚂 Episode 2476\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.649 ↑ 0.128 → 0.032 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 2477\t Score = -23.22\n",
            "🚂 Episode 2477\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.096 ↑ 0.202 → 0.191 ◼ 0.011 ↓ 0.426 \t Metric 0.397 \n",
            "Episode Nr. 2478\t Score = -23.22\n",
            "🚂 Episode 2478\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.064 ↑ 0.330 → 0.149 ◼ 0.011 ↓ 0.340 \t Metric 0.397 \n",
            "Episode Nr. 2479\t Score = -20.436666666666664\n",
            "🚂 Episode 2479\t 🏆 Score: -0.027 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.026 ↑ 0.882 → 0.039 ◼ 0.013 ↓ 0.013 \t Metric 0.397 \n",
            "Episode Nr. 2480\t Score = -20.436666666666664\n",
            "🚂 Episode 2480\t 🏆 Score: -0.027 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.197 ← 0.039 ↑ 0.434 → 0.289 ◼ 0.013 ↓ 0.026 \t Metric 0.397 \n",
            "Episode Nr. 2481\t Score = -23.22\n",
            "🚂 Episode 2481\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.149 → 0.681 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2482\t Score = -22.619999999999997\n",
            "🚂 Episode 2482\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.020 ↑ 0.170 → 0.301 ◼ 0.111 ↓ 0.373 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2483\t Score = -22.619999999999997\n",
            "🚂 Episode 2483\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.405 ↑ 0.281 → 0.065 ◼ 0.222 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2484\t Score = -22.91\n",
            "🚂 Episode 2484\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 24.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.006 ← 0.038 ↑ 0.077 → 0.071 ◼ 0.776 ↓ 0.032 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 2485\t Score = 9.563333333333334\n",
            "🚂 Episode 2485\t 🏆 Score: 0.013 Avg: -0.030\t 💯 Done: 33.33% Avg: 25.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.026 ↑ 0.382 → 0.132 ◼ 0.382 ↓ 0.053 \t Metric 0.5965 \n",
            "Episode Nr. 2486\t Score = -22.619999999999997\n",
            "🚂 Episode 2486\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 25.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.163 ← 0.033 ↑ 0.098 → 0.065 ◼ 0.471 ↓ 0.170 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2487\t Score = -32.190000000000005\n",
            "🚂 Episode 2487\t 🏆 Score: -0.043 Avg: -0.030\t 💯 Done: 33.33% Avg: 25.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.194 ← 0.024 ↑ 0.063 → 0.012 ◼ 0.345 ↓ 0.361 \t Metric 0.6341666666666667 \n",
            "Episode Nr. 2488\t Score = -23.22\n",
            "🚂 Episode 2488\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 25.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.298 ← 0.074 ↑ 0.117 → 0.032 ◼ 0.447 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2489\t Score = 8.79\n",
            "🚂 Episode 2489\t 🏆 Score: 0.012 Avg: -0.030\t 💯 Done: 33.33% Avg: 25.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2490\t Score = 9.563333333333334\n",
            "🚂 Episode 2490\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 25.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.039 ↑ 0.421 → 0.105 ◼ 0.368 ↓ 0.053 \t Metric 0.5965 \n",
            "Episode Nr. 2491\t Score = 9.563333333333334\n",
            "🚂 Episode 2491\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 25.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.026 ↑ 0.421 → 0.039 ◼ 0.368 ↓ 0.132 \t Metric 0.5965 \n",
            "Episode Nr. 2492\t Score = 9.563333333333334\n",
            "🚂 Episode 2492\t 🏆 Score: 0.013 Avg: -0.028\t 💯 Done: 33.33% Avg: 25.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.039 ↑ 0.421 → 0.053 ◼ 0.382 ↓ 0.092 \t Metric 0.5965 \n",
            "Episode Nr. 2493\t Score = -42.53999999999999\n",
            "🚂 Episode 2493\t 🏆 Score: -0.057 Avg: -0.029\t 💯 Done: 0.00% Avg: 25.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.105 ← 0.019 ↑ 0.258 → 0.447 ◼ 0.010 ↓ 0.161 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2494\t Score = -22.619999999999997\n",
            "🚂 Episode 2494\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 25.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.052 ← 0.039 ↑ 0.157 → 0.013 ◼ 0.484 ↓ 0.255 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2495\t Score = -23.22\n",
            "🚂 Episode 2495\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 25.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.085 ↑ 0.117 → 0.021 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2496\t Score = -23.22\n",
            "🚂 Episode 2496\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 25.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.085 ↑ 0.117 → 0.032 ◼ 0.628 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2497\t Score = -23.22\n",
            "🚂 Episode 2497\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 25.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.128 ← 0.543 ↑ 0.170 → 0.021 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2498\t Score = -23.22\n",
            "🚂 Episode 2498\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 25.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.117 ← 0.074 ↑ 0.277 → 0.032 ◼ 0.415 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 2499\t Score = -22.619999999999997\n",
            "🚂 Episode 2499\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 25.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.078 ← 0.333 ↑ 0.399 → 0.072 ◼ 0.085 ↓ 0.033 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2500\t Score = -23.22\n",
            "🚂 Episode 2500\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 25.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.191 ↑ 0.064 → 0.085 ◼ 0.234 ↓ 0.319 \t Metric 0.397 \n",
            "Episode Nr. 2501\t Score = -22.619999999999997\n",
            "🚂 Episode 2501\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 25.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.098 ↑ 0.856 → 0.013 ◼ 0.020 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2502\t Score = -22.619999999999997\n",
            "🚂 Episode 2502\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 26.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.261 ← 0.124 ↑ 0.072 → 0.438 ◼ 0.007 ↓ 0.098 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2503\t Score = -23.22\n",
            "🚂 Episode 2503\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 26.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.447 ↑ 0.287 → 0.096 ◼ 0.011 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 2504\t Score = -23.22\n",
            "🚂 Episode 2504\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 26.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.032 ↑ 0.351 → 0.138 ◼ 0.011 ↓ 0.457 \t Metric 0.397 \n",
            "Episode Nr. 2505\t Score = 8.79\n",
            "🚂 Episode 2505\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 26.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2506\t Score = -23.22\n",
            "🚂 Episode 2506\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 26.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.032 ↑ 0.894 → 0.021 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2507\t Score = -22.619999999999997\n",
            "🚂 Episode 2507\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 26.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.529 ← 0.052 ↑ 0.046 → 0.222 ◼ 0.007 ↓ 0.144 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2508\t Score = -105.01999999999994\n",
            "🚂 Episode 2508\t 🏆 Score: -0.140 Avg: -0.030\t 💯 Done: 0.00% Avg: 26.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.166 ← 0.004 ↑ 0.027 → 0.788 ◼ 0.008 ↓ 0.008 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2509\t Score = -23.22\n",
            "🚂 Episode 2509\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.606 ↑ 0.138 → 0.117 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 2510\t Score = -22.619999999999997\n",
            "🚂 Episode 2510\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.065 ← 0.333 ↑ 0.098 → 0.078 ◼ 0.379 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2511\t Score = -22.619999999999997\n",
            "🚂 Episode 2511\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.359 ↑ 0.242 → 0.118 ◼ 0.229 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2512\t Score = -23.22\n",
            "🚂 Episode 2512\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.585 ↑ 0.255 → 0.085 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2513\t Score = -23.22\n",
            "🚂 Episode 2513\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.170 ↑ 0.106 → 0.053 ◼ 0.532 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 2514\t Score = -22.619999999999997\n",
            "🚂 Episode 2514\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.386 ↑ 0.085 → 0.124 ◼ 0.111 ↓ 0.275 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2515\t Score = -23.22\n",
            "🚂 Episode 2515\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.362 ↑ 0.149 → 0.319 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 2516\t Score = -42.53999999999999\n",
            "🚂 Episode 2516\t 🏆 Score: -0.057 Avg: -0.030\t 💯 Done: 0.00% Avg: 26.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.256 ← 0.037 ↑ 0.194 → 0.054 ◼ 0.371 ↓ 0.087 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2517\t Score = -42.53999999999999\n",
            "🚂 Episode 2517\t 🏆 Score: -0.057 Avg: -0.030\t 💯 Done: 0.00% Avg: 26.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.155 ← 0.006 ↑ 0.128 → 0.293 ◼ 0.151 ↓ 0.266 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2518\t Score = -23.22\n",
            "🚂 Episode 2518\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.553 ← 0.085 ↑ 0.117 → 0.021 ◼ 0.191 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2519\t Score = -23.22\n",
            "🚂 Episode 2519\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.255 ↑ 0.170 → 0.415 ◼ 0.011 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 2520\t Score = -22.619999999999997\n",
            "🚂 Episode 2520\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.098 ↑ 0.078 → 0.020 ◼ 0.765 ↓ 0.033 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2521\t Score = -23.22\n",
            "🚂 Episode 2521\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.638 ↑ 0.181 → 0.032 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2522\t Score = -23.22\n",
            "🚂 Episode 2522\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.298 → 0.053 ◼ 0.223 ↓ 0.234 \t Metric 0.397 \n",
            "Episode Nr. 2523\t Score = -23.22\n",
            "🚂 Episode 2523\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.170 ↑ 0.532 → 0.032 ◼ 0.191 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2524\t Score = -23.22\n",
            "🚂 Episode 2524\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.096 ↑ 0.074 → 0.043 ◼ 0.628 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 2525\t Score = -23.22\n",
            "🚂 Episode 2525\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.106 ↑ 0.085 → 0.085 ◼ 0.011 ↓ 0.649 \t Metric 0.397 \n",
            "Episode Nr. 2526\t Score = -20.436666666666664\n",
            "🚂 Episode 2526\t 🏆 Score: -0.027 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.039 ↑ 0.211 → 0.066 ◼ 0.026 ↓ 0.645 \t Metric 0.397 \n",
            "Episode Nr. 2527\t Score = -23.520000000000003\n",
            "🚂 Episode 2527\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.104 ← 0.062 ↑ 0.125 → 0.031 ◼ 0.635 ↓ 0.042 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2528\t Score = -22.619999999999997\n",
            "🚂 Episode 2528\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.163 ↑ 0.085 → 0.026 ◼ 0.078 ↓ 0.621 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2529\t Score = -22.619999999999997\n",
            "🚂 Episode 2529\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.072 ← 0.085 ↑ 0.359 → 0.026 ◼ 0.092 ↓ 0.366 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2530\t Score = -23.22\n",
            "🚂 Episode 2530\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 26.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.191 ↑ 0.170 → 0.085 ◼ 0.181 ↓ 0.287 \t Metric 0.397 \n",
            "Episode Nr. 2531\t Score = -23.22\n",
            "🚂 Episode 2531\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.160 ↑ 0.149 → 0.043 ◼ 0.213 ↓ 0.383 \t Metric 0.397 \n",
            "Episode Nr. 2532\t Score = -23.22\n",
            "🚂 Episode 2532\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.170 → 0.043 ◼ 0.011 ↓ 0.585 \t Metric 0.397 \n",
            "Episode Nr. 2533\t Score = -23.22\n",
            "🚂 Episode 2533\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.106 ↑ 0.181 → 0.043 ◼ 0.011 ↓ 0.574 \t Metric 0.397 \n",
            "Episode Nr. 2534\t Score = -23.22\n",
            "🚂 Episode 2534\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.074 ↑ 0.309 → 0.053 ◼ 0.138 ↓ 0.362 \t Metric 0.397 \n",
            "Episode Nr. 2535\t Score = -23.22\n",
            "🚂 Episode 2535\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.340 ↑ 0.181 → 0.287 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2536\t Score = -23.22\n",
            "🚂 Episode 2536\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.128 ↑ 0.649 → 0.064 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2537\t Score = 8.79\n",
            "🚂 Episode 2537\t 🏆 Score: 0.012 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2538\t Score = -23.22\n",
            "🚂 Episode 2538\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.287 ↑ 0.266 → 0.043 ◼ 0.149 ↓ 0.245 \t Metric 0.397 \n",
            "Episode Nr. 2539\t Score = -23.22\n",
            "🚂 Episode 2539\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.298 ↑ 0.106 → 0.043 ◼ 0.511 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2540\t Score = -22.619999999999997\n",
            "🚂 Episode 2540\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.124 ← 0.137 ↑ 0.516 → 0.046 ◼ 0.078 ↓ 0.098 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2541\t Score = 8.79\n",
            "🚂 Episode 2541\t 🏆 Score: 0.012 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2542\t Score = -23.22\n",
            "🚂 Episode 2542\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.096 ↑ 0.255 → 0.032 ◼ 0.574 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2543\t Score = -23.22\n",
            "🚂 Episode 2543\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.191 ↑ 0.213 → 0.043 ◼ 0.511 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2544\t Score = 8.79\n",
            "🚂 Episode 2544\t 🏆 Score: 0.012 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2545\t Score = 8.79\n",
            "🚂 Episode 2545\t 🏆 Score: 0.012 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2546\t Score = -23.22\n",
            "🚂 Episode 2546\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.106 ↑ 0.330 → 0.043 ◼ 0.149 ↓ 0.362 \t Metric 0.397 \n",
            "Episode Nr. 2547\t Score = -22.619999999999997\n",
            "🚂 Episode 2547\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.020 ↑ 0.856 → 0.026 ◼ 0.007 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2548\t Score = 8.79\n",
            "🚂 Episode 2548\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2549\t Score = -23.22\n",
            "🚂 Episode 2549\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.096 → 0.660 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2550\t Score = -23.22\n",
            "🚂 Episode 2550\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.223 → 0.117 ◼ 0.011 ↓ 0.521 \t Metric 0.397 \n",
            "Episode Nr. 2551\t Score = -23.22\n",
            "🚂 Episode 2551\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.032 ↑ 0.149 → 0.064 ◼ 0.011 ↓ 0.691 \t Metric 0.397 \n",
            "Episode Nr. 2552\t Score = -23.22\n",
            "🚂 Episode 2552\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.043 ↑ 0.638 → 0.021 ◼ 0.011 ↓ 0.277 \t Metric 0.397 \n",
            "Episode Nr. 2553\t Score = -23.22\n",
            "🚂 Episode 2553\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.032 ↑ 0.819 → 0.021 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2554\t Score = -22.619999999999997\n",
            "🚂 Episode 2554\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.346 ← 0.373 ↑ 0.124 → 0.059 ◼ 0.007 ↓ 0.092 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2555\t Score = 8.79\n",
            "🚂 Episode 2555\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2556\t Score = -22.619999999999997\n",
            "🚂 Episode 2556\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.229 ↑ 0.340 → 0.085 ◼ 0.026 ↓ 0.314 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2557\t Score = -23.22\n",
            "🚂 Episode 2557\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.181 ↑ 0.096 → 0.032 ◼ 0.553 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 2558\t Score = -23.22\n",
            "🚂 Episode 2558\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.255 ↑ 0.085 → 0.032 ◼ 0.553 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 2559\t Score = -22.619999999999997\n",
            "🚂 Episode 2559\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.268 ↑ 0.059 → 0.052 ◼ 0.497 ↓ 0.111 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2560\t Score = -23.22\n",
            "🚂 Episode 2560\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.032 ↑ 0.628 → 0.043 ◼ 0.011 ↓ 0.266 \t Metric 0.397 \n",
            "Episode Nr. 2561\t Score = -23.22\n",
            "🚂 Episode 2561\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.032 ↑ 0.266 → 0.649 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2562\t Score = -23.22\n",
            "🚂 Episode 2562\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.160 ← 0.053 ↑ 0.181 → 0.553 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2563\t Score = -22.619999999999997\n",
            "🚂 Episode 2563\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.183 ↑ 0.118 → 0.333 ◼ 0.020 ↓ 0.340 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2564\t Score = -23.22\n",
            "🚂 Episode 2564\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.138 ↑ 0.213 → 0.032 ◼ 0.532 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2565\t Score = 8.79\n",
            "🚂 Episode 2565\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2566\t Score = 8.79\n",
            "🚂 Episode 2566\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2567\t Score = -23.22\n",
            "🚂 Episode 2567\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.074 ↑ 0.223 → 0.032 ◼ 0.543 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2568\t Score = -23.22\n",
            "🚂 Episode 2568\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.074 ↑ 0.160 → 0.021 ◼ 0.638 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2569\t Score = -23.22\n",
            "🚂 Episode 2569\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.064 → 0.096 ◼ 0.532 ↓ 0.117 \t Metric 0.397 \n",
            "Episode Nr. 2570\t Score = -23.22\n",
            "🚂 Episode 2570\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.149 → 0.064 ◼ 0.447 ↓ 0.160 \t Metric 0.397 \n",
            "Episode Nr. 2571\t Score = -23.22\n",
            "🚂 Episode 2571\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.128 ↑ 0.245 → 0.064 ◼ 0.394 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2572\t Score = -23.22\n",
            "🚂 Episode 2572\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.160 ↑ 0.191 → 0.160 ◼ 0.213 ↓ 0.245 \t Metric 0.397 \n",
            "Episode Nr. 2573\t Score = -23.22\n",
            "🚂 Episode 2573\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.160 → 0.574 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2574\t Score = -23.22\n",
            "🚂 Episode 2574\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.160 ↑ 0.202 → 0.043 ◼ 0.170 ↓ 0.415 \t Metric 0.397 \n",
            "Episode Nr. 2575\t Score = -23.22\n",
            "🚂 Episode 2575\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.181 → 0.053 ◼ 0.160 ↓ 0.415 \t Metric 0.397 \n",
            "Episode Nr. 2576\t Score = 8.79\n",
            "🚂 Episode 2576\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 29.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2577\t Score = -23.520000000000003\n",
            "🚂 Episode 2577\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 29.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.646 ↑ 0.167 → 0.052 ◼ 0.021 ↓ 0.104 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2578\t Score = -23.22\n",
            "🚂 Episode 2578\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 29.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.032 ↑ 0.777 → 0.160 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2579\t Score = -22.619999999999997\n",
            "🚂 Episode 2579\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.052 ← 0.209 ↑ 0.451 → 0.052 ◼ 0.007 ↓ 0.229 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2580\t Score = -23.22\n",
            "🚂 Episode 2580\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.032 ↑ 0.255 → 0.436 ◼ 0.011 ↓ 0.255 \t Metric 0.397 \n",
            "Episode Nr. 2581\t Score = -23.520000000000003\n",
            "🚂 Episode 2581\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.031 ↑ 0.271 → 0.646 ◼ 0.021 ↓ 0.021 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2582\t Score = -23.22\n",
            "🚂 Episode 2582\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.032 ↑ 0.372 → 0.032 ◼ 0.149 ↓ 0.404 \t Metric 0.397 \n",
            "Episode Nr. 2583\t Score = -23.22\n",
            "🚂 Episode 2583\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.447 ↑ 0.287 → 0.096 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 2584\t Score = -22.619999999999997\n",
            "🚂 Episode 2584\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.170 ↑ 0.621 → 0.078 ◼ 0.046 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2585\t Score = -22.619999999999997\n",
            "🚂 Episode 2585\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.399 ← 0.046 ↑ 0.248 → 0.078 ◼ 0.007 ↓ 0.222 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2586\t Score = -23.22\n",
            "🚂 Episode 2586\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.032 ↑ 0.234 → 0.457 ◼ 0.032 ↓ 0.213 \t Metric 0.397 \n",
            "Episode Nr. 2587\t Score = -23.22\n",
            "🚂 Episode 2587\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.585 ↑ 0.149 → 0.032 ◼ 0.011 ↓ 0.213 \t Metric 0.397 \n",
            "Episode Nr. 2588\t Score = -22.619999999999997\n",
            "🚂 Episode 2588\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.425 ↑ 0.078 → 0.013 ◼ 0.333 ↓ 0.131 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2589\t Score = -23.22\n",
            "🚂 Episode 2589\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.181 ↑ 0.128 → 0.021 ◼ 0.011 ↓ 0.170 \t Metric 0.397 \n",
            "Episode Nr. 2590\t Score = -23.22\n",
            "🚂 Episode 2590\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.117 ← 0.074 ↑ 0.074 → 0.085 ◼ 0.564 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 2591\t Score = -22.619999999999997\n",
            "🚂 Episode 2591\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.353 ← 0.046 ↑ 0.222 → 0.020 ◼ 0.288 ↓ 0.072 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2592\t Score = 8.79\n",
            "🚂 Episode 2592\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 29.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2593\t Score = -23.22\n",
            "🚂 Episode 2593\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.266 ← 0.170 ↑ 0.447 → 0.074 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2594\t Score = -23.22\n",
            "🚂 Episode 2594\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 29.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.160 ↑ 0.096 → 0.532 ◼ 0.011 ↓ 0.191 \t Metric 0.397 \n",
            "Episode Nr. 2595\t Score = -22.619999999999997\n",
            "🚂 Episode 2595\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 30.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.131 ← 0.353 ↑ 0.085 → 0.033 ◼ 0.007 ↓ 0.392 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2596\t Score = -23.22\n",
            "🚂 Episode 2596\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 30.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.064 ↑ 0.277 → 0.043 ◼ 0.032 ↓ 0.564 \t Metric 0.397 \n",
            "Episode Nr. 2597\t Score = 8.79\n",
            "🚂 Episode 2597\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 30.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2598\t Score = -23.22\n",
            "🚂 Episode 2598\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 30.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.096 → 0.245 ◼ 0.234 ↓ 0.234 \t Metric 0.397 \n",
            "Episode Nr. 2599\t Score = -23.22\n",
            "🚂 Episode 2599\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 30.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.234 ↑ 0.128 → 0.426 ◼ 0.011 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 2600\t Score = -23.22\n",
            "🚂 Episode 2600\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 30.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.085 ↑ 0.170 → 0.053 ◼ 0.468 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 2601\t Score = 8.79\n",
            "🚂 Episode 2601\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 30.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2602\t Score = -22.619999999999997\n",
            "🚂 Episode 2602\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 30.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.222 ← 0.046 ↑ 0.105 → 0.026 ◼ 0.412 ↓ 0.190 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2603\t Score = 8.496666666666664\n",
            "🚂 Episode 2603\t 🏆 Score: 0.011 Avg: -0.027\t 💯 Done: 33.33% Avg: 30.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.42714285714285716 \n",
            "Episode Nr. 2604\t Score = -23.22\n",
            "🚂 Episode 2604\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 30.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.330 ← 0.117 ↑ 0.383 → 0.053 ◼ 0.011 ↓ 0.106 \t Metric 0.397 \n",
            "Episode Nr. 2605\t Score = -23.520000000000003\n",
            "🚂 Episode 2605\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 30.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.125 ↑ 0.156 → 0.031 ◼ 0.635 ↓ 0.031 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2606\t Score = -22.619999999999997\n",
            "🚂 Episode 2606\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 30.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.052 ← 0.078 ↑ 0.052 → 0.026 ◼ 0.758 ↓ 0.033 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2607\t Score = -23.22\n",
            "🚂 Episode 2607\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 30.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.128 ↑ 0.213 → 0.064 ◼ 0.138 ↓ 0.404 \t Metric 0.397 \n",
            "Episode Nr. 2608\t Score = -23.22\n",
            "🚂 Episode 2608\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 30.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.160 ↑ 0.213 → 0.043 ◼ 0.149 ↓ 0.415 \t Metric 0.397 \n",
            "Episode Nr. 2609\t Score = 8.79\n",
            "🚂 Episode 2609\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2610\t Score = -23.22\n",
            "🚂 Episode 2610\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.053 ↑ 0.213 → 0.043 ◼ 0.011 ↓ 0.585 \t Metric 0.397 \n",
            "Episode Nr. 2611\t Score = 8.79\n",
            "🚂 Episode 2611\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2612\t Score = -23.22\n",
            "🚂 Episode 2612\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.191 ↑ 0.191 → 0.213 ◼ 0.149 ↓ 0.234 \t Metric 0.397 \n",
            "Episode Nr. 2613\t Score = 8.79\n",
            "🚂 Episode 2613\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2614\t Score = -23.520000000000003\n",
            "🚂 Episode 2614\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.104 ← 0.073 ↑ 0.312 → 0.104 ◼ 0.156 ↓ 0.250 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2615\t Score = -22.619999999999997\n",
            "🚂 Episode 2615\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.176 ↑ 0.092 → 0.026 ◼ 0.118 ↓ 0.569 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2616\t Score = -22.619999999999997\n",
            "🚂 Episode 2616\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.190 ↑ 0.111 → 0.026 ◼ 0.078 ↓ 0.575 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2617\t Score = -23.22\n",
            "🚂 Episode 2617\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.160 ↑ 0.191 → 0.128 ◼ 0.149 ↓ 0.340 \t Metric 0.397 \n",
            "Episode Nr. 2618\t Score = -23.22\n",
            "🚂 Episode 2618\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.096 ↑ 0.106 → 0.032 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2619\t Score = -23.22\n",
            "🚂 Episode 2619\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.074 ↑ 0.149 → 0.032 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2620\t Score = -23.22\n",
            "🚂 Episode 2620\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.053 ↑ 0.245 → 0.032 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2621\t Score = -23.22\n",
            "🚂 Episode 2621\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.191 → 0.106 ◼ 0.149 ↓ 0.340 \t Metric 0.397 \n",
            "Episode Nr. 2622\t Score = -22.619999999999997\n",
            "🚂 Episode 2622\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.118 ← 0.085 ↑ 0.575 → 0.092 ◼ 0.013 ↓ 0.118 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2623\t Score = -23.22\n",
            "🚂 Episode 2623\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.053 ↑ 0.160 → 0.032 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2624\t Score = -22.619999999999997\n",
            "🚂 Episode 2624\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.425 ↑ 0.144 → 0.020 ◼ 0.346 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2625\t Score = -45.01999999999994\n",
            "🚂 Episode 2625\t 🏆 Score: -0.060 Avg: -0.027\t 💯 Done: 0.00% Avg: 30.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.184 ← 0.218 ↑ 0.549 → 0.030 ◼ 0.004 ↓ 0.015 \t Metric 0.39749999999999996 \n",
            "Episode Nr. 2626\t Score = 8.79\n",
            "🚂 Episode 2626\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2627\t Score = 8.496666666666664\n",
            "🚂 Episode 2627\t 🏆 Score: 0.011 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.42714285714285716 \n",
            "Episode Nr. 2628\t Score = -23.520000000000003\n",
            "🚂 Episode 2628\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.062 ← 0.177 ↑ 0.406 → 0.208 ◼ 0.031 ↓ 0.115 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2629\t Score = -23.22\n",
            "🚂 Episode 2629\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.053 ↑ 0.181 → 0.138 ◼ 0.149 ↓ 0.415 \t Metric 0.397 \n",
            "Episode Nr. 2630\t Score = -23.22\n",
            "🚂 Episode 2630\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.064 ↑ 0.128 → 0.160 ◼ 0.149 ↓ 0.404 \t Metric 0.397 \n",
            "Episode Nr. 2631\t Score = 8.79\n",
            "🚂 Episode 2631\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2632\t Score = -22.619999999999997\n",
            "🚂 Episode 2632\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.477 ↑ 0.078 → 0.020 ◼ 0.392 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2633\t Score = -22.619999999999997\n",
            "🚂 Episode 2633\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.078 ← 0.118 ↑ 0.719 → 0.026 ◼ 0.007 ↓ 0.052 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2634\t Score = -22.619999999999997\n",
            "🚂 Episode 2634\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.366 ← 0.026 ↑ 0.163 → 0.418 ◼ 0.007 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2635\t Score = -23.22\n",
            "🚂 Episode 2635\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.106 ↑ 0.074 → 0.394 ◼ 0.011 ↓ 0.404 \t Metric 0.397 \n",
            "Episode Nr. 2636\t Score = -23.520000000000003\n",
            "🚂 Episode 2636\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.229 ↑ 0.125 → 0.094 ◼ 0.021 ↓ 0.521 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2637\t Score = 8.643333333333333\n",
            "🚂 Episode 2637\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 30.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2638\t Score = -23.22\n",
            "🚂 Episode 2638\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.596 ↑ 0.160 → 0.096 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2639\t Score = -22.91\n",
            "🚂 Episode 2639\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.006 ← 0.077 ↑ 0.058 → 0.058 ◼ 0.776 ↓ 0.026 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 2640\t Score = -23.22\n",
            "🚂 Episode 2640\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 30.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.213 → 0.245 ◼ 0.149 ↓ 0.202 \t Metric 0.397 \n",
            "Episode Nr. 2641\t Score = 8.79\n",
            "🚂 Episode 2641\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 30.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2642\t Score = -22.619999999999997\n",
            "🚂 Episode 2642\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 30.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.105 ↑ 0.157 → 0.026 ◼ 0.379 ↓ 0.327 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2643\t Score = -23.22\n",
            "🚂 Episode 2643\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.064 ↑ 0.170 → 0.032 ◼ 0.468 ↓ 0.181 \t Metric 0.397 \n",
            "Episode Nr. 2644\t Score = -23.22\n",
            "🚂 Episode 2644\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.096 ↑ 0.096 → 0.032 ◼ 0.638 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2645\t Score = -23.22\n",
            "🚂 Episode 2645\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.117 → 0.032 ◼ 0.628 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2646\t Score = -22.619999999999997\n",
            "🚂 Episode 2646\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.078 ↑ 0.098 → 0.026 ◼ 0.758 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2647\t Score = -23.22\n",
            "🚂 Episode 2647\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.074 ↑ 0.202 → 0.032 ◼ 0.617 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2648\t Score = -23.22\n",
            "🚂 Episode 2648\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.287 ↑ 0.319 → 0.043 ◼ 0.234 ↓ 0.106 \t Metric 0.397 \n",
            "Episode Nr. 2649\t Score = -23.22\n",
            "🚂 Episode 2649\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.138 ↑ 0.457 → 0.223 ◼ 0.149 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2650\t Score = -23.22\n",
            "🚂 Episode 2650\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.117 → 0.032 ◼ 0.628 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2651\t Score = -23.22\n",
            "🚂 Episode 2651\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.106 → 0.032 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2652\t Score = -23.22\n",
            "🚂 Episode 2652\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.085 → 0.255 ◼ 0.149 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 2653\t Score = -22.619999999999997\n",
            "🚂 Episode 2653\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.320 ← 0.124 ↑ 0.268 → 0.078 ◼ 0.085 ↓ 0.124 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2654\t Score = -23.22\n",
            "🚂 Episode 2654\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.181 ↑ 0.138 → 0.043 ◼ 0.011 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 2655\t Score = -23.22\n",
            "🚂 Episode 2655\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.032 ↑ 0.723 → 0.043 ◼ 0.096 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 2656\t Score = -23.22\n",
            "🚂 Episode 2656\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.043 ↑ 0.691 → 0.096 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 2657\t Score = -23.520000000000003\n",
            "🚂 Episode 2657\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.135 ← 0.167 ↑ 0.177 → 0.365 ◼ 0.021 ↓ 0.135 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2658\t Score = -23.22\n",
            "🚂 Episode 2658\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.160 ↑ 0.138 → 0.053 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 2659\t Score = 8.79\n",
            "🚂 Episode 2659\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2660\t Score = -22.619999999999997\n",
            "🚂 Episode 2660\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.170 ↑ 0.673 → 0.026 ◼ 0.013 ↓ 0.092 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2661\t Score = -23.22\n",
            "🚂 Episode 2661\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.074 ↑ 0.213 → 0.170 ◼ 0.149 ↓ 0.372 \t Metric 0.397 \n",
            "Episode Nr. 2662\t Score = 8.79\n",
            "🚂 Episode 2662\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2663\t Score = -23.22\n",
            "🚂 Episode 2663\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.106 ↑ 0.287 → 0.085 ◼ 0.149 ↓ 0.362 \t Metric 0.397 \n",
            "Episode Nr. 2664\t Score = -22.619999999999997\n",
            "🚂 Episode 2664\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.176 ← 0.124 ↑ 0.444 → 0.131 ◼ 0.026 ↓ 0.098 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2665\t Score = 8.643333333333333\n",
            "🚂 Episode 2665\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2666\t Score = -22.91\n",
            "🚂 Episode 2666\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.141 ↑ 0.705 → 0.026 ◼ 0.013 ↓ 0.090 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 2667\t Score = 8.79\n",
            "🚂 Episode 2667\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2668\t Score = -23.22\n",
            "🚂 Episode 2668\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.255 → 0.043 ◼ 0.596 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2669\t Score = -23.22\n",
            "🚂 Episode 2669\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.149 → 0.223 ◼ 0.011 ↓ 0.436 \t Metric 0.397 \n",
            "Episode Nr. 2670\t Score = 8.643333333333333\n",
            "🚂 Episode 2670\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2671\t Score = -23.22\n",
            "🚂 Episode 2671\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.032 ↑ 0.426 → 0.457 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2672\t Score = 8.79\n",
            "🚂 Episode 2672\t 🏆 Score: 0.012 Avg: -0.024\t 💯 Done: 33.33% Avg: 31.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2673\t Score = -23.22\n",
            "🚂 Episode 2673\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 31.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.138 → 0.149 ◼ 0.011 ↓ 0.511 \t Metric 0.397 \n",
            "Episode Nr. 2674\t Score = -22.619999999999997\n",
            "🚂 Episode 2674\t 🏆 Score: -0.030 Avg: -0.024\t 💯 Done: 33.33% Avg: 31.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.359 ↑ 0.281 → 0.013 ◼ 0.059 ↓ 0.281 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2675\t Score = -22.619999999999997\n",
            "🚂 Episode 2675\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.111 ↑ 0.216 → 0.268 ◼ 0.307 ↓ 0.092 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2676\t Score = -22.619999999999997\n",
            "🚂 Episode 2676\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.111 ↑ 0.288 → 0.196 ◼ 0.314 ↓ 0.085 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2677\t Score = -23.22\n",
            "🚂 Episode 2677\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.106 → 0.032 ◼ 0.638 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2678\t Score = -22.619999999999997\n",
            "🚂 Episode 2678\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.124 ↑ 0.301 → 0.190 ◼ 0.307 ↓ 0.059 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2679\t Score = -23.22\n",
            "🚂 Episode 2679\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.106 ↑ 0.181 → 0.245 ◼ 0.011 ↓ 0.362 \t Metric 0.397 \n",
            "Episode Nr. 2680\t Score = -22.619999999999997\n",
            "🚂 Episode 2680\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.052 ← 0.033 ↑ 0.346 → 0.196 ◼ 0.288 ↓ 0.085 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2681\t Score = -23.22\n",
            "🚂 Episode 2681\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.085 ↑ 0.128 → 0.032 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2682\t Score = -23.22\n",
            "🚂 Episode 2682\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.181 ↑ 0.223 → 0.032 ◼ 0.468 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 2683\t Score = -23.22\n",
            "🚂 Episode 2683\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.085 ↑ 0.362 → 0.149 ◼ 0.011 ↓ 0.383 \t Metric 0.397 \n",
            "Episode Nr. 2684\t Score = -23.22\n",
            "🚂 Episode 2684\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.043 ↑ 0.330 → 0.032 ◼ 0.468 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2685\t Score = -22.619999999999997\n",
            "🚂 Episode 2685\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.046 ← 0.131 ↑ 0.327 → 0.020 ◼ 0.288 ↓ 0.190 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2686\t Score = -23.22\n",
            "🚂 Episode 2686\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.096 → 0.234 ◼ 0.021 ↓ 0.436 \t Metric 0.397 \n",
            "Episode Nr. 2687\t Score = 8.79\n",
            "🚂 Episode 2687\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2688\t Score = 8.79\n",
            "🚂 Episode 2688\t 🏆 Score: 0.012 Avg: -0.024\t 💯 Done: 33.33% Avg: 31.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2689\t Score = 8.643333333333333\n",
            "🚂 Episode 2689\t 🏆 Score: 0.012 Avg: -0.024\t 💯 Done: 33.33% Avg: 31.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2690\t Score = -23.520000000000003\n",
            "🚂 Episode 2690\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 31.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.188 ↑ 0.094 → 0.260 ◼ 0.021 ↓ 0.417 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2691\t Score = -23.22\n",
            "🚂 Episode 2691\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 31.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.138 ↑ 0.287 → 0.043 ◼ 0.457 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 2692\t Score = -23.22\n",
            "🚂 Episode 2692\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 31.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.436 → 0.245 ◼ 0.011 ↓ 0.234 \t Metric 0.397 \n",
            "Episode Nr. 2693\t Score = 8.643333333333333\n",
            "🚂 Episode 2693\t 🏆 Score: 0.012 Avg: -0.024\t 💯 Done: 33.33% Avg: 31.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2694\t Score = -102.53999999999999\n",
            "🚂 Episode 2694\t 🏆 Score: -0.137 Avg: -0.025\t 💯 Done: 0.00% Avg: 31.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.001 ← 0.352 ↑ 0.007 → 0.004 ◼ 0.633 ↓ 0.003 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2695\t Score = -32.52\n",
            "🚂 Episode 2695\t 🏆 Score: -0.043 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.006 ← 0.090 ↑ 0.147 → 0.346 ◼ 0.013 ↓ 0.397 \t Metric 0.38149999999999995 \n",
            "Episode Nr. 2696\t Score = -23.22\n",
            "🚂 Episode 2696\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.085 ↑ 0.170 → 0.362 ◼ 0.021 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 2697\t Score = -23.22\n",
            "🚂 Episode 2697\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.489 ↑ 0.245 → 0.043 ◼ 0.138 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 2698\t Score = 9.016666666666666\n",
            "🚂 Episode 2698\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.024 ← 0.098 ↑ 0.256 → 0.463 ◼ 0.037 ↓ 0.122 \t Metric 0.5985 \n",
            "Episode Nr. 2699\t Score = 8.79\n",
            "🚂 Episode 2699\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2700\t Score = -23.22\n",
            "🚂 Episode 2700\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.106 ↑ 0.170 → 0.500 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2701\t Score = -23.22\n",
            "🚂 Episode 2701\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.202 ← 0.447 ↑ 0.245 → 0.043 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2702\t Score = -23.22\n",
            "🚂 Episode 2702\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.181 ↑ 0.181 → 0.181 ◼ 0.021 ↓ 0.394 \t Metric 0.397 \n",
            "Episode Nr. 2703\t Score = -22.619999999999997\n",
            "🚂 Episode 2703\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.046 ← 0.124 ↑ 0.222 → 0.405 ◼ 0.007 ↓ 0.196 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2704\t Score = -22.619999999999997\n",
            "🚂 Episode 2704\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.144 ← 0.242 ↑ 0.294 → 0.026 ◼ 0.007 ↓ 0.288 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2705\t Score = -23.22\n",
            "🚂 Episode 2705\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.681 → 0.032 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 2706\t Score = 8.79\n",
            "🚂 Episode 2706\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2707\t Score = -23.22\n",
            "🚂 Episode 2707\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.096 ↑ 0.181 → 0.032 ◼ 0.638 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2708\t Score = -23.22\n",
            "🚂 Episode 2708\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.074 ↑ 0.245 → 0.319 ◼ 0.011 ↓ 0.340 \t Metric 0.397 \n",
            "Episode Nr. 2709\t Score = -23.22\n",
            "🚂 Episode 2709\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.085 ↑ 0.819 → 0.032 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2710\t Score = -23.22\n",
            "🚂 Episode 2710\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.106 → 0.426 ◼ 0.011 ↓ 0.266 \t Metric 0.397 \n",
            "Episode Nr. 2711\t Score = -23.22\n",
            "🚂 Episode 2711\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.117 → 0.319 ◼ 0.011 ↓ 0.362 \t Metric 0.397 \n",
            "Episode Nr. 2712\t Score = -23.520000000000003\n",
            "🚂 Episode 2712\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.177 ↑ 0.115 → 0.385 ◼ 0.021 ↓ 0.292 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2713\t Score = -22.619999999999997\n",
            "🚂 Episode 2713\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.059 ↑ 0.510 → 0.111 ◼ 0.033 ↓ 0.281 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2714\t Score = -22.619999999999997\n",
            "🚂 Episode 2714\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.255 ↑ 0.216 → 0.281 ◼ 0.007 ↓ 0.229 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2715\t Score = -22.619999999999997\n",
            "🚂 Episode 2715\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.078 ← 0.137 ↑ 0.595 → 0.046 ◼ 0.007 ↓ 0.137 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2716\t Score = -22.619999999999997\n",
            "🚂 Episode 2716\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.111 ← 0.359 ↑ 0.144 → 0.078 ◼ 0.007 ↓ 0.301 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2717\t Score = -23.22\n",
            "🚂 Episode 2717\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.117 → 0.032 ◼ 0.628 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2718\t Score = -23.22\n",
            "🚂 Episode 2718\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.426 ← 0.149 ↑ 0.319 → 0.043 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2719\t Score = -23.22\n",
            "🚂 Episode 2719\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 31.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.053 ↑ 0.862 → 0.032 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2720\t Score = -22.619999999999997\n",
            "🚂 Episode 2720\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.320 ↑ 0.425 → 0.092 ◼ 0.007 ↓ 0.150 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2721\t Score = -23.22\n",
            "🚂 Episode 2721\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.149 ↑ 0.362 → 0.213 ◼ 0.011 ↓ 0.255 \t Metric 0.397 \n",
            "Episode Nr. 2722\t Score = -23.22\n",
            "🚂 Episode 2722\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.074 ↑ 0.213 → 0.032 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2723\t Score = -23.22\n",
            "🚂 Episode 2723\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.096 → 0.032 ◼ 0.628 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2724\t Score = -23.22\n",
            "🚂 Episode 2724\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.032 ↑ 0.532 → 0.170 ◼ 0.011 ↓ 0.245 \t Metric 0.397 \n",
            "Episode Nr. 2725\t Score = -23.22\n",
            "🚂 Episode 2725\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.053 ↑ 0.245 → 0.043 ◼ 0.628 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2726\t Score = -23.22\n",
            "🚂 Episode 2726\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.117 ↑ 0.266 → 0.223 ◼ 0.011 ↓ 0.362 \t Metric 0.397 \n",
            "Episode Nr. 2727\t Score = -23.22\n",
            "🚂 Episode 2727\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.809 → 0.032 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 2728\t Score = -23.22\n",
            "🚂 Episode 2728\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.106 → 0.032 ◼ 0.628 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2729\t Score = -23.22\n",
            "🚂 Episode 2729\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.043 ↑ 0.340 → 0.468 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2730\t Score = 8.79\n",
            "🚂 Episode 2730\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2731\t Score = 10.11\n",
            "🚂 Episode 2731\t 🏆 Score: 0.013 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.257 → 0.586 ◼ 0.043 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 2732\t Score = -23.22\n",
            "🚂 Episode 2732\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.043 ↑ 0.351 → 0.170 ◼ 0.053 ↓ 0.372 \t Metric 0.397 \n",
            "Episode Nr. 2733\t Score = -22.619999999999997\n",
            "🚂 Episode 2733\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.163 ← 0.275 ↑ 0.105 → 0.111 ◼ 0.007 ↓ 0.340 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2734\t Score = -22.619999999999997\n",
            "🚂 Episode 2734\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.046 ↑ 0.693 → 0.026 ◼ 0.020 ↓ 0.209 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2735\t Score = -22.619999999999997\n",
            "🚂 Episode 2735\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.203 ↑ 0.719 → 0.026 ◼ 0.007 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2736\t Score = -50.819999999999965\n",
            "🚂 Episode 2736\t 🏆 Score: -0.068 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.103 ↑ 0.099 → 0.750 ◼ 0.004 ↓ 0.039 \t Metric 0.351 \n",
            "Episode Nr. 2737\t Score = -23.22\n",
            "🚂 Episode 2737\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.106 → 0.202 ◼ 0.043 ↓ 0.521 \t Metric 0.397 \n",
            "Episode Nr. 2738\t Score = -23.22\n",
            "🚂 Episode 2738\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.181 → 0.106 ◼ 0.160 ↓ 0.426 \t Metric 0.397 \n",
            "Episode Nr. 2739\t Score = -23.22\n",
            "🚂 Episode 2739\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.096 → 0.106 ◼ 0.500 ↓ 0.170 \t Metric 0.397 \n",
            "Episode Nr. 2740\t Score = 8.79\n",
            "🚂 Episode 2740\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2741\t Score = -23.22\n",
            "🚂 Episode 2741\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.085 ↑ 0.149 → 0.096 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2742\t Score = -23.22\n",
            "🚂 Episode 2742\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.074 ↑ 0.223 → 0.021 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2743\t Score = -23.22\n",
            "🚂 Episode 2743\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.223 → 0.255 ◼ 0.149 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 2744\t Score = -23.22\n",
            "🚂 Episode 2744\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.128 ↑ 0.255 → 0.149 ◼ 0.032 ↓ 0.426 \t Metric 0.397 \n",
            "Episode Nr. 2745\t Score = -23.22\n",
            "🚂 Episode 2745\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.160 ↑ 0.191 → 0.128 ◼ 0.074 ↓ 0.436 \t Metric 0.397 \n",
            "Episode Nr. 2746\t Score = 8.643333333333333\n",
            "🚂 Episode 2746\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2747\t Score = 8.79\n",
            "🚂 Episode 2747\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2748\t Score = -23.22\n",
            "🚂 Episode 2748\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.202 → 0.043 ◼ 0.149 ↓ 0.415 \t Metric 0.397 \n",
            "Episode Nr. 2749\t Score = -23.22\n",
            "🚂 Episode 2749\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.106 → 0.043 ◼ 0.628 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2750\t Score = 8.79\n",
            "🚂 Episode 2750\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2751\t Score = -22.619999999999997\n",
            "🚂 Episode 2751\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.176 ← 0.046 ↑ 0.399 → 0.026 ◼ 0.216 ↓ 0.137 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2752\t Score = -23.22\n",
            "🚂 Episode 2752\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.064 ↑ 0.223 → 0.032 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2753\t Score = 8.643333333333333\n",
            "🚂 Episode 2753\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2754\t Score = -22.619999999999997\n",
            "🚂 Episode 2754\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.203 ← 0.098 ↑ 0.085 → 0.026 ◼ 0.392 ↓ 0.196 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2755\t Score = -23.22\n",
            "🚂 Episode 2755\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.160 ↑ 0.245 → 0.053 ◼ 0.149 ↓ 0.383 \t Metric 0.397 \n",
            "Episode Nr. 2756\t Score = -105.01999999999994\n",
            "🚂 Episode 2756\t 🏆 Score: -0.140 Avg: -0.026\t 💯 Done: 0.00% Avg: 32.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.584 ← 0.052 ↑ 0.045 → 0.230 ◼ 0.082 ↓ 0.007 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2757\t Score = -23.22\n",
            "🚂 Episode 2757\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.096 ↑ 0.128 → 0.394 ◼ 0.362 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2758\t Score = -23.819999999999997\n",
            "🚂 Episode 2758\t 🏆 Score: -0.032 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.051 ↑ 0.347 → 0.347 ◼ 0.051 ↓ 0.194 \t Metric 0.396 \n",
            "Episode Nr. 2759\t Score = -23.22\n",
            "🚂 Episode 2759\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.479 ↑ 0.404 → 0.043 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2760\t Score = -23.22\n",
            "🚂 Episode 2760\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.043 ↑ 0.830 → 0.043 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2761\t Score = -23.22\n",
            "🚂 Episode 2761\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.14%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.351 ← 0.053 ↑ 0.245 → 0.032 ◼ 0.298 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2762\t Score = 8.79\n",
            "🚂 Episode 2762\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2763\t Score = -23.22\n",
            "🚂 Episode 2763\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.266 ← 0.117 ↑ 0.511 → 0.032 ◼ 0.021 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2764\t Score = -23.22\n",
            "🚂 Episode 2764\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.489 ↑ 0.383 → 0.032 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2765\t Score = -23.22\n",
            "🚂 Episode 2765\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.213 ↑ 0.085 → 0.255 ◼ 0.011 ↓ 0.426 \t Metric 0.397 \n",
            "Episode Nr. 2766\t Score = -23.22\n",
            "🚂 Episode 2766\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.106 → 0.032 ◼ 0.638 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2767\t Score = -23.22\n",
            "🚂 Episode 2767\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.074 ↑ 0.223 → 0.191 ◼ 0.128 ↓ 0.362 \t Metric 0.397 \n",
            "Episode Nr. 2768\t Score = -23.22\n",
            "🚂 Episode 2768\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.085 ↑ 0.191 → 0.043 ◼ 0.638 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2769\t Score = -23.22\n",
            "🚂 Episode 2769\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.362 ← 0.085 ↑ 0.351 → 0.170 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2770\t Score = -23.520000000000003\n",
            "🚂 Episode 2770\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.125 ↑ 0.271 → 0.104 ◼ 0.146 ↓ 0.333 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2771\t Score = -23.22\n",
            "🚂 Episode 2771\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.181 ↑ 0.734 → 0.043 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2772\t Score = 10.11\n",
            "🚂 Episode 2772\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.286 → 0.600 ◼ 0.014 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 2773\t Score = 8.79\n",
            "🚂 Episode 2773\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2774\t Score = -22.619999999999997\n",
            "🚂 Episode 2774\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.131 ↑ 0.059 → 0.464 ◼ 0.020 ↓ 0.320 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2775\t Score = -22.619999999999997\n",
            "🚂 Episode 2775\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.288 ↑ 0.092 → 0.124 ◼ 0.386 ↓ 0.098 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2776\t Score = -22.619999999999997\n",
            "🚂 Episode 2776\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.046 ↑ 0.085 → 0.399 ◼ 0.340 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2777\t Score = -22.619999999999997\n",
            "🚂 Episode 2777\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.052 ← 0.092 ↑ 0.196 → 0.425 ◼ 0.092 ↓ 0.144 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2778\t Score = -23.520000000000003\n",
            "🚂 Episode 2778\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.073 ← 0.562 ↑ 0.219 → 0.042 ◼ 0.021 ↓ 0.083 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2779\t Score = -23.22\n",
            "🚂 Episode 2779\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.128 ↑ 0.170 → 0.021 ◼ 0.149 ↓ 0.436 \t Metric 0.397 \n",
            "Episode Nr. 2780\t Score = -23.22\n",
            "🚂 Episode 2780\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.117 ↑ 0.191 → 0.074 ◼ 0.149 ↓ 0.372 \t Metric 0.397 \n",
            "Episode Nr. 2781\t Score = 8.79\n",
            "🚂 Episode 2781\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2782\t Score = -22.619999999999997\n",
            "🚂 Episode 2782\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.072 ← 0.065 ↑ 0.196 → 0.098 ◼ 0.346 ↓ 0.222 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2783\t Score = 8.79\n",
            "🚂 Episode 2783\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2784\t Score = 8.79\n",
            "🚂 Episode 2784\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2785\t Score = -22.619999999999997\n",
            "🚂 Episode 2785\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.111 ↑ 0.373 → 0.026 ◼ 0.366 ↓ 0.118 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2786\t Score = -23.22\n",
            "🚂 Episode 2786\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.213 → 0.032 ◼ 0.468 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 2787\t Score = -23.22\n",
            "🚂 Episode 2787\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.191 → 0.085 ◼ 0.149 ↓ 0.372 \t Metric 0.397 \n",
            "Episode Nr. 2788\t Score = -23.22\n",
            "🚂 Episode 2788\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.191 → 0.415 ◼ 0.043 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 2789\t Score = -22.619999999999997\n",
            "🚂 Episode 2789\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.039 ↑ 0.523 → 0.033 ◼ 0.268 ↓ 0.105 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2790\t Score = -23.22\n",
            "🚂 Episode 2790\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.691 ↑ 0.223 → 0.043 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2791\t Score = -23.22\n",
            "🚂 Episode 2791\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.447 ↑ 0.223 → 0.234 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 2792\t Score = -42.53999999999999\n",
            "🚂 Episode 2792\t 🏆 Score: -0.057 Avg: -0.025\t 💯 Done: 0.00% Avg: 32.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.084 ← 0.150 ↑ 0.253 → 0.103 ◼ 0.347 ↓ 0.062 \t Metric 0.6625 \n",
            "Episode Nr. 2793\t Score = 8.79\n",
            "🚂 Episode 2793\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.14%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2794\t Score = -23.22\n",
            "🚂 Episode 2794\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.032 ↑ 0.606 → 0.213 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2795\t Score = -23.22\n",
            "🚂 Episode 2795\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.106 ↑ 0.840 → 0.021 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2796\t Score = -23.22\n",
            "🚂 Episode 2796\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.266 ↑ 0.074 → 0.574 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 2797\t Score = -23.22\n",
            "🚂 Episode 2797\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.053 ↑ 0.106 → 0.574 ◼ 0.011 ↓ 0.245 \t Metric 0.397 \n",
            "Episode Nr. 2798\t Score = -23.22\n",
            "🚂 Episode 2798\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.138 ↑ 0.106 → 0.404 ◼ 0.032 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 2799\t Score = -23.22\n",
            "🚂 Episode 2799\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.340 ↑ 0.053 → 0.277 ◼ 0.032 ↓ 0.287 \t Metric 0.397 \n",
            "Episode Nr. 2800\t Score = -23.22\n",
            "🚂 Episode 2800\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.191 ↑ 0.064 → 0.032 ◼ 0.011 ↓ 0.681 \t Metric 0.397 \n",
            "Episode Nr. 2801\t Score = -105.01999999999994\n",
            "🚂 Episode 2801\t 🏆 Score: -0.140 Avg: -0.027\t 💯 Done: 0.00% Avg: 31.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.012 ↑ 0.023 → 0.004 ◼ 0.544 ↓ 0.409 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2802\t Score = -22.619999999999997\n",
            "🚂 Episode 2802\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 31.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.176 ← 0.033 ↑ 0.458 → 0.020 ◼ 0.216 ↓ 0.098 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2803\t Score = 8.79\n",
            "🚂 Episode 2803\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2804\t Score = -23.22\n",
            "🚂 Episode 2804\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.053 ↑ 0.245 → 0.021 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2805\t Score = -23.22\n",
            "🚂 Episode 2805\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.638 ↑ 0.245 → 0.021 ◼ 0.053 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2806\t Score = -22.619999999999997\n",
            "🚂 Episode 2806\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.065 ↑ 0.405 → 0.020 ◼ 0.386 ↓ 0.118 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2807\t Score = -23.22\n",
            "🚂 Episode 2807\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.330 ↑ 0.191 → 0.021 ◼ 0.415 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2808\t Score = -22.619999999999997\n",
            "🚂 Episode 2808\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 31.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.111 ↑ 0.144 → 0.020 ◼ 0.392 ↓ 0.327 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2809\t Score = -23.22\n",
            "🚂 Episode 2809\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.138 ↑ 0.255 → 0.287 ◼ 0.117 ↓ 0.191 \t Metric 0.397 \n",
            "Episode Nr. 2810\t Score = -23.22\n",
            "🚂 Episode 2810\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.106 ↑ 0.287 → 0.255 ◼ 0.149 ↓ 0.191 \t Metric 0.397 \n",
            "Episode Nr. 2811\t Score = -23.520000000000003\n",
            "🚂 Episode 2811\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.198 ↑ 0.208 → 0.156 ◼ 0.156 ↓ 0.271 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2812\t Score = -22.619999999999997\n",
            "🚂 Episode 2812\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.105 ↑ 0.150 → 0.033 ◼ 0.386 ↓ 0.320 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2813\t Score = -22.619999999999997\n",
            "🚂 Episode 2813\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.039 ↑ 0.137 → 0.020 ◼ 0.778 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2814\t Score = -23.22\n",
            "🚂 Episode 2814\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.191 ↑ 0.128 → 0.202 ◼ 0.149 ↓ 0.309 \t Metric 0.397 \n",
            "Episode Nr. 2815\t Score = -23.22\n",
            "🚂 Episode 2815\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.160 ↑ 0.170 → 0.426 ◼ 0.011 ↓ 0.223 \t Metric 0.397 \n",
            "Episode Nr. 2816\t Score = -23.22\n",
            "🚂 Episode 2816\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.202 → 0.426 ◼ 0.011 ↓ 0.234 \t Metric 0.397 \n",
            "Episode Nr. 2817\t Score = -22.619999999999997\n",
            "🚂 Episode 2817\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.294 ← 0.052 ↑ 0.222 → 0.059 ◼ 0.078 ↓ 0.294 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2818\t Score = -23.22\n",
            "🚂 Episode 2818\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.128 → 0.479 ◼ 0.011 ↓ 0.181 \t Metric 0.397 \n",
            "Episode Nr. 2819\t Score = -23.22\n",
            "🚂 Episode 2819\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.128 ↑ 0.191 → 0.372 ◼ 0.011 ↓ 0.287 \t Metric 0.397 \n",
            "Episode Nr. 2820\t Score = -22.91\n",
            "🚂 Episode 2820\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.167 ↑ 0.506 → 0.090 ◼ 0.071 ↓ 0.154 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 2821\t Score = -23.22\n",
            "🚂 Episode 2821\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.117 → 0.457 ◼ 0.032 ↓ 0.181 \t Metric 0.397 \n",
            "Episode Nr. 2822\t Score = 8.79\n",
            "🚂 Episode 2822\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2823\t Score = -23.22\n",
            "🚂 Episode 2823\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.085 ↑ 0.277 → 0.096 ◼ 0.160 ↓ 0.372 \t Metric 0.397 \n",
            "Episode Nr. 2824\t Score = -23.22\n",
            "🚂 Episode 2824\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.213 ↑ 0.245 → 0.032 ◼ 0.479 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2825\t Score = -23.22\n",
            "🚂 Episode 2825\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.128 → 0.415 ◼ 0.032 ↓ 0.223 \t Metric 0.397 \n",
            "Episode Nr. 2826\t Score = -23.22\n",
            "🚂 Episode 2826\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.053 ↑ 0.255 → 0.043 ◼ 0.628 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2827\t Score = -22.619999999999997\n",
            "🚂 Episode 2827\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.046 ↑ 0.660 → 0.020 ◼ 0.144 ↓ 0.124 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2828\t Score = -23.520000000000003\n",
            "🚂 Episode 2828\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.125 ↑ 0.188 → 0.146 ◼ 0.135 ↓ 0.396 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2829\t Score = -22.619999999999997\n",
            "🚂 Episode 2829\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.359 ↑ 0.359 → 0.033 ◼ 0.013 ↓ 0.229 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2830\t Score = -23.22\n",
            "🚂 Episode 2830\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.181 → 0.426 ◼ 0.011 ↓ 0.255 \t Metric 0.397 \n",
            "Episode Nr. 2831\t Score = -22.619999999999997\n",
            "🚂 Episode 2831\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.157 ↑ 0.366 → 0.124 ◼ 0.072 ↓ 0.248 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2832\t Score = -22.619999999999997\n",
            "🚂 Episode 2832\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.248 ← 0.052 ↑ 0.373 → 0.111 ◼ 0.007 ↓ 0.209 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2833\t Score = -23.22\n",
            "🚂 Episode 2833\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.138 ↑ 0.266 → 0.266 ◼ 0.032 ↓ 0.287 \t Metric 0.397 \n",
            "Episode Nr. 2834\t Score = -23.22\n",
            "🚂 Episode 2834\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.787 ↑ 0.138 → 0.032 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2835\t Score = -22.619999999999997\n",
            "🚂 Episode 2835\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.288 ← 0.163 ↑ 0.124 → 0.065 ◼ 0.013 ↓ 0.346 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2836\t Score = -23.22\n",
            "🚂 Episode 2836\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.223 ↑ 0.202 → 0.043 ◼ 0.447 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2837\t Score = 8.79\n",
            "🚂 Episode 2837\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2838\t Score = -23.22\n",
            "🚂 Episode 2838\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.553 ↑ 0.191 → 0.032 ◼ 0.181 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2839\t Score = -23.22\n",
            "🚂 Episode 2839\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.096 → 0.447 ◼ 0.011 ↓ 0.245 \t Metric 0.397 \n",
            "Episode Nr. 2840\t Score = -23.22\n",
            "🚂 Episode 2840\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.106 ↑ 0.096 → 0.106 ◼ 0.638 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2841\t Score = 8.79\n",
            "🚂 Episode 2841\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2842\t Score = -22.619999999999997\n",
            "🚂 Episode 2842\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.288 ← 0.497 ↑ 0.059 → 0.052 ◼ 0.098 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2843\t Score = -23.22\n",
            "🚂 Episode 2843\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.223 → 0.160 ◼ 0.011 ↓ 0.404 \t Metric 0.397 \n",
            "Episode Nr. 2844\t Score = -23.22\n",
            "🚂 Episode 2844\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.181 ↑ 0.255 → 0.032 ◼ 0.383 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2845\t Score = -23.22\n",
            "🚂 Episode 2845\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.213 → 0.213 ◼ 0.138 ↓ 0.234 \t Metric 0.397 \n",
            "Episode Nr. 2846\t Score = 8.643333333333333\n",
            "🚂 Episode 2846\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2847\t Score = -23.22\n",
            "🚂 Episode 2847\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.085 ↑ 0.266 → 0.309 ◼ 0.011 ↓ 0.319 \t Metric 0.397 \n",
            "Episode Nr. 2848\t Score = -22.619999999999997\n",
            "🚂 Episode 2848\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.196 ← 0.477 ↑ 0.065 → 0.020 ◼ 0.222 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2849\t Score = -22.619999999999997\n",
            "🚂 Episode 2849\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.216 ↑ 0.392 → 0.092 ◼ 0.020 ↓ 0.261 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2850\t Score = -105.01999999999994\n",
            "🚂 Episode 2850\t 🏆 Score: -0.140 Avg: -0.028\t 💯 Done: 0.00% Avg: 32.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.776 ↑ 0.021 → 0.117 ◼ 0.004 ↓ 0.075 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 2851\t Score = -23.22\n",
            "🚂 Episode 2851\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.128 ↑ 0.085 → 0.096 ◼ 0.319 ↓ 0.362 \t Metric 0.397 \n",
            "Episode Nr. 2852\t Score = -23.22\n",
            "🚂 Episode 2852\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.138 ↑ 0.085 → 0.277 ◼ 0.149 ↓ 0.340 \t Metric 0.397 \n",
            "Episode Nr. 2853\t Score = -22.619999999999997\n",
            "🚂 Episode 2853\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.379 ↑ 0.131 → 0.118 ◼ 0.072 ↓ 0.261 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2854\t Score = -23.22\n",
            "🚂 Episode 2854\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.138 ↑ 0.074 → 0.170 ◼ 0.160 ↓ 0.362 \t Metric 0.397 \n",
            "Episode Nr. 2855\t Score = -23.22\n",
            "🚂 Episode 2855\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.149 ↑ 0.074 → 0.170 ◼ 0.149 ↓ 0.372 \t Metric 0.397 \n",
            "Episode Nr. 2856\t Score = -102.53999999999999\n",
            "🚂 Episode 2856\t 🏆 Score: -0.137 Avg: -0.029\t 💯 Done: 0.00% Avg: 31.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.345 ← 0.457 ↑ 0.015 → 0.021 ◼ 0.125 ↓ 0.037 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2857\t Score = -23.22\n",
            "🚂 Episode 2857\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.223 ↑ 0.085 → 0.287 ◼ 0.043 ↓ 0.351 \t Metric 0.397 \n",
            "Episode Nr. 2858\t Score = -23.22\n",
            "🚂 Episode 2858\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.202 ↑ 0.138 → 0.404 ◼ 0.032 ↓ 0.202 \t Metric 0.397 \n",
            "Episode Nr. 2859\t Score = -22.619999999999997\n",
            "🚂 Episode 2859\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.078 ← 0.052 ↑ 0.353 → 0.078 ◼ 0.281 ↓ 0.157 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2860\t Score = -102.53999999999999\n",
            "🚂 Episode 2860\t 🏆 Score: -0.137 Avg: -0.030\t 💯 Done: 0.00% Avg: 31.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.346 ← 0.129 ↑ 0.017 → 0.292 ◼ 0.183 ↓ 0.034 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2861\t Score = -23.22\n",
            "🚂 Episode 2861\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.053 → 0.479 ◼ 0.021 ↓ 0.245 \t Metric 0.397 \n",
            "Episode Nr. 2862\t Score = -22.619999999999997\n",
            "🚂 Episode 2862\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.124 ↑ 0.248 → 0.072 ◼ 0.216 ↓ 0.255 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2863\t Score = -22.91\n",
            "🚂 Episode 2863\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.019 ← 0.237 ↑ 0.468 → 0.019 ◼ 0.019 ↓ 0.237 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 2864\t Score = -22.619999999999997\n",
            "🚂 Episode 2864\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.314 ← 0.065 ↑ 0.216 → 0.072 ◼ 0.007 ↓ 0.327 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2865\t Score = -23.22\n",
            "🚂 Episode 2865\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.532 ↑ 0.277 → 0.043 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2866\t Score = -23.22\n",
            "🚂 Episode 2866\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.043 ↑ 0.766 → 0.032 ◼ 0.021 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2867\t Score = -23.22\n",
            "🚂 Episode 2867\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.149 ↑ 0.096 → 0.319 ◼ 0.128 ↓ 0.223 \t Metric 0.397 \n",
            "Episode Nr. 2868\t Score = -22.619999999999997\n",
            "🚂 Episode 2868\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.072 ← 0.418 ↑ 0.078 → 0.020 ◼ 0.392 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2869\t Score = -23.22\n",
            "🚂 Episode 2869\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.128 → 0.032 ◼ 0.638 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2870\t Score = -23.22\n",
            "🚂 Episode 2870\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.032 ↑ 0.255 → 0.032 ◼ 0.628 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2871\t Score = -23.22\n",
            "🚂 Episode 2871\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.149 ↑ 0.128 → 0.479 ◼ 0.011 ↓ 0.170 \t Metric 0.397 \n",
            "Episode Nr. 2872\t Score = -22.619999999999997\n",
            "🚂 Episode 2872\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.856 ↑ 0.072 → 0.020 ◼ 0.007 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2873\t Score = -22.619999999999997\n",
            "🚂 Episode 2873\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.131 ← 0.523 ↑ 0.085 → 0.020 ◼ 0.229 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2874\t Score = -23.22\n",
            "🚂 Episode 2874\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.074 ↑ 0.213 → 0.032 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2875\t Score = -23.22\n",
            "🚂 Episode 2875\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.053 ↑ 0.245 → 0.032 ◼ 0.628 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2876\t Score = 8.79\n",
            "🚂 Episode 2876\t 🏆 Score: 0.012 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2877\t Score = -22.619999999999997\n",
            "🚂 Episode 2877\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.673 ↑ 0.105 → 0.026 ◼ 0.170 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2878\t Score = -23.22\n",
            "🚂 Episode 2878\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.117 → 0.255 ◼ 0.128 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 2879\t Score = -23.22\n",
            "🚂 Episode 2879\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.468 ← 0.117 ↑ 0.213 → 0.032 ◼ 0.011 ↓ 0.160 \t Metric 0.397 \n",
            "Episode Nr. 2880\t Score = -22.619999999999997\n",
            "🚂 Episode 2880\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.078 ↑ 0.490 → 0.020 ◼ 0.163 ↓ 0.209 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2881\t Score = 8.79\n",
            "🚂 Episode 2881\t 🏆 Score: 0.012 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2882\t Score = -22.619999999999997\n",
            "🚂 Episode 2882\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.392 ← 0.268 ↑ 0.163 → 0.150 ◼ 0.007 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2883\t Score = -42.53999999999999\n",
            "🚂 Episode 2883\t 🏆 Score: -0.057 Avg: -0.030\t 💯 Done: 0.00% Avg: 31.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.126 ← 0.468 ↑ 0.165 → 0.014 ◼ 0.083 ↓ 0.144 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 2884\t Score = -23.22\n",
            "🚂 Episode 2884\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.106 → 0.255 ◼ 0.404 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2885\t Score = -22.619999999999997\n",
            "🚂 Episode 2885\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.183 ↑ 0.105 → 0.059 ◼ 0.301 ↓ 0.327 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2886\t Score = -23.22\n",
            "🚂 Episode 2886\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.074 ↑ 0.713 → 0.021 ◼ 0.011 ↓ 0.160 \t Metric 0.397 \n",
            "Episode Nr. 2887\t Score = -22.619999999999997\n",
            "🚂 Episode 2887\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.144 ← 0.536 ↑ 0.072 → 0.229 ◼ 0.007 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2888\t Score = -22.619999999999997\n",
            "🚂 Episode 2888\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 31.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.216 ← 0.176 ↑ 0.458 → 0.131 ◼ 0.013 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2889\t Score = 10.11\n",
            "🚂 Episode 2889\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.014 ↑ 0.257 → 0.629 ◼ 0.014 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 2890\t Score = -20.436666666666664\n",
            "🚂 Episode 2890\t 🏆 Score: -0.027 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.053 ↑ 0.224 → 0.592 ◼ 0.013 ↓ 0.105 \t Metric 0.397 \n",
            "Episode Nr. 2891\t Score = -23.22\n",
            "🚂 Episode 2891\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.213 ↑ 0.064 → 0.032 ◼ 0.011 ↓ 0.660 \t Metric 0.397 \n",
            "Episode Nr. 2892\t Score = -23.22\n",
            "🚂 Episode 2892\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.202 ↑ 0.053 → 0.021 ◼ 0.011 ↓ 0.691 \t Metric 0.397 \n",
            "Episode Nr. 2893\t Score = -23.22\n",
            "🚂 Episode 2893\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.064 ↑ 0.138 → 0.043 ◼ 0.011 ↓ 0.649 \t Metric 0.397 \n",
            "Episode Nr. 2894\t Score = -22.619999999999997\n",
            "🚂 Episode 2894\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.242 ↑ 0.359 → 0.059 ◼ 0.170 ↓ 0.157 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2895\t Score = -22.619999999999997\n",
            "🚂 Episode 2895\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.399 ↑ 0.288 → 0.092 ◼ 0.020 ↓ 0.196 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2896\t Score = -23.22\n",
            "🚂 Episode 2896\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.043 → 0.521 ◼ 0.011 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 2897\t Score = -24.119999999999997\n",
            "🚂 Episode 2897\t 🏆 Score: -0.032 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.050 ↑ 0.140 → 0.110 ◼ 0.020 ↓ 0.670 \t Metric 0.39549999999999996 \n",
            "Episode Nr. 2898\t Score = 8.79\n",
            "🚂 Episode 2898\t 🏆 Score: 0.012 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2899\t Score = 8.79\n",
            "🚂 Episode 2899\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 31.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2900\t Score = -24.419999999999998\n",
            "🚂 Episode 2900\t 🏆 Score: -0.033 Avg: -0.028\t 💯 Done: 33.33% Avg: 31.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.030 ↑ 0.260 → 0.650 ◼ 0.010 ↓ 0.030 \t Metric 0.395 \n",
            "Episode Nr. 2901\t Score = -23.22\n",
            "🚂 Episode 2901\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 31.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.106 → 0.543 ◼ 0.011 ↓ 0.213 \t Metric 0.397 \n",
            "Episode Nr. 2902\t Score = -22.619999999999997\n",
            "🚂 Episode 2902\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.039 ↑ 0.092 → 0.072 ◼ 0.490 ↓ 0.301 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2903\t Score = -22.619999999999997\n",
            "🚂 Episode 2903\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 31.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.065 ↑ 0.451 → 0.052 ◼ 0.026 ↓ 0.379 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2904\t Score = 8.79\n",
            "🚂 Episode 2904\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 31.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2905\t Score = -23.22\n",
            "🚂 Episode 2905\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 31.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.085 ↑ 0.596 → 0.085 ◼ 0.128 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 2906\t Score = -23.22\n",
            "🚂 Episode 2906\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 31.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.138 ↑ 0.511 → 0.128 ◼ 0.128 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2907\t Score = -23.22\n",
            "🚂 Episode 2907\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 31.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.213 ↑ 0.404 → 0.202 ◼ 0.128 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2908\t Score = -23.22\n",
            "🚂 Episode 2908\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 31.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.500 → 0.277 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2909\t Score = -23.22\n",
            "🚂 Episode 2909\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.064 ↑ 0.819 → 0.053 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2910\t Score = -22.619999999999997\n",
            "🚂 Episode 2910\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.307 ← 0.078 ↑ 0.026 → 0.438 ◼ 0.098 ↓ 0.052 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2911\t Score = -23.22\n",
            "🚂 Episode 2911\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.149 ↑ 0.032 → 0.117 ◼ 0.234 ↓ 0.457 \t Metric 0.397 \n",
            "Episode Nr. 2912\t Score = -23.22\n",
            "🚂 Episode 2912\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.106 ↑ 0.074 → 0.128 ◼ 0.255 ↓ 0.426 \t Metric 0.397 \n",
            "Episode Nr. 2913\t Score = -22.619999999999997\n",
            "🚂 Episode 2913\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.072 ↑ 0.052 → 0.346 ◼ 0.497 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2914\t Score = -23.22\n",
            "🚂 Episode 2914\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.096 → 0.128 ◼ 0.309 ↓ 0.340 \t Metric 0.397 \n",
            "Episode Nr. 2915\t Score = -50.169999999999995\n",
            "🚂 Episode 2915\t 🏆 Score: -0.067 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.023 ↑ 0.034 → 0.009 ◼ 0.916 ↓ 0.007 \t Metric 0.5825 \n",
            "Episode Nr. 2916\t Score = -22.91\n",
            "🚂 Episode 2916\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.006 ← 0.404 ↑ 0.333 → 0.077 ◼ 0.090 ↓ 0.090 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 2917\t Score = -22.619999999999997\n",
            "🚂 Episode 2917\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.327 ↑ 0.451 → 0.039 ◼ 0.078 ↓ 0.065 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2918\t Score = -23.22\n",
            "🚂 Episode 2918\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.074 ↑ 0.266 → 0.170 ◼ 0.128 ↓ 0.351 \t Metric 0.397 \n",
            "Episode Nr. 2919\t Score = -22.619999999999997\n",
            "🚂 Episode 2919\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.373 ↑ 0.216 → 0.092 ◼ 0.078 ↓ 0.216 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2920\t Score = -23.22\n",
            "🚂 Episode 2920\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.074 ↑ 0.213 → 0.032 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2921\t Score = -23.22\n",
            "🚂 Episode 2921\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.138 ↑ 0.128 → 0.043 ◼ 0.011 ↓ 0.660 \t Metric 0.397 \n",
            "Episode Nr. 2922\t Score = -23.22\n",
            "🚂 Episode 2922\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.223 ↑ 0.074 → 0.277 ◼ 0.128 ↓ 0.287 \t Metric 0.397 \n",
            "Episode Nr. 2923\t Score = -22.619999999999997\n",
            "🚂 Episode 2923\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.072 ↑ 0.484 → 0.065 ◼ 0.007 ↓ 0.366 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2924\t Score = -23.22\n",
            "🚂 Episode 2924\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.096 ↑ 0.191 → 0.191 ◼ 0.160 ↓ 0.351 \t Metric 0.397 \n",
            "Episode Nr. 2925\t Score = -23.22\n",
            "🚂 Episode 2925\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.085 → 0.043 ◼ 0.628 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2926\t Score = -23.22\n",
            "🚂 Episode 2926\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.138 ↑ 0.319 → 0.032 ◼ 0.415 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 2927\t Score = -23.22\n",
            "🚂 Episode 2927\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.096 ↑ 0.340 → 0.117 ◼ 0.149 ↓ 0.287 \t Metric 0.397 \n",
            "Episode Nr. 2928\t Score = 8.79\n",
            "🚂 Episode 2928\t 🏆 Score: 0.012 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2929\t Score = -23.22\n",
            "🚂 Episode 2929\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.660 ↑ 0.160 → 0.032 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 2930\t Score = -23.22\n",
            "🚂 Episode 2930\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.096 ↑ 0.223 → 0.160 ◼ 0.128 ↓ 0.383 \t Metric 0.397 \n",
            "Episode Nr. 2931\t Score = -22.619999999999997\n",
            "🚂 Episode 2931\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.392 ← 0.052 ↑ 0.124 → 0.020 ◼ 0.392 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2932\t Score = -23.22\n",
            "🚂 Episode 2932\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.074 ↑ 0.245 → 0.213 ◼ 0.138 ↓ 0.319 \t Metric 0.397 \n",
            "Episode Nr. 2933\t Score = -22.619999999999997\n",
            "🚂 Episode 2933\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.072 ← 0.346 ↑ 0.366 → 0.078 ◼ 0.078 ↓ 0.059 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2934\t Score = -22.619999999999997\n",
            "🚂 Episode 2934\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.275 ↑ 0.353 → 0.072 ◼ 0.007 ↓ 0.268 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2935\t Score = -23.22\n",
            "🚂 Episode 2935\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.170 ↑ 0.106 → 0.032 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2936\t Score = -22.619999999999997\n",
            "🚂 Episode 2936\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.137 ← 0.373 ↑ 0.059 → 0.020 ◼ 0.392 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2937\t Score = -23.22\n",
            "🚂 Episode 2937\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.085 ↑ 0.234 → 0.032 ◼ 0.074 ↓ 0.553 \t Metric 0.397 \n",
            "Episode Nr. 2938\t Score = -23.22\n",
            "🚂 Episode 2938\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.106 ↑ 0.202 → 0.277 ◼ 0.128 ↓ 0.277 \t Metric 0.397 \n",
            "Episode Nr. 2939\t Score = -22.619999999999997\n",
            "🚂 Episode 2939\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.281 ↑ 0.516 → 0.026 ◼ 0.085 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2940\t Score = -22.619999999999997\n",
            "🚂 Episode 2940\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.190 ← 0.242 ↑ 0.229 → 0.314 ◼ 0.007 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2941\t Score = -23.22\n",
            "🚂 Episode 2941\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.277 ↑ 0.149 → 0.500 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2942\t Score = -22.619999999999997\n",
            "🚂 Episode 2942\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.405 ↑ 0.314 → 0.020 ◼ 0.007 ↓ 0.229 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2943\t Score = -23.22\n",
            "🚂 Episode 2943\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.309 ↑ 0.074 → 0.394 ◼ 0.032 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 2944\t Score = -22.619999999999997\n",
            "🚂 Episode 2944\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.124 ← 0.216 ↑ 0.072 → 0.163 ◼ 0.020 ↓ 0.405 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2945\t Score = -23.22\n",
            "🚂 Episode 2945\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.064 → 0.032 ◼ 0.319 ↓ 0.372 \t Metric 0.397 \n",
            "Episode Nr. 2946\t Score = -23.22\n",
            "🚂 Episode 2946\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.117 ↑ 0.074 → 0.085 ◼ 0.553 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 2947\t Score = -22.619999999999997\n",
            "🚂 Episode 2947\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.072 ← 0.216 ↑ 0.183 → 0.150 ◼ 0.359 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2948\t Score = -23.22\n",
            "🚂 Episode 2948\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.628 ← 0.053 ↑ 0.170 → 0.032 ◼ 0.106 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2949\t Score = -23.22\n",
            "🚂 Episode 2949\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.117 ↑ 0.372 → 0.043 ◼ 0.319 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 2950\t Score = -23.22\n",
            "🚂 Episode 2950\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.128 ↑ 0.149 → 0.043 ◼ 0.234 ↓ 0.362 \t Metric 0.397 \n",
            "Episode Nr. 2951\t Score = 8.79\n",
            "🚂 Episode 2951\t 🏆 Score: 0.012 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2952\t Score = -22.619999999999997\n",
            "🚂 Episode 2952\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.052 ← 0.078 ↑ 0.065 → 0.020 ◼ 0.778 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2953\t Score = -23.520000000000003\n",
            "🚂 Episode 2953\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.083 ↑ 0.375 → 0.042 ◼ 0.156 ↓ 0.333 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 2954\t Score = -23.22\n",
            "🚂 Episode 2954\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.064 ↑ 0.245 → 0.053 ◼ 0.149 ↓ 0.394 \t Metric 0.397 \n",
            "Episode Nr. 2955\t Score = -23.22\n",
            "🚂 Episode 2955\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.096 ↑ 0.181 → 0.043 ◼ 0.170 ↓ 0.415 \t Metric 0.397 \n",
            "Episode Nr. 2956\t Score = 8.79\n",
            "🚂 Episode 2956\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2957\t Score = -23.22\n",
            "🚂 Episode 2957\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.734 ↑ 0.085 → 0.053 ◼ 0.106 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2958\t Score = -23.22\n",
            "🚂 Episode 2958\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.564 ↑ 0.202 → 0.064 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 2959\t Score = -23.22\n",
            "🚂 Episode 2959\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.628 → 0.160 ◼ 0.128 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2960\t Score = -23.22\n",
            "🚂 Episode 2960\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.128 ↑ 0.596 → 0.053 ◼ 0.170 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2961\t Score = -23.22\n",
            "🚂 Episode 2961\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.032 ↑ 0.628 → 0.149 ◼ 0.170 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2962\t Score = -23.22\n",
            "🚂 Episode 2962\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.053 ↑ 0.234 → 0.032 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2963\t Score = -23.22\n",
            "🚂 Episode 2963\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.160 ↑ 0.085 → 0.053 ◼ 0.553 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2964\t Score = -23.22\n",
            "🚂 Episode 2964\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.138 ↑ 0.202 → 0.170 ◼ 0.128 ↓ 0.277 \t Metric 0.397 \n",
            "Episode Nr. 2965\t Score = -23.779999999999998\n",
            "🚂 Episode 2965\t 🏆 Score: -0.032 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.301 ← 0.331 ↑ 0.074 → 0.117 ◼ 0.172 ↓ 0.006 \t Metric 0.6583333333333333 \n",
            "Episode Nr. 2966\t Score = -23.22\n",
            "🚂 Episode 2966\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.287 → 0.191 ◼ 0.149 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 2967\t Score = -23.22\n",
            "🚂 Episode 2967\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.468 ← 0.138 ↑ 0.298 → 0.043 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 2968\t Score = -22.619999999999997\n",
            "🚂 Episode 2968\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.137 ← 0.242 ↑ 0.373 → 0.092 ◼ 0.085 ↓ 0.072 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2969\t Score = -23.22\n",
            "🚂 Episode 2969\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.468 ← 0.160 ↑ 0.298 → 0.043 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2970\t Score = -23.22\n",
            "🚂 Episode 2970\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.128 ↑ 0.181 → 0.032 ◼ 0.638 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2971\t Score = -23.22\n",
            "🚂 Episode 2971\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.117 ↑ 0.277 → 0.149 ◼ 0.128 ↓ 0.309 \t Metric 0.397 \n",
            "Episode Nr. 2972\t Score = -23.22\n",
            "🚂 Episode 2972\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.138 ↑ 0.138 → 0.500 ◼ 0.170 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2973\t Score = -22.619999999999997\n",
            "🚂 Episode 2973\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.046 ← 0.477 ↑ 0.059 → 0.170 ◼ 0.242 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2974\t Score = -22.619999999999997\n",
            "🚂 Episode 2974\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.301 ↑ 0.601 → 0.039 ◼ 0.033 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2975\t Score = -23.22\n",
            "🚂 Episode 2975\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.202 ↑ 0.479 → 0.149 ◼ 0.128 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2976\t Score = -23.22\n",
            "🚂 Episode 2976\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.213 ↑ 0.170 → 0.213 ◼ 0.128 ↓ 0.266 \t Metric 0.397 \n",
            "Episode Nr. 2977\t Score = -23.22\n",
            "🚂 Episode 2977\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.255 ↑ 0.160 → 0.149 ◼ 0.415 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2978\t Score = -23.22\n",
            "🚂 Episode 2978\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.138 ↑ 0.702 → 0.117 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 2979\t Score = -23.22\n",
            "🚂 Episode 2979\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.043 ↑ 0.755 → 0.117 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 2980\t Score = -23.22\n",
            "🚂 Episode 2980\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.032 → 0.670 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 2981\t Score = -102.53999999999999\n",
            "🚂 Episode 2981\t 🏆 Score: -0.137 Avg: -0.030\t 💯 Done: 0.00% Avg: 32.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.006 ↑ 0.010 → 0.434 ◼ 0.396 ↓ 0.101 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 2982\t Score = -30.12\n",
            "🚂 Episode 2982\t 🏆 Score: -0.040 Avg: -0.030\t 💯 Done: 33.33% Avg: 32.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.086 ↑ 0.150 → 0.021 ◼ 0.264 ↓ 0.421 \t Metric 0.38549999999999995 \n",
            "Episode Nr. 2983\t Score = 8.643333333333333\n",
            "🚂 Episode 2983\t 🏆 Score: 0.012 Avg: -0.030\t 💯 Done: 33.33% Avg: 32.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2984\t Score = -23.22\n",
            "🚂 Episode 2984\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 32.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.117 ↑ 0.170 → 0.053 ◼ 0.149 ↓ 0.404 \t Metric 0.397 \n",
            "Episode Nr. 2985\t Score = -23.22\n",
            "🚂 Episode 2985\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 32.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.074 ↑ 0.266 → 0.043 ◼ 0.149 ↓ 0.372 \t Metric 0.397 \n",
            "Episode Nr. 2986\t Score = -22.619999999999997\n",
            "🚂 Episode 2986\t 🏆 Score: -0.030 Avg: -0.030\t 💯 Done: 33.33% Avg: 32.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.065 ← 0.366 ↑ 0.418 → 0.026 ◼ 0.078 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2987\t Score = 8.643333333333333\n",
            "🚂 Episode 2987\t 🏆 Score: 0.012 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 2988\t Score = -23.22\n",
            "🚂 Episode 2988\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.670 ↑ 0.170 → 0.043 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 2989\t Score = -23.22\n",
            "🚂 Episode 2989\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.138 ↑ 0.160 → 0.032 ◼ 0.617 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 2990\t Score = -23.22\n",
            "🚂 Episode 2990\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.106 ↑ 0.160 → 0.149 ◼ 0.128 ↓ 0.383 \t Metric 0.397 \n",
            "Episode Nr. 2991\t Score = -23.22\n",
            "🚂 Episode 2991\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.160 → 0.149 ◼ 0.128 ↓ 0.351 \t Metric 0.397 \n",
            "Episode Nr. 2992\t Score = -23.22\n",
            "🚂 Episode 2992\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.191 ↑ 0.223 → 0.138 ◼ 0.128 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 2993\t Score = 3.179999999999997\n",
            "🚂 Episode 2993\t 🏆 Score: 0.004 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.016 ← 0.016 ↑ 0.153 → 0.371 ◼ 0.411 ↓ 0.032 \t Metric 0.5905 \n",
            "Episode Nr. 2994\t Score = -22.619999999999997\n",
            "🚂 Episode 2994\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.346 ↑ 0.379 → 0.111 ◼ 0.059 ↓ 0.072 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2995\t Score = 8.79\n",
            "🚂 Episode 2995\t 🏆 Score: 0.012 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 2996\t Score = -23.22\n",
            "🚂 Episode 2996\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.160 ↑ 0.255 → 0.255 ◼ 0.128 ↓ 0.191 \t Metric 0.397 \n",
            "Episode Nr. 2997\t Score = -23.22\n",
            "🚂 Episode 2997\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.628 → 0.138 ◼ 0.128 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 2998\t Score = -22.619999999999997\n",
            "🚂 Episode 2998\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 32.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.131 ↑ 0.065 → 0.124 ◼ 0.379 ↓ 0.281 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 2999\t Score = 8.496666666666664\n",
            "🚂 Episode 2999\t 🏆 Score: 0.011 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.42714285714285716 \n",
            "Episode Nr. 3000\t Score = -23.22\n",
            "🚂 Episode 3000\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.074 ↑ 0.670 → 0.128 ◼ 0.085 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3001\t Score = -23.22\n",
            "🚂 Episode 3001\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.223 ↑ 0.372 → 0.319 ◼ 0.053 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3002\t Score = -24.419999999999998\n",
            "🚂 Episode 3002\t 🏆 Score: -0.033 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.020 ↑ 0.150 → 0.160 ◼ 0.640 ↓ 0.020 \t Metric 0.395 \n",
            "Episode Nr. 3003\t Score = -22.619999999999997\n",
            "🚂 Episode 3003\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.418 ↑ 0.379 → 0.072 ◼ 0.007 ↓ 0.105 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3004\t Score = 8.79\n",
            "🚂 Episode 3004\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3005\t Score = -23.22\n",
            "🚂 Episode 3005\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.085 ↑ 0.723 → 0.021 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3006\t Score = 8.79\n",
            "🚂 Episode 3006\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3007\t Score = -20.436666666666664\n",
            "🚂 Episode 3007\t 🏆 Score: -0.027 Avg: -0.028\t 💯 Done: 33.33% Avg: 32.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.197 ← 0.039 ↑ 0.158 → 0.500 ◼ 0.013 ↓ 0.092 \t Metric 0.397 \n",
            "Episode Nr. 3008\t Score = 8.79\n",
            "🚂 Episode 3008\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3009\t Score = 8.79\n",
            "🚂 Episode 3009\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3010\t Score = -22.619999999999997\n",
            "🚂 Episode 3010\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.281 ← 0.229 ↑ 0.144 → 0.078 ◼ 0.190 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3011\t Score = -23.22\n",
            "🚂 Episode 3011\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.223 ↑ 0.096 → 0.638 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3012\t Score = -23.22\n",
            "🚂 Episode 3012\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.128 → 0.447 ◼ 0.117 ↓ 0.106 \t Metric 0.397 \n",
            "Episode Nr. 3013\t Score = -23.22\n",
            "🚂 Episode 3013\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.096 ↑ 0.213 → 0.372 ◼ 0.149 ↓ 0.160 \t Metric 0.397 \n",
            "Episode Nr. 3014\t Score = -22.619999999999997\n",
            "🚂 Episode 3014\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.425 ↑ 0.307 → 0.026 ◼ 0.144 ↓ 0.085 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3015\t Score = 8.643333333333333\n",
            "🚂 Episode 3015\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3016\t Score = -23.22\n",
            "🚂 Episode 3016\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.213 ↑ 0.117 → 0.223 ◼ 0.128 ↓ 0.309 \t Metric 0.397 \n",
            "Episode Nr. 3017\t Score = -23.22\n",
            "🚂 Episode 3017\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.213 ↑ 0.085 → 0.032 ◼ 0.617 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3018\t Score = -23.22\n",
            "🚂 Episode 3018\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.043 ↑ 0.255 → 0.032 ◼ 0.638 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3019\t Score = -23.22\n",
            "🚂 Episode 3019\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.074 ↑ 0.202 → 0.032 ◼ 0.638 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3020\t Score = -23.22\n",
            "🚂 Episode 3020\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.149 ↑ 0.149 → 0.032 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3021\t Score = -23.22\n",
            "🚂 Episode 3021\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.628 ↑ 0.181 → 0.043 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3022\t Score = -23.22\n",
            "🚂 Episode 3022\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.223 ↑ 0.096 → 0.362 ◼ 0.117 ↓ 0.191 \t Metric 0.397 \n",
            "Episode Nr. 3023\t Score = -22.619999999999997\n",
            "🚂 Episode 3023\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.078 ← 0.418 ↑ 0.458 → 0.026 ◼ 0.007 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3024\t Score = -22.619999999999997\n",
            "🚂 Episode 3024\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.392 ↑ 0.484 → 0.026 ◼ 0.013 ↓ 0.065 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3025\t Score = 8.79\n",
            "🚂 Episode 3025\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3026\t Score = -22.619999999999997\n",
            "🚂 Episode 3026\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.248 ← 0.255 ↑ 0.275 → 0.033 ◼ 0.007 ↓ 0.183 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3027\t Score = 8.79\n",
            "🚂 Episode 3027\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3028\t Score = 8.496666666666664\n",
            "🚂 Episode 3028\t 🏆 Score: 0.011 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.42714285714285716 \n",
            "Episode Nr. 3029\t Score = 8.643333333333333\n",
            "🚂 Episode 3029\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3030\t Score = -23.22\n",
            "🚂 Episode 3030\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.532 ↑ 0.181 → 0.032 ◼ 0.160 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 3031\t Score = -23.22\n",
            "🚂 Episode 3031\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.638 → 0.138 ◼ 0.128 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3032\t Score = -23.22\n",
            "🚂 Episode 3032\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.149 ↑ 0.532 → 0.149 ◼ 0.128 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3033\t Score = -22.619999999999997\n",
            "🚂 Episode 3033\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.399 ↑ 0.248 → 0.092 ◼ 0.078 ↓ 0.157 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3034\t Score = 8.79\n",
            "🚂 Episode 3034\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3035\t Score = -23.22\n",
            "🚂 Episode 3035\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.074 ↑ 0.191 → 0.032 ◼ 0.638 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3036\t Score = -22.619999999999997\n",
            "🚂 Episode 3036\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.444 ↑ 0.242 → 0.020 ◼ 0.007 ↓ 0.196 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3037\t Score = 8.79\n",
            "🚂 Episode 3037\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3038\t Score = -23.22\n",
            "🚂 Episode 3038\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.628 ↑ 0.255 → 0.043 ◼ 0.021 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3039\t Score = -23.22\n",
            "🚂 Episode 3039\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.096 ↑ 0.181 → 0.255 ◼ 0.404 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3040\t Score = -23.22\n",
            "🚂 Episode 3040\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.117 → 0.372 ◼ 0.011 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 3041\t Score = -23.22\n",
            "🚂 Episode 3041\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.064 ↑ 0.351 → 0.255 ◼ 0.011 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 3042\t Score = -23.22\n",
            "🚂 Episode 3042\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.213 → 0.362 ◼ 0.011 ↓ 0.234 \t Metric 0.397 \n",
            "Episode Nr. 3043\t Score = -23.22\n",
            "🚂 Episode 3043\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.628 ↑ 0.181 → 0.043 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3044\t Score = 8.643333333333333\n",
            "🚂 Episode 3044\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3045\t Score = -23.22\n",
            "🚂 Episode 3045\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.096 ↑ 0.191 → 0.032 ◼ 0.011 ↓ 0.649 \t Metric 0.397 \n",
            "Episode Nr. 3046\t Score = -22.619999999999997\n",
            "🚂 Episode 3046\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.353 ← 0.190 ↑ 0.248 → 0.033 ◼ 0.007 ↓ 0.170 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3047\t Score = -23.22\n",
            "🚂 Episode 3047\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.074 ↑ 0.351 → 0.202 ◼ 0.128 ↓ 0.223 \t Metric 0.397 \n",
            "Episode Nr. 3048\t Score = -23.22\n",
            "🚂 Episode 3048\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.138 ↑ 0.191 → 0.362 ◼ 0.011 ↓ 0.287 \t Metric 0.397 \n",
            "Episode Nr. 3049\t Score = -23.22\n",
            "🚂 Episode 3049\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.213 ↑ 0.138 → 0.564 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 3050\t Score = -23.520000000000003\n",
            "🚂 Episode 3050\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.062 ↑ 0.458 → 0.427 ◼ 0.021 ↓ 0.021 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3051\t Score = -23.22\n",
            "🚂 Episode 3051\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.074 ↑ 0.287 → 0.362 ◼ 0.011 ↓ 0.255 \t Metric 0.397 \n",
            "Episode Nr. 3052\t Score = -23.22\n",
            "🚂 Episode 3052\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.511 ↑ 0.309 → 0.043 ◼ 0.011 ↓ 0.117 \t Metric 0.397 \n",
            "Episode Nr. 3053\t Score = -23.520000000000003\n",
            "🚂 Episode 3053\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.031 ↑ 0.708 → 0.031 ◼ 0.021 ↓ 0.198 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3054\t Score = -23.22\n",
            "🚂 Episode 3054\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.553 → 0.191 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 3055\t Score = -22.619999999999997\n",
            "🚂 Episode 3055\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.124 ↑ 0.033 → 0.745 ◼ 0.007 ↓ 0.085 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3056\t Score = -23.22\n",
            "🚂 Episode 3056\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.128 → 0.649 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3057\t Score = -25.62\n",
            "🚂 Episode 3057\t 🏆 Score: -0.034 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.136 ← 0.164 ↑ 0.255 → 0.036 ◼ 0.400 ↓ 0.009 \t Metric 0.393 \n",
            "Episode Nr. 3058\t Score = -23.22\n",
            "🚂 Episode 3058\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.128 ↑ 0.085 → 0.649 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3059\t Score = -23.22\n",
            "🚂 Episode 3059\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.106 ↑ 0.085 → 0.660 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3060\t Score = -23.22\n",
            "🚂 Episode 3060\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.085 ↑ 0.436 → 0.096 ◼ 0.277 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3061\t Score = -23.779999999999998\n",
            "🚂 Episode 3061\t 🏆 Score: -0.032 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.012 ← 0.018 ↑ 0.086 → 0.104 ◼ 0.761 ↓ 0.018 \t Metric 0.6583333333333333 \n",
            "Episode Nr. 3062\t Score = -22.619999999999997\n",
            "🚂 Episode 3062\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.052 ↑ 0.346 → 0.026 ◼ 0.373 ↓ 0.163 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3063\t Score = -22.619999999999997\n",
            "🚂 Episode 3063\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.359 ↑ 0.392 → 0.020 ◼ 0.144 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3064\t Score = -23.22\n",
            "🚂 Episode 3064\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.457 → 0.170 ◼ 0.149 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3065\t Score = -22.619999999999997\n",
            "🚂 Episode 3065\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.392 ← 0.092 ↑ 0.072 → 0.026 ◼ 0.392 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3066\t Score = -23.22\n",
            "🚂 Episode 3066\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.074 → 0.032 ◼ 0.638 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3067\t Score = -23.22\n",
            "🚂 Episode 3067\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.128 ↑ 0.181 → 0.032 ◼ 0.638 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3068\t Score = 8.79\n",
            "🚂 Episode 3068\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3069\t Score = -23.22\n",
            "🚂 Episode 3069\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.117 → 0.032 ◼ 0.638 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3070\t Score = -23.22\n",
            "🚂 Episode 3070\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.053 ↑ 0.702 → 0.053 ◼ 0.149 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3071\t Score = -23.22\n",
            "🚂 Episode 3071\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.245 → 0.213 ◼ 0.138 ↓ 0.191 \t Metric 0.397 \n",
            "Episode Nr. 3072\t Score = -23.22\n",
            "🚂 Episode 3072\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.394 → 0.340 ◼ 0.128 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3073\t Score = 8.79\n",
            "🚂 Episode 3073\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3074\t Score = -23.22\n",
            "🚂 Episode 3074\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.223 ↑ 0.096 → 0.447 ◼ 0.128 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3075\t Score = -22.619999999999997\n",
            "🚂 Episode 3075\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.144 ↑ 0.660 → 0.020 ◼ 0.013 ↓ 0.072 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3076\t Score = -22.619999999999997\n",
            "🚂 Episode 3076\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.176 ↑ 0.386 → 0.026 ◼ 0.261 ↓ 0.065 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3077\t Score = -22.619999999999997\n",
            "🚂 Episode 3077\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.124 ↑ 0.268 → 0.111 ◼ 0.359 ↓ 0.131 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3078\t Score = -22.619999999999997\n",
            "🚂 Episode 3078\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.157 ↑ 0.569 → 0.092 ◼ 0.124 ↓ 0.052 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3079\t Score = -23.22\n",
            "🚂 Episode 3079\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.043 ↑ 0.819 → 0.021 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3080\t Score = -23.22\n",
            "🚂 Episode 3080\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.149 ↑ 0.138 → 0.638 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3081\t Score = -23.22\n",
            "🚂 Episode 3081\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.202 ↑ 0.053 → 0.500 ◼ 0.011 ↓ 0.181 \t Metric 0.397 \n",
            "Episode Nr. 3082\t Score = -23.22\n",
            "🚂 Episode 3082\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.468 ← 0.202 ↑ 0.096 → 0.032 ◼ 0.011 ↓ 0.191 \t Metric 0.397 \n",
            "Episode Nr. 3083\t Score = -23.22\n",
            "🚂 Episode 3083\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.255 ↑ 0.202 → 0.362 ◼ 0.032 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 3084\t Score = -23.22\n",
            "🚂 Episode 3084\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.681 ← 0.106 ↑ 0.160 → 0.032 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3085\t Score = -22.619999999999997\n",
            "🚂 Episode 3085\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.248 ← 0.170 ↑ 0.157 → 0.039 ◼ 0.268 ↓ 0.118 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3086\t Score = -23.22\n",
            "🚂 Episode 3086\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.415 → 0.085 ◼ 0.064 ↓ 0.245 \t Metric 0.397 \n",
            "Episode Nr. 3087\t Score = -22.619999999999997\n",
            "🚂 Episode 3087\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.392 ↑ 0.353 → 0.190 ◼ 0.013 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3088\t Score = 8.79\n",
            "🚂 Episode 3088\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3089\t Score = -23.22\n",
            "🚂 Episode 3089\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.074 ↑ 0.128 → 0.660 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3090\t Score = -23.22\n",
            "🚂 Episode 3090\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.074 → 0.660 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3091\t Score = -23.22\n",
            "🚂 Episode 3091\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.106 → 0.351 ◼ 0.011 ↓ 0.319 \t Metric 0.397 \n",
            "Episode Nr. 3092\t Score = 10.11\n",
            "🚂 Episode 3092\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.014 ↑ 0.914 → 0.014 ◼ 0.014 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3093\t Score = -23.520000000000003\n",
            "🚂 Episode 3093\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.333 ↑ 0.167 → 0.281 ◼ 0.021 ↓ 0.188 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3094\t Score = -22.619999999999997\n",
            "🚂 Episode 3094\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.059 ← 0.072 ↑ 0.020 → 0.026 ◼ 0.157 ↓ 0.667 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3095\t Score = -45.01999999999994\n",
            "🚂 Episode 3095\t 🏆 Score: -0.060 Avg: -0.026\t 💯 Done: 0.00% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.004 ↑ 0.038 → 0.023 ◼ 0.011 ↓ 0.917 \t Metric 0.39749999999999996 \n",
            "Episode Nr. 3096\t Score = 10.11\n",
            "🚂 Episode 3096\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.014 ↑ 0.214 → 0.229 ◼ 0.457 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3097\t Score = -22.619999999999997\n",
            "🚂 Episode 3097\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.137 ↑ 0.092 → 0.072 ◼ 0.092 ↓ 0.595 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3098\t Score = -22.619999999999997\n",
            "🚂 Episode 3098\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.059 ← 0.020 ↑ 0.105 → 0.020 ◼ 0.771 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3099\t Score = -23.22\n",
            "🚂 Episode 3099\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.053 ↑ 0.255 → 0.032 ◼ 0.638 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3100\t Score = -23.520000000000003\n",
            "🚂 Episode 3100\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.625 ↑ 0.135 → 0.042 ◼ 0.021 ↓ 0.167 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3101\t Score = -22.619999999999997\n",
            "🚂 Episode 3101\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.327 ↑ 0.379 → 0.078 ◼ 0.092 ↓ 0.118 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3102\t Score = -22.619999999999997\n",
            "🚂 Episode 3102\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.379 ↑ 0.412 → 0.092 ◼ 0.007 ↓ 0.105 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3103\t Score = -23.22\n",
            "🚂 Episode 3103\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.213 ↑ 0.074 → 0.277 ◼ 0.128 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 3104\t Score = -23.22\n",
            "🚂 Episode 3104\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.085 → 0.436 ◼ 0.032 ↓ 0.234 \t Metric 0.397 \n",
            "Episode Nr. 3105\t Score = -22.619999999999997\n",
            "🚂 Episode 3105\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.124 ↑ 0.059 → 0.033 ◼ 0.758 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3106\t Score = -23.22\n",
            "🚂 Episode 3106\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.053 ↑ 0.287 → 0.032 ◼ 0.468 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3107\t Score = 10.11\n",
            "🚂 Episode 3107\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.014 ↑ 0.257 → 0.514 ◼ 0.143 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3108\t Score = -23.22\n",
            "🚂 Episode 3108\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.170 → 0.032 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3109\t Score = 8.349999999999998\n",
            "🚂 Episode 3109\t 🏆 Score: 0.011 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4275 \n",
            "Episode Nr. 3110\t Score = -22.619999999999997\n",
            "🚂 Episode 3110\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.046 ↑ 0.366 → 0.183 ◼ 0.281 ↓ 0.105 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3111\t Score = -23.22\n",
            "🚂 Episode 3111\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.532 ↑ 0.191 → 0.043 ◼ 0.117 ↓ 0.106 \t Metric 0.397 \n",
            "Episode Nr. 3112\t Score = -22.619999999999997\n",
            "🚂 Episode 3112\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.405 ↑ 0.157 → 0.026 ◼ 0.392 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3113\t Score = -23.22\n",
            "🚂 Episode 3113\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.287 ↑ 0.128 → 0.032 ◼ 0.372 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 3114\t Score = -23.22\n",
            "🚂 Episode 3114\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.181 ↑ 0.149 → 0.053 ◼ 0.468 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3115\t Score = -22.619999999999997\n",
            "🚂 Episode 3115\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.190 ← 0.137 ↑ 0.405 → 0.078 ◼ 0.124 ↓ 0.065 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3116\t Score = -23.22\n",
            "🚂 Episode 3116\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.213 ↑ 0.160 → 0.330 ◼ 0.021 ↓ 0.245 \t Metric 0.397 \n",
            "Episode Nr. 3117\t Score = -23.22\n",
            "🚂 Episode 3117\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.213 ↑ 0.074 → 0.032 ◼ 0.628 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3118\t Score = -23.22\n",
            "🚂 Episode 3118\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.202 ↑ 0.117 → 0.309 ◼ 0.011 ↓ 0.340 \t Metric 0.397 \n",
            "Episode Nr. 3119\t Score = -23.22\n",
            "🚂 Episode 3119\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.053 ↑ 0.234 → 0.032 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3120\t Score = -23.22\n",
            "🚂 Episode 3120\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.053 ↑ 0.223 → 0.032 ◼ 0.638 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3121\t Score = -23.22\n",
            "🚂 Episode 3121\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.149 ↑ 0.149 → 0.043 ◼ 0.606 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3122\t Score = -22.619999999999997\n",
            "🚂 Episode 3122\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.150 ↑ 0.144 → 0.150 ◼ 0.288 ↓ 0.242 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3123\t Score = -23.22\n",
            "🚂 Episode 3123\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.181 ↑ 0.362 → 0.351 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 3124\t Score = -23.22\n",
            "🚂 Episode 3124\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.202 ↑ 0.074 → 0.032 ◼ 0.617 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3125\t Score = -23.22\n",
            "🚂 Episode 3125\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.149 ↑ 0.128 → 0.043 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3126\t Score = 10.11\n",
            "🚂 Episode 3126\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.229 → 0.614 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3127\t Score = -23.22\n",
            "🚂 Episode 3127\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.053 ↑ 0.234 → 0.043 ◼ 0.628 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3128\t Score = -22.619999999999997\n",
            "🚂 Episode 3128\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.477 ↑ 0.222 → 0.085 ◼ 0.007 ↓ 0.176 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3129\t Score = -23.22\n",
            "🚂 Episode 3129\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.223 ↑ 0.138 → 0.266 ◼ 0.021 ↓ 0.330 \t Metric 0.397 \n",
            "Episode Nr. 3130\t Score = -23.22\n",
            "🚂 Episode 3130\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.128 ↑ 0.255 → 0.266 ◼ 0.011 ↓ 0.319 \t Metric 0.397 \n",
            "Episode Nr. 3131\t Score = -22.619999999999997\n",
            "🚂 Episode 3131\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.131 ↑ 0.111 → 0.150 ◼ 0.268 ↓ 0.307 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3132\t Score = -22.619999999999997\n",
            "🚂 Episode 3132\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.150 ↑ 0.144 → 0.150 ◼ 0.288 ↓ 0.242 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3133\t Score = -23.22\n",
            "🚂 Episode 3133\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.043 ↑ 0.245 → 0.032 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3134\t Score = -23.22\n",
            "🚂 Episode 3134\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.362 ↑ 0.436 → 0.043 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3135\t Score = -23.22\n",
            "🚂 Episode 3135\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.096 ↑ 0.553 → 0.287 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3136\t Score = -23.22\n",
            "🚂 Episode 3136\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.223 ↑ 0.096 → 0.255 ◼ 0.128 ↓ 0.277 \t Metric 0.397 \n",
            "Episode Nr. 3137\t Score = -23.22\n",
            "🚂 Episode 3137\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.277 ← 0.383 ↑ 0.181 → 0.043 ◼ 0.011 ↓ 0.106 \t Metric 0.397 \n",
            "Episode Nr. 3138\t Score = -22.619999999999997\n",
            "🚂 Episode 3138\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.261 ← 0.046 ↑ 0.301 → 0.150 ◼ 0.007 ↓ 0.235 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3139\t Score = -23.22\n",
            "🚂 Episode 3139\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.202 ↑ 0.117 → 0.309 ◼ 0.011 ↓ 0.340 \t Metric 0.397 \n",
            "Episode Nr. 3140\t Score = -23.22\n",
            "🚂 Episode 3140\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.106 ↑ 0.660 → 0.053 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3141\t Score = -22.619999999999997\n",
            "🚂 Episode 3141\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.183 ← 0.261 ↑ 0.183 → 0.144 ◼ 0.007 ↓ 0.222 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3142\t Score = -23.22\n",
            "🚂 Episode 3142\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.223 ↑ 0.096 → 0.362 ◼ 0.011 ↓ 0.277 \t Metric 0.397 \n",
            "Episode Nr. 3143\t Score = -23.22\n",
            "🚂 Episode 3143\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.170 ↑ 0.117 → 0.032 ◼ 0.638 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3144\t Score = -23.22\n",
            "🚂 Episode 3144\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.149 ↑ 0.255 → 0.117 ◼ 0.149 ↓ 0.309 \t Metric 0.397 \n",
            "Episode Nr. 3145\t Score = -22.619999999999997\n",
            "🚂 Episode 3145\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.484 ↑ 0.065 → 0.020 ◼ 0.392 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3146\t Score = -22.91\n",
            "🚂 Episode 3146\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.282 ← 0.192 ↑ 0.147 → 0.077 ◼ 0.013 ↓ 0.288 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 3147\t Score = -23.22\n",
            "🚂 Episode 3147\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.404 ↑ 0.532 → 0.032 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3148\t Score = 10.11\n",
            "🚂 Episode 3148\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.014 ↑ 0.600 → 0.300 ◼ 0.014 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3149\t Score = -22.619999999999997\n",
            "🚂 Episode 3149\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.118 ↑ 0.026 → 0.614 ◼ 0.007 ↓ 0.150 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3150\t Score = -22.619999999999997\n",
            "🚂 Episode 3150\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.170 ↑ 0.052 → 0.412 ◼ 0.314 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3151\t Score = -22.619999999999997\n",
            "🚂 Episode 3151\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.046 ↑ 0.137 → 0.392 ◼ 0.392 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3152\t Score = 10.11\n",
            "🚂 Episode 3152\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.186 → 0.071 ◼ 0.629 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3153\t Score = 8.79\n",
            "🚂 Episode 3153\t 🏆 Score: 0.012 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3154\t Score = -23.22\n",
            "🚂 Episode 3154\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.691 ↑ 0.074 → 0.032 ◼ 0.011 ↓ 0.160 \t Metric 0.397 \n",
            "Episode Nr. 3155\t Score = -23.22\n",
            "🚂 Episode 3155\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.170 ↑ 0.117 → 0.532 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 3156\t Score = 10.11\n",
            "🚂 Episode 3156\t 🏆 Score: 0.013 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.229 → 0.229 ◼ 0.429 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3157\t Score = -23.22\n",
            "🚂 Episode 3157\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.245 ↑ 0.085 → 0.032 ◼ 0.011 ↓ 0.532 \t Metric 0.397 \n",
            "Episode Nr. 3158\t Score = -23.22\n",
            "🚂 Episode 3158\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.234 → 0.394 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 3159\t Score = -23.22\n",
            "🚂 Episode 3159\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.149 ↑ 0.787 → 0.032 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3160\t Score = -23.22\n",
            "🚂 Episode 3160\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.170 ↑ 0.415 → 0.213 ◼ 0.011 ↓ 0.170 \t Metric 0.397 \n",
            "Episode Nr. 3161\t Score = -23.22\n",
            "🚂 Episode 3161\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.521 ← 0.202 ↑ 0.053 → 0.043 ◼ 0.011 ↓ 0.170 \t Metric 0.397 \n",
            "Episode Nr. 3162\t Score = 10.11\n",
            "🚂 Episode 3162\t 🏆 Score: 0.013 Avg: -0.025\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.200 ↑ 0.186 → 0.129 ◼ 0.371 ↓ 0.086 \t Metric 0.5925 \n",
            "Episode Nr. 3163\t Score = -22.619999999999997\n",
            "🚂 Episode 3163\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.327 ← 0.124 ↑ 0.065 → 0.026 ◼ 0.379 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3164\t Score = -22.619999999999997\n",
            "🚂 Episode 3164\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.320 ← 0.124 ↑ 0.052 → 0.026 ◼ 0.392 ↓ 0.085 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3165\t Score = -22.619999999999997\n",
            "🚂 Episode 3165\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.288 ← 0.078 ↑ 0.105 → 0.033 ◼ 0.392 ↓ 0.105 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3166\t Score = -22.619999999999997\n",
            "🚂 Episode 3166\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.078 ↑ 0.052 → 0.052 ◼ 0.778 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3167\t Score = -22.619999999999997\n",
            "🚂 Episode 3167\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.085 ↑ 0.092 → 0.020 ◼ 0.758 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3168\t Score = 10.11\n",
            "🚂 Episode 3168\t 🏆 Score: 0.013 Avg: -0.025\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.414 → 0.071 ◼ 0.429 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3169\t Score = 8.496666666666664\n",
            "🚂 Episode 3169\t 🏆 Score: 0.011 Avg: -0.025\t 💯 Done: 33.33% Avg: 33.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.42714285714285716 \n",
            "Episode Nr. 3170\t Score = 10.11\n",
            "🚂 Episode 3170\t 🏆 Score: 0.013 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.386 → 0.086 ◼ 0.429 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3171\t Score = -22.619999999999997\n",
            "🚂 Episode 3171\t 🏆 Score: -0.030 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.386 ↑ 0.196 → 0.033 ◼ 0.118 ↓ 0.248 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3172\t Score = -23.22\n",
            "🚂 Episode 3172\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 33.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.585 ↑ 0.245 → 0.032 ◼ 0.011 ↓ 0.106 \t Metric 0.397 \n",
            "Episode Nr. 3173\t Score = -23.22\n",
            "🚂 Episode 3173\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 33.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.511 ↑ 0.309 → 0.032 ◼ 0.011 ↓ 0.117 \t Metric 0.397 \n",
            "Episode Nr. 3174\t Score = 10.11\n",
            "🚂 Episode 3174\t 🏆 Score: 0.013 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.214 → 0.629 ◼ 0.043 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3175\t Score = -22.619999999999997\n",
            "🚂 Episode 3175\t 🏆 Score: -0.030 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.346 ↑ 0.320 → 0.144 ◼ 0.013 ↓ 0.150 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3176\t Score = 8.79\n",
            "🚂 Episode 3176\t 🏆 Score: 0.012 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3177\t Score = -23.22\n",
            "🚂 Episode 3177\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.500 ↑ 0.128 → 0.032 ◼ 0.191 ↓ 0.106 \t Metric 0.397 \n",
            "Episode Nr. 3178\t Score = -22.619999999999997\n",
            "🚂 Episode 3178\t 🏆 Score: -0.030 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.046 ← 0.105 ↑ 0.222 → 0.065 ◼ 0.307 ↓ 0.255 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3179\t Score = -23.22\n",
            "🚂 Episode 3179\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.202 ↑ 0.085 → 0.032 ◼ 0.511 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3180\t Score = -23.520000000000003\n",
            "🚂 Episode 3180\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.042 ← 0.177 ↑ 0.083 → 0.052 ◼ 0.625 ↓ 0.021 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3181\t Score = -22.619999999999997\n",
            "🚂 Episode 3181\t 🏆 Score: -0.030 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.503 ↑ 0.059 → 0.020 ◼ 0.379 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3182\t Score = -23.22\n",
            "🚂 Episode 3182\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.096 ↑ 0.213 → 0.277 ◼ 0.117 ↓ 0.245 \t Metric 0.397 \n",
            "Episode Nr. 3183\t Score = -23.22\n",
            "🚂 Episode 3183\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.074 ↑ 0.298 → 0.404 ◼ 0.011 ↓ 0.181 \t Metric 0.397 \n",
            "Episode Nr. 3184\t Score = -22.619999999999997\n",
            "🚂 Episode 3184\t 🏆 Score: -0.030 Avg: -0.024\t 💯 Done: 33.33% Avg: 33.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.484 ↑ 0.059 → 0.020 ◼ 0.386 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3185\t Score = -22.619999999999997\n",
            "🚂 Episode 3185\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 33.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.065 ↑ 0.261 → 0.150 ◼ 0.196 ↓ 0.242 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3186\t Score = -22.619999999999997\n",
            "🚂 Episode 3186\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 33.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.405 ↑ 0.203 → 0.092 ◼ 0.052 ↓ 0.157 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3187\t Score = -42.53999999999999\n",
            "🚂 Episode 3187\t 🏆 Score: -0.057 Avg: -0.025\t 💯 Done: 0.00% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.445 ← 0.138 ↑ 0.021 → 0.014 ◼ 0.369 ↓ 0.014 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 3188\t Score = -23.22\n",
            "🚂 Episode 3188\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.234 ↑ 0.266 → 0.170 ◼ 0.011 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 3189\t Score = -23.22\n",
            "🚂 Episode 3189\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.085 ↑ 0.287 → 0.564 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3190\t Score = -23.22\n",
            "🚂 Episode 3190\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.213 ↑ 0.085 → 0.638 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3191\t Score = -23.22\n",
            "🚂 Episode 3191\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.117 ↑ 0.181 → 0.234 ◼ 0.415 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3192\t Score = -22.619999999999997\n",
            "🚂 Episode 3192\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.105 ← 0.412 ↑ 0.222 → 0.020 ◼ 0.026 ↓ 0.216 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3193\t Score = -23.22\n",
            "🚂 Episode 3193\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.372 ↑ 0.543 → 0.032 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3194\t Score = -22.619999999999997\n",
            "🚂 Episode 3194\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.209 ↑ 0.444 → 0.020 ◼ 0.092 ↓ 0.144 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3195\t Score = -22.619999999999997\n",
            "🚂 Episode 3195\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.137 ← 0.098 ↑ 0.451 → 0.046 ◼ 0.007 ↓ 0.261 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3196\t Score = -23.22\n",
            "🚂 Episode 3196\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.223 ↑ 0.074 → 0.362 ◼ 0.011 ↓ 0.287 \t Metric 0.397 \n",
            "Episode Nr. 3197\t Score = -23.22\n",
            "🚂 Episode 3197\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.574 ↑ 0.234 → 0.117 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3198\t Score = 8.79\n",
            "🚂 Episode 3198\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3199\t Score = -22.619999999999997\n",
            "🚂 Episode 3199\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.405 ← 0.078 ↑ 0.412 → 0.072 ◼ 0.007 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3200\t Score = -23.22\n",
            "🚂 Episode 3200\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.340 ↑ 0.202 → 0.032 ◼ 0.383 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3201\t Score = -23.22\n",
            "🚂 Episode 3201\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.106 ↑ 0.170 → 0.032 ◼ 0.628 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3202\t Score = 10.11\n",
            "🚂 Episode 3202\t 🏆 Score: 0.013 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.243 → 0.629 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3203\t Score = -23.22\n",
            "🚂 Episode 3203\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.489 ↑ 0.298 → 0.053 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3204\t Score = -23.22\n",
            "🚂 Episode 3204\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.128 ↑ 0.670 → 0.032 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3205\t Score = -22.619999999999997\n",
            "🚂 Episode 3205\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.046 ← 0.203 ↑ 0.438 → 0.052 ◼ 0.078 ↓ 0.183 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3206\t Score = 10.11\n",
            "🚂 Episode 3206\t 🏆 Score: 0.013 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.086 ← 0.014 ↑ 0.214 → 0.600 ◼ 0.071 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3207\t Score = -22.619999999999997\n",
            "🚂 Episode 3207\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.353 ← 0.131 ↑ 0.131 → 0.065 ◼ 0.157 ↓ 0.163 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3208\t Score = -22.619999999999997\n",
            "🚂 Episode 3208\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.418 ↑ 0.216 → 0.020 ◼ 0.085 ↓ 0.222 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3209\t Score = 8.79\n",
            "🚂 Episode 3209\t 🏆 Score: 0.012 Avg: -0.024\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3210\t Score = -23.22\n",
            "🚂 Episode 3210\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.202 ← 0.096 ↑ 0.532 → 0.128 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3211\t Score = 10.11\n",
            "🚂 Episode 3211\t 🏆 Score: 0.013 Avg: -0.024\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.071 ← 0.029 ↑ 0.186 → 0.629 ◼ 0.071 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3212\t Score = -22.619999999999997\n",
            "🚂 Episode 3212\t 🏆 Score: -0.030 Avg: -0.024\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.052 ↑ 0.275 → 0.294 ◼ 0.105 ↓ 0.242 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3213\t Score = 10.11\n",
            "🚂 Episode 3213\t 🏆 Score: 0.013 Avg: -0.024\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.071 ← 0.043 ↑ 0.414 → 0.157 ◼ 0.300 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3214\t Score = 8.643333333333333\n",
            "🚂 Episode 3214\t 🏆 Score: 0.012 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3215\t Score = -22.619999999999997\n",
            "🚂 Episode 3215\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.248 ← 0.248 ↑ 0.222 → 0.020 ◼ 0.007 ↓ 0.255 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3216\t Score = -23.22\n",
            "🚂 Episode 3216\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.713 ← 0.149 ↑ 0.085 → 0.032 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3217\t Score = -23.22\n",
            "🚂 Episode 3217\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.649 ↑ 0.128 → 0.032 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3218\t Score = 10.11\n",
            "🚂 Episode 3218\t 🏆 Score: 0.013 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.357 → 0.529 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3219\t Score = 10.11\n",
            "🚂 Episode 3219\t 🏆 Score: 0.013 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.257 → 0.614 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3220\t Score = -22.619999999999997\n",
            "🚂 Episode 3220\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.301 ↑ 0.216 → 0.111 ◼ 0.170 ↓ 0.190 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3221\t Score = -23.22\n",
            "🚂 Episode 3221\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.596 ↑ 0.074 → 0.032 ◼ 0.053 ↓ 0.223 \t Metric 0.397 \n",
            "Episode Nr. 3222\t Score = -23.22\n",
            "🚂 Episode 3222\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.287 ↑ 0.457 → 0.032 ◼ 0.074 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3223\t Score = 8.79\n",
            "🚂 Episode 3223\t 🏆 Score: 0.012 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3224\t Score = -22.619999999999997\n",
            "🚂 Episode 3224\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.065 ← 0.105 ↑ 0.510 → 0.039 ◼ 0.046 ↓ 0.235 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3225\t Score = -23.22\n",
            "🚂 Episode 3225\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.149 ↑ 0.138 → 0.032 ◼ 0.011 ↓ 0.638 \t Metric 0.397 \n",
            "Episode Nr. 3226\t Score = -23.22\n",
            "🚂 Episode 3226\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.170 ↑ 0.074 → 0.032 ◼ 0.128 ↓ 0.521 \t Metric 0.397 \n",
            "Episode Nr. 3227\t Score = 8.79\n",
            "🚂 Episode 3227\t 🏆 Score: 0.012 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3228\t Score = -23.22\n",
            "🚂 Episode 3228\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.160 ↑ 0.191 → 0.043 ◼ 0.457 ↓ 0.117 \t Metric 0.397 \n",
            "Episode Nr. 3229\t Score = -23.22\n",
            "🚂 Episode 3229\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.149 ↑ 0.128 → 0.032 ◼ 0.011 ↓ 0.649 \t Metric 0.397 \n",
            "Episode Nr. 3230\t Score = -22.619999999999997\n",
            "🚂 Episode 3230\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.340 ↑ 0.379 → 0.026 ◼ 0.013 ↓ 0.229 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3231\t Score = -22.619999999999997\n",
            "🚂 Episode 3231\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.150 ↑ 0.235 → 0.216 ◼ 0.190 ↓ 0.190 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3232\t Score = -23.22\n",
            "🚂 Episode 3232\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.074 ↑ 0.436 → 0.447 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3233\t Score = -22.619999999999997\n",
            "🚂 Episode 3233\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.706 ↑ 0.052 → 0.020 ◼ 0.007 ↓ 0.196 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3234\t Score = 8.79\n",
            "🚂 Episode 3234\t 🏆 Score: 0.012 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3235\t Score = -23.22\n",
            "🚂 Episode 3235\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.160 ↑ 0.340 → 0.447 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3236\t Score = -22.619999999999997\n",
            "🚂 Episode 3236\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.229 ← 0.353 ↑ 0.072 → 0.092 ◼ 0.092 ↓ 0.163 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3237\t Score = -23.819999999999997\n",
            "🚂 Episode 3237\t 🏆 Score: -0.032 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.031 ← 0.122 ↑ 0.133 → 0.327 ◼ 0.163 ↓ 0.224 \t Metric 0.396 \n",
            "Episode Nr. 3238\t Score = -22.619999999999997\n",
            "🚂 Episode 3238\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.118 ↑ 0.235 → 0.137 ◼ 0.209 ↓ 0.209 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3239\t Score = -23.22\n",
            "🚂 Episode 3239\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.170 ↑ 0.213 → 0.500 ◼ 0.011 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 3240\t Score = -23.22\n",
            "🚂 Episode 3240\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.096 ↑ 0.415 → 0.415 ◼ 0.032 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3241\t Score = -23.22\n",
            "🚂 Episode 3241\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.223 ↑ 0.223 → 0.404 ◼ 0.106 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3242\t Score = 8.79\n",
            "🚂 Episode 3242\t 🏆 Score: 0.012 Avg: -0.023\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3243\t Score = -23.22\n",
            "🚂 Episode 3243\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.064 ↑ 0.415 → 0.191 ◼ 0.032 ↓ 0.277 \t Metric 0.397 \n",
            "Episode Nr. 3244\t Score = -23.22\n",
            "🚂 Episode 3244\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.532 ↑ 0.266 → 0.117 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3245\t Score = -23.22\n",
            "🚂 Episode 3245\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.160 ↑ 0.191 → 0.543 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 3246\t Score = -23.22\n",
            "🚂 Episode 3246\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.170 ↑ 0.202 → 0.457 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3247\t Score = 8.79\n",
            "🚂 Episode 3247\t 🏆 Score: 0.012 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3248\t Score = -23.22\n",
            "🚂 Episode 3248\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.074 ↑ 0.277 → 0.468 ◼ 0.011 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 3249\t Score = -23.22\n",
            "🚂 Episode 3249\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.691 ↑ 0.117 → 0.128 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3250\t Score = -23.520000000000003\n",
            "🚂 Episode 3250\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.052 ← 0.188 ↑ 0.083 → 0.552 ◼ 0.031 ↓ 0.094 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3251\t Score = 8.643333333333333\n",
            "🚂 Episode 3251\t 🏆 Score: 0.012 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3252\t Score = 10.11\n",
            "🚂 Episode 3252\t 🏆 Score: 0.013 Avg: -0.022\t 💯 Done: 33.33% Avg: 33.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.257 → 0.271 ◼ 0.371 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3253\t Score = -22.619999999999997\n",
            "🚂 Episode 3253\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.359 ↑ 0.314 → 0.026 ◼ 0.078 ↓ 0.190 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3254\t Score = 10.11\n",
            "🚂 Episode 3254\t 🏆 Score: 0.013 Avg: -0.022\t 💯 Done: 33.33% Avg: 33.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.071 ← 0.014 ↑ 0.214 → 0.214 ◼ 0.429 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3255\t Score = -35.81999999999999\n",
            "🚂 Episode 3255\t 🏆 Score: -0.048 Avg: -0.022\t 💯 Done: 33.33% Avg: 33.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.388 ← 0.185 ↑ 0.124 → 0.275 ◼ 0.017 ↓ 0.011 \t Metric 0.376 \n",
            "Episode Nr. 3256\t Score = -24.72\n",
            "🚂 Episode 3256\t 🏆 Score: -0.033 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.039 ↑ 0.127 → 0.775 ◼ 0.020 ↓ 0.020 \t Metric 0.39449999999999996 \n",
            "Episode Nr. 3257\t Score = -22.619999999999997\n",
            "🚂 Episode 3257\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.183 ← 0.203 ↑ 0.255 → 0.033 ◼ 0.078 ↓ 0.248 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3258\t Score = -22.619999999999997\n",
            "🚂 Episode 3258\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.150 ← 0.288 ↑ 0.261 → 0.026 ◼ 0.052 ↓ 0.222 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3259\t Score = -23.22\n",
            "🚂 Episode 3259\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.170 ↑ 0.106 → 0.032 ◼ 0.298 ↓ 0.351 \t Metric 0.397 \n",
            "Episode Nr. 3260\t Score = -22.619999999999997\n",
            "🚂 Episode 3260\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.052 ← 0.052 ↑ 0.203 → 0.294 ◼ 0.111 ↓ 0.288 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3261\t Score = -22.619999999999997\n",
            "🚂 Episode 3261\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.471 ↑ 0.072 → 0.020 ◼ 0.007 ↓ 0.405 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3262\t Score = -22.619999999999997\n",
            "🚂 Episode 3262\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.111 ← 0.431 ↑ 0.078 → 0.020 ◼ 0.007 ↓ 0.353 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3263\t Score = 8.79\n",
            "🚂 Episode 3263\t 🏆 Score: 0.012 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3264\t Score = 8.79\n",
            "🚂 Episode 3264\t 🏆 Score: 0.012 Avg: -0.022\t 💯 Done: 33.33% Avg: 33.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3265\t Score = -22.619999999999997\n",
            "🚂 Episode 3265\t 🏆 Score: -0.030 Avg: -0.022\t 💯 Done: 33.33% Avg: 33.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.320 ← 0.085 ↑ 0.052 → 0.248 ◼ 0.157 ↓ 0.137 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3266\t Score = -23.22\n",
            "🚂 Episode 3266\t 🏆 Score: -0.031 Avg: -0.022\t 💯 Done: 33.33% Avg: 33.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.521 ← 0.064 ↑ 0.202 → 0.043 ◼ 0.011 ↓ 0.160 \t Metric 0.397 \n",
            "Episode Nr. 3267\t Score = -22.619999999999997\n",
            "🚂 Episode 3267\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 33.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.340 ← 0.039 ↑ 0.092 → 0.052 ◼ 0.392 ↓ 0.085 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3268\t Score = 8.79\n",
            "🚂 Episode 3268\t 🏆 Score: 0.012 Avg: -0.022\t 💯 Done: 33.33% Avg: 33.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3269\t Score = 8.79\n",
            "🚂 Episode 3269\t 🏆 Score: 0.012 Avg: -0.022\t 💯 Done: 33.33% Avg: 33.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3270\t Score = 10.11\n",
            "🚂 Episode 3270\t 🏆 Score: 0.013 Avg: -0.022\t 💯 Done: 33.33% Avg: 33.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.114 ↑ 0.214 → 0.243 ◼ 0.357 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3271\t Score = 8.79\n",
            "🚂 Episode 3271\t 🏆 Score: 0.012 Avg: -0.021\t 💯 Done: 33.33% Avg: 33.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3272\t Score = -23.22\n",
            "🚂 Episode 3272\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 33.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.032 ↑ 0.894 → 0.021 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3273\t Score = -23.22\n",
            "🚂 Episode 3273\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 33.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.053 → 0.649 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 3274\t Score = 10.11\n",
            "🚂 Episode 3274\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 33.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.171 → 0.600 ◼ 0.043 ↓ 0.129 \t Metric 0.5925 \n",
            "Episode Nr. 3275\t Score = -42.53999999999999\n",
            "🚂 Episode 3275\t 🏆 Score: -0.057 Avg: -0.021\t 💯 Done: 0.00% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.511 ← 0.004 ↑ 0.016 → 0.012 ◼ 0.452 ↓ 0.006 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 3276\t Score = 10.11\n",
            "🚂 Episode 3276\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.200 → 0.057 ◼ 0.629 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3277\t Score = 8.79\n",
            "🚂 Episode 3277\t 🏆 Score: 0.012 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3278\t Score = -23.22\n",
            "🚂 Episode 3278\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.053 ↑ 0.160 → 0.191 ◼ 0.053 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3279\t Score = -20.436666666666664\n",
            "🚂 Episode 3279\t 🏆 Score: -0.027 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.066 ← 0.618 ↑ 0.171 → 0.118 ◼ 0.013 ↓ 0.013 \t Metric 0.397 \n",
            "Episode Nr. 3280\t Score = 8.79\n",
            "🚂 Episode 3280\t 🏆 Score: 0.012 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3281\t Score = -22.619999999999997\n",
            "🚂 Episode 3281\t 🏆 Score: -0.030 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.314 ← 0.098 ↑ 0.137 → 0.078 ◼ 0.359 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3282\t Score = -22.619999999999997\n",
            "🚂 Episode 3282\t 🏆 Score: -0.030 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.281 ← 0.111 ↑ 0.092 → 0.124 ◼ 0.346 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3283\t Score = -22.619999999999997\n",
            "🚂 Episode 3283\t 🏆 Score: -0.030 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.314 ← 0.131 ↑ 0.072 → 0.137 ◼ 0.327 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3284\t Score = -22.91\n",
            "🚂 Episode 3284\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.474 ↑ 0.064 → 0.032 ◼ 0.397 ↓ 0.006 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 3285\t Score = -22.619999999999997\n",
            "🚂 Episode 3285\t 🏆 Score: -0.030 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.320 ← 0.052 ↑ 0.255 → 0.137 ◼ 0.092 ↓ 0.144 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3286\t Score = -23.22\n",
            "🚂 Episode 3286\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.170 ↑ 0.106 → 0.532 ◼ 0.053 ↓ 0.106 \t Metric 0.397 \n",
            "Episode Nr. 3287\t Score = -23.22\n",
            "🚂 Episode 3287\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.500 ← 0.106 ↑ 0.245 → 0.128 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3288\t Score = 8.496666666666664\n",
            "🚂 Episode 3288\t 🏆 Score: 0.011 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.42714285714285716 \n",
            "Episode Nr. 3289\t Score = -23.22\n",
            "🚂 Episode 3289\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.777 ↑ 0.106 → 0.053 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3290\t Score = -22.619999999999997\n",
            "🚂 Episode 3290\t 🏆 Score: -0.030 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.431 ↑ 0.131 → 0.026 ◼ 0.379 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3291\t Score = 10.11\n",
            "🚂 Episode 3291\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.229 → 0.614 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3292\t Score = 8.643333333333333\n",
            "🚂 Episode 3292\t 🏆 Score: 0.012 Avg: -0.020\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3293\t Score = -22.619999999999997\n",
            "🚂 Episode 3293\t 🏆 Score: -0.030 Avg: -0.021\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.150 ← 0.098 ↑ 0.490 → 0.137 ◼ 0.078 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3294\t Score = 10.11\n",
            "🚂 Episode 3294\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.071 ← 0.014 ↑ 0.243 → 0.329 ◼ 0.314 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3295\t Score = 8.79\n",
            "🚂 Episode 3295\t 🏆 Score: 0.012 Avg: -0.020\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3296\t Score = -22.619999999999997\n",
            "🚂 Episode 3296\t 🏆 Score: -0.030 Avg: -0.020\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.314 ← 0.085 ↑ 0.222 → 0.137 ◼ 0.078 ↓ 0.163 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3297\t Score = 8.643333333333333\n",
            "🚂 Episode 3297\t 🏆 Score: 0.012 Avg: -0.020\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3298\t Score = 10.11\n",
            "🚂 Episode 3298\t 🏆 Score: 0.013 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.257 → 0.286 ◼ 0.357 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3299\t Score = -23.22\n",
            "🚂 Episode 3299\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.117 ↑ 0.170 → 0.660 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3300\t Score = -22.619999999999997\n",
            "🚂 Episode 3300\t 🏆 Score: -0.030 Avg: -0.020\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.314 ← 0.085 ↑ 0.392 → 0.085 ◼ 0.078 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3301\t Score = -23.520000000000003\n",
            "🚂 Episode 3301\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.052 ← 0.667 ↑ 0.135 → 0.052 ◼ 0.021 ↓ 0.073 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3302\t Score = -23.22\n",
            "🚂 Episode 3302\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.681 ↑ 0.085 → 0.032 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 3303\t Score = 10.11\n",
            "🚂 Episode 3303\t 🏆 Score: 0.013 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.243 → 0.443 ◼ 0.214 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3304\t Score = -22.619999999999997\n",
            "🚂 Episode 3304\t 🏆 Score: -0.030 Avg: -0.020\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.314 ← 0.052 ↑ 0.340 → 0.092 ◼ 0.085 ↓ 0.118 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3305\t Score = 8.79\n",
            "🚂 Episode 3305\t 🏆 Score: 0.012 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3306\t Score = -22.619999999999997\n",
            "🚂 Episode 3306\t 🏆 Score: -0.030 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.327 ← 0.098 ↑ 0.111 → 0.111 ◼ 0.078 ↓ 0.275 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3307\t Score = -22.619999999999997\n",
            "🚂 Episode 3307\t 🏆 Score: -0.030 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.392 ← 0.131 ↑ 0.294 → 0.085 ◼ 0.007 ↓ 0.092 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3308\t Score = 10.11\n",
            "🚂 Episode 3308\t 🏆 Score: 0.013 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.214 → 0.357 ◼ 0.329 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3309\t Score = -23.22\n",
            "🚂 Episode 3309\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.340 ← 0.138 ↑ 0.191 → 0.287 ◼ 0.021 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3310\t Score = -22.91\n",
            "🚂 Episode 3310\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.269 ← 0.205 ↑ 0.237 → 0.058 ◼ 0.013 ↓ 0.218 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 3311\t Score = -22.619999999999997\n",
            "🚂 Episode 3311\t 🏆 Score: -0.030 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.157 ← 0.072 ↑ 0.320 → 0.098 ◼ 0.216 ↓ 0.137 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3312\t Score = 8.79\n",
            "🚂 Episode 3312\t 🏆 Score: 0.012 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3313\t Score = -20.436666666666664\n",
            "🚂 Episode 3313\t 🏆 Score: -0.027 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.066 ← 0.039 ↑ 0.184 → 0.092 ◼ 0.013 ↓ 0.605 \t Metric 0.397 \n",
            "Episode Nr. 3314\t Score = -20.436666666666664\n",
            "🚂 Episode 3314\t 🏆 Score: -0.027 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.066 ← 0.513 ↑ 0.197 → 0.066 ◼ 0.013 ↓ 0.145 \t Metric 0.397 \n",
            "Episode Nr. 3315\t Score = 10.11\n",
            "🚂 Episode 3315\t 🏆 Score: 0.013 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.257 → 0.614 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3316\t Score = -22.619999999999997\n",
            "🚂 Episode 3316\t 🏆 Score: -0.030 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.641 ↑ 0.052 → 0.020 ◼ 0.007 ↓ 0.261 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3317\t Score = -22.619999999999997\n",
            "🚂 Episode 3317\t 🏆 Score: -0.030 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.137 ↑ 0.510 → 0.039 ◼ 0.059 ↓ 0.235 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3318\t Score = 10.11\n",
            "🚂 Episode 3318\t 🏆 Score: 0.013 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.243 → 0.400 ◼ 0.257 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3319\t Score = -22.91\n",
            "🚂 Episode 3319\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.019 ← 0.051 ↑ 0.282 → 0.154 ◼ 0.276 ↓ 0.218 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 3320\t Score = 8.79\n",
            "🚂 Episode 3320\t 🏆 Score: 0.012 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3321\t Score = -22.619999999999997\n",
            "🚂 Episode 3321\t 🏆 Score: -0.030 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.392 ← 0.026 ↑ 0.288 → 0.092 ◼ 0.007 ↓ 0.196 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3322\t Score = -23.22\n",
            "🚂 Episode 3322\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.436 ← 0.202 ↑ 0.138 → 0.149 ◼ 0.053 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3323\t Score = -22.619999999999997\n",
            "🚂 Episode 3323\t 🏆 Score: -0.030 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.392 ↑ 0.405 → 0.046 ◼ 0.039 ↓ 0.085 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3324\t Score = 10.11\n",
            "🚂 Episode 3324\t 🏆 Score: 0.013 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.229 → 0.600 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3325\t Score = 10.11\n",
            "🚂 Episode 3325\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.243 → 0.214 ◼ 0.414 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3326\t Score = 8.643333333333333\n",
            "🚂 Episode 3326\t 🏆 Score: 0.012 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3327\t Score = -23.22\n",
            "🚂 Episode 3327\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.191 → 0.032 ◼ 0.011 ↓ 0.638 \t Metric 0.397 \n",
            "Episode Nr. 3328\t Score = -22.619999999999997\n",
            "🚂 Episode 3328\t 🏆 Score: -0.030 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.248 ↑ 0.118 → 0.209 ◼ 0.007 ↓ 0.412 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3329\t Score = 10.11\n",
            "🚂 Episode 3329\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.057 ↑ 0.186 → 0.614 ◼ 0.014 ↓ 0.100 \t Metric 0.5925 \n",
            "Episode Nr. 3330\t Score = -20.436666666666664\n",
            "🚂 Episode 3330\t 🏆 Score: -0.027 Avg: -0.018\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.276 ← 0.039 ↑ 0.184 → 0.434 ◼ 0.013 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3331\t Score = -42.53999999999999\n",
            "🚂 Episode 3331\t 🏆 Score: -0.057 Avg: -0.018\t 💯 Done: 0.00% Avg: 32.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.476 ← 0.115 ↑ 0.019 → 0.047 ◼ 0.342 ↓ 0.002 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 3332\t Score = -23.22\n",
            "🚂 Episode 3332\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.479 ← 0.160 ↑ 0.149 → 0.032 ◼ 0.011 ↓ 0.170 \t Metric 0.397 \n",
            "Episode Nr. 3333\t Score = 10.11\n",
            "🚂 Episode 3333\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.371 → 0.071 ◼ 0.457 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3334\t Score = -20.436666666666664\n",
            "🚂 Episode 3334\t 🏆 Score: -0.027 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.026 ↑ 0.211 → 0.697 ◼ 0.013 ↓ 0.026 \t Metric 0.397 \n",
            "Episode Nr. 3335\t Score = 10.11\n",
            "🚂 Episode 3335\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.157 ↑ 0.400 → 0.043 ◼ 0.314 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3336\t Score = -22.619999999999997\n",
            "🚂 Episode 3336\t 🏆 Score: -0.030 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.320 ← 0.085 ↑ 0.144 → 0.026 ◼ 0.118 ↓ 0.307 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3337\t Score = 8.79\n",
            "🚂 Episode 3337\t 🏆 Score: 0.012 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3338\t Score = -23.22\n",
            "🚂 Episode 3338\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.638 ↑ 0.117 → 0.053 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 3339\t Score = -23.22\n",
            "🚂 Episode 3339\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.309 ← 0.362 ↑ 0.117 → 0.053 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 3340\t Score = -23.22\n",
            "🚂 Episode 3340\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.564 ← 0.032 ↑ 0.181 → 0.043 ◼ 0.011 ↓ 0.170 \t Metric 0.397 \n",
            "Episode Nr. 3341\t Score = 10.11\n",
            "🚂 Episode 3341\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.214 ↑ 0.400 → 0.271 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3342\t Score = 10.11\n",
            "🚂 Episode 3342\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.400 ↑ 0.386 → 0.057 ◼ 0.071 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3343\t Score = -23.22\n",
            "🚂 Episode 3343\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.585 ↑ 0.138 → 0.234 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3344\t Score = -22.619999999999997\n",
            "🚂 Episode 3344\t 🏆 Score: -0.030 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.301 ← 0.092 ↑ 0.497 → 0.026 ◼ 0.007 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3345\t Score = -53.21999999999997\n",
            "🚂 Episode 3345\t 🏆 Score: -0.071 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.575 ← 0.058 ↑ 0.037 → 0.017 ◼ 0.007 ↓ 0.306 \t Metric 0.347 \n",
            "Episode Nr. 3346\t Score = -23.520000000000003\n",
            "🚂 Episode 3346\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.479 ← 0.177 ↑ 0.167 → 0.031 ◼ 0.021 ↓ 0.125 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3347\t Score = -23.22\n",
            "🚂 Episode 3347\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.787 ↑ 0.096 → 0.032 ◼ 0.032 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3348\t Score = -23.22\n",
            "🚂 Episode 3348\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.521 ↑ 0.149 → 0.043 ◼ 0.011 ↓ 0.255 \t Metric 0.397 \n",
            "Episode Nr. 3349\t Score = -23.22\n",
            "🚂 Episode 3349\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.383 ↑ 0.245 → 0.032 ◼ 0.021 ↓ 0.277 \t Metric 0.397 \n",
            "Episode Nr. 3350\t Score = 10.11\n",
            "🚂 Episode 3350\t 🏆 Score: 0.013 Avg: -0.019\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.429 ↑ 0.343 → 0.100 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3351\t Score = 8.79\n",
            "🚂 Episode 3351\t 🏆 Score: 0.012 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3352\t Score = 10.11\n",
            "🚂 Episode 3352\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.057 ↑ 0.200 → 0.600 ◼ 0.043 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3353\t Score = -23.22\n",
            "🚂 Episode 3353\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.745 ↑ 0.170 → 0.043 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3354\t Score = -22.619999999999997\n",
            "🚂 Episode 3354\t 🏆 Score: -0.030 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.477 ↑ 0.144 → 0.026 ◼ 0.007 ↓ 0.327 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3355\t Score = 8.79\n",
            "🚂 Episode 3355\t 🏆 Score: 0.012 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3356\t Score = 10.11\n",
            "🚂 Episode 3356\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.229 → 0.600 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3357\t Score = -23.22\n",
            "🚂 Episode 3357\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.436 ← 0.032 ↑ 0.330 → 0.074 ◼ 0.011 ↓ 0.117 \t Metric 0.397 \n",
            "Episode Nr. 3358\t Score = -22.619999999999997\n",
            "🚂 Episode 3358\t 🏆 Score: -0.030 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.190 ← 0.105 ↑ 0.190 → 0.229 ◼ 0.007 ↓ 0.281 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3359\t Score = -23.22\n",
            "🚂 Episode 3359\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.457 ← 0.032 ↑ 0.309 → 0.064 ◼ 0.021 ↓ 0.117 \t Metric 0.397 \n",
            "Episode Nr. 3360\t Score = -22.619999999999997\n",
            "🚂 Episode 3360\t 🏆 Score: -0.030 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.359 ← 0.098 ↑ 0.399 → 0.026 ◼ 0.013 ↓ 0.105 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3361\t Score = -23.520000000000003\n",
            "🚂 Episode 3361\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.125 ↑ 0.167 → 0.031 ◼ 0.021 ↓ 0.646 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3362\t Score = -22.619999999999997\n",
            "🚂 Episode 3362\t 🏆 Score: -0.030 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.353 ← 0.026 ↑ 0.288 → 0.150 ◼ 0.013 ↓ 0.170 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3363\t Score = 8.79\n",
            "🚂 Episode 3363\t 🏆 Score: 0.012 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3364\t Score = 8.79\n",
            "🚂 Episode 3364\t 🏆 Score: 0.012 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3365\t Score = -23.22\n",
            "🚂 Episode 3365\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.096 ↑ 0.170 → 0.043 ◼ 0.011 ↓ 0.660 \t Metric 0.397 \n",
            "Episode Nr. 3366\t Score = -23.22\n",
            "🚂 Episode 3366\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.128 ↑ 0.138 → 0.043 ◼ 0.011 ↓ 0.660 \t Metric 0.397 \n",
            "Episode Nr. 3367\t Score = 10.11\n",
            "🚂 Episode 3367\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.186 → 0.629 ◼ 0.043 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3368\t Score = 10.11\n",
            "🚂 Episode 3368\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.557 ↑ 0.286 → 0.043 ◼ 0.014 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3369\t Score = -23.22\n",
            "🚂 Episode 3369\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.415 ↑ 0.223 → 0.032 ◼ 0.011 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 3370\t Score = -22.619999999999997\n",
            "🚂 Episode 3370\t 🏆 Score: -0.030 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.203 ↑ 0.059 → 0.320 ◼ 0.275 ↓ 0.052 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3371\t Score = -23.22\n",
            "🚂 Episode 3371\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.117 ↑ 0.149 → 0.053 ◼ 0.053 ↓ 0.596 \t Metric 0.397 \n",
            "Episode Nr. 3372\t Score = 10.11\n",
            "🚂 Episode 3372\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.229 → 0.214 ◼ 0.429 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3373\t Score = 10.11\n",
            "🚂 Episode 3373\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.229 → 0.229 ◼ 0.429 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3374\t Score = 8.643333333333333\n",
            "🚂 Episode 3374\t 🏆 Score: 0.012 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3375\t Score = -22.619999999999997\n",
            "🚂 Episode 3375\t 🏆 Score: -0.030 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.124 ← 0.327 ↑ 0.216 → 0.150 ◼ 0.059 ↓ 0.124 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3376\t Score = -22.619999999999997\n",
            "🚂 Episode 3376\t 🏆 Score: -0.030 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.255 ← 0.020 ↑ 0.359 → 0.170 ◼ 0.007 ↓ 0.190 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3377\t Score = 10.11\n",
            "🚂 Episode 3377\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.371 ↑ 0.257 → 0.143 ◼ 0.157 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3378\t Score = -23.22\n",
            "🚂 Episode 3378\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.479 ← 0.128 ↑ 0.085 → 0.032 ◼ 0.011 ↓ 0.266 \t Metric 0.397 \n",
            "Episode Nr. 3379\t Score = 8.643333333333333\n",
            "🚂 Episode 3379\t 🏆 Score: 0.012 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3380\t Score = -23.22\n",
            "🚂 Episode 3380\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.223 ← 0.426 ↑ 0.128 → 0.043 ◼ 0.011 ↓ 0.170 \t Metric 0.397 \n",
            "Episode Nr. 3381\t Score = 8.79\n",
            "🚂 Episode 3381\t 🏆 Score: 0.012 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3382\t Score = -23.22\n",
            "🚂 Episode 3382\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.543 ↑ 0.096 → 0.032 ◼ 0.011 ↓ 0.298 \t Metric 0.397 \n",
            "Episode Nr. 3383\t Score = -22.619999999999997\n",
            "🚂 Episode 3383\t 🏆 Score: -0.030 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.255 ← 0.163 ↑ 0.307 → 0.033 ◼ 0.007 ↓ 0.235 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3384\t Score = 10.11\n",
            "🚂 Episode 3384\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.486 ↑ 0.371 → 0.043 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3385\t Score = 10.11\n",
            "🚂 Episode 3385\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.429 ↑ 0.229 → 0.214 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3386\t Score = 10.11\n",
            "🚂 Episode 3386\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.014 ↑ 0.214 → 0.629 ◼ 0.071 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3387\t Score = -22.619999999999997\n",
            "🚂 Episode 3387\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.346 ← 0.059 ↑ 0.235 → 0.157 ◼ 0.007 ↓ 0.196 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3388\t Score = 10.11\n",
            "🚂 Episode 3388\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.171 → 0.643 ◼ 0.043 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3389\t Score = 10.11\n",
            "🚂 Episode 3389\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.071 ↑ 0.214 → 0.629 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3390\t Score = 10.11\n",
            "🚂 Episode 3390\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.314 ↑ 0.386 → 0.186 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3391\t Score = -23.22\n",
            "🚂 Episode 3391\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.149 ↑ 0.255 → 0.032 ◼ 0.011 ↓ 0.521 \t Metric 0.397 \n",
            "Episode Nr. 3392\t Score = 8.79\n",
            "🚂 Episode 3392\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3393\t Score = 10.11\n",
            "🚂 Episode 3393\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.200 → 0.629 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3394\t Score = 10.11\n",
            "🚂 Episode 3394\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.129 ↑ 0.229 → 0.143 ◼ 0.429 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3395\t Score = 10.11\n",
            "🚂 Episode 3395\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.057 ↑ 0.271 → 0.229 ◼ 0.386 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3396\t Score = -22.619999999999997\n",
            "🚂 Episode 3396\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.203 ← 0.020 ↑ 0.314 → 0.307 ◼ 0.007 ↓ 0.150 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3397\t Score = 8.643333333333333\n",
            "🚂 Episode 3397\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3398\t Score = 10.11\n",
            "🚂 Episode 3398\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.214 → 0.514 ◼ 0.171 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3399\t Score = -22.619999999999997\n",
            "🚂 Episode 3399\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.294 ← 0.020 ↑ 0.359 → 0.176 ◼ 0.007 ↓ 0.144 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3400\t Score = -22.619999999999997\n",
            "🚂 Episode 3400\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.379 ← 0.065 ↑ 0.366 → 0.072 ◼ 0.007 ↓ 0.111 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3401\t Score = 10.11\n",
            "🚂 Episode 3401\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.200 → 0.614 ◼ 0.043 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3402\t Score = 10.11\n",
            "🚂 Episode 3402\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.071 ↑ 0.229 → 0.543 ◼ 0.057 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3403\t Score = -22.619999999999997\n",
            "🚂 Episode 3403\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.353 ← 0.124 ↑ 0.340 → 0.150 ◼ 0.007 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3404\t Score = -23.22\n",
            "🚂 Episode 3404\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.106 ↑ 0.191 → 0.606 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 3405\t Score = -22.619999999999997\n",
            "🚂 Episode 3405\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.059 ← 0.248 ↑ 0.392 → 0.144 ◼ 0.078 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3406\t Score = -22.619999999999997\n",
            "🚂 Episode 3406\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.359 ← 0.170 ↑ 0.072 → 0.020 ◼ 0.039 ↓ 0.340 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3407\t Score = -23.22\n",
            "🚂 Episode 3407\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.447 ← 0.074 ↑ 0.234 → 0.032 ◼ 0.011 ↓ 0.202 \t Metric 0.397 \n",
            "Episode Nr. 3408\t Score = -22.619999999999997\n",
            "🚂 Episode 3408\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.216 ← 0.229 ↑ 0.222 → 0.085 ◼ 0.007 ↓ 0.242 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3409\t Score = -23.22\n",
            "🚂 Episode 3409\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.128 ↑ 0.202 → 0.574 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 3410\t Score = -23.22\n",
            "🚂 Episode 3410\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.181 → 0.585 ◼ 0.032 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3411\t Score = -22.619999999999997\n",
            "🚂 Episode 3411\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.778 ↑ 0.111 → 0.020 ◼ 0.039 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3412\t Score = -23.22\n",
            "🚂 Episode 3412\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.266 ← 0.170 ↑ 0.213 → 0.255 ◼ 0.011 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 3413\t Score = 10.11\n",
            "🚂 Episode 3413\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.157 ↑ 0.286 → 0.043 ◼ 0.429 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3414\t Score = -23.22\n",
            "🚂 Episode 3414\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.436 ↑ 0.096 → 0.117 ◼ 0.011 ↓ 0.309 \t Metric 0.397 \n",
            "Episode Nr. 3415\t Score = -23.22\n",
            "🚂 Episode 3415\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.394 ← 0.106 ↑ 0.117 → 0.202 ◼ 0.011 ↓ 0.170 \t Metric 0.397 \n",
            "Episode Nr. 3416\t Score = -22.619999999999997\n",
            "🚂 Episode 3416\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.503 ↑ 0.105 → 0.170 ◼ 0.007 ↓ 0.209 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3417\t Score = -23.22\n",
            "🚂 Episode 3417\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 33.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.245 ↑ 0.128 → 0.468 ◼ 0.011 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 3418\t Score = -23.22\n",
            "🚂 Episode 3418\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 33.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.564 ↑ 0.085 → 0.309 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3419\t Score = 9.973333333333331\n",
            "🚂 Episode 3419\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.028 ← 0.528 ↑ 0.222 → 0.097 ◼ 0.056 ↓ 0.069 \t Metric 0.593 \n",
            "Episode Nr. 3420\t Score = 10.11\n",
            "🚂 Episode 3420\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.200 → 0.629 ◼ 0.071 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3421\t Score = 9.973333333333331\n",
            "🚂 Episode 3421\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.028 ← 0.097 ↑ 0.236 → 0.319 ◼ 0.278 ↓ 0.042 \t Metric 0.593 \n",
            "Episode Nr. 3422\t Score = -23.22\n",
            "🚂 Episode 3422\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.660 ↑ 0.149 → 0.032 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3423\t Score = 8.79\n",
            "🚂 Episode 3423\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3424\t Score = -22.619999999999997\n",
            "🚂 Episode 3424\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.137 ← 0.503 ↑ 0.098 → 0.026 ◼ 0.013 ↓ 0.222 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3425\t Score = 10.11\n",
            "🚂 Episode 3425\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.243 → 0.414 ◼ 0.229 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3426\t Score = -22.619999999999997\n",
            "🚂 Episode 3426\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.229 ← 0.059 ↑ 0.425 → 0.203 ◼ 0.007 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3427\t Score = 10.11\n",
            "🚂 Episode 3427\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.129 ↑ 0.343 → 0.429 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3428\t Score = -23.22\n",
            "🚂 Episode 3428\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.777 ↑ 0.117 → 0.032 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3429\t Score = -23.22\n",
            "🚂 Episode 3429\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.138 ↑ 0.202 → 0.043 ◼ 0.011 ↓ 0.585 \t Metric 0.397 \n",
            "Episode Nr. 3430\t Score = 10.11\n",
            "🚂 Episode 3430\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.129 ↑ 0.314 → 0.057 ◼ 0.429 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3431\t Score = 10.11\n",
            "🚂 Episode 3431\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.186 ↑ 0.243 → 0.100 ◼ 0.429 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3432\t Score = -23.22\n",
            "🚂 Episode 3432\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.362 ↑ 0.085 → 0.032 ◼ 0.011 ↓ 0.489 \t Metric 0.397 \n",
            "Episode Nr. 3433\t Score = 10.11\n",
            "🚂 Episode 3433\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.229 → 0.614 ◼ 0.057 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3434\t Score = -23.22\n",
            "🚂 Episode 3434\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.298 ← 0.394 ↑ 0.160 → 0.096 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3435\t Score = -22.619999999999997\n",
            "🚂 Episode 3435\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 33.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.222 ← 0.137 ↑ 0.157 → 0.281 ◼ 0.013 ↓ 0.190 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3436\t Score = 10.11\n",
            "🚂 Episode 3436\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.171 ↑ 0.214 → 0.486 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3437\t Score = 8.643333333333333\n",
            "🚂 Episode 3437\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3438\t Score = -105.01999999999994\n",
            "🚂 Episode 3438\t 🏆 Score: -0.140 Avg: -0.015\t 💯 Done: 0.00% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.012 ← 0.421 ↑ 0.015 → 0.012 ◼ 0.004 ↓ 0.537 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3439\t Score = -23.520000000000003\n",
            "🚂 Episode 3439\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.031 ← 0.125 ↑ 0.146 → 0.031 ◼ 0.021 ↓ 0.646 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3440\t Score = 10.11\n",
            "🚂 Episode 3440\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.129 ↑ 0.214 → 0.471 ◼ 0.086 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3441\t Score = -23.22\n",
            "🚂 Episode 3441\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.255 ← 0.287 ↑ 0.298 → 0.128 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3442\t Score = -23.22\n",
            "🚂 Episode 3442\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.585 ↑ 0.160 → 0.191 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3443\t Score = 10.11\n",
            "🚂 Episode 3443\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.414 → 0.057 ◼ 0.429 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3444\t Score = -23.22\n",
            "🚂 Episode 3444\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.351 ← 0.213 ↑ 0.064 → 0.266 ◼ 0.053 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3445\t Score = -22.619999999999997\n",
            "🚂 Episode 3445\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.484 ← 0.072 ↑ 0.320 → 0.052 ◼ 0.013 ↓ 0.059 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3446\t Score = 10.11\n",
            "🚂 Episode 3446\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.271 → 0.614 ◼ 0.057 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3447\t Score = -27.12\n",
            "🚂 Episode 3447\t 🏆 Score: -0.036 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.050 ← 0.400 ↑ 0.158 → 0.225 ◼ 0.125 ↓ 0.042 \t Metric 0.39049999999999996 \n",
            "Episode Nr. 3448\t Score = -23.22\n",
            "🚂 Episode 3448\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.564 ↑ 0.149 → 0.096 ◼ 0.011 ↓ 0.160 \t Metric 0.397 \n",
            "Episode Nr. 3449\t Score = 10.11\n",
            "🚂 Episode 3449\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.214 → 0.614 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3450\t Score = -23.22\n",
            "🚂 Episode 3450\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.128 ← 0.032 ↑ 0.309 → 0.489 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3451\t Score = 10.11\n",
            "🚂 Episode 3451\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.529 ↑ 0.214 → 0.043 ◼ 0.114 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3452\t Score = 10.11\n",
            "🚂 Episode 3452\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.214 → 0.229 ◼ 0.429 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3453\t Score = -23.22\n",
            "🚂 Episode 3453\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.128 ↑ 0.234 → 0.053 ◼ 0.011 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 3454\t Score = -24.36\n",
            "🚂 Episode 3454\t 🏆 Score: -0.032 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.193 ← 0.269 ↑ 0.199 → 0.099 ◼ 0.041 ↓ 0.199 \t Metric 0.6566666666666667 \n",
            "Episode Nr. 3455\t Score = -23.22\n",
            "🚂 Episode 3455\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.043 ↑ 0.266 → 0.574 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3456\t Score = -23.22\n",
            "🚂 Episode 3456\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.160 ← 0.532 ↑ 0.106 → 0.043 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 3457\t Score = 10.11\n",
            "🚂 Episode 3457\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.043 ↑ 0.214 → 0.614 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3458\t Score = 8.79\n",
            "🚂 Episode 3458\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3459\t Score = 10.11\n",
            "🚂 Episode 3459\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.129 ↑ 0.200 → 0.129 ◼ 0.429 ↓ 0.100 \t Metric 0.5925 \n",
            "Episode Nr. 3460\t Score = 10.11\n",
            "🚂 Episode 3460\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.071 ↑ 0.229 → 0.186 ◼ 0.414 ↓ 0.086 \t Metric 0.5925 \n",
            "Episode Nr. 3461\t Score = 10.11\n",
            "🚂 Episode 3461\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.057 ↑ 0.214 → 0.586 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3462\t Score = -23.22\n",
            "🚂 Episode 3462\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.809 ↑ 0.096 → 0.032 ◼ 0.021 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3463\t Score = -22.619999999999997\n",
            "🚂 Episode 3463\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.124 ← 0.157 ↑ 0.046 → 0.366 ◼ 0.007 ↓ 0.301 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3464\t Score = 10.11\n",
            "🚂 Episode 3464\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.186 ↑ 0.243 → 0.471 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3465\t Score = -20.436666666666664\n",
            "🚂 Episode 3465\t 🏆 Score: -0.027 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.408 ↑ 0.224 → 0.053 ◼ 0.026 ↓ 0.263 \t Metric 0.397 \n",
            "Episode Nr. 3466\t Score = -26.52\n",
            "🚂 Episode 3466\t 🏆 Score: -0.035 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.017 ← 0.552 ↑ 0.069 → 0.026 ◼ 0.259 ↓ 0.078 \t Metric 0.39149999999999996 \n",
            "Episode Nr. 3467\t Score = 10.11\n",
            "🚂 Episode 3467\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.400 → 0.429 ◼ 0.071 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3468\t Score = -22.619999999999997\n",
            "🚂 Episode 3468\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.327 ← 0.190 ↑ 0.046 → 0.020 ◼ 0.203 ↓ 0.216 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3469\t Score = -22.619999999999997\n",
            "🚂 Episode 3469\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.203 ← 0.111 ↑ 0.425 → 0.170 ◼ 0.072 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3470\t Score = 8.79\n",
            "🚂 Episode 3470\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3471\t Score = -23.22\n",
            "🚂 Episode 3471\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.255 → 0.032 ◼ 0.011 ↓ 0.628 \t Metric 0.397 \n",
            "Episode Nr. 3472\t Score = 10.11\n",
            "🚂 Episode 3472\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.186 → 0.643 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3473\t Score = 10.11\n",
            "🚂 Episode 3473\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.300 → 0.457 ◼ 0.143 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3474\t Score = -23.22\n",
            "🚂 Episode 3474\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.149 ↑ 0.138 → 0.032 ◼ 0.011 ↓ 0.638 \t Metric 0.397 \n",
            "Episode Nr. 3475\t Score = 8.79\n",
            "🚂 Episode 3475\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3476\t Score = 10.11\n",
            "🚂 Episode 3476\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.471 ↑ 0.214 → 0.171 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3477\t Score = 10.11\n",
            "🚂 Episode 3477\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.200 → 0.486 ◼ 0.186 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3478\t Score = 8.79\n",
            "🚂 Episode 3478\t 🏆 Score: 0.012 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3479\t Score = -22.619999999999997\n",
            "🚂 Episode 3479\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.333 ← 0.105 ↑ 0.359 → 0.137 ◼ 0.039 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3480\t Score = -22.619999999999997\n",
            "🚂 Episode 3480\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.268 ← 0.105 ↑ 0.464 → 0.137 ◼ 0.013 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3481\t Score = -23.22\n",
            "🚂 Episode 3481\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.106 ↑ 0.106 → 0.723 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3482\t Score = -23.22\n",
            "🚂 Episode 3482\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.191 ↑ 0.234 → 0.128 ◼ 0.011 ↓ 0.404 \t Metric 0.397 \n",
            "Episode Nr. 3483\t Score = -22.619999999999997\n",
            "🚂 Episode 3483\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.105 ← 0.229 ↑ 0.294 → 0.216 ◼ 0.007 ↓ 0.150 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3484\t Score = -23.22\n",
            "🚂 Episode 3484\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.202 ↑ 0.074 → 0.372 ◼ 0.011 ↓ 0.309 \t Metric 0.397 \n",
            "Episode Nr. 3485\t Score = 10.11\n",
            "🚂 Episode 3485\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.329 → 0.514 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3486\t Score = 10.11\n",
            "🚂 Episode 3486\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.229 ↑ 0.329 → 0.157 ◼ 0.186 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3487\t Score = -23.22\n",
            "🚂 Episode 3487\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.660 ↑ 0.117 → 0.128 ◼ 0.032 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3488\t Score = -23.22\n",
            "🚂 Episode 3488\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.043 ↑ 0.234 → 0.032 ◼ 0.011 ↓ 0.649 \t Metric 0.397 \n",
            "Episode Nr. 3489\t Score = 10.11\n",
            "🚂 Episode 3489\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.057 ↑ 0.200 → 0.614 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3490\t Score = -22.619999999999997\n",
            "🚂 Episode 3490\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.209 ← 0.288 ↑ 0.085 → 0.020 ◼ 0.013 ↓ 0.386 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3491\t Score = 10.11\n",
            "🚂 Episode 3491\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.229 → 0.600 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3492\t Score = -23.22\n",
            "🚂 Episode 3492\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.436 ← 0.170 ↑ 0.170 → 0.032 ◼ 0.011 ↓ 0.181 \t Metric 0.397 \n",
            "Episode Nr. 3493\t Score = -23.22\n",
            "🚂 Episode 3493\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.681 ↑ 0.074 → 0.032 ◼ 0.128 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3494\t Score = -22.619999999999997\n",
            "🚂 Episode 3494\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.144 ← 0.059 ↑ 0.431 → 0.203 ◼ 0.092 ↓ 0.072 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3495\t Score = -31.319999999999993\n",
            "🚂 Episode 3495\t 🏆 Score: -0.042 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.321 ← 0.173 ↑ 0.251 → 0.049 ◼ 0.016 ↓ 0.189 \t Metric 0.6366666666666667 \n",
            "Episode Nr. 3496\t Score = -102.53999999999999\n",
            "🚂 Episode 3496\t 🏆 Score: -0.137 Avg: -0.015\t 💯 Done: 0.00% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.493 ← 0.113 ↑ 0.287 → 0.019 ◼ 0.013 ↓ 0.075 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3497\t Score = 10.11\n",
            "🚂 Episode 3497\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.071 ↑ 0.300 → 0.486 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3498\t Score = 8.79\n",
            "🚂 Episode 3498\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3499\t Score = -23.22\n",
            "🚂 Episode 3499\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.649 ↑ 0.074 → 0.096 ◼ 0.011 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 3500\t Score = -22.619999999999997\n",
            "🚂 Episode 3500\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.294 ← 0.039 ↑ 0.464 → 0.137 ◼ 0.026 ↓ 0.039 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3501\t Score = -22.619999999999997\n",
            "🚂 Episode 3501\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.373 ↑ 0.216 → 0.105 ◼ 0.052 ↓ 0.170 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3502\t Score = 10.11\n",
            "🚂 Episode 3502\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.214 → 0.614 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3503\t Score = -34.019999999999996\n",
            "🚂 Episode 3503\t 🏆 Score: -0.045 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.163 ← 0.253 ↑ 0.078 → 0.253 ◼ 0.223 ↓ 0.030 \t Metric 0.379 \n",
            "Episode Nr. 3504\t Score = 10.11\n",
            "🚂 Episode 3504\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.243 → 0.586 ◼ 0.086 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3505\t Score = 10.11\n",
            "🚂 Episode 3505\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.200 → 0.629 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3506\t Score = 8.79\n",
            "🚂 Episode 3506\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3507\t Score = -23.22\n",
            "🚂 Episode 3507\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.213 ↑ 0.064 → 0.032 ◼ 0.011 ↓ 0.660 \t Metric 0.397 \n",
            "Episode Nr. 3508\t Score = -22.619999999999997\n",
            "🚂 Episode 3508\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.144 ← 0.085 ↑ 0.399 → 0.281 ◼ 0.013 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3509\t Score = 9.973333333333331\n",
            "🚂 Episode 3509\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.028 ← 0.042 ↑ 0.181 → 0.639 ◼ 0.056 ↓ 0.056 \t Metric 0.5935 \n",
            "Episode Nr. 3510\t Score = 10.11\n",
            "🚂 Episode 3510\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.200 → 0.586 ◼ 0.100 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3511\t Score = -28.919999999999998\n",
            "🚂 Episode 3511\t 🏆 Score: -0.039 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.447 ← 0.152 ↑ 0.174 → 0.045 ◼ 0.167 ↓ 0.015 \t Metric 0.38749999999999996 \n",
            "Episode Nr. 3512\t Score = 8.79\n",
            "🚂 Episode 3512\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3513\t Score = -23.22\n",
            "🚂 Episode 3513\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.117 ↑ 0.181 → 0.489 ◼ 0.128 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 3514\t Score = -23.22\n",
            "🚂 Episode 3514\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.106 ↑ 0.191 → 0.128 ◼ 0.021 ↓ 0.532 \t Metric 0.397 \n",
            "Episode Nr. 3515\t Score = -22.619999999999997\n",
            "🚂 Episode 3515\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.105 ← 0.425 ↑ 0.039 → 0.157 ◼ 0.007 ↓ 0.268 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3516\t Score = -22.619999999999997\n",
            "🚂 Episode 3516\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.275 ← 0.405 ↑ 0.124 → 0.085 ◼ 0.007 ↓ 0.105 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3517\t Score = -22.619999999999997\n",
            "🚂 Episode 3517\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.340 ← 0.144 ↑ 0.144 → 0.026 ◼ 0.007 ↓ 0.340 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3518\t Score = -23.22\n",
            "🚂 Episode 3518\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.543 ↑ 0.128 → 0.074 ◼ 0.011 ↓ 0.191 \t Metric 0.397 \n",
            "Episode Nr. 3519\t Score = -22.619999999999997\n",
            "🚂 Episode 3519\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.229 ← 0.248 ↑ 0.392 → 0.026 ◼ 0.007 ↓ 0.098 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3520\t Score = -23.22\n",
            "🚂 Episode 3520\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.138 ← 0.553 ↑ 0.096 → 0.032 ◼ 0.011 ↓ 0.170 \t Metric 0.397 \n",
            "Episode Nr. 3521\t Score = 8.79\n",
            "🚂 Episode 3521\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3522\t Score = -23.520000000000003\n",
            "🚂 Episode 3522\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.312 ← 0.229 ↑ 0.365 → 0.042 ◼ 0.021 ↓ 0.031 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3523\t Score = -23.22\n",
            "🚂 Episode 3523\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.426 ← 0.202 ↑ 0.213 → 0.128 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3524\t Score = -23.22\n",
            "🚂 Episode 3524\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.426 ← 0.128 ↑ 0.213 → 0.170 ◼ 0.021 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3525\t Score = 8.79\n",
            "🚂 Episode 3525\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3526\t Score = -22.619999999999997\n",
            "🚂 Episode 3526\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.118 ← 0.601 ↑ 0.092 → 0.052 ◼ 0.020 ↓ 0.118 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3527\t Score = -22.619999999999997\n",
            "🚂 Episode 3527\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.078 ← 0.366 ↑ 0.144 → 0.085 ◼ 0.013 ↓ 0.314 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3528\t Score = -23.22\n",
            "🚂 Episode 3528\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.415 ← 0.170 ↑ 0.255 → 0.117 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3529\t Score = -22.91\n",
            "🚂 Episode 3529\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.090 ← 0.391 ↑ 0.096 → 0.346 ◼ 0.013 ↓ 0.064 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 3530\t Score = 10.11\n",
            "🚂 Episode 3530\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.100 ↑ 0.229 → 0.543 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3531\t Score = 10.11\n",
            "🚂 Episode 3531\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.414 → 0.043 ◼ 0.429 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3532\t Score = -22.619999999999997\n",
            "🚂 Episode 3532\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.327 ← 0.190 ↑ 0.046 → 0.176 ◼ 0.059 ↓ 0.203 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3533\t Score = -23.22\n",
            "🚂 Episode 3533\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.394 ↑ 0.149 → 0.223 ◼ 0.181 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3534\t Score = 10.11\n",
            "🚂 Episode 3534\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.271 → 0.586 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3535\t Score = 10.11\n",
            "🚂 Episode 3535\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.129 ↑ 0.229 → 0.543 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3536\t Score = 10.11\n",
            "🚂 Episode 3536\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.600 ↑ 0.229 → 0.043 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3537\t Score = -23.22\n",
            "🚂 Episode 3537\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.415 ↑ 0.085 → 0.340 ◼ 0.096 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3538\t Score = 10.11\n",
            "🚂 Episode 3538\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.257 → 0.200 ◼ 0.443 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3539\t Score = 10.11\n",
            "🚂 Episode 3539\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.229 → 0.629 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3540\t Score = -23.22\n",
            "🚂 Episode 3540\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.043 ↑ 0.372 → 0.404 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3541\t Score = -23.22\n",
            "🚂 Episode 3541\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.574 ↑ 0.181 → 0.117 ◼ 0.021 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3542\t Score = 8.79\n",
            "🚂 Episode 3542\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3543\t Score = -23.22\n",
            "🚂 Episode 3543\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.043 ↑ 0.255 → 0.032 ◼ 0.011 ↓ 0.638 \t Metric 0.397 \n",
            "Episode Nr. 3544\t Score = -23.22\n",
            "🚂 Episode 3544\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.202 ← 0.489 ↑ 0.074 → 0.106 ◼ 0.011 ↓ 0.117 \t Metric 0.397 \n",
            "Episode Nr. 3545\t Score = 10.11\n",
            "🚂 Episode 3545\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.214 → 0.629 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3546\t Score = -22.619999999999997\n",
            "🚂 Episode 3546\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.137 ↑ 0.183 → 0.261 ◼ 0.007 ↓ 0.327 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3547\t Score = 10.11\n",
            "🚂 Episode 3547\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.386 ↑ 0.314 → 0.114 ◼ 0.086 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3548\t Score = -23.22\n",
            "🚂 Episode 3548\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.128 ↑ 0.149 → 0.532 ◼ 0.149 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3549\t Score = -23.22\n",
            "🚂 Episode 3549\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.202 ↑ 0.266 → 0.032 ◼ 0.011 ↓ 0.468 \t Metric 0.397 \n",
            "Episode Nr. 3550\t Score = 10.11\n",
            "🚂 Episode 3550\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.229 → 0.614 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3551\t Score = 10.11\n",
            "🚂 Episode 3551\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.129 ↑ 0.243 → 0.457 ◼ 0.057 ↓ 0.100 \t Metric 0.5925 \n",
            "Episode Nr. 3552\t Score = 8.643333333333333\n",
            "🚂 Episode 3552\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3553\t Score = 10.11\n",
            "🚂 Episode 3553\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.014 ↑ 0.400 → 0.071 ◼ 0.457 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3554\t Score = 8.79\n",
            "🚂 Episode 3554\t 🏆 Score: 0.012 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3555\t Score = -33.35\n",
            "🚂 Episode 3555\t 🏆 Score: -0.044 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.197 ← 0.258 ↑ 0.027 → 0.174 ◼ 0.080 ↓ 0.265 \t Metric 0.6308333333333334 \n",
            "Episode Nr. 3556\t Score = -22.619999999999997\n",
            "🚂 Episode 3556\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.137 ← 0.405 ↑ 0.190 → 0.052 ◼ 0.007 ↓ 0.209 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3557\t Score = 10.11\n",
            "🚂 Episode 3557\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.443 → 0.186 ◼ 0.286 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3558\t Score = 8.79\n",
            "🚂 Episode 3558\t 🏆 Score: 0.012 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3559\t Score = -22.619999999999997\n",
            "🚂 Episode 3559\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.431 ← 0.314 ↑ 0.059 → 0.020 ◼ 0.092 ↓ 0.085 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3560\t Score = -3.42\n",
            "🚂 Episode 3560\t 🏆 Score: -0.005 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.012 ← 0.006 ↑ 0.100 → 0.459 ◼ 0.118 ↓ 0.306 \t Metric 0.5775 \n",
            "Episode Nr. 3561\t Score = -22.619999999999997\n",
            "🚂 Episode 3561\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.170 ← 0.255 ↑ 0.510 → 0.020 ◼ 0.026 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3562\t Score = -22.619999999999997\n",
            "🚂 Episode 3562\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.196 ← 0.190 ↑ 0.353 → 0.065 ◼ 0.039 ↓ 0.157 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3563\t Score = -50.819999999999965\n",
            "🚂 Episode 3563\t 🏆 Score: -0.068 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.401 ↑ 0.138 → 0.259 ◼ 0.004 ↓ 0.194 \t Metric 0.351 \n",
            "Episode Nr. 3564\t Score = 10.11\n",
            "🚂 Episode 3564\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.043 ↑ 0.200 → 0.600 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3565\t Score = -23.520000000000003\n",
            "🚂 Episode 3565\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.312 ↑ 0.177 → 0.031 ◼ 0.021 ↓ 0.448 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3566\t Score = -22.619999999999997\n",
            "🚂 Episode 3566\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.294 ← 0.020 ↑ 0.425 → 0.170 ◼ 0.078 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3567\t Score = 10.11\n",
            "🚂 Episode 3567\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.071 ← 0.300 ↑ 0.357 → 0.186 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3568\t Score = -25.02\n",
            "🚂 Episode 3568\t 🏆 Score: -0.033 Avg: -0.014\t 💯 Done: 33.33% Avg: 33.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.311 ← 0.189 ↑ 0.226 → 0.047 ◼ 0.019 ↓ 0.208 \t Metric 0.394 \n",
            "Episode Nr. 3569\t Score = -102.53999999999999\n",
            "🚂 Episode 3569\t 🏆 Score: -0.137 Avg: -0.016\t 💯 Done: 0.00% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.264 ← 0.493 ↑ 0.008 → 0.108 ◼ 0.004 ↓ 0.122 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3570\t Score = 10.11\n",
            "🚂 Episode 3570\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.629 ↑ 0.214 → 0.043 ◼ 0.014 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3571\t Score = -23.22\n",
            "🚂 Episode 3571\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.213 ↑ 0.170 → 0.032 ◼ 0.011 ↓ 0.553 \t Metric 0.397 \n",
            "Episode Nr. 3572\t Score = -23.22\n",
            "🚂 Episode 3572\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.479 ↑ 0.149 → 0.096 ◼ 0.181 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 3573\t Score = 8.79\n",
            "🚂 Episode 3573\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3574\t Score = 10.11\n",
            "🚂 Episode 3574\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.300 → 0.486 ◼ 0.086 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3575\t Score = -23.22\n",
            "🚂 Episode 3575\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.277 ← 0.117 ↑ 0.149 → 0.298 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 3576\t Score = 10.11\n",
            "🚂 Episode 3576\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.043 ↑ 0.386 → 0.429 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3577\t Score = -23.22\n",
            "🚂 Episode 3577\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.298 ← 0.362 ↑ 0.160 → 0.117 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3578\t Score = 8.79\n",
            "🚂 Episode 3578\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3579\t Score = -22.619999999999997\n",
            "🚂 Episode 3579\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.131 ↑ 0.301 → 0.046 ◼ 0.346 ↓ 0.170 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3580\t Score = -23.22\n",
            "🚂 Episode 3580\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.287 ↑ 0.191 → 0.032 ◼ 0.255 ↓ 0.223 \t Metric 0.397 \n",
            "Episode Nr. 3581\t Score = -22.619999999999997\n",
            "🚂 Episode 3581\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.275 ← 0.085 ↑ 0.170 → 0.281 ◼ 0.007 ↓ 0.183 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3582\t Score = -22.619999999999997\n",
            "🚂 Episode 3582\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.118 ← 0.275 ↑ 0.412 → 0.092 ◼ 0.007 ↓ 0.098 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3583\t Score = 10.11\n",
            "🚂 Episode 3583\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.214 → 0.586 ◼ 0.071 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3584\t Score = 10.11\n",
            "🚂 Episode 3584\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.229 → 0.600 ◼ 0.071 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3585\t Score = -23.22\n",
            "🚂 Episode 3585\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.447 ← 0.160 ↑ 0.149 → 0.117 ◼ 0.032 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3586\t Score = 10.11\n",
            "🚂 Episode 3586\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.414 → 0.443 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3587\t Score = -22.619999999999997\n",
            "🚂 Episode 3587\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.412 ↑ 0.085 → 0.020 ◼ 0.007 ↓ 0.458 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3588\t Score = -23.22\n",
            "🚂 Episode 3588\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.053 ↑ 0.234 → 0.032 ◼ 0.277 ↓ 0.383 \t Metric 0.397 \n",
            "Episode Nr. 3589\t Score = 8.79\n",
            "🚂 Episode 3589\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3590\t Score = 8.79\n",
            "🚂 Episode 3590\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3591\t Score = 8.79\n",
            "🚂 Episode 3591\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3592\t Score = -22.619999999999997\n",
            "🚂 Episode 3592\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.190 ← 0.183 ↑ 0.105 → 0.020 ◼ 0.007 ↓ 0.497 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3593\t Score = 10.11\n",
            "🚂 Episode 3593\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.043 ↑ 0.286 → 0.543 ◼ 0.057 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3594\t Score = -23.22\n",
            "🚂 Episode 3594\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.170 ← 0.032 ↑ 0.564 → 0.053 ◼ 0.085 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3595\t Score = 8.79\n",
            "🚂 Episode 3595\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3596\t Score = -105.01999999999994\n",
            "🚂 Episode 3596\t 🏆 Score: -0.140 Avg: -0.015\t 💯 Done: 0.00% Avg: 32.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.327 ↑ 0.019 → 0.632 ◼ 0.011 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3597\t Score = 10.11\n",
            "🚂 Episode 3597\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.071 ↑ 0.214 → 0.229 ◼ 0.386 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3598\t Score = -22.619999999999997\n",
            "🚂 Episode 3598\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.431 ↑ 0.059 → 0.020 ◼ 0.007 ↓ 0.471 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3599\t Score = 8.79\n",
            "🚂 Episode 3599\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3600\t Score = -23.22\n",
            "🚂 Episode 3600\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.436 ← 0.191 ↑ 0.160 → 0.032 ◼ 0.021 ↓ 0.160 \t Metric 0.397 \n",
            "Episode Nr. 3601\t Score = -22.619999999999997\n",
            "🚂 Episode 3601\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.261 ← 0.150 ↑ 0.471 → 0.078 ◼ 0.013 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3602\t Score = -23.22\n",
            "🚂 Episode 3602\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.277 ← 0.447 ↑ 0.117 → 0.117 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3603\t Score = 10.11\n",
            "🚂 Episode 3603\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.186 → 0.629 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3604\t Score = 10.11\n",
            "🚂 Episode 3604\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.214 → 0.657 ◼ 0.071 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3605\t Score = -22.619999999999997\n",
            "🚂 Episode 3605\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.105 ← 0.301 ↑ 0.268 → 0.033 ◼ 0.052 ↓ 0.242 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3606\t Score = -22.619999999999997\n",
            "🚂 Episode 3606\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.229 ← 0.059 ↑ 0.314 → 0.359 ◼ 0.026 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3607\t Score = -22.619999999999997\n",
            "🚂 Episode 3607\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.268 ← 0.490 ↑ 0.065 → 0.033 ◼ 0.092 ↓ 0.052 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3608\t Score = -23.22\n",
            "🚂 Episode 3608\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.479 ← 0.128 ↑ 0.223 → 0.149 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3609\t Score = -23.22\n",
            "🚂 Episode 3609\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.266 → 0.245 ◼ 0.287 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3610\t Score = 9.973333333333331\n",
            "🚂 Episode 3610\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.042 ↑ 0.208 → 0.639 ◼ 0.056 ↓ 0.042 \t Metric 0.593 \n",
            "Episode Nr. 3611\t Score = -22.619999999999997\n",
            "🚂 Episode 3611\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.216 ← 0.137 ↑ 0.105 → 0.039 ◼ 0.144 ↓ 0.359 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3612\t Score = 10.11\n",
            "🚂 Episode 3612\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.271 → 0.600 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3613\t Score = -23.22\n",
            "🚂 Episode 3613\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.723 ↑ 0.160 → 0.064 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3614\t Score = 10.11\n",
            "🚂 Episode 3614\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.014 ↑ 0.257 → 0.614 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3615\t Score = 8.79\n",
            "🚂 Episode 3615\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3616\t Score = 10.11\n",
            "🚂 Episode 3616\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.271 → 0.571 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3617\t Score = -22.619999999999997\n",
            "🚂 Episode 3617\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.314 ↑ 0.157 → 0.144 ◼ 0.046 ↓ 0.255 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3618\t Score = 10.11\n",
            "🚂 Episode 3618\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.343 ↑ 0.357 → 0.186 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3619\t Score = 8.79\n",
            "🚂 Episode 3619\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3620\t Score = -22.619999999999997\n",
            "🚂 Episode 3620\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.340 ← 0.203 ↑ 0.072 → 0.020 ◼ 0.007 ↓ 0.359 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3621\t Score = -23.22\n",
            "🚂 Episode 3621\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.617 ← 0.128 ↑ 0.138 → 0.053 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3622\t Score = 10.11\n",
            "🚂 Episode 3622\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.086 ↑ 0.229 → 0.571 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3623\t Score = 10.11\n",
            "🚂 Episode 3623\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.057 ↑ 0.214 → 0.600 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3624\t Score = -23.520000000000003\n",
            "🚂 Episode 3624\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.042 ← 0.760 ↑ 0.125 → 0.031 ◼ 0.021 ↓ 0.021 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3625\t Score = 10.11\n",
            "🚂 Episode 3625\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.257 → 0.614 ◼ 0.071 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3626\t Score = 10.11\n",
            "🚂 Episode 3626\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.257 → 0.614 ◼ 0.071 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3627\t Score = 10.11\n",
            "🚂 Episode 3627\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.229 → 0.643 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3628\t Score = -22.91\n",
            "🚂 Episode 3628\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.109 ← 0.064 ↑ 0.340 → 0.321 ◼ 0.026 ↓ 0.141 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 3629\t Score = -23.22\n",
            "🚂 Episode 3629\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.777 ↑ 0.149 → 0.032 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3630\t Score = -23.22\n",
            "🚂 Episode 3630\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.543 ↑ 0.074 → 0.032 ◼ 0.011 ↓ 0.319 \t Metric 0.397 \n",
            "Episode Nr. 3631\t Score = -42.53999999999999\n",
            "🚂 Episode 3631\t 🏆 Score: -0.057 Avg: -0.014\t 💯 Done: 0.00% Avg: 32.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.425 ← 0.144 ↑ 0.123 → 0.294 ◼ 0.002 ↓ 0.012 \t Metric 0.6625 \n",
            "Episode Nr. 3632\t Score = 8.643333333333333\n",
            "🚂 Episode 3632\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3633\t Score = 10.11\n",
            "🚂 Episode 3633\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.229 → 0.643 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3634\t Score = -22.619999999999997\n",
            "🚂 Episode 3634\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.203 ← 0.281 ↑ 0.157 → 0.052 ◼ 0.007 ↓ 0.301 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3635\t Score = -23.22\n",
            "🚂 Episode 3635\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.191 ↑ 0.266 → 0.032 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3636\t Score = 10.11\n",
            "🚂 Episode 3636\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.271 → 0.600 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3637\t Score = 8.79\n",
            "🚂 Episode 3637\t 🏆 Score: 0.012 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3638\t Score = 8.79\n",
            "🚂 Episode 3638\t 🏆 Score: 0.012 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3639\t Score = 10.11\n",
            "🚂 Episode 3639\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.400 → 0.429 ◼ 0.043 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3640\t Score = -23.22\n",
            "🚂 Episode 3640\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.585 ↑ 0.149 → 0.032 ◼ 0.191 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3641\t Score = 8.643333333333333\n",
            "🚂 Episode 3641\t 🏆 Score: 0.012 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3642\t Score = 10.11\n",
            "🚂 Episode 3642\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.229 → 0.271 ◼ 0.386 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3643\t Score = -23.22\n",
            "🚂 Episode 3643\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.234 ↑ 0.064 → 0.532 ◼ 0.011 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 3644\t Score = 10.11\n",
            "🚂 Episode 3644\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.214 → 0.629 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3645\t Score = 10.11\n",
            "🚂 Episode 3645\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.214 → 0.614 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3646\t Score = -20.436666666666664\n",
            "🚂 Episode 3646\t 🏆 Score: -0.027 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.026 ↑ 0.211 → 0.513 ◼ 0.013 ↓ 0.197 \t Metric 0.397 \n",
            "Episode Nr. 3647\t Score = -22.619999999999997\n",
            "🚂 Episode 3647\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.320 ← 0.176 ↑ 0.098 → 0.065 ◼ 0.013 ↓ 0.327 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3648\t Score = 10.11\n",
            "🚂 Episode 3648\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.043 ↑ 0.243 → 0.557 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3649\t Score = -22.619999999999997\n",
            "🚂 Episode 3649\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.320 ↑ 0.118 → 0.111 ◼ 0.078 ↓ 0.366 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3650\t Score = -23.22\n",
            "🚂 Episode 3650\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.415 ↑ 0.245 → 0.064 ◼ 0.011 ↓ 0.255 \t Metric 0.397 \n",
            "Episode Nr. 3651\t Score = 10.11\n",
            "🚂 Episode 3651\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.443 ↑ 0.200 → 0.229 ◼ 0.043 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3652\t Score = -22.619999999999997\n",
            "🚂 Episode 3652\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.209 ← 0.209 ↑ 0.353 → 0.105 ◼ 0.033 ↓ 0.092 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3653\t Score = 10.11\n",
            "🚂 Episode 3653\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.257 ↑ 0.171 → 0.086 ◼ 0.386 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3654\t Score = -22.619999999999997\n",
            "🚂 Episode 3654\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.301 ← 0.078 ↑ 0.314 → 0.137 ◼ 0.046 ↓ 0.124 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3655\t Score = 10.11\n",
            "🚂 Episode 3655\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.271 → 0.614 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3656\t Score = -22.619999999999997\n",
            "🚂 Episode 3656\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.216 ← 0.118 ↑ 0.150 → 0.203 ◼ 0.065 ↓ 0.248 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3657\t Score = 8.79\n",
            "🚂 Episode 3657\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3658\t Score = -22.619999999999997\n",
            "🚂 Episode 3658\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.065 ← 0.203 ↑ 0.098 → 0.046 ◼ 0.111 ↓ 0.477 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3659\t Score = 8.79\n",
            "🚂 Episode 3659\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3660\t Score = 8.79\n",
            "🚂 Episode 3660\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3661\t Score = 10.11\n",
            "🚂 Episode 3661\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.171 ↑ 0.400 → 0.286 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3662\t Score = 10.11\n",
            "🚂 Episode 3662\t 🏆 Score: 0.013 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.400 → 0.129 ◼ 0.357 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3663\t Score = -23.22\n",
            "🚂 Episode 3663\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.213 ↑ 0.074 → 0.415 ◼ 0.011 ↓ 0.266 \t Metric 0.397 \n",
            "Episode Nr. 3664\t Score = -23.22\n",
            "🚂 Episode 3664\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.255 ← 0.149 ↑ 0.245 → 0.234 ◼ 0.011 ↓ 0.106 \t Metric 0.397 \n",
            "Episode Nr. 3665\t Score = -22.619999999999997\n",
            "🚂 Episode 3665\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.242 ↑ 0.046 → 0.020 ◼ 0.052 ↓ 0.549 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3666\t Score = -23.22\n",
            "🚂 Episode 3666\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.500 ← 0.032 ↑ 0.351 → 0.085 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3667\t Score = -23.22\n",
            "🚂 Episode 3667\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.660 ↑ 0.074 → 0.202 ◼ 0.021 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3668\t Score = -22.619999999999997\n",
            "🚂 Episode 3668\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.065 ↑ 0.157 → 0.268 ◼ 0.007 ↓ 0.497 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3669\t Score = 8.79\n",
            "🚂 Episode 3669\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3670\t Score = -45.01999999999994\n",
            "🚂 Episode 3670\t 🏆 Score: -0.060 Avg: -0.013\t 💯 Done: 0.00% Avg: 32.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.635 ← 0.297 ↑ 0.030 → 0.030 ◼ 0.004 ↓ 0.004 \t Metric 0.39749999999999996 \n",
            "Episode Nr. 3671\t Score = -22.619999999999997\n",
            "🚂 Episode 3671\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.314 ← 0.216 ↑ 0.281 → 0.118 ◼ 0.013 ↓ 0.059 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3672\t Score = -23.520000000000003\n",
            "🚂 Episode 3672\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.448 ← 0.094 ↑ 0.281 → 0.052 ◼ 0.021 ↓ 0.104 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3673\t Score = 8.79\n",
            "🚂 Episode 3673\t 🏆 Score: 0.012 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3674\t Score = -23.22\n",
            "🚂 Episode 3674\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.117 ↑ 0.160 → 0.660 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3675\t Score = 10.11\n",
            "🚂 Episode 3675\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.200 → 0.629 ◼ 0.071 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3676\t Score = -22.619999999999997\n",
            "🚂 Episode 3676\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.346 ← 0.098 ↑ 0.333 → 0.065 ◼ 0.007 ↓ 0.150 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3677\t Score = 10.11\n",
            "🚂 Episode 3677\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.500 ↑ 0.214 → 0.143 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3678\t Score = -22.619999999999997\n",
            "🚂 Episode 3678\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.046 ← 0.026 ↑ 0.320 → 0.229 ◼ 0.065 ↓ 0.314 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3679\t Score = -23.22\n",
            "🚂 Episode 3679\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.787 ↑ 0.106 → 0.032 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3680\t Score = 10.11\n",
            "🚂 Episode 3680\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.229 → 0.271 ◼ 0.400 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3681\t Score = -22.619999999999997\n",
            "🚂 Episode 3681\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.209 ← 0.183 ↑ 0.111 → 0.209 ◼ 0.026 ↓ 0.261 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3682\t Score = -22.619999999999997\n",
            "🚂 Episode 3682\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.301 ← 0.163 ↑ 0.340 → 0.033 ◼ 0.033 ↓ 0.131 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3683\t Score = -22.619999999999997\n",
            "🚂 Episode 3683\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.111 ← 0.163 ↑ 0.399 → 0.183 ◼ 0.020 ↓ 0.124 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3684\t Score = -22.619999999999997\n",
            "🚂 Episode 3684\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.203 ← 0.163 ↑ 0.046 → 0.170 ◼ 0.105 ↓ 0.314 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3685\t Score = -102.53999999999999\n",
            "🚂 Episode 3685\t 🏆 Score: -0.137 Avg: -0.015\t 💯 Done: 0.00% Avg: 32.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.148 ← 0.494 ↑ 0.010 → 0.010 ◼ 0.158 ↓ 0.180 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3686\t Score = -23.22\n",
            "🚂 Episode 3686\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.468 ← 0.223 ↑ 0.138 → 0.117 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3687\t Score = 8.643333333333333\n",
            "🚂 Episode 3687\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3688\t Score = 10.11\n",
            "🚂 Episode 3688\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.229 → 0.600 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3689\t Score = -23.22\n",
            "🚂 Episode 3689\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.128 ↑ 0.170 → 0.638 ◼ 0.032 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3690\t Score = -22.619999999999997\n",
            "🚂 Episode 3690\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.405 ↑ 0.131 → 0.118 ◼ 0.007 ↓ 0.248 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3691\t Score = -23.22\n",
            "🚂 Episode 3691\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.532 ← 0.043 ↑ 0.287 → 0.117 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3692\t Score = -22.619999999999997\n",
            "🚂 Episode 3692\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.046 ← 0.379 ↑ 0.327 → 0.039 ◼ 0.078 ↓ 0.131 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3693\t Score = 8.643333333333333\n",
            "🚂 Episode 3693\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3694\t Score = 8.79\n",
            "🚂 Episode 3694\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3695\t Score = 10.11\n",
            "🚂 Episode 3695\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.243 → 0.614 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3696\t Score = 10.11\n",
            "🚂 Episode 3696\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.214 → 0.629 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3697\t Score = 8.79\n",
            "🚂 Episode 3697\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3698\t Score = -23.22\n",
            "🚂 Episode 3698\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.787 ↑ 0.128 → 0.032 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3699\t Score = -22.619999999999997\n",
            "🚂 Episode 3699\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.144 ↑ 0.131 → 0.235 ◼ 0.118 ↓ 0.346 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3700\t Score = -23.22\n",
            "🚂 Episode 3700\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.191 ← 0.372 ↑ 0.170 → 0.053 ◼ 0.202 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3701\t Score = 8.643333333333333\n",
            "🚂 Episode 3701\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3702\t Score = -23.22\n",
            "🚂 Episode 3702\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.287 ← 0.106 ↑ 0.160 → 0.426 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3703\t Score = 10.11\n",
            "🚂 Episode 3703\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.471 ↑ 0.371 → 0.071 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3704\t Score = -22.619999999999997\n",
            "🚂 Episode 3704\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.444 ↑ 0.052 → 0.144 ◼ 0.085 ↓ 0.255 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3705\t Score = -23.22\n",
            "🚂 Episode 3705\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.266 ↑ 0.170 → 0.181 ◼ 0.298 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 3706\t Score = -22.619999999999997\n",
            "🚂 Episode 3706\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.163 ← 0.222 ↑ 0.346 → 0.144 ◼ 0.026 ↓ 0.098 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3707\t Score = 10.11\n",
            "🚂 Episode 3707\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.186 → 0.643 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3708\t Score = 8.79\n",
            "🚂 Episode 3708\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3709\t Score = 8.643333333333333\n",
            "🚂 Episode 3709\t 🏆 Score: 0.012 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3710\t Score = 10.11\n",
            "🚂 Episode 3710\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.429 ↑ 0.286 → 0.186 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3711\t Score = -22.619999999999997\n",
            "🚂 Episode 3711\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.235 ← 0.294 ↑ 0.059 → 0.026 ◼ 0.007 ↓ 0.379 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3712\t Score = 10.11\n",
            "🚂 Episode 3712\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.214 → 0.357 ◼ 0.357 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3713\t Score = -23.22\n",
            "🚂 Episode 3713\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.298 ← 0.394 ↑ 0.128 → 0.043 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3714\t Score = 8.79\n",
            "🚂 Episode 3714\t 🏆 Score: 0.012 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3715\t Score = 10.11\n",
            "🚂 Episode 3715\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.214 → 0.600 ◼ 0.071 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3716\t Score = 10.11\n",
            "🚂 Episode 3716\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.014 ↑ 0.286 → 0.571 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3717\t Score = 8.79\n",
            "🚂 Episode 3717\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3718\t Score = 10.11\n",
            "🚂 Episode 3718\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.600 ↑ 0.214 → 0.071 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3719\t Score = -23.22\n",
            "🚂 Episode 3719\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.245 ↑ 0.064 → 0.053 ◼ 0.011 ↓ 0.521 \t Metric 0.397 \n",
            "Episode Nr. 3720\t Score = -22.619999999999997\n",
            "🚂 Episode 3720\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.314 ← 0.209 ↑ 0.340 → 0.026 ◼ 0.007 ↓ 0.105 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3721\t Score = -23.22\n",
            "🚂 Episode 3721\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.245 → 0.128 ◼ 0.415 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 3722\t Score = 8.79\n",
            "🚂 Episode 3722\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3723\t Score = -22.619999999999997\n",
            "🚂 Episode 3723\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.170 ↑ 0.118 → 0.229 ◼ 0.007 ↓ 0.392 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3724\t Score = -23.22\n",
            "🚂 Episode 3724\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.372 ↑ 0.096 → 0.426 ◼ 0.011 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 3725\t Score = 8.79\n",
            "🚂 Episode 3725\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3726\t Score = 8.79\n",
            "🚂 Episode 3726\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3727\t Score = 10.11\n",
            "🚂 Episode 3727\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.014 ↑ 0.471 → 0.071 ◼ 0.414 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3728\t Score = -23.22\n",
            "🚂 Episode 3728\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.383 ↑ 0.074 → 0.415 ◼ 0.096 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3729\t Score = -22.619999999999997\n",
            "🚂 Episode 3729\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.144 ← 0.137 ↑ 0.229 → 0.248 ◼ 0.007 ↓ 0.235 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3730\t Score = -23.22\n",
            "🚂 Episode 3730\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.383 ↑ 0.138 → 0.096 ◼ 0.351 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3731\t Score = 10.11\n",
            "🚂 Episode 3731\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.214 → 0.629 ◼ 0.086 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3732\t Score = -22.619999999999997\n",
            "🚂 Episode 3732\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.065 ← 0.373 ↑ 0.275 → 0.065 ◼ 0.072 ↓ 0.150 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3733\t Score = 10.11\n",
            "🚂 Episode 3733\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.071 ← 0.014 ↑ 0.214 → 0.600 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3734\t Score = 10.11\n",
            "🚂 Episode 3734\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.057 ↑ 0.200 → 0.571 ◼ 0.057 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3735\t Score = -22.619999999999997\n",
            "🚂 Episode 3735\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.314 ← 0.176 ↑ 0.098 → 0.078 ◼ 0.013 ↓ 0.320 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3736\t Score = -22.619999999999997\n",
            "🚂 Episode 3736\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.190 ← 0.150 ↑ 0.412 → 0.203 ◼ 0.007 ↓ 0.039 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3737\t Score = 10.11\n",
            "🚂 Episode 3737\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.071 ↑ 0.286 → 0.543 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3738\t Score = 10.11\n",
            "🚂 Episode 3738\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.071 ↑ 0.371 → 0.100 ◼ 0.414 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3739\t Score = -22.619999999999997\n",
            "🚂 Episode 3739\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.065 ← 0.379 ↑ 0.046 → 0.131 ◼ 0.124 ↓ 0.255 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3740\t Score = -23.22\n",
            "🚂 Episode 3740\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.298 ↑ 0.234 → 0.362 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3741\t Score = -23.22\n",
            "🚂 Episode 3741\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.160 ← 0.553 ↑ 0.074 → 0.138 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 3742\t Score = 10.11\n",
            "🚂 Episode 3742\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.200 → 0.686 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3743\t Score = 9.973333333333331\n",
            "🚂 Episode 3743\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.028 ← 0.125 ↑ 0.625 → 0.153 ◼ 0.056 ↓ 0.014 \t Metric 0.5935 \n",
            "Episode Nr. 3744\t Score = -23.22\n",
            "🚂 Episode 3744\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.128 ← 0.660 ↑ 0.085 → 0.106 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3745\t Score = -22.619999999999997\n",
            "🚂 Episode 3745\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.288 ← 0.111 ↑ 0.065 → 0.248 ◼ 0.013 ↓ 0.275 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3746\t Score = -22.619999999999997\n",
            "🚂 Episode 3746\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.144 ← 0.627 ↑ 0.131 → 0.026 ◼ 0.007 ↓ 0.065 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3747\t Score = -23.22\n",
            "🚂 Episode 3747\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.277 ↑ 0.138 → 0.319 ◼ 0.064 ↓ 0.181 \t Metric 0.397 \n",
            "Episode Nr. 3748\t Score = -105.01999999999994\n",
            "🚂 Episode 3748\t 🏆 Score: -0.140 Avg: -0.014\t 💯 Done: 0.00% Avg: 32.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.131 ← 0.309 ↑ 0.023 → 0.012 ◼ 0.069 ↓ 0.456 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3749\t Score = -22.619999999999997\n",
            "🚂 Episode 3749\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.216 ← 0.222 ↑ 0.092 → 0.118 ◼ 0.118 ↓ 0.235 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3750\t Score = -23.22\n",
            "🚂 Episode 3750\t 🏆 Score: -0.031 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.043 ↑ 0.245 → 0.649 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3751\t Score = -105.01999999999994\n",
            "🚂 Episode 3751\t 🏆 Score: -0.140 Avg: -0.015\t 💯 Done: 0.00% Avg: 32.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.012 ← 0.124 ↑ 0.019 → 0.440 ◼ 0.158 ↓ 0.247 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3752\t Score = 10.11\n",
            "🚂 Episode 3752\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.100 ↑ 0.200 → 0.586 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3753\t Score = -105.01999999999994\n",
            "🚂 Episode 3753\t 🏆 Score: -0.140 Avg: -0.016\t 💯 Done: 0.00% Avg: 31.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.668 ← 0.075 ↑ 0.211 → 0.029 ◼ 0.004 ↓ 0.014 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3754\t Score = -22.619999999999997\n",
            "🚂 Episode 3754\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 31.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.366 ↑ 0.118 → 0.059 ◼ 0.072 ↓ 0.379 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3755\t Score = -102.53999999999999\n",
            "🚂 Episode 3755\t 🏆 Score: -0.137 Avg: -0.018\t 💯 Done: 0.00% Avg: 31.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.148 ← 0.501 ↑ 0.008 → 0.095 ◼ 0.051 ↓ 0.197 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3756\t Score = 10.11\n",
            "🚂 Episode 3756\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.271 → 0.586 ◼ 0.071 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3757\t Score = 10.11\n",
            "🚂 Episode 3757\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.357 → 0.429 ◼ 0.157 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3758\t Score = -23.22\n",
            "🚂 Episode 3758\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.117 ← 0.553 ↑ 0.149 → 0.128 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3759\t Score = -22.619999999999997\n",
            "🚂 Episode 3759\t 🏆 Score: -0.030 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.170 ← 0.268 ↑ 0.137 → 0.176 ◼ 0.007 ↓ 0.242 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3760\t Score = 8.79\n",
            "🚂 Episode 3760\t 🏆 Score: 0.012 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3761\t Score = -23.22\n",
            "🚂 Episode 3761\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.160 ← 0.191 ↑ 0.064 → 0.479 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3762\t Score = 10.11\n",
            "🚂 Episode 3762\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.314 ↑ 0.214 → 0.400 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3763\t Score = 10.11\n",
            "🚂 Episode 3763\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.600 ↑ 0.229 → 0.057 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3764\t Score = 10.11\n",
            "🚂 Episode 3764\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 31.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.186 ↑ 0.243 → 0.443 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3765\t Score = 10.11\n",
            "🚂 Episode 3765\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 31.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.414 → 0.129 ◼ 0.371 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3766\t Score = -23.22\n",
            "🚂 Episode 3766\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 31.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.234 ← 0.479 ↑ 0.096 → 0.128 ◼ 0.053 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3767\t Score = -22.91\n",
            "🚂 Episode 3767\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 31.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.288 ← 0.115 ↑ 0.327 → 0.109 ◼ 0.013 ↓ 0.147 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 3768\t Score = -22.91\n",
            "🚂 Episode 3768\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 31.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.179 ← 0.186 ↑ 0.141 → 0.083 ◼ 0.147 ↓ 0.263 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 3769\t Score = -102.53999999999999\n",
            "🚂 Episode 3769\t 🏆 Score: -0.137 Avg: -0.018\t 💯 Done: 0.00% Avg: 31.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.346 ← 0.316 ↑ 0.010 → 0.030 ◼ 0.059 ↓ 0.239 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3770\t Score = 10.11\n",
            "🚂 Episode 3770\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.143 ↑ 0.229 → 0.471 ◼ 0.071 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3771\t Score = -22.619999999999997\n",
            "🚂 Episode 3771\t 🏆 Score: -0.030 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.281 ← 0.190 ↑ 0.157 → 0.150 ◼ 0.007 ↓ 0.216 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3772\t Score = 8.79\n",
            "🚂 Episode 3772\t 🏆 Score: 0.012 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3773\t Score = 10.11\n",
            "🚂 Episode 3773\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.014 ↑ 0.186 → 0.643 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3774\t Score = -105.01999999999994\n",
            "🚂 Episode 3774\t 🏆 Score: -0.140 Avg: -0.018\t 💯 Done: 0.00% Avg: 31.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.278 ↑ 0.023 → 0.259 ◼ 0.220 ↓ 0.212 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3775\t Score = -105.01999999999994\n",
            "🚂 Episode 3775\t 🏆 Score: -0.140 Avg: -0.019\t 💯 Done: 0.00% Avg: 30.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.151 ↑ 0.019 → 0.568 ◼ 0.008 ↓ 0.251 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3776\t Score = -105.01999999999994\n",
            "🚂 Episode 3776\t 🏆 Score: -0.140 Avg: -0.020\t 💯 Done: 0.00% Avg: 30.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.170 ← 0.282 ↑ 0.015 → 0.344 ◼ 0.185 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3777\t Score = 10.11\n",
            "🚂 Episode 3777\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.129 ↑ 0.229 → 0.257 ◼ 0.343 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3778\t Score = -105.01999999999994\n",
            "🚂 Episode 3778\t 🏆 Score: -0.140 Avg: -0.021\t 💯 Done: 0.00% Avg: 30.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.019 ← 0.004 ↑ 0.019 → 0.606 ◼ 0.004 ↓ 0.347 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3779\t Score = 10.11\n",
            "🚂 Episode 3779\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.229 → 0.600 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3780\t Score = -23.22\n",
            "🚂 Episode 3780\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.234 ← 0.351 ↑ 0.234 → 0.032 ◼ 0.011 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 3781\t Score = -105.01999999999994\n",
            "🚂 Episode 3781\t 🏆 Score: -0.140 Avg: -0.022\t 💯 Done: 0.00% Avg: 30.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.259 ↑ 0.023 → 0.228 ◼ 0.127 ↓ 0.359 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3782\t Score = 10.11\n",
            "🚂 Episode 3782\t 🏆 Score: 0.013 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.300 → 0.543 ◼ 0.071 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3783\t Score = -22.619999999999997\n",
            "🚂 Episode 3783\t 🏆 Score: -0.030 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.072 ← 0.281 ↑ 0.307 → 0.098 ◼ 0.078 ↓ 0.163 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3784\t Score = 10.11\n",
            "🚂 Episode 3784\t 🏆 Score: 0.013 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.200 → 0.643 ◼ 0.071 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3785\t Score = -23.22\n",
            "🚂 Episode 3785\t 🏆 Score: -0.031 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.14%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.511 ← 0.223 ↑ 0.117 → 0.128 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3786\t Score = -22.619999999999997\n",
            "🚂 Episode 3786\t 🏆 Score: -0.030 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.359 ← 0.065 ↑ 0.412 → 0.085 ◼ 0.020 ↓ 0.059 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3787\t Score = -22.619999999999997\n",
            "🚂 Episode 3787\t 🏆 Score: -0.030 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.118 ← 0.144 ↑ 0.137 → 0.333 ◼ 0.007 ↓ 0.261 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3788\t Score = -105.01999999999994\n",
            "🚂 Episode 3788\t 🏆 Score: -0.140 Avg: -0.023\t 💯 Done: 0.00% Avg: 29.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.162 ↑ 0.019 → 0.510 ◼ 0.301 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3789\t Score = -22.619999999999997\n",
            "🚂 Episode 3789\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 29.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.255 ← 0.052 ↑ 0.373 → 0.216 ◼ 0.007 ↓ 0.098 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3790\t Score = -105.01999999999994\n",
            "🚂 Episode 3790\t 🏆 Score: -0.140 Avg: -0.024\t 💯 Done: 0.00% Avg: 29.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.162 ↑ 0.008 → 0.131 ◼ 0.008 ↓ 0.683 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3791\t Score = -23.22\n",
            "🚂 Episode 3791\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 29.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.053 ← 0.394 ↑ 0.074 → 0.362 ◼ 0.011 ↓ 0.106 \t Metric 0.397 \n",
            "Episode Nr. 3792\t Score = 8.79\n",
            "🚂 Episode 3792\t 🏆 Score: 0.012 Avg: -0.024\t 💯 Done: 33.33% Avg: 29.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3793\t Score = -23.22\n",
            "🚂 Episode 3793\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 29.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.128 ↑ 0.191 → 0.032 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 3794\t Score = 10.11\n",
            "🚂 Episode 3794\t 🏆 Score: 0.013 Avg: -0.024\t 💯 Done: 33.33% Avg: 29.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.186 → 0.643 ◼ 0.071 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3795\t Score = 10.11\n",
            "🚂 Episode 3795\t 🏆 Score: 0.013 Avg: -0.023\t 💯 Done: 33.33% Avg: 29.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.014 ↑ 0.457 → 0.443 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3796\t Score = -102.53999999999999\n",
            "🚂 Episode 3796\t 🏆 Score: -0.137 Avg: -0.025\t 💯 Done: 0.00% Avg: 29.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.213 ← 0.409 ↑ 0.012 → 0.142 ◼ 0.097 ↓ 0.126 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3797\t Score = -23.520000000000003\n",
            "🚂 Episode 3797\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.198 ↑ 0.125 → 0.052 ◼ 0.021 ↓ 0.594 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3798\t Score = -105.01999999999994\n",
            "🚂 Episode 3798\t 🏆 Score: -0.140 Avg: -0.026\t 💯 Done: 0.00% Avg: 29.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.097 ← 0.591 ↑ 0.015 → 0.205 ◼ 0.008 ↓ 0.085 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3799\t Score = -23.22\n",
            "🚂 Episode 3799\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 29.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.468 ← 0.053 ↑ 0.287 → 0.085 ◼ 0.032 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 3800\t Score = 10.11\n",
            "🚂 Episode 3800\t 🏆 Score: 0.013 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.057 ↑ 0.257 → 0.600 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3801\t Score = 10.11\n",
            "🚂 Episode 3801\t 🏆 Score: 0.013 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.357 ↑ 0.157 → 0.343 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3802\t Score = -23.22\n",
            "🚂 Episode 3802\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.426 ← 0.191 ↑ 0.245 → 0.032 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3803\t Score = -23.22\n",
            "🚂 Episode 3803\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.138 ↑ 0.213 → 0.053 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3804\t Score = -105.01999999999994\n",
            "🚂 Episode 3804\t 🏆 Score: -0.140 Avg: -0.026\t 💯 Done: 0.00% Avg: 29.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.459 ↑ 0.023 → 0.019 ◼ 0.035 ↓ 0.456 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3805\t Score = 10.11\n",
            "🚂 Episode 3805\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 29.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.014 ↑ 0.400 → 0.429 ◼ 0.043 ↓ 0.100 \t Metric 0.5925 \n",
            "Episode Nr. 3806\t Score = -23.22\n",
            "🚂 Episode 3806\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 29.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.181 ← 0.585 ↑ 0.064 → 0.117 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3807\t Score = -23.22\n",
            "🚂 Episode 3807\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 29.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.277 ← 0.191 ↑ 0.096 → 0.330 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3808\t Score = -22.619999999999997\n",
            "🚂 Episode 3808\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 29.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.235 ← 0.229 ↑ 0.065 → 0.098 ◼ 0.007 ↓ 0.366 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3809\t Score = -105.01999999999994\n",
            "🚂 Episode 3809\t 🏆 Score: -0.140 Avg: -0.027\t 💯 Done: 0.00% Avg: 29.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.127 ↑ 0.019 → 0.494 ◼ 0.073 ↓ 0.278 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3810\t Score = -22.619999999999997\n",
            "🚂 Episode 3810\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 29.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.275 ← 0.157 ↑ 0.150 → 0.033 ◼ 0.098 ↓ 0.288 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3811\t Score = -105.01999999999994\n",
            "🚂 Episode 3811\t 🏆 Score: -0.140 Avg: -0.028\t 💯 Done: 0.00% Avg: 28.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.166 ← 0.224 ↑ 0.023 → 0.251 ◼ 0.004 ↓ 0.332 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3812\t Score = 10.11\n",
            "🚂 Episode 3812\t 🏆 Score: 0.013 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.271 → 0.386 ◼ 0.286 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3813\t Score = 8.79\n",
            "🚂 Episode 3813\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 28.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3814\t Score = -23.22\n",
            "🚂 Episode 3814\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.500 ← 0.160 ↑ 0.191 → 0.064 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 3815\t Score = -105.01999999999994\n",
            "🚂 Episode 3815\t 🏆 Score: -0.140 Avg: -0.029\t 💯 Done: 0.00% Avg: 28.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.208 ↑ 0.019 → 0.355 ◼ 0.100 ↓ 0.313 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3816\t Score = 8.79\n",
            "🚂 Episode 3816\t 🏆 Score: 0.012 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3817\t Score = -23.22\n",
            "🚂 Episode 3817\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.574 ↑ 0.191 → 0.138 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 3818\t Score = 10.11\n",
            "🚂 Episode 3818\t 🏆 Score: 0.013 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.243 → 0.629 ◼ 0.071 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3819\t Score = -23.22\n",
            "🚂 Episode 3819\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.436 ← 0.128 ↑ 0.213 → 0.181 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3820\t Score = -23.22\n",
            "🚂 Episode 3820\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.117 ← 0.574 ↑ 0.074 → 0.043 ◼ 0.011 ↓ 0.181 \t Metric 0.397 \n",
            "Episode Nr. 3821\t Score = -105.01999999999994\n",
            "🚂 Episode 3821\t 🏆 Score: -0.140 Avg: -0.029\t 💯 Done: 0.00% Avg: 28.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.533 ↑ 0.015 → 0.019 ◼ 0.004 ↓ 0.425 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3822\t Score = -22.619999999999997\n",
            "🚂 Episode 3822\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 28.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.216 ← 0.124 ↑ 0.092 → 0.085 ◼ 0.026 ↓ 0.458 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3823\t Score = -23.22\n",
            "🚂 Episode 3823\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 28.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.553 ← 0.149 ↑ 0.149 → 0.085 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3824\t Score = -22.619999999999997\n",
            "🚂 Episode 3824\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 28.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.301 ← 0.170 ↑ 0.431 → 0.020 ◼ 0.007 ↓ 0.072 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3825\t Score = 10.11\n",
            "🚂 Episode 3825\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 28.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.400 ↑ 0.229 → 0.257 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3826\t Score = -23.22\n",
            "🚂 Episode 3826\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 28.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.415 ← 0.149 ↑ 0.245 → 0.064 ◼ 0.011 ↓ 0.117 \t Metric 0.397 \n",
            "Episode Nr. 3827\t Score = -102.53999999999999\n",
            "🚂 Episode 3827\t 🏆 Score: -0.137 Avg: -0.030\t 💯 Done: 0.00% Avg: 28.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.215 ← 0.352 ↑ 0.010 → 0.275 ◼ 0.042 ↓ 0.107 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3828\t Score = 10.11\n",
            "🚂 Episode 3828\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 28.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.229 ↑ 0.214 → 0.429 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3829\t Score = -105.01999999999994\n",
            "🚂 Episode 3829\t 🏆 Score: -0.140 Avg: -0.030\t 💯 Done: 0.00% Avg: 28.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.220 ↑ 0.019 → 0.452 ◼ 0.174 ↓ 0.131 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3830\t Score = -105.01999999999994\n",
            "🚂 Episode 3830\t 🏆 Score: -0.140 Avg: -0.032\t 💯 Done: 0.00% Avg: 28.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.293 ↑ 0.023 → 0.529 ◼ 0.081 ↓ 0.069 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3831\t Score = 10.11\n",
            "🚂 Episode 3831\t 🏆 Score: 0.013 Avg: -0.031\t 💯 Done: 33.33% Avg: 28.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.257 → 0.386 ◼ 0.286 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3832\t Score = 8.79\n",
            "🚂 Episode 3832\t 🏆 Score: 0.012 Avg: -0.031\t 💯 Done: 33.33% Avg: 28.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3833\t Score = -22.619999999999997\n",
            "🚂 Episode 3833\t 🏆 Score: -0.030 Avg: -0.031\t 💯 Done: 33.33% Avg: 28.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.157 ← 0.072 ↑ 0.261 → 0.320 ◼ 0.020 ↓ 0.170 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3834\t Score = -105.01999999999994\n",
            "🚂 Episode 3834\t 🏆 Score: -0.140 Avg: -0.032\t 💯 Done: 0.00% Avg: 27.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.035 ← 0.081 ↑ 0.019 → 0.533 ◼ 0.004 ↓ 0.328 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3835\t Score = -22.619999999999997\n",
            "🚂 Episode 3835\t 🏆 Score: -0.030 Avg: -0.032\t 💯 Done: 33.33% Avg: 27.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.163 ← 0.288 ↑ 0.294 → 0.183 ◼ 0.033 ↓ 0.039 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3836\t Score = -105.01999999999994\n",
            "🚂 Episode 3836\t 🏆 Score: -0.140 Avg: -0.033\t 💯 Done: 0.00% Avg: 27.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.135 ↑ 0.023 → 0.012 ◼ 0.015 ↓ 0.776 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3837\t Score = 9.836666666666664\n",
            "🚂 Episode 3837\t 🏆 Score: 0.013 Avg: -0.032\t 💯 Done: 33.33% Avg: 27.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.568 ↑ 0.230 → 0.108 ◼ 0.054 ↓ 0.027 \t Metric 0.5935 \n",
            "Episode Nr. 3838\t Score = -22.619999999999997\n",
            "🚂 Episode 3838\t 🏆 Score: -0.030 Avg: -0.032\t 💯 Done: 33.33% Avg: 27.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.072 ← 0.216 ↑ 0.052 → 0.412 ◼ 0.013 ↓ 0.235 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3839\t Score = -105.01999999999994\n",
            "🚂 Episode 3839\t 🏆 Score: -0.140 Avg: -0.033\t 💯 Done: 0.00% Avg: 27.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.309 ↑ 0.019 → 0.259 ◼ 0.263 ↓ 0.143 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3840\t Score = 10.11\n",
            "🚂 Episode 3840\t 🏆 Score: 0.013 Avg: -0.033\t 💯 Done: 33.33% Avg: 27.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.586 ↑ 0.243 → 0.100 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3841\t Score = -105.01999999999994\n",
            "🚂 Episode 3841\t 🏆 Score: -0.140 Avg: -0.034\t 💯 Done: 0.00% Avg: 27.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.309 ↑ 0.019 → 0.012 ◼ 0.344 ↓ 0.313 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3842\t Score = -22.619999999999997\n",
            "🚂 Episode 3842\t 🏆 Score: -0.030 Avg: -0.034\t 💯 Done: 33.33% Avg: 27.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.320 ← 0.190 ↑ 0.098 → 0.209 ◼ 0.007 ↓ 0.176 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3843\t Score = 9.973333333333331\n",
            "🚂 Episode 3843\t 🏆 Score: 0.013 Avg: -0.033\t 💯 Done: 33.33% Avg: 27.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.028 ↑ 0.431 → 0.181 ◼ 0.333 ↓ 0.014 \t Metric 0.5935 \n",
            "Episode Nr. 3844\t Score = -22.619999999999997\n",
            "🚂 Episode 3844\t 🏆 Score: -0.030 Avg: -0.033\t 💯 Done: 33.33% Avg: 27.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.137 ← 0.327 ↑ 0.235 → 0.046 ◼ 0.078 ↓ 0.176 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3845\t Score = -105.01999999999994\n",
            "🚂 Episode 3845\t 🏆 Score: -0.140 Avg: -0.035\t 💯 Done: 0.00% Avg: 27.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.139 ↑ 0.027 → 0.174 ◼ 0.286 ↓ 0.336 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3846\t Score = -22.619999999999997\n",
            "🚂 Episode 3846\t 🏆 Score: -0.030 Avg: -0.034\t 💯 Done: 33.33% Avg: 27.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.190 ← 0.288 ↑ 0.157 → 0.118 ◼ 0.007 ↓ 0.242 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3847\t Score = -23.22\n",
            "🚂 Episode 3847\t 🏆 Score: -0.031 Avg: -0.034\t 💯 Done: 33.33% Avg: 27.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.596 ↑ 0.138 → 0.117 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3848\t Score = -23.22\n",
            "🚂 Episode 3848\t 🏆 Score: -0.031 Avg: -0.034\t 💯 Done: 33.33% Avg: 27.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.468 ← 0.053 ↑ 0.287 → 0.117 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 3849\t Score = -102.53999999999999\n",
            "🚂 Episode 3849\t 🏆 Score: -0.137 Avg: -0.035\t 💯 Done: 0.00% Avg: 27.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.198 ← 0.208 ↑ 0.010 → 0.178 ◼ 0.273 ↓ 0.134 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3850\t Score = -22.619999999999997\n",
            "🚂 Episode 3850\t 🏆 Score: -0.030 Avg: -0.035\t 💯 Done: 33.33% Avg: 27.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.176 ← 0.216 ↑ 0.261 → 0.092 ◼ 0.105 ↓ 0.150 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3851\t Score = 9.973333333333331\n",
            "🚂 Episode 3851\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 27.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.056 ↑ 0.181 → 0.667 ◼ 0.056 ↓ 0.028 \t Metric 0.5935 \n",
            "Episode Nr. 3852\t Score = -105.01999999999994\n",
            "🚂 Episode 3852\t 🏆 Score: -0.140 Avg: -0.036\t 💯 Done: 0.00% Avg: 26.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.081 ↑ 0.012 → 0.494 ◼ 0.189 ↓ 0.216 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3853\t Score = -23.22\n",
            "🚂 Episode 3853\t 🏆 Score: -0.031 Avg: -0.036\t 💯 Done: 33.33% Avg: 27.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.585 ↑ 0.074 → 0.043 ◼ 0.053 ↓ 0.234 \t Metric 0.397 \n",
            "Episode Nr. 3854\t Score = -102.53999999999999\n",
            "🚂 Episode 3854\t 🏆 Score: -0.137 Avg: -0.037\t 💯 Done: 0.00% Avg: 26.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.221 ← 0.281 ↑ 0.012 → 0.287 ◼ 0.134 ↓ 0.065 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3855\t Score = 10.11\n",
            "🚂 Episode 3855\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 26.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.286 ↑ 0.243 → 0.300 ◼ 0.114 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3856\t Score = -22.619999999999997\n",
            "🚂 Episode 3856\t 🏆 Score: -0.030 Avg: -0.036\t 💯 Done: 33.33% Avg: 26.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.052 ← 0.203 ↑ 0.235 → 0.268 ◼ 0.078 ↓ 0.163 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3857\t Score = 10.11\n",
            "🚂 Episode 3857\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 26.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.014 ↑ 0.186 → 0.657 ◼ 0.071 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3858\t Score = -102.53999999999999\n",
            "🚂 Episode 3858\t 🏆 Score: -0.137 Avg: -0.037\t 💯 Done: 0.00% Avg: 26.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.036 ← 0.275 ↑ 0.010 → 0.184 ◼ 0.275 ↓ 0.221 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3859\t Score = 8.79\n",
            "🚂 Episode 3859\t 🏆 Score: 0.012 Avg: -0.036\t 💯 Done: 33.33% Avg: 26.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3860\t Score = -23.22\n",
            "🚂 Episode 3860\t 🏆 Score: -0.031 Avg: -0.036\t 💯 Done: 33.33% Avg: 26.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.085 ↑ 0.245 → 0.096 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 3861\t Score = 10.11\n",
            "🚂 Episode 3861\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 26.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.457 ↑ 0.286 → 0.114 ◼ 0.043 ↓ 0.086 \t Metric 0.5925 \n",
            "Episode Nr. 3862\t Score = -102.53999999999999\n",
            "🚂 Episode 3862\t 🏆 Score: -0.137 Avg: -0.037\t 💯 Done: 0.00% Avg: 26.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.350 ← 0.346 ↑ 0.012 → 0.093 ◼ 0.055 ↓ 0.144 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3863\t Score = -105.01999999999994\n",
            "🚂 Episode 3863\t 🏆 Score: -0.140 Avg: -0.038\t 💯 Done: 0.00% Avg: 26.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.012 ← 0.459 ↑ 0.027 → 0.425 ◼ 0.004 ↓ 0.073 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3864\t Score = 10.11\n",
            "🚂 Episode 3864\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 26.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.214 → 0.657 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3865\t Score = 10.11\n",
            "🚂 Episode 3865\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 26.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.200 → 0.657 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3866\t Score = -102.53999999999999\n",
            "🚂 Episode 3866\t 🏆 Score: -0.137 Avg: -0.038\t 💯 Done: 0.00% Avg: 26.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.300 ← 0.237 ↑ 0.010 → 0.085 ◼ 0.302 ↓ 0.065 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3867\t Score = 10.11\n",
            "🚂 Episode 3867\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 26.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.386 ↑ 0.171 → 0.314 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3868\t Score = -22.619999999999997\n",
            "🚂 Episode 3868\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 26.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.320 ← 0.078 ↑ 0.418 → 0.085 ◼ 0.013 ↓ 0.085 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3869\t Score = -105.01999999999994\n",
            "🚂 Episode 3869\t 🏆 Score: -0.140 Avg: -0.038\t 💯 Done: 0.00% Avg: 26.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.054 ↑ 0.019 → 0.714 ◼ 0.023 ↓ 0.185 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3870\t Score = -102.53999999999999\n",
            "🚂 Episode 3870\t 🏆 Score: -0.137 Avg: -0.039\t 💯 Done: 0.00% Avg: 25.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.186 ← 0.172 ↑ 0.008 → 0.174 ◼ 0.243 ↓ 0.217 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3871\t Score = 10.11\n",
            "🚂 Episode 3871\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 25.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.371 → 0.500 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3872\t Score = 10.11\n",
            "🚂 Episode 3872\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.414 ↑ 0.443 → 0.057 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3873\t Score = -105.01999999999994\n",
            "🚂 Episode 3873\t 🏆 Score: -0.140 Avg: -0.039\t 💯 Done: 0.00% Avg: 25.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.263 ↑ 0.019 → 0.645 ◼ 0.004 ↓ 0.066 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3874\t Score = -23.22\n",
            "🚂 Episode 3874\t 🏆 Score: -0.031 Avg: -0.039\t 💯 Done: 33.33% Avg: 25.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.245 ← 0.191 ↑ 0.149 → 0.330 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 3875\t Score = 10.11\n",
            "🚂 Episode 3875\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 25.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.257 → 0.586 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3876\t Score = 8.79\n",
            "🚂 Episode 3876\t 🏆 Score: 0.012 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3877\t Score = 8.79\n",
            "🚂 Episode 3877\t 🏆 Score: 0.012 Avg: -0.038\t 💯 Done: 33.33% Avg: 26.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3878\t Score = -22.91\n",
            "🚂 Episode 3878\t 🏆 Score: -0.031 Avg: -0.038\t 💯 Done: 33.33% Avg: 26.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.346 ← 0.199 ↑ 0.115 → 0.026 ◼ 0.064 ↓ 0.250 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 3879\t Score = 10.11\n",
            "🚂 Episode 3879\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 26.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.329 → 0.171 ◼ 0.429 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3880\t Score = -105.01999999999994\n",
            "🚂 Episode 3880\t 🏆 Score: -0.140 Avg: -0.038\t 💯 Done: 0.00% Avg: 25.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.251 ↑ 0.023 → 0.398 ◼ 0.320 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3881\t Score = 10.11\n",
            "🚂 Episode 3881\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.214 → 0.600 ◼ 0.071 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3882\t Score = 10.11\n",
            "🚂 Episode 3882\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 26.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.186 → 0.629 ◼ 0.043 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3883\t Score = -22.619999999999997\n",
            "🚂 Episode 3883\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 26.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.078 ← 0.209 ↑ 0.144 → 0.353 ◼ 0.013 ↓ 0.203 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3884\t Score = -105.01999999999994\n",
            "🚂 Episode 3884\t 🏆 Score: -0.140 Avg: -0.038\t 💯 Done: 0.00% Avg: 25.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.154 ↑ 0.023 → 0.421 ◼ 0.162 ↓ 0.236 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3885\t Score = -105.01999999999994\n",
            "🚂 Episode 3885\t 🏆 Score: -0.140 Avg: -0.039\t 💯 Done: 0.00% Avg: 25.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.440 ↑ 0.012 → 0.290 ◼ 0.004 ↓ 0.251 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3886\t Score = 10.11\n",
            "🚂 Episode 3886\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.157 → 0.314 ◼ 0.429 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3887\t Score = -105.01999999999994\n",
            "🚂 Episode 3887\t 🏆 Score: -0.140 Avg: -0.040\t 💯 Done: 0.00% Avg: 25.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.282 ↑ 0.012 → 0.042 ◼ 0.220 ↓ 0.440 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3888\t Score = -22.619999999999997\n",
            "🚂 Episode 3888\t 🏆 Score: -0.030 Avg: -0.039\t 💯 Done: 33.33% Avg: 25.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.150 ← 0.059 ↑ 0.373 → 0.392 ◼ 0.007 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3889\t Score = -105.01999999999994\n",
            "🚂 Episode 3889\t 🏆 Score: -0.140 Avg: -0.040\t 💯 Done: 0.00% Avg: 25.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.135 ↑ 0.023 → 0.517 ◼ 0.004 ↓ 0.313 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3890\t Score = 10.11\n",
            "🚂 Episode 3890\t 🏆 Score: 0.013 Avg: -0.040\t 💯 Done: 33.33% Avg: 25.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.386 → 0.186 ◼ 0.329 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3891\t Score = -22.619999999999997\n",
            "🚂 Episode 3891\t 🏆 Score: -0.030 Avg: -0.040\t 💯 Done: 33.33% Avg: 25.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.118 ← 0.242 ↑ 0.150 → 0.229 ◼ 0.105 ↓ 0.157 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3892\t Score = -22.619999999999997\n",
            "🚂 Episode 3892\t 🏆 Score: -0.030 Avg: -0.040\t 💯 Done: 33.33% Avg: 25.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.301 ← 0.072 ↑ 0.392 → 0.085 ◼ 0.078 ↓ 0.072 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3893\t Score = -22.619999999999997\n",
            "🚂 Episode 3893\t 🏆 Score: -0.030 Avg: -0.040\t 💯 Done: 33.33% Avg: 25.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.065 ← 0.373 ↑ 0.105 → 0.190 ◼ 0.013 ↓ 0.255 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3894\t Score = 10.11\n",
            "🚂 Episode 3894\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 25.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.029 ↑ 0.214 → 0.429 ◼ 0.257 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3895\t Score = -105.01999999999994\n",
            "🚂 Episode 3895\t 🏆 Score: -0.140 Avg: -0.040\t 💯 Done: 0.00% Avg: 25.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.224 ← 0.104 ↑ 0.008 → 0.317 ◼ 0.282 ↓ 0.066 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3896\t Score = -105.01999999999994\n",
            "🚂 Episode 3896\t 🏆 Score: -0.140 Avg: -0.041\t 💯 Done: 0.00% Avg: 25.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.012 ← 0.282 ↑ 0.008 → 0.313 ◼ 0.324 ↓ 0.062 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3897\t Score = -105.01999999999994\n",
            "🚂 Episode 3897\t 🏆 Score: -0.140 Avg: -0.042\t 💯 Done: 0.00% Avg: 24.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.015 ↑ 0.019 → 0.857 ◼ 0.004 ↓ 0.100 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3898\t Score = -23.520000000000003\n",
            "🚂 Episode 3898\t 🏆 Score: -0.031 Avg: -0.042\t 💯 Done: 33.33% Avg: 24.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.062 ← 0.458 ↑ 0.052 → 0.219 ◼ 0.021 ↓ 0.188 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 3899\t Score = -105.01999999999994\n",
            "🚂 Episode 3899\t 🏆 Score: -0.140 Avg: -0.043\t 💯 Done: 0.00% Avg: 24.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.035 ← 0.282 ↑ 0.019 → 0.139 ◼ 0.058 ↓ 0.467 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3900\t Score = 10.11\n",
            "🚂 Episode 3900\t 🏆 Score: 0.013 Avg: -0.042\t 💯 Done: 33.33% Avg: 24.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.229 → 0.243 ◼ 0.457 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3901\t Score = -22.619999999999997\n",
            "🚂 Episode 3901\t 🏆 Score: -0.030 Avg: -0.042\t 💯 Done: 33.33% Avg: 24.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.111 ← 0.105 ↑ 0.281 → 0.418 ◼ 0.007 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3902\t Score = -105.01999999999994\n",
            "🚂 Episode 3902\t 🏆 Score: -0.140 Avg: -0.043\t 💯 Done: 0.00% Avg: 24.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.012 ← 0.529 ↑ 0.023 → 0.290 ◼ 0.008 ↓ 0.139 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3903\t Score = -105.01999999999994\n",
            "🚂 Episode 3903\t 🏆 Score: -0.140 Avg: -0.044\t 💯 Done: 0.00% Avg: 24.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.097 ← 0.328 ↑ 0.019 → 0.012 ◼ 0.197 ↓ 0.347 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3904\t Score = -22.619999999999997\n",
            "🚂 Episode 3904\t 🏆 Score: -0.030 Avg: -0.044\t 💯 Done: 33.33% Avg: 24.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.137 ← 0.268 ↑ 0.065 → 0.196 ◼ 0.072 ↓ 0.261 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3905\t Score = 10.11\n",
            "🚂 Episode 3905\t 🏆 Score: 0.013 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.214 → 0.614 ◼ 0.071 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3906\t Score = -23.22\n",
            "🚂 Episode 3906\t 🏆 Score: -0.031 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.500 ← 0.234 ↑ 0.106 → 0.138 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3907\t Score = 8.79\n",
            "🚂 Episode 3907\t 🏆 Score: 0.012 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3908\t Score = 8.79\n",
            "🚂 Episode 3908\t 🏆 Score: 0.012 Avg: -0.042\t 💯 Done: 33.33% Avg: 24.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3909\t Score = -105.01999999999994\n",
            "🚂 Episode 3909\t 🏆 Score: -0.140 Avg: -0.043\t 💯 Done: 0.00% Avg: 24.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.247 ↑ 0.019 → 0.440 ◼ 0.008 ↓ 0.278 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3910\t Score = -23.22\n",
            "🚂 Episode 3910\t 🏆 Score: -0.031 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.628 ↑ 0.096 → 0.213 ◼ 0.021 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 3911\t Score = 8.79\n",
            "🚂 Episode 3911\t 🏆 Score: 0.012 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3912\t Score = 10.11\n",
            "🚂 Episode 3912\t 🏆 Score: 0.013 Avg: -0.042\t 💯 Done: 33.33% Avg: 24.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.186 → 0.557 ◼ 0.143 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3913\t Score = -22.619999999999997\n",
            "🚂 Episode 3913\t 🏆 Score: -0.030 Avg: -0.042\t 💯 Done: 33.33% Avg: 24.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.137 ← 0.288 ↑ 0.052 → 0.124 ◼ 0.242 ↓ 0.157 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3914\t Score = -23.22\n",
            "🚂 Episode 3914\t 🏆 Score: -0.031 Avg: -0.042\t 💯 Done: 33.33% Avg: 25.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.479 ← 0.043 ↑ 0.287 → 0.096 ◼ 0.011 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 3915\t Score = 8.643333333333333\n",
            "🚂 Episode 3915\t 🏆 Score: 0.012 Avg: -0.041\t 💯 Done: 33.33% Avg: 25.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3916\t Score = -105.01999999999994\n",
            "🚂 Episode 3916\t 🏆 Score: -0.140 Avg: -0.042\t 💯 Done: 0.00% Avg: 24.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.320 ← 0.637 ↑ 0.012 → 0.019 ◼ 0.004 ↓ 0.008 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3917\t Score = -22.619999999999997\n",
            "🚂 Episode 3917\t 🏆 Score: -0.030 Avg: -0.042\t 💯 Done: 33.33% Avg: 24.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.144 ← 0.105 ↑ 0.144 → 0.275 ◼ 0.020 ↓ 0.314 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3918\t Score = -105.01999999999994\n",
            "🚂 Episode 3918\t 🏆 Score: -0.140 Avg: -0.043\t 💯 Done: 0.00% Avg: 24.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.224 ↑ 0.023 → 0.104 ◼ 0.097 ↓ 0.548 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3919\t Score = -105.01999999999994\n",
            "🚂 Episode 3919\t 🏆 Score: -0.140 Avg: -0.044\t 💯 Done: 0.00% Avg: 24.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.004 ↑ 0.023 → 0.382 ◼ 0.220 ↓ 0.363 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3920\t Score = 10.11\n",
            "🚂 Episode 3920\t 🏆 Score: 0.013 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.057 ↑ 0.329 → 0.486 ◼ 0.043 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3921\t Score = 10.11\n",
            "🚂 Episode 3921\t 🏆 Score: 0.013 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.329 ↑ 0.243 → 0.314 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3922\t Score = 8.79\n",
            "🚂 Episode 3922\t 🏆 Score: 0.012 Avg: -0.042\t 💯 Done: 33.33% Avg: 24.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3923\t Score = 10.11\n",
            "🚂 Episode 3923\t 🏆 Score: 0.013 Avg: -0.042\t 💯 Done: 33.33% Avg: 24.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.329 → 0.457 ◼ 0.071 ↓ 0.100 \t Metric 0.5925 \n",
            "Episode Nr. 3924\t Score = 10.11\n",
            "🚂 Episode 3924\t 🏆 Score: 0.013 Avg: -0.041\t 💯 Done: 33.33% Avg: 24.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.586 ↑ 0.200 → 0.043 ◼ 0.071 ↓ 0.086 \t Metric 0.5925 \n",
            "Episode Nr. 3925\t Score = -105.01999999999994\n",
            "🚂 Episode 3925\t 🏆 Score: -0.140 Avg: -0.042\t 💯 Done: 0.00% Avg: 24.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.259 ← 0.421 ↑ 0.015 → 0.166 ◼ 0.035 ↓ 0.104 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3926\t Score = -105.01999999999994\n",
            "🚂 Episode 3926\t 🏆 Score: -0.140 Avg: -0.043\t 💯 Done: 0.00% Avg: 24.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.162 ↑ 0.019 → 0.263 ◼ 0.004 ↓ 0.548 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3927\t Score = -23.22\n",
            "🚂 Episode 3927\t 🏆 Score: -0.031 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.117 ← 0.170 ↑ 0.245 → 0.404 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 3928\t Score = 10.11\n",
            "🚂 Episode 3928\t 🏆 Score: 0.013 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.200 → 0.657 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3929\t Score = -105.01999999999994\n",
            "🚂 Episode 3929\t 🏆 Score: -0.140 Avg: -0.044\t 💯 Done: 0.00% Avg: 24.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.332 ↑ 0.035 → 0.012 ◼ 0.162 ↓ 0.452 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3930\t Score = -105.01999999999994\n",
            "🚂 Episode 3930\t 🏆 Score: -0.140 Avg: -0.044\t 💯 Done: 0.00% Avg: 24.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.185 ← 0.174 ↑ 0.019 → 0.317 ◼ 0.089 ↓ 0.216 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3931\t Score = 10.11\n",
            "🚂 Episode 3931\t 🏆 Score: 0.013 Avg: -0.044\t 💯 Done: 33.33% Avg: 24.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.400 → 0.443 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3932\t Score = 10.11\n",
            "🚂 Episode 3932\t 🏆 Score: 0.013 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.243 → 0.600 ◼ 0.043 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3933\t Score = 10.11\n",
            "🚂 Episode 3933\t 🏆 Score: 0.013 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.314 → 0.543 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3934\t Score = -22.619999999999997\n",
            "🚂 Episode 3934\t 🏆 Score: -0.030 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.150 ← 0.268 ↑ 0.190 → 0.157 ◼ 0.007 ↓ 0.229 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3935\t Score = -102.53999999999999\n",
            "🚂 Episode 3935\t 🏆 Score: -0.137 Avg: -0.044\t 💯 Done: 0.00% Avg: 24.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.405 ← 0.227 ↑ 0.010 → 0.198 ◼ 0.097 ↓ 0.063 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3936\t Score = 8.79\n",
            "🚂 Episode 3936\t 🏆 Score: 0.012 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3937\t Score = -22.619999999999997\n",
            "🚂 Episode 3937\t 🏆 Score: -0.030 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.216 ← 0.111 ↑ 0.438 → 0.033 ◼ 0.092 ↓ 0.111 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3938\t Score = 8.496666666666664\n",
            "🚂 Episode 3938\t 🏆 Score: 0.011 Avg: -0.042\t 💯 Done: 33.33% Avg: 24.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.42714285714285716 \n",
            "Episode Nr. 3939\t Score = -23.22\n",
            "🚂 Episode 3939\t 🏆 Score: -0.031 Avg: -0.042\t 💯 Done: 33.33% Avg: 24.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.255 ← 0.245 ↑ 0.096 → 0.266 ◼ 0.011 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 3940\t Score = -105.01999999999994\n",
            "🚂 Episode 3940\t 🏆 Score: -0.140 Avg: -0.043\t 💯 Done: 0.00% Avg: 24.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.004 ↑ 0.012 → 0.363 ◼ 0.375 ↓ 0.243 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3941\t Score = 10.11\n",
            "🚂 Episode 3941\t 🏆 Score: 0.013 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.414 → 0.443 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3942\t Score = -22.619999999999997\n",
            "🚂 Episode 3942\t 🏆 Score: -0.030 Avg: -0.043\t 💯 Done: 33.33% Avg: 24.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.072 ← 0.346 ↑ 0.176 → 0.137 ◼ 0.007 ↓ 0.261 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3943\t Score = 8.79\n",
            "🚂 Episode 3943\t 🏆 Score: 0.012 Avg: -0.042\t 💯 Done: 33.33% Avg: 24.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3944\t Score = 10.11\n",
            "🚂 Episode 3944\t 🏆 Score: 0.013 Avg: -0.041\t 💯 Done: 33.33% Avg: 24.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.429 → 0.071 ◼ 0.414 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3945\t Score = -22.619999999999997\n",
            "🚂 Episode 3945\t 🏆 Score: -0.030 Avg: -0.041\t 💯 Done: 33.33% Avg: 24.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.248 ↑ 0.307 → 0.255 ◼ 0.105 ↓ 0.052 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3946\t Score = -22.619999999999997\n",
            "🚂 Episode 3946\t 🏆 Score: -0.030 Avg: -0.041\t 💯 Done: 33.33% Avg: 24.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.118 ← 0.353 ↑ 0.137 → 0.163 ◼ 0.013 ↓ 0.216 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3947\t Score = 10.11\n",
            "🚂 Episode 3947\t 🏆 Score: 0.013 Avg: -0.041\t 💯 Done: 33.33% Avg: 24.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.200 → 0.586 ◼ 0.071 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 3948\t Score = -23.22\n",
            "🚂 Episode 3948\t 🏆 Score: -0.031 Avg: -0.041\t 💯 Done: 33.33% Avg: 24.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.064 ← 0.181 ↑ 0.702 → 0.032 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3949\t Score = 8.79\n",
            "🚂 Episode 3949\t 🏆 Score: 0.012 Avg: -0.040\t 💯 Done: 33.33% Avg: 25.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3950\t Score = 10.11\n",
            "🚂 Episode 3950\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 25.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.157 → 0.671 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3951\t Score = 10.11\n",
            "🚂 Episode 3951\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 25.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.400 ↑ 0.429 → 0.057 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3952\t Score = -23.22\n",
            "🚂 Episode 3952\t 🏆 Score: -0.031 Avg: -0.039\t 💯 Done: 33.33% Avg: 25.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.245 ← 0.383 ↑ 0.213 → 0.106 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 3953\t Score = 10.11\n",
            "🚂 Episode 3953\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.157 → 0.671 ◼ 0.071 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3954\t Score = -102.53999999999999\n",
            "🚂 Episode 3954\t 🏆 Score: -0.137 Avg: -0.039\t 💯 Done: 0.00% Avg: 25.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.267 ← 0.245 ↑ 0.008 → 0.069 ◼ 0.109 ↓ 0.302 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3955\t Score = 8.79\n",
            "🚂 Episode 3955\t 🏆 Score: 0.012 Avg: -0.039\t 💯 Done: 33.33% Avg: 25.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3956\t Score = -22.619999999999997\n",
            "🚂 Episode 3956\t 🏆 Score: -0.030 Avg: -0.039\t 💯 Done: 33.33% Avg: 25.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.072 ← 0.131 ↑ 0.092 → 0.510 ◼ 0.007 ↓ 0.190 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3957\t Score = 10.11\n",
            "🚂 Episode 3957\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.243 → 0.257 ◼ 0.414 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3958\t Score = 10.11\n",
            "🚂 Episode 3958\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.171 ↑ 0.171 → 0.529 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3959\t Score = 8.79\n",
            "🚂 Episode 3959\t 🏆 Score: 0.012 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 3960\t Score = 10.11\n",
            "🚂 Episode 3960\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.386 ↑ 0.371 → 0.143 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3961\t Score = 8.496666666666664\n",
            "🚂 Episode 3961\t 🏆 Score: 0.011 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.42714285714285716 \n",
            "Episode Nr. 3962\t Score = -22.619999999999997\n",
            "🚂 Episode 3962\t 🏆 Score: -0.030 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.190 ← 0.222 ↑ 0.444 → 0.124 ◼ 0.007 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3963\t Score = 10.11\n",
            "🚂 Episode 3963\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.214 → 0.629 ◼ 0.071 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3964\t Score = -102.53999999999999\n",
            "🚂 Episode 3964\t 🏆 Score: -0.137 Avg: -0.037\t 💯 Done: 0.00% Avg: 25.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.289 ← 0.316 ↑ 0.010 → 0.180 ◼ 0.020 ↓ 0.186 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3965\t Score = 10.11\n",
            "🚂 Episode 3965\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.029 ↑ 0.186 → 0.643 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3966\t Score = 10.11\n",
            "🚂 Episode 3966\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.214 → 0.614 ◼ 0.086 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3967\t Score = 10.11\n",
            "🚂 Episode 3967\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 25.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.414 ↑ 0.457 → 0.057 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3968\t Score = -105.01999999999994\n",
            "🚂 Episode 3968\t 🏆 Score: -0.140 Avg: -0.036\t 💯 Done: 0.00% Avg: 25.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.012 ← 0.004 ↑ 0.008 → 0.332 ◼ 0.436 ↓ 0.208 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3969\t Score = -105.01999999999994\n",
            "🚂 Episode 3969\t 🏆 Score: -0.140 Avg: -0.037\t 💯 Done: 0.00% Avg: 25.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.012 ← 0.008 ↑ 0.015 → 0.124 ◼ 0.282 ↓ 0.560 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3970\t Score = 10.11\n",
            "🚂 Episode 3970\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.071 ← 0.029 ↑ 0.214 → 0.600 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3971\t Score = 10.11\n",
            "🚂 Episode 3971\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.071 ← 0.029 ↑ 0.214 → 0.629 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3972\t Score = -102.53999999999999\n",
            "🚂 Episode 3972\t 🏆 Score: -0.137 Avg: -0.037\t 💯 Done: 0.00% Avg: 25.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.283 ← 0.267 ↑ 0.018 → 0.134 ◼ 0.065 ↓ 0.233 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3973\t Score = -23.22\n",
            "🚂 Episode 3973\t 🏆 Score: -0.031 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.223 ↑ 0.064 → 0.500 ◼ 0.043 ↓ 0.160 \t Metric 0.397 \n",
            "Episode Nr. 3974\t Score = -102.53999999999999\n",
            "🚂 Episode 3974\t 🏆 Score: -0.137 Avg: -0.038\t 💯 Done: 0.00% Avg: 25.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.443 ↑ 0.004 → 0.097 ◼ 0.152 ↓ 0.273 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3975\t Score = 10.11\n",
            "🚂 Episode 3975\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.257 → 0.586 ◼ 0.086 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3976\t Score = -23.22\n",
            "🚂 Episode 3976\t 🏆 Score: -0.031 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.213 ↑ 0.074 → 0.681 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 3977\t Score = -22.619999999999997\n",
            "🚂 Episode 3977\t 🏆 Score: -0.030 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.373 ← 0.085 ↑ 0.111 → 0.163 ◼ 0.007 ↓ 0.261 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3978\t Score = -22.619999999999997\n",
            "🚂 Episode 3978\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.124 ← 0.229 ↑ 0.229 → 0.301 ◼ 0.026 ↓ 0.092 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3979\t Score = 10.11\n",
            "🚂 Episode 3979\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.071 ↑ 0.200 → 0.629 ◼ 0.071 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3980\t Score = -102.53999999999999\n",
            "🚂 Episode 3980\t 🏆 Score: -0.137 Avg: -0.038\t 💯 Done: 0.00% Avg: 25.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.130 ← 0.358 ↑ 0.006 → 0.144 ◼ 0.132 ↓ 0.229 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3981\t Score = 10.11\n",
            "🚂 Episode 3981\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.129 ↑ 0.186 → 0.286 ◼ 0.357 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3982\t Score = 10.11\n",
            "🚂 Episode 3982\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.229 → 0.657 ◼ 0.057 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3983\t Score = 10.11\n",
            "🚂 Episode 3983\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.343 → 0.557 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3984\t Score = -105.01999999999994\n",
            "🚂 Episode 3984\t 🏆 Score: -0.140 Avg: -0.037\t 💯 Done: 0.00% Avg: 25.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.448 ↑ 0.019 → 0.031 ◼ 0.162 ↓ 0.336 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3985\t Score = -105.01999999999994\n",
            "🚂 Episode 3985\t 🏆 Score: -0.140 Avg: -0.038\t 💯 Done: 0.00% Avg: 24.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.656 ↑ 0.019 → 0.313 ◼ 0.004 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3986\t Score = 10.11\n",
            "🚂 Episode 3986\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.143 ↑ 0.214 → 0.529 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3987\t Score = -102.53999999999999\n",
            "🚂 Episode 3987\t 🏆 Score: -0.137 Avg: -0.039\t 💯 Done: 0.00% Avg: 24.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.138 ← 0.385 ↑ 0.008 → 0.148 ◼ 0.168 ↓ 0.152 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3988\t Score = -23.22\n",
            "🚂 Episode 3988\t 🏆 Score: -0.031 Avg: -0.039\t 💯 Done: 33.33% Avg: 24.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.277 ↑ 0.096 → 0.319 ◼ 0.277 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3989\t Score = -23.22\n",
            "🚂 Episode 3989\t 🏆 Score: -0.031 Avg: -0.039\t 💯 Done: 33.33% Avg: 24.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.128 ← 0.191 ↑ 0.213 → 0.436 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 3990\t Score = 10.11\n",
            "🚂 Episode 3990\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.329 ↑ 0.271 → 0.243 ◼ 0.114 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 3991\t Score = -102.53999999999999\n",
            "🚂 Episode 3991\t 🏆 Score: -0.137 Avg: -0.039\t 💯 Done: 0.00% Avg: 24.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.176 ← 0.261 ↑ 0.004 → 0.204 ◼ 0.038 ↓ 0.318 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 3992\t Score = 10.11\n",
            "🚂 Episode 3992\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 24.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.186 → 0.629 ◼ 0.086 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 3993\t Score = 8.643333333333333\n",
            "🚂 Episode 3993\t 🏆 Score: 0.012 Avg: -0.038\t 💯 Done: 33.33% Avg: 24.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 3994\t Score = 10.11\n",
            "🚂 Episode 3994\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.229 → 0.229 ◼ 0.429 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 3995\t Score = -23.22\n",
            "🚂 Episode 3995\t 🏆 Score: -0.031 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.202 ← 0.457 ↑ 0.117 → 0.106 ◼ 0.021 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 3996\t Score = -105.01999999999994\n",
            "🚂 Episode 3996\t 🏆 Score: -0.140 Avg: -0.039\t 💯 Done: 0.00% Avg: 24.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.274 ↑ 0.019 → 0.220 ◼ 0.162 ↓ 0.317 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 3997\t Score = -22.619999999999997\n",
            "🚂 Episode 3997\t 🏆 Score: -0.030 Avg: -0.039\t 💯 Done: 33.33% Avg: 24.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.229 ← 0.131 ↑ 0.150 → 0.163 ◼ 0.007 ↓ 0.320 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 3998\t Score = 10.11\n",
            "🚂 Episode 3998\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.029 ↑ 0.200 → 0.629 ◼ 0.057 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 3999\t Score = 10.11\n",
            "🚂 Episode 3999\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.400 → 0.471 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4000\t Score = -105.01999999999994\n",
            "🚂 Episode 4000\t 🏆 Score: -0.140 Avg: -0.039\t 💯 Done: 0.00% Avg: 24.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.363 ↑ 0.019 → 0.197 ◼ 0.347 ↓ 0.069 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4001\t Score = -105.01999999999994\n",
            "🚂 Episode 4001\t 🏆 Score: -0.140 Avg: -0.040\t 💯 Done: 0.00% Avg: 24.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.459 ↑ 0.015 → 0.077 ◼ 0.120 ↓ 0.320 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4002\t Score = -22.619999999999997\n",
            "🚂 Episode 4002\t 🏆 Score: -0.030 Avg: -0.039\t 💯 Done: 33.33% Avg: 24.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.327 ← 0.098 ↑ 0.366 → 0.196 ◼ 0.007 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4003\t Score = -22.619999999999997\n",
            "🚂 Episode 4003\t 🏆 Score: -0.030 Avg: -0.039\t 💯 Done: 33.33% Avg: 24.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.209 ← 0.124 ↑ 0.137 → 0.288 ◼ 0.013 ↓ 0.229 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4004\t Score = 10.11\n",
            "🚂 Episode 4004\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 24.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.186 ↑ 0.414 → 0.229 ◼ 0.129 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4005\t Score = -22.619999999999997\n",
            "🚂 Episode 4005\t 🏆 Score: -0.030 Avg: -0.039\t 💯 Done: 33.33% Avg: 24.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.373 ← 0.118 ↑ 0.085 → 0.157 ◼ 0.007 ↓ 0.261 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4006\t Score = 10.11\n",
            "🚂 Episode 4006\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.357 → 0.529 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4007\t Score = 10.11\n",
            "🚂 Episode 4007\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.214 → 0.643 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4008\t Score = 10.11\n",
            "🚂 Episode 4008\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.229 ↑ 0.286 → 0.414 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4009\t Score = -23.520000000000003\n",
            "🚂 Episode 4009\t 🏆 Score: -0.031 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.083 ← 0.188 ↑ 0.094 → 0.531 ◼ 0.021 ↓ 0.083 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 4010\t Score = -22.619999999999997\n",
            "🚂 Episode 4010\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.078 ← 0.261 ↑ 0.242 → 0.203 ◼ 0.026 ↓ 0.190 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4011\t Score = -22.619999999999997\n",
            "🚂 Episode 4011\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.320 ← 0.137 ↑ 0.183 → 0.229 ◼ 0.046 ↓ 0.085 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4012\t Score = -22.619999999999997\n",
            "🚂 Episode 4012\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.235 ← 0.078 ↑ 0.327 → 0.327 ◼ 0.007 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4013\t Score = -22.619999999999997\n",
            "🚂 Episode 4013\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.268 ← 0.196 ↑ 0.248 → 0.229 ◼ 0.013 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4014\t Score = 10.11\n",
            "🚂 Episode 4014\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.071 ← 0.029 ↑ 0.171 → 0.671 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4015\t Score = 10.11\n",
            "🚂 Episode 4015\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.186 ↑ 0.214 → 0.500 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4016\t Score = 8.79\n",
            "🚂 Episode 4016\t 🏆 Score: 0.012 Avg: -0.035\t 💯 Done: 33.33% Avg: 25.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4017\t Score = -102.53999999999999\n",
            "🚂 Episode 4017\t 🏆 Score: -0.137 Avg: -0.036\t 💯 Done: 0.00% Avg: 25.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.229 ← 0.304 ↑ 0.036 → 0.128 ◼ 0.219 ↓ 0.083 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 4018\t Score = -102.53999999999999\n",
            "🚂 Episode 4018\t 🏆 Score: -0.137 Avg: -0.037\t 💯 Done: 0.00% Avg: 25.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.051 ← 0.350 ↑ 0.030 → 0.091 ◼ 0.150 ↓ 0.328 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 4019\t Score = -102.53999999999999\n",
            "🚂 Episode 4019\t 🏆 Score: -0.137 Avg: -0.038\t 💯 Done: 0.00% Avg: 25.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.051 ← 0.259 ↑ 0.049 → 0.221 ◼ 0.168 ↓ 0.251 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 4020\t Score = -22.619999999999997\n",
            "🚂 Episode 4020\t 🏆 Score: -0.030 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.301 ← 0.052 ↑ 0.444 → 0.176 ◼ 0.007 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4021\t Score = 8.79\n",
            "🚂 Episode 4021\t 🏆 Score: 0.012 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4022\t Score = -23.22\n",
            "🚂 Episode 4022\t 🏆 Score: -0.031 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.468 ← 0.202 ↑ 0.128 → 0.160 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 4023\t Score = -105.01999999999994\n",
            "🚂 Episode 4023\t 🏆 Score: -0.140 Avg: -0.039\t 💯 Done: 0.00% Avg: 25.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.344 ↑ 0.019 → 0.158 ◼ 0.004 ↓ 0.471 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4024\t Score = 10.11\n",
            "🚂 Episode 4024\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.14%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.186 ↑ 0.429 → 0.243 ◼ 0.086 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4025\t Score = 8.79\n",
            "🚂 Episode 4025\t 🏆 Score: 0.012 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4026\t Score = -105.01999999999994\n",
            "🚂 Episode 4026\t 🏆 Score: -0.140 Avg: -0.039\t 💯 Done: 0.00% Avg: 24.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.278 ↑ 0.019 → 0.514 ◼ 0.008 ↓ 0.178 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4027\t Score = 10.11\n",
            "🚂 Episode 4027\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.029 ↑ 0.386 → 0.471 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4028\t Score = -23.22\n",
            "🚂 Episode 4028\t 🏆 Score: -0.031 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.043 ↑ 0.319 → 0.128 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4029\t Score = 10.11\n",
            "🚂 Episode 4029\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.029 ↑ 0.200 → 0.629 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4030\t Score = -22.619999999999997\n",
            "🚂 Episode 4030\t 🏆 Score: -0.030 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.242 ← 0.078 ↑ 0.314 → 0.235 ◼ 0.020 ↓ 0.111 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4031\t Score = -23.22\n",
            "🚂 Episode 4031\t 🏆 Score: -0.031 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.340 ↑ 0.064 → 0.500 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 4032\t Score = 10.11\n",
            "🚂 Episode 4032\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.243 → 0.629 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4033\t Score = -22.619999999999997\n",
            "🚂 Episode 4033\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.183 ← 0.111 ↑ 0.072 → 0.477 ◼ 0.007 ↓ 0.150 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4034\t Score = -23.22\n",
            "🚂 Episode 4034\t 🏆 Score: -0.031 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.223 ↑ 0.043 → 0.064 ◼ 0.011 ↓ 0.170 \t Metric 0.397 \n",
            "Episode Nr. 4035\t Score = -23.22\n",
            "🚂 Episode 4035\t 🏆 Score: -0.031 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.457 ← 0.202 ↑ 0.096 → 0.160 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 4036\t Score = 10.11\n",
            "🚂 Episode 4036\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.086 ↑ 0.114 → 0.671 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4037\t Score = -105.01999999999994\n",
            "🚂 Episode 4037\t 🏆 Score: -0.140 Avg: -0.037\t 💯 Done: 0.00% Avg: 25.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.263 ↑ 0.008 → 0.189 ◼ 0.220 ↓ 0.313 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4038\t Score = -23.22\n",
            "🚂 Episode 4038\t 🏆 Score: -0.031 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.330 ← 0.340 ↑ 0.149 → 0.053 ◼ 0.011 ↓ 0.117 \t Metric 0.397 \n",
            "Episode Nr. 4039\t Score = -105.01999999999994\n",
            "🚂 Episode 4039\t 🏆 Score: -0.140 Avg: -0.038\t 💯 Done: 0.00% Avg: 25.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.208 ← 0.309 ↑ 0.023 → 0.266 ◼ 0.004 ↓ 0.189 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4040\t Score = -23.22\n",
            "🚂 Episode 4040\t 🏆 Score: -0.031 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.191 ↑ 0.085 → 0.511 ◼ 0.011 ↓ 0.117 \t Metric 0.397 \n",
            "Episode Nr. 4041\t Score = -23.22\n",
            "🚂 Episode 4041\t 🏆 Score: -0.031 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.638 ↑ 0.128 → 0.064 ◼ 0.011 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 4042\t Score = -102.53999999999999\n",
            "🚂 Episode 4042\t 🏆 Score: -0.137 Avg: -0.039\t 💯 Done: 0.00% Avg: 25.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.061 ↑ 0.132 → 0.150 ◼ 0.113 ↓ 0.486 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 4043\t Score = 10.11\n",
            "🚂 Episode 4043\t 🏆 Score: 0.013 Avg: -0.039\t 💯 Done: 33.33% Avg: 25.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.414 ↑ 0.429 → 0.057 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4044\t Score = 10.11\n",
            "🚂 Episode 4044\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.414 ↑ 0.243 → 0.229 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4045\t Score = 10.11\n",
            "🚂 Episode 4045\t 🏆 Score: 0.013 Avg: -0.038\t 💯 Done: 33.33% Avg: 25.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.229 → 0.614 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4046\t Score = 10.11\n",
            "🚂 Episode 4046\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.286 → 0.557 ◼ 0.057 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4047\t Score = -23.22\n",
            "🚂 Episode 4047\t 🏆 Score: -0.031 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.383 ← 0.234 ↑ 0.074 → 0.053 ◼ 0.128 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 4048\t Score = 8.79\n",
            "🚂 Episode 4048\t 🏆 Score: 0.012 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4049\t Score = 10.11\n",
            "🚂 Episode 4049\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.057 ↑ 0.286 → 0.571 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4050\t Score = -102.53999999999999\n",
            "🚂 Episode 4050\t 🏆 Score: -0.137 Avg: -0.037\t 💯 Done: 0.00% Avg: 25.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.180 ← 0.557 ↑ 0.014 → 0.079 ◼ 0.130 ↓ 0.040 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 4051\t Score = 10.11\n",
            "🚂 Episode 4051\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.257 ↑ 0.429 → 0.229 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4052\t Score = -105.01999999999994\n",
            "🚂 Episode 4052\t 🏆 Score: -0.140 Avg: -0.038\t 💯 Done: 0.00% Avg: 25.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.274 ↑ 0.019 → 0.413 ◼ 0.039 ↓ 0.251 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4053\t Score = 10.11\n",
            "🚂 Episode 4053\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.214 → 0.657 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4054\t Score = 8.79\n",
            "🚂 Episode 4054\t 🏆 Score: 0.012 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4055\t Score = 6.4799999999999995\n",
            "🚂 Episode 4055\t 🏆 Score: 0.009 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.173 ← 0.029 ↑ 0.154 → 0.433 ◼ 0.202 ↓ 0.010 \t Metric 0.594 \n",
            "Episode Nr. 4056\t Score = -105.01999999999994\n",
            "🚂 Episode 4056\t 🏆 Score: -0.140 Avg: -0.037\t 💯 Done: 0.00% Avg: 25.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.009 ← 0.073 ↑ 0.006 → 0.150 ◼ 0.760 ↓ 0.003 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4057\t Score = 10.11\n",
            "🚂 Episode 4057\t 🏆 Score: 0.013 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.186 → 0.729 ◼ 0.014 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4058\t Score = -22.619999999999997\n",
            "🚂 Episode 4058\t 🏆 Score: -0.030 Avg: -0.037\t 💯 Done: 33.33% Avg: 25.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.261 ← 0.098 ↑ 0.379 → 0.229 ◼ 0.007 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4059\t Score = 10.11\n",
            "🚂 Episode 4059\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.200 → 0.671 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4060\t Score = 8.79\n",
            "🚂 Episode 4060\t 🏆 Score: 0.012 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4061\t Score = -105.01999999999994\n",
            "🚂 Episode 4061\t 🏆 Score: -0.140 Avg: -0.037\t 💯 Done: 0.00% Avg: 25.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.158 ← 0.251 ↑ 0.019 → 0.510 ◼ 0.008 ↓ 0.054 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4062\t Score = 9.973333333333331\n",
            "🚂 Episode 4062\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.153 ↑ 0.375 → 0.389 ◼ 0.056 ↓ 0.014 \t Metric 0.593 \n",
            "Episode Nr. 4063\t Score = 10.11\n",
            "🚂 Episode 4063\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.486 ↑ 0.329 → 0.057 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4064\t Score = -102.53999999999999\n",
            "🚂 Episode 4064\t 🏆 Score: -0.137 Avg: -0.037\t 💯 Done: 0.00% Avg: 25.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.119 ← 0.364 ↑ 0.099 → 0.055 ◼ 0.156 ↓ 0.208 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 4065\t Score = 10.11\n",
            "🚂 Episode 4065\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.071 ← 0.029 ↑ 0.357 → 0.486 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4066\t Score = -22.619999999999997\n",
            "🚂 Episode 4066\t 🏆 Score: -0.030 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.294 ← 0.118 ↑ 0.170 → 0.235 ◼ 0.033 ↓ 0.150 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4067\t Score = 10.11\n",
            "🚂 Episode 4067\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.043 ↑ 0.186 → 0.671 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4068\t Score = -22.619999999999997\n",
            "🚂 Episode 4068\t 🏆 Score: -0.030 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.111 ← 0.105 ↑ 0.281 → 0.366 ◼ 0.007 ↓ 0.131 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4069\t Score = -23.22\n",
            "🚂 Episode 4069\t 🏆 Score: -0.031 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.138 ← 0.223 ↑ 0.468 → 0.138 ◼ 0.021 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4070\t Score = 10.11\n",
            "🚂 Episode 4070\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 25.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.171 → 0.686 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4071\t Score = 10.11\n",
            "🚂 Episode 4071\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 25.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.329 → 0.400 ◼ 0.143 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 4072\t Score = -23.22\n",
            "🚂 Episode 4072\t 🏆 Score: -0.031 Avg: -0.035\t 💯 Done: 33.33% Avg: 25.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.330 ← 0.074 ↑ 0.543 → 0.032 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4073\t Score = -105.01999999999994\n",
            "🚂 Episode 4073\t 🏆 Score: -0.140 Avg: -0.036\t 💯 Done: 0.00% Avg: 25.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.336 ← 0.239 ↑ 0.023 → 0.239 ◼ 0.158 ↓ 0.004 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4074\t Score = -102.53999999999999\n",
            "🚂 Episode 4074\t 🏆 Score: -0.137 Avg: -0.037\t 💯 Done: 0.00% Avg: 25.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.109 ← 0.332 ↑ 0.053 → 0.221 ◼ 0.051 ↓ 0.233 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 4075\t Score = 10.11\n",
            "🚂 Episode 4075\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.429 → 0.100 ◼ 0.386 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4076\t Score = 10.11\n",
            "🚂 Episode 4076\t 🏆 Score: 0.013 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.214 → 0.643 ◼ 0.071 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4077\t Score = -23.22\n",
            "🚂 Episode 4077\t 🏆 Score: -0.031 Avg: -0.036\t 💯 Done: 33.33% Avg: 25.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.106 ↑ 0.170 → 0.170 ◼ 0.011 ↓ 0.532 \t Metric 0.397 \n",
            "Episode Nr. 4078\t Score = 10.11\n",
            "🚂 Episode 4078\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 25.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.400 ↑ 0.457 → 0.071 ◼ 0.014 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4079\t Score = -23.22\n",
            "🚂 Episode 4079\t 🏆 Score: -0.031 Avg: -0.035\t 💯 Done: 33.33% Avg: 25.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.223 ↑ 0.160 → 0.489 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 4080\t Score = 10.11\n",
            "🚂 Episode 4080\t 🏆 Score: 0.013 Avg: -0.035\t 💯 Done: 33.33% Avg: 25.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.229 → 0.671 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4081\t Score = -23.22\n",
            "🚂 Episode 4081\t 🏆 Score: -0.031 Avg: -0.034\t 💯 Done: 33.33% Avg: 25.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.074 ↑ 0.277 → 0.128 ◼ 0.021 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4082\t Score = 10.11\n",
            "🚂 Episode 4082\t 🏆 Score: 0.013 Avg: -0.034\t 💯 Done: 33.33% Avg: 26.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.171 → 0.686 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4083\t Score = 10.11\n",
            "🚂 Episode 4083\t 🏆 Score: 0.013 Avg: -0.034\t 💯 Done: 33.33% Avg: 26.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.257 → 0.600 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4084\t Score = -22.619999999999997\n",
            "🚂 Episode 4084\t 🏆 Score: -0.030 Avg: -0.034\t 💯 Done: 33.33% Avg: 26.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.183 ← 0.261 ↑ 0.072 → 0.183 ◼ 0.007 ↓ 0.294 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4085\t Score = -23.22\n",
            "🚂 Episode 4085\t 🏆 Score: -0.031 Avg: -0.033\t 💯 Done: 33.33% Avg: 26.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.096 → 0.670 ◼ 0.032 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4086\t Score = -23.22\n",
            "🚂 Episode 4086\t 🏆 Score: -0.031 Avg: -0.033\t 💯 Done: 33.33% Avg: 26.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.415 ← 0.223 ↑ 0.309 → 0.032 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4087\t Score = -24.419999999999998\n",
            "🚂 Episode 4087\t 🏆 Score: -0.033 Avg: -0.033\t 💯 Done: 33.33% Avg: 26.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.280 ↑ 0.150 → 0.370 ◼ 0.010 ↓ 0.170 \t Metric 0.395 \n",
            "Episode Nr. 4088\t Score = 8.79\n",
            "🚂 Episode 4088\t 🏆 Score: 0.012 Avg: -0.033\t 💯 Done: 33.33% Avg: 26.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4089\t Score = -22.619999999999997\n",
            "🚂 Episode 4089\t 🏆 Score: -0.030 Avg: -0.033\t 💯 Done: 33.33% Avg: 26.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.150 ← 0.092 ↑ 0.549 → 0.183 ◼ 0.007 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4090\t Score = 8.79\n",
            "🚂 Episode 4090\t 🏆 Score: 0.012 Avg: -0.033\t 💯 Done: 33.33% Avg: 26.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4091\t Score = -23.22\n",
            "🚂 Episode 4091\t 🏆 Score: -0.031 Avg: -0.032\t 💯 Done: 33.33% Avg: 26.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.202 ↑ 0.128 → 0.074 ◼ 0.021 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 4092\t Score = -105.01999999999994\n",
            "🚂 Episode 4092\t 🏆 Score: -0.140 Avg: -0.034\t 💯 Done: 0.00% Avg: 26.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.220 ← 0.216 ↑ 0.012 → 0.046 ◼ 0.278 ↓ 0.228 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4093\t Score = 8.643333333333333\n",
            "🚂 Episode 4093\t 🏆 Score: 0.012 Avg: -0.033\t 💯 Done: 33.33% Avg: 26.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 4094\t Score = -22.619999999999997\n",
            "🚂 Episode 4094\t 🏆 Score: -0.030 Avg: -0.033\t 💯 Done: 33.33% Avg: 26.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.242 ← 0.072 ↑ 0.366 → 0.203 ◼ 0.007 ↓ 0.111 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4095\t Score = -23.22\n",
            "🚂 Episode 4095\t 🏆 Score: -0.031 Avg: -0.033\t 💯 Done: 33.33% Avg: 26.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.362 ← 0.191 ↑ 0.128 → 0.277 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 4096\t Score = -23.22\n",
            "🚂 Episode 4096\t 🏆 Score: -0.031 Avg: -0.033\t 💯 Done: 33.33% Avg: 26.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.213 ↑ 0.053 → 0.447 ◼ 0.011 ↓ 0.266 \t Metric 0.397 \n",
            "Episode Nr. 4097\t Score = 10.11\n",
            "🚂 Episode 4097\t 🏆 Score: 0.013 Avg: -0.033\t 💯 Done: 33.33% Avg: 26.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.471 → 0.357 ◼ 0.114 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4098\t Score = 10.11\n",
            "🚂 Episode 4098\t 🏆 Score: 0.013 Avg: -0.032\t 💯 Done: 33.33% Avg: 26.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.200 → 0.586 ◼ 0.114 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4099\t Score = 10.11\n",
            "🚂 Episode 4099\t 🏆 Score: 0.013 Avg: -0.032\t 💯 Done: 33.33% Avg: 26.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.171 → 0.686 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4100\t Score = 8.79\n",
            "🚂 Episode 4100\t 🏆 Score: 0.012 Avg: -0.031\t 💯 Done: 33.33% Avg: 26.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4101\t Score = -22.619999999999997\n",
            "🚂 Episode 4101\t 🏆 Score: -0.030 Avg: -0.031\t 💯 Done: 33.33% Avg: 26.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.157 ← 0.203 ↑ 0.183 → 0.431 ◼ 0.007 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4102\t Score = -102.53999999999999\n",
            "🚂 Episode 4102\t 🏆 Score: -0.137 Avg: -0.032\t 💯 Done: 0.00% Avg: 26.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.134 ← 0.294 ↑ 0.176 → 0.125 ◼ 0.020 ↓ 0.251 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 4103\t Score = 10.11\n",
            "🚂 Episode 4103\t 🏆 Score: 0.013 Avg: -0.032\t 💯 Done: 33.33% Avg: 26.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.443 → 0.057 ◼ 0.429 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4104\t Score = 10.11\n",
            "🚂 Episode 4104\t 🏆 Score: 0.013 Avg: -0.031\t 💯 Done: 33.33% Avg: 26.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.286 ↑ 0.200 → 0.329 ◼ 0.100 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4105\t Score = 8.79\n",
            "🚂 Episode 4105\t 🏆 Score: 0.012 Avg: -0.031\t 💯 Done: 33.33% Avg: 26.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4106\t Score = -22.619999999999997\n",
            "🚂 Episode 4106\t 🏆 Score: -0.030 Avg: -0.031\t 💯 Done: 33.33% Avg: 26.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.242 ← 0.124 ↑ 0.281 → 0.294 ◼ 0.007 ↓ 0.052 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4107\t Score = 10.11\n",
            "🚂 Episode 4107\t 🏆 Score: 0.013 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.229 → 0.629 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4108\t Score = -23.22\n",
            "🚂 Episode 4108\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.574 ↑ 0.043 → 0.191 ◼ 0.011 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 4109\t Score = -23.22\n",
            "🚂 Episode 4109\t 🏆 Score: -0.031 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.479 ← 0.160 ↑ 0.074 → 0.085 ◼ 0.011 ↓ 0.191 \t Metric 0.397 \n",
            "Episode Nr. 4110\t Score = 8.79\n",
            "🚂 Episode 4110\t 🏆 Score: 0.012 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4111\t Score = 10.11\n",
            "🚂 Episode 4111\t 🏆 Score: 0.013 Avg: -0.030\t 💯 Done: 33.33% Avg: 27.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.414 → 0.086 ◼ 0.429 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4112\t Score = 10.11\n",
            "🚂 Episode 4112\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.329 → 0.557 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4113\t Score = 10.11\n",
            "🚂 Episode 4113\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.457 → 0.214 ◼ 0.271 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4114\t Score = -105.01999999999994\n",
            "🚂 Episode 4114\t 🏆 Score: -0.140 Avg: -0.030\t 💯 Done: 0.00% Avg: 27.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.097 ↑ 0.019 → 0.228 ◼ 0.035 ↓ 0.618 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4115\t Score = 10.11\n",
            "🚂 Episode 4115\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.214 → 0.629 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4116\t Score = 8.79\n",
            "🚂 Episode 4116\t 🏆 Score: 0.012 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4117\t Score = -23.22\n",
            "🚂 Episode 4117\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.319 ← 0.085 ↑ 0.394 → 0.160 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 4118\t Score = 10.11\n",
            "🚂 Episode 4118\t 🏆 Score: 0.013 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.371 → 0.514 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4119\t Score = -23.22\n",
            "🚂 Episode 4119\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.436 ↑ 0.160 → 0.351 ◼ 0.021 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4120\t Score = -22.619999999999997\n",
            "🚂 Episode 4120\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.327 ← 0.288 ↑ 0.072 → 0.124 ◼ 0.007 ↓ 0.183 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4121\t Score = -23.22\n",
            "🚂 Episode 4121\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.191 ↑ 0.149 → 0.596 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4122\t Score = -23.22\n",
            "🚂 Episode 4122\t 🏆 Score: -0.031 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.287 ↑ 0.245 → 0.255 ◼ 0.011 ↓ 0.181 \t Metric 0.397 \n",
            "Episode Nr. 4123\t Score = -22.619999999999997\n",
            "🚂 Episode 4123\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.105 ← 0.222 ↑ 0.131 → 0.333 ◼ 0.007 ↓ 0.203 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4124\t Score = -22.619999999999997\n",
            "🚂 Episode 4124\t 🏆 Score: -0.030 Avg: -0.029\t 💯 Done: 33.33% Avg: 27.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.288 ← 0.170 ↑ 0.144 → 0.333 ◼ 0.007 ↓ 0.059 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4125\t Score = 10.11\n",
            "🚂 Episode 4125\t 🏆 Score: 0.013 Avg: -0.028\t 💯 Done: 33.33% Avg: 27.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.429 ↑ 0.157 → 0.300 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4126\t Score = -23.22\n",
            "🚂 Episode 4126\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 27.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.202 ← 0.202 ↑ 0.096 → 0.426 ◼ 0.043 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 4127\t Score = 10.11\n",
            "🚂 Episode 4127\t 🏆 Score: 0.013 Avg: -0.028\t 💯 Done: 33.33% Avg: 27.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.457 → 0.057 ◼ 0.429 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4128\t Score = 10.11\n",
            "🚂 Episode 4128\t 🏆 Score: 0.013 Avg: -0.028\t 💯 Done: 33.33% Avg: 27.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.443 → 0.071 ◼ 0.429 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4129\t Score = -23.22\n",
            "🚂 Episode 4129\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.372 ← 0.362 ↑ 0.106 → 0.138 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4130\t Score = 10.11\n",
            "🚂 Episode 4130\t 🏆 Score: 0.013 Avg: -0.027\t 💯 Done: 33.33% Avg: 28.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.057 ↑ 0.171 → 0.657 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4131\t Score = 10.11\n",
            "🚂 Episode 4131\t 🏆 Score: 0.013 Avg: -0.027\t 💯 Done: 33.33% Avg: 28.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.400 → 0.071 ◼ 0.429 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4132\t Score = -105.01999999999994\n",
            "🚂 Episode 4132\t 🏆 Score: -0.140 Avg: -0.028\t 💯 Done: 0.00% Avg: 27.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.008 ← 0.784 ↑ 0.019 → 0.012 ◼ 0.004 ↓ 0.174 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4133\t Score = 10.11\n",
            "🚂 Episode 4133\t 🏆 Score: 0.013 Avg: -0.027\t 💯 Done: 33.33% Avg: 27.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.057 ↑ 0.386 → 0.443 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4134\t Score = -22.91\n",
            "🚂 Episode 4134\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 27.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.327 ↑ 0.096 → 0.199 ◼ 0.128 ↓ 0.237 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 4135\t Score = -22.619999999999997\n",
            "🚂 Episode 4135\t 🏆 Score: -0.030 Avg: -0.028\t 💯 Done: 33.33% Avg: 27.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.124 ← 0.137 ↑ 0.261 → 0.412 ◼ 0.007 ↓ 0.059 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4136\t Score = -23.22\n",
            "🚂 Episode 4136\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.553 ↑ 0.064 → 0.309 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 4137\t Score = -23.22\n",
            "🚂 Episode 4137\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.043 ↑ 0.245 → 0.213 ◼ 0.479 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4138\t Score = -23.22\n",
            "🚂 Episode 4138\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.202 ↑ 0.553 → 0.106 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 4139\t Score = -23.22\n",
            "🚂 Episode 4139\t 🏆 Score: -0.031 Avg: -0.028\t 💯 Done: 33.33% Avg: 28.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.128 ↑ 0.138 → 0.234 ◼ 0.011 ↓ 0.468 \t Metric 0.397 \n",
            "Episode Nr. 4140\t Score = 8.79\n",
            "🚂 Episode 4140\t 🏆 Score: 0.012 Avg: -0.027\t 💯 Done: 33.33% Avg: 28.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4141\t Score = -23.22\n",
            "🚂 Episode 4141\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 28.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.298 ← 0.149 ↑ 0.128 → 0.234 ◼ 0.064 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 4142\t Score = -23.22\n",
            "🚂 Episode 4142\t 🏆 Score: -0.031 Avg: -0.027\t 💯 Done: 33.33% Avg: 28.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.351 ↑ 0.266 → 0.032 ◼ 0.330 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4143\t Score = -22.619999999999997\n",
            "🚂 Episode 4143\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 28.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.281 ↑ 0.052 → 0.163 ◼ 0.033 ↓ 0.464 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4144\t Score = 10.11\n",
            "🚂 Episode 4144\t 🏆 Score: 0.013 Avg: -0.027\t 💯 Done: 33.33% Avg: 28.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.029 ↑ 0.386 → 0.471 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4145\t Score = -22.619999999999997\n",
            "🚂 Episode 4145\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 28.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.301 ← 0.150 ↑ 0.294 → 0.196 ◼ 0.013 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4146\t Score = 10.11\n",
            "🚂 Episode 4146\t 🏆 Score: 0.013 Avg: -0.027\t 💯 Done: 33.33% Avg: 28.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.029 ↑ 0.214 → 0.614 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4147\t Score = -22.619999999999997\n",
            "🚂 Episode 4147\t 🏆 Score: -0.030 Avg: -0.027\t 💯 Done: 33.33% Avg: 28.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.320 ← 0.137 ↑ 0.294 → 0.209 ◼ 0.013 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4148\t Score = 10.11\n",
            "🚂 Episode 4148\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 28.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.029 ↑ 0.171 → 0.686 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4149\t Score = -22.619999999999997\n",
            "🚂 Episode 4149\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 28.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.046 ↑ 0.503 → 0.301 ◼ 0.007 ↓ 0.059 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4150\t Score = 10.11\n",
            "🚂 Episode 4150\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 28.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.043 ↑ 0.143 → 0.657 ◼ 0.043 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 4151\t Score = -23.22\n",
            "🚂 Episode 4151\t 🏆 Score: -0.031 Avg: -0.026\t 💯 Done: 33.33% Avg: 28.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.287 ← 0.521 ↑ 0.085 → 0.053 ◼ 0.021 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 4152\t Score = -24.419999999999998\n",
            "🚂 Episode 4152\t 🏆 Score: -0.033 Avg: -0.026\t 💯 Done: 33.33% Avg: 28.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.160 ← 0.290 ↑ 0.150 → 0.380 ◼ 0.010 ↓ 0.010 \t Metric 0.395 \n",
            "Episode Nr. 4153\t Score = 10.11\n",
            "🚂 Episode 4153\t 🏆 Score: 0.013 Avg: -0.026\t 💯 Done: 33.33% Avg: 28.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.057 ↑ 0.200 → 0.614 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4154\t Score = -22.619999999999997\n",
            "🚂 Episode 4154\t 🏆 Score: -0.030 Avg: -0.026\t 💯 Done: 33.33% Avg: 28.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.137 ↑ 0.190 → 0.529 ◼ 0.013 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4155\t Score = 8.79\n",
            "🚂 Episode 4155\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 28.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4156\t Score = -22.619999999999997\n",
            "🚂 Episode 4156\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.405 ← 0.078 ↑ 0.137 → 0.150 ◼ 0.007 ↓ 0.222 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4157\t Score = 10.11\n",
            "🚂 Episode 4157\t 🏆 Score: 0.013 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.200 → 0.600 ◼ 0.114 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4158\t Score = -22.619999999999997\n",
            "🚂 Episode 4158\t 🏆 Score: -0.030 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.582 ↑ 0.346 → 0.033 ◼ 0.007 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4159\t Score = -22.91\n",
            "🚂 Episode 4159\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.135 ← 0.288 ↑ 0.071 → 0.365 ◼ 0.045 ↓ 0.096 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 4160\t Score = -23.22\n",
            "🚂 Episode 4160\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.479 ↑ 0.085 → 0.053 ◼ 0.319 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 4161\t Score = -23.22\n",
            "🚂 Episode 4161\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.468 ← 0.149 ↑ 0.245 → 0.032 ◼ 0.011 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 4162\t Score = -23.22\n",
            "🚂 Episode 4162\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.489 ↑ 0.096 → 0.340 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 4163\t Score = 10.11\n",
            "🚂 Episode 4163\t 🏆 Score: 0.013 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.386 → 0.257 ◼ 0.257 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4164\t Score = -23.22\n",
            "🚂 Episode 4164\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.574 ↑ 0.170 → 0.191 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 4165\t Score = 10.11\n",
            "🚂 Episode 4165\t 🏆 Score: 0.013 Avg: -0.024\t 💯 Done: 33.33% Avg: 29.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.100 ↑ 0.243 → 0.557 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4166\t Score = 8.79\n",
            "🚂 Episode 4166\t 🏆 Score: 0.012 Avg: -0.024\t 💯 Done: 33.33% Avg: 29.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4167\t Score = -105.01999999999994\n",
            "🚂 Episode 4167\t 🏆 Score: -0.140 Avg: -0.025\t 💯 Done: 0.00% Avg: 29.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.004 ← 0.317 ↑ 0.023 → 0.046 ◼ 0.483 ↓ 0.127 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4168\t Score = 8.643333333333333\n",
            "🚂 Episode 4168\t 🏆 Score: 0.012 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 4169\t Score = 10.11\n",
            "🚂 Episode 4169\t 🏆 Score: 0.013 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.243 → 0.657 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4170\t Score = -23.22\n",
            "🚂 Episode 4170\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.160 ← 0.564 ↑ 0.053 → 0.181 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 4171\t Score = -23.22\n",
            "🚂 Episode 4171\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.160 ↑ 0.085 → 0.266 ◼ 0.011 ↓ 0.468 \t Metric 0.397 \n",
            "Episode Nr. 4172\t Score = -23.22\n",
            "🚂 Episode 4172\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.128 ↑ 0.138 → 0.043 ◼ 0.011 ↓ 0.670 \t Metric 0.397 \n",
            "Episode Nr. 4173\t Score = -23.22\n",
            "🚂 Episode 4173\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.500 ↑ 0.117 → 0.074 ◼ 0.011 ↓ 0.287 \t Metric 0.397 \n",
            "Episode Nr. 4174\t Score = 10.11\n",
            "🚂 Episode 4174\t 🏆 Score: 0.013 Avg: -0.024\t 💯 Done: 33.33% Avg: 29.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.214 → 0.643 ◼ 0.071 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4175\t Score = -22.619999999999997\n",
            "🚂 Episode 4175\t 🏆 Score: -0.030 Avg: -0.024\t 💯 Done: 33.33% Avg: 29.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.137 ← 0.170 ↑ 0.235 → 0.373 ◼ 0.007 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4176\t Score = -23.22\n",
            "🚂 Episode 4176\t 🏆 Score: -0.031 Avg: -0.025\t 💯 Done: 33.33% Avg: 29.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.096 → 0.202 ◼ 0.479 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4177\t Score = 10.11\n",
            "🚂 Episode 4177\t 🏆 Score: 0.013 Avg: -0.024\t 💯 Done: 33.33% Avg: 29.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.243 → 0.629 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4178\t Score = -23.22\n",
            "🚂 Episode 4178\t 🏆 Score: -0.031 Avg: -0.024\t 💯 Done: 33.33% Avg: 29.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.277 ← 0.213 ↑ 0.074 → 0.351 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 4179\t Score = 8.643333333333333\n",
            "🚂 Episode 4179\t 🏆 Score: 0.012 Avg: -0.024\t 💯 Done: 33.33% Avg: 29.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 4180\t Score = 10.11\n",
            "🚂 Episode 4180\t 🏆 Score: 0.013 Avg: -0.023\t 💯 Done: 33.33% Avg: 29.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.386 ↑ 0.400 → 0.100 ◼ 0.057 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4181\t Score = 10.11\n",
            "🚂 Episode 4181\t 🏆 Score: 0.013 Avg: -0.023\t 💯 Done: 33.33% Avg: 29.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.386 ↑ 0.400 → 0.114 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4182\t Score = -22.619999999999997\n",
            "🚂 Episode 4182\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 29.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.163 ↑ 0.471 → 0.170 ◼ 0.085 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4183\t Score = -23.22\n",
            "🚂 Episode 4183\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 29.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.223 ← 0.309 ↑ 0.064 → 0.245 ◼ 0.011 ↓ 0.149 \t Metric 0.397 \n",
            "Episode Nr. 4184\t Score = 10.11\n",
            "🚂 Episode 4184\t 🏆 Score: 0.013 Avg: -0.023\t 💯 Done: 33.33% Avg: 29.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.443 → 0.443 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4185\t Score = 10.11\n",
            "🚂 Episode 4185\t 🏆 Score: 0.013 Avg: -0.023\t 💯 Done: 33.33% Avg: 29.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.271 → 0.614 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4186\t Score = -22.619999999999997\n",
            "🚂 Episode 4186\t 🏆 Score: -0.030 Avg: -0.023\t 💯 Done: 33.33% Avg: 29.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.196 ↑ 0.065 → 0.438 ◼ 0.013 ↓ 0.196 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4187\t Score = -23.22\n",
            "🚂 Episode 4187\t 🏆 Score: -0.031 Avg: -0.023\t 💯 Done: 33.33% Avg: 29.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.691 ↑ 0.064 → 0.032 ◼ 0.011 ↓ 0.191 \t Metric 0.397 \n",
            "Episode Nr. 4188\t Score = 10.11\n",
            "🚂 Episode 4188\t 🏆 Score: 0.013 Avg: -0.022\t 💯 Done: 33.33% Avg: 29.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.214 → 0.671 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4189\t Score = 10.11\n",
            "🚂 Episode 4189\t 🏆 Score: 0.013 Avg: -0.022\t 💯 Done: 33.33% Avg: 29.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.043 ↑ 0.157 → 0.686 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4190\t Score = -23.22\n",
            "🚂 Episode 4190\t 🏆 Score: -0.031 Avg: -0.022\t 💯 Done: 33.33% Avg: 29.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.138 ← 0.064 ↑ 0.255 → 0.032 ◼ 0.457 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 4191\t Score = -23.22\n",
            "🚂 Episode 4191\t 🏆 Score: -0.031 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.553 ↑ 0.340 → 0.053 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 4192\t Score = -22.619999999999997\n",
            "🚂 Episode 4192\t 🏆 Score: -0.030 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.065 ← 0.373 ↑ 0.170 → 0.183 ◼ 0.078 ↓ 0.131 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4193\t Score = -23.779999999999998\n",
            "🚂 Episode 4193\t 🏆 Score: -0.032 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.147 ← 0.160 ↑ 0.374 → 0.221 ◼ 0.006 ↓ 0.092 \t Metric 0.6583333333333333 \n",
            "Episode Nr. 4194\t Score = 10.11\n",
            "🚂 Episode 4194\t 🏆 Score: 0.013 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.229 → 0.657 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4195\t Score = -22.619999999999997\n",
            "🚂 Episode 4195\t 🏆 Score: -0.030 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.281 ← 0.170 ↑ 0.444 → 0.072 ◼ 0.007 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4196\t Score = 8.79\n",
            "🚂 Episode 4196\t 🏆 Score: 0.012 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4197\t Score = -22.619999999999997\n",
            "🚂 Episode 4197\t 🏆 Score: -0.030 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.170 ↑ 0.425 → 0.020 ◼ 0.052 ↓ 0.327 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4198\t Score = 10.11\n",
            "🚂 Episode 4198\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.286 → 0.386 ◼ 0.229 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4199\t Score = -22.91\n",
            "🚂 Episode 4199\t 🏆 Score: -0.031 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.237 ← 0.282 ↑ 0.147 → 0.160 ◼ 0.013 ↓ 0.160 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 4200\t Score = 8.79\n",
            "🚂 Episode 4200\t 🏆 Score: 0.012 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4201\t Score = 8.79\n",
            "🚂 Episode 4201\t 🏆 Score: 0.012 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4202\t Score = -22.619999999999997\n",
            "🚂 Episode 4202\t 🏆 Score: -0.030 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.137 ↑ 0.490 → 0.026 ◼ 0.320 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4203\t Score = 10.11\n",
            "🚂 Episode 4203\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.414 ↑ 0.171 → 0.286 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4204\t Score = -23.22\n",
            "🚂 Episode 4204\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.191 ↑ 0.064 → 0.447 ◼ 0.011 ↓ 0.266 \t Metric 0.397 \n",
            "Episode Nr. 4205\t Score = -22.619999999999997\n",
            "🚂 Episode 4205\t 🏆 Score: -0.030 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.484 ← 0.150 ↑ 0.203 → 0.150 ◼ 0.007 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4206\t Score = 10.11\n",
            "🚂 Episode 4206\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.029 ↑ 0.229 → 0.629 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4207\t Score = -102.53999999999999\n",
            "🚂 Episode 4207\t 🏆 Score: -0.137 Avg: -0.022\t 💯 Done: 0.00% Avg: 30.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.172 ← 0.174 ↑ 0.225 → 0.166 ◼ 0.026 ↓ 0.237 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 4208\t Score = 10.11\n",
            "🚂 Episode 4208\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.629 ↑ 0.171 → 0.100 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4209\t Score = -23.22\n",
            "🚂 Episode 4209\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.074 → 0.681 ◼ 0.032 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4210\t Score = 10.11\n",
            "🚂 Episode 4210\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.057 ↑ 0.200 → 0.629 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4211\t Score = -22.619999999999997\n",
            "🚂 Episode 4211\t 🏆 Score: -0.030 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.418 ↑ 0.065 → 0.235 ◼ 0.039 ↓ 0.222 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4212\t Score = 9.836666666666664\n",
            "🚂 Episode 4212\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.027 ← 0.027 ↑ 0.527 → 0.041 ◼ 0.351 ↓ 0.027 \t Metric 0.594 \n",
            "Episode Nr. 4213\t Score = -22.619999999999997\n",
            "🚂 Episode 4213\t 🏆 Score: -0.030 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.216 ↑ 0.229 → 0.229 ◼ 0.007 ↓ 0.235 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4214\t Score = -102.53999999999999\n",
            "🚂 Episode 4214\t 🏆 Score: -0.137 Avg: -0.022\t 💯 Done: 0.00% Avg: 30.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.156 ← 0.350 ↑ 0.249 → 0.071 ◼ 0.099 ↓ 0.075 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 4215\t Score = -22.619999999999997\n",
            "🚂 Episode 4215\t 🏆 Score: -0.030 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.386 ← 0.229 ↑ 0.346 → 0.020 ◼ 0.013 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4216\t Score = 10.11\n",
            "🚂 Episode 4216\t 🏆 Score: 0.013 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.443 → 0.443 ◼ 0.029 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4217\t Score = 8.79\n",
            "🚂 Episode 4217\t 🏆 Score: 0.012 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4218\t Score = -23.22\n",
            "🚂 Episode 4218\t 🏆 Score: -0.031 Avg: -0.022\t 💯 Done: 33.33% Avg: 30.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.149 ← 0.521 ↑ 0.149 → 0.106 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 4219\t Score = 8.79\n",
            "🚂 Episode 4219\t 🏆 Score: 0.012 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4220\t Score = 10.11\n",
            "🚂 Episode 4220\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.257 → 0.586 ◼ 0.057 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4221\t Score = -23.22\n",
            "🚂 Episode 4221\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.085 → 0.053 ◼ 0.596 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 4222\t Score = 10.11\n",
            "🚂 Episode 4222\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.429 ↑ 0.414 → 0.057 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4223\t Score = 8.79\n",
            "🚂 Episode 4223\t 🏆 Score: 0.012 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4224\t Score = 10.11\n",
            "🚂 Episode 4224\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.057 ↑ 0.200 → 0.629 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4225\t Score = -23.22\n",
            "🚂 Episode 4225\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.266 ↑ 0.032 → 0.606 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 4226\t Score = 8.79\n",
            "🚂 Episode 4226\t 🏆 Score: 0.012 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4227\t Score = -23.22\n",
            "🚂 Episode 4227\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.298 ← 0.521 ↑ 0.096 → 0.032 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 4228\t Score = -23.22\n",
            "🚂 Episode 4228\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.170 → 0.574 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 4229\t Score = 10.11\n",
            "🚂 Episode 4229\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.086 ↑ 0.357 → 0.171 ◼ 0.329 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4230\t Score = 8.79\n",
            "🚂 Episode 4230\t 🏆 Score: 0.012 Avg: -0.019\t 💯 Done: 33.33% Avg: 30.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4231\t Score = -23.22\n",
            "🚂 Episode 4231\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 30.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.277 ↑ 0.074 → 0.457 ◼ 0.170 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4232\t Score = -23.22\n",
            "🚂 Episode 4232\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.117 → 0.160 ◼ 0.511 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4233\t Score = -23.22\n",
            "🚂 Episode 4233\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.117 → 0.649 ◼ 0.021 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4234\t Score = -23.22\n",
            "🚂 Episode 4234\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.457 ↑ 0.170 → 0.319 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4235\t Score = -23.22\n",
            "🚂 Episode 4235\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.234 ← 0.106 ↑ 0.309 → 0.277 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 4236\t Score = -23.22\n",
            "🚂 Episode 4236\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.787 ↑ 0.085 → 0.053 ◼ 0.021 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 4237\t Score = 10.11\n",
            "🚂 Episode 4237\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.214 → 0.686 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4238\t Score = -22.619999999999997\n",
            "🚂 Episode 4238\t 🏆 Score: -0.030 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.281 ← 0.124 ↑ 0.183 → 0.288 ◼ 0.007 ↓ 0.118 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4239\t Score = 8.79\n",
            "🚂 Episode 4239\t 🏆 Score: 0.012 Avg: -0.019\t 💯 Done: 33.33% Avg: 30.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4240\t Score = 8.79\n",
            "🚂 Episode 4240\t 🏆 Score: 0.012 Avg: -0.019\t 💯 Done: 33.33% Avg: 30.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4241\t Score = 8.643333333333333\n",
            "🚂 Episode 4241\t 🏆 Score: 0.012 Avg: -0.019\t 💯 Done: 33.33% Avg: 30.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 4242\t Score = -22.619999999999997\n",
            "🚂 Episode 4242\t 🏆 Score: -0.030 Avg: -0.019\t 💯 Done: 33.33% Avg: 30.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.150 ← 0.072 ↑ 0.379 → 0.314 ◼ 0.033 ↓ 0.052 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4243\t Score = -105.01999999999994\n",
            "🚂 Episode 4243\t 🏆 Score: -0.140 Avg: -0.020\t 💯 Done: 0.00% Avg: 30.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.255 ← 0.185 ↑ 0.027 → 0.309 ◼ 0.189 ↓ 0.035 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4244\t Score = 10.11\n",
            "🚂 Episode 4244\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.029 ↑ 0.214 → 0.643 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4245\t Score = -23.22\n",
            "🚂 Episode 4245\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.298 ← 0.245 ↑ 0.202 → 0.043 ◼ 0.011 ↓ 0.202 \t Metric 0.397 \n",
            "Episode Nr. 4246\t Score = -23.22\n",
            "🚂 Episode 4246\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.213 ↑ 0.074 → 0.660 ◼ 0.032 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4247\t Score = -22.619999999999997\n",
            "🚂 Episode 4247\t 🏆 Score: -0.030 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.412 ← 0.072 ↑ 0.359 → 0.052 ◼ 0.007 ↓ 0.098 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4248\t Score = -23.22\n",
            "🚂 Episode 4248\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.340 ↑ 0.085 → 0.521 ◼ 0.032 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4249\t Score = -23.22\n",
            "🚂 Episode 4249\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.426 ← 0.149 ↑ 0.351 → 0.053 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4250\t Score = -22.619999999999997\n",
            "🚂 Episode 4250\t 🏆 Score: -0.030 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.105 ← 0.229 ↑ 0.190 → 0.320 ◼ 0.065 ↓ 0.092 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4251\t Score = -23.22\n",
            "🚂 Episode 4251\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.362 ↑ 0.043 → 0.468 ◼ 0.096 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4252\t Score = -23.520000000000003\n",
            "🚂 Episode 4252\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.281 ← 0.188 ↑ 0.219 → 0.281 ◼ 0.021 ↓ 0.010 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 4253\t Score = -22.619999999999997\n",
            "🚂 Episode 4253\t 🏆 Score: -0.030 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.137 ← 0.255 ↑ 0.261 → 0.150 ◼ 0.013 ↓ 0.183 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4254\t Score = -23.22\n",
            "🚂 Episode 4254\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.096 ← 0.191 ↑ 0.500 → 0.181 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4255\t Score = 10.11\n",
            "🚂 Episode 4255\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.057 ↑ 0.214 → 0.657 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4256\t Score = 10.11\n",
            "🚂 Episode 4256\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.043 ↑ 0.171 → 0.686 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4257\t Score = 10.11\n",
            "🚂 Episode 4257\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.200 ↑ 0.243 → 0.243 ◼ 0.271 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4258\t Score = -23.22\n",
            "🚂 Episode 4258\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.500 ↑ 0.085 → 0.074 ◼ 0.011 ↓ 0.319 \t Metric 0.397 \n",
            "Episode Nr. 4259\t Score = -23.22\n",
            "🚂 Episode 4259\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.447 ← 0.202 ↑ 0.223 → 0.074 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 4260\t Score = -23.22\n",
            "🚂 Episode 4260\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.309 ↑ 0.223 → 0.404 ◼ 0.032 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4261\t Score = -23.22\n",
            "🚂 Episode 4261\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.149 ← 0.160 ↑ 0.160 → 0.468 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 4262\t Score = -23.22\n",
            "🚂 Episode 4262\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.064 ↑ 0.436 → 0.447 ◼ 0.032 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4263\t Score = -23.22\n",
            "🚂 Episode 4263\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.223 ↑ 0.085 → 0.447 ◼ 0.223 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4264\t Score = -23.22\n",
            "🚂 Episode 4264\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 31.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.255 ↑ 0.021 → 0.511 ◼ 0.181 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4265\t Score = 8.643333333333333\n",
            "🚂 Episode 4265\t 🏆 Score: 0.012 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 4266\t Score = -105.01999999999994\n",
            "🚂 Episode 4266\t 🏆 Score: -0.140 Avg: -0.021\t 💯 Done: 0.00% Avg: 30.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.050 ← 0.467 ↑ 0.019 → 0.263 ◼ 0.174 ↓ 0.027 \t Metric 0.19999999999999996 \n",
            "Episode Nr. 4267\t Score = 10.11\n",
            "🚂 Episode 4267\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.329 ↑ 0.271 → 0.286 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4268\t Score = -23.22\n",
            "🚂 Episode 4268\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.638 ← 0.213 ↑ 0.085 → 0.043 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4269\t Score = 9.973333333333331\n",
            "🚂 Episode 4269\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.069 ← 0.056 ↑ 0.250 → 0.556 ◼ 0.056 ↓ 0.014 \t Metric 0.5935 \n",
            "Episode Nr. 4270\t Score = 8.79\n",
            "🚂 Episode 4270\t 🏆 Score: 0.012 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4271\t Score = -23.22\n",
            "🚂 Episode 4271\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.745 ↑ 0.181 → 0.032 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4272\t Score = -23.22\n",
            "🚂 Episode 4272\t 🏆 Score: -0.031 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.404 ↑ 0.074 → 0.436 ◼ 0.064 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4273\t Score = 10.11\n",
            "🚂 Episode 4273\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.457 → 0.043 ◼ 0.429 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4274\t Score = 8.79\n",
            "🚂 Episode 4274\t 🏆 Score: 0.012 Avg: -0.020\t 💯 Done: 33.33% Avg: 30.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4275\t Score = -22.619999999999997\n",
            "🚂 Episode 4275\t 🏆 Score: -0.030 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.190 ↑ 0.301 → 0.235 ◼ 0.092 ↓ 0.170 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4276\t Score = 10.11\n",
            "🚂 Episode 4276\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.443 → 0.200 ◼ 0.286 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4277\t Score = -22.91\n",
            "🚂 Episode 4277\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.231 ↑ 0.186 → 0.282 ◼ 0.019 ↓ 0.269 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 4278\t Score = -22.619999999999997\n",
            "🚂 Episode 4278\t 🏆 Score: -0.030 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.163 ↑ 0.510 → 0.020 ◼ 0.111 ↓ 0.190 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4279\t Score = -22.619999999999997\n",
            "🚂 Episode 4279\t 🏆 Score: -0.030 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.163 ↑ 0.065 → 0.484 ◼ 0.007 ↓ 0.248 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4280\t Score = -23.22\n",
            "🚂 Episode 4280\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.213 ↑ 0.053 → 0.128 ◼ 0.021 ↓ 0.564 \t Metric 0.397 \n",
            "Episode Nr. 4281\t Score = -23.22\n",
            "🚂 Episode 4281\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.457 ← 0.149 ↑ 0.160 → 0.191 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 4282\t Score = -23.22\n",
            "🚂 Episode 4282\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.340 ↑ 0.223 → 0.043 ◼ 0.298 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4283\t Score = -22.619999999999997\n",
            "🚂 Episode 4283\t 🏆 Score: -0.030 Avg: -0.021\t 💯 Done: 33.33% Avg: 31.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.078 ← 0.098 ↑ 0.320 → 0.359 ◼ 0.007 ↓ 0.137 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4284\t Score = 8.79\n",
            "🚂 Episode 4284\t 🏆 Score: 0.012 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4285\t Score = 8.79\n",
            "🚂 Episode 4285\t 🏆 Score: 0.012 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4286\t Score = -23.22\n",
            "🚂 Episode 4286\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.426 ← 0.074 ↑ 0.255 → 0.202 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 4287\t Score = -102.53999999999999\n",
            "🚂 Episode 4287\t 🏆 Score: -0.137 Avg: -0.021\t 💯 Done: 0.00% Avg: 30.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.028 ← 0.215 ↑ 0.285 → 0.164 ◼ 0.160 ↓ 0.148 \t Metric 0.33333333333333337 \n",
            "Episode Nr. 4288\t Score = 8.643333333333333\n",
            "🚂 Episode 4288\t 🏆 Score: 0.012 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 4289\t Score = 9.973333333333331\n",
            "🚂 Episode 4289\t 🏆 Score: 0.013 Avg: -0.021\t 💯 Done: 33.33% Avg: 30.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.042 ← 0.375 ↑ 0.236 → 0.264 ◼ 0.069 ↓ 0.014 \t Metric 0.5935 \n",
            "Episode Nr. 4290\t Score = 10.11\n",
            "🚂 Episode 4290\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.043 ↑ 0.229 → 0.614 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4291\t Score = -23.22\n",
            "🚂 Episode 4291\t 🏆 Score: -0.031 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.213 ↑ 0.064 → 0.606 ◼ 0.053 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 4292\t Score = 10.11\n",
            "🚂 Episode 4292\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.071 ← 0.057 ↑ 0.171 → 0.629 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4293\t Score = -22.619999999999997\n",
            "🚂 Episode 4293\t 🏆 Score: -0.030 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.242 ← 0.144 ↑ 0.484 → 0.098 ◼ 0.026 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4294\t Score = -22.619999999999997\n",
            "🚂 Episode 4294\t 🏆 Score: -0.030 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.144 ← 0.111 ↑ 0.124 → 0.412 ◼ 0.013 ↓ 0.196 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4295\t Score = 8.643333333333333\n",
            "🚂 Episode 4295\t 🏆 Score: 0.012 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 4296\t Score = 10.11\n",
            "🚂 Episode 4296\t 🏆 Score: 0.013 Avg: -0.020\t 💯 Done: 33.33% Avg: 31.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.043 ↑ 0.286 → 0.557 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4297\t Score = 10.11\n",
            "🚂 Episode 4297\t 🏆 Score: 0.013 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.114 ↑ 0.171 → 0.614 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4298\t Score = -23.22\n",
            "🚂 Episode 4298\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.117 ↑ 0.160 → 0.074 ◼ 0.011 ↓ 0.628 \t Metric 0.397 \n",
            "Episode Nr. 4299\t Score = -22.619999999999997\n",
            "🚂 Episode 4299\t 🏆 Score: -0.030 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.163 ← 0.118 ↑ 0.229 → 0.314 ◼ 0.007 ↓ 0.170 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4300\t Score = 9.973333333333331\n",
            "🚂 Episode 4300\t 🏆 Score: 0.013 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.042 ← 0.069 ↑ 0.222 → 0.569 ◼ 0.056 ↓ 0.042 \t Metric 0.593 \n",
            "Episode Nr. 4301\t Score = 8.79\n",
            "🚂 Episode 4301\t 🏆 Score: 0.012 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4302\t Score = -23.22\n",
            "🚂 Episode 4302\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.383 ↑ 0.117 → 0.053 ◼ 0.011 ↓ 0.415 \t Metric 0.397 \n",
            "Episode Nr. 4303\t Score = -23.22\n",
            "🚂 Episode 4303\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.117 ↑ 0.117 → 0.394 ◼ 0.011 ↓ 0.255 \t Metric 0.397 \n",
            "Episode Nr. 4304\t Score = 8.79\n",
            "🚂 Episode 4304\t 🏆 Score: 0.012 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4305\t Score = -23.520000000000003\n",
            "🚂 Episode 4305\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.062 ← 0.573 ↑ 0.156 → 0.167 ◼ 0.021 ↓ 0.021 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 4306\t Score = 10.11\n",
            "🚂 Episode 4306\t 🏆 Score: 0.013 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.414 → 0.457 ◼ 0.057 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4307\t Score = -22.619999999999997\n",
            "🚂 Episode 4307\t 🏆 Score: -0.030 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.379 ← 0.059 ↑ 0.503 → 0.020 ◼ 0.007 ↓ 0.033 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4308\t Score = -23.22\n",
            "🚂 Episode 4308\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.383 ↑ 0.170 → 0.415 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4309\t Score = -22.619999999999997\n",
            "🚂 Episode 4309\t 🏆 Score: -0.030 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.209 ← 0.118 ↑ 0.150 → 0.281 ◼ 0.007 ↓ 0.235 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4310\t Score = -22.91\n",
            "🚂 Episode 4310\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.212 ← 0.199 ↑ 0.083 → 0.269 ◼ 0.013 ↓ 0.224 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 4311\t Score = -23.22\n",
            "🚂 Episode 4311\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.351 ← 0.149 ↑ 0.160 → 0.181 ◼ 0.085 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 4312\t Score = -23.520000000000003\n",
            "🚂 Episode 4312\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.302 ← 0.365 ↑ 0.115 → 0.156 ◼ 0.021 ↓ 0.042 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 4313\t Score = 9.973333333333331\n",
            "🚂 Episode 4313\t 🏆 Score: 0.013 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.042 ↑ 0.431 → 0.431 ◼ 0.056 ↓ 0.028 \t Metric 0.5935 \n",
            "Episode Nr. 4314\t Score = -22.619999999999997\n",
            "🚂 Episode 4314\t 🏆 Score: -0.030 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.124 ← 0.248 ↑ 0.105 → 0.242 ◼ 0.033 ↓ 0.248 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4315\t Score = -23.22\n",
            "🚂 Episode 4315\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.074 ↑ 0.234 → 0.298 ◼ 0.362 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4316\t Score = 10.11\n",
            "🚂 Episode 4316\t 🏆 Score: 0.013 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.100 ↑ 0.129 → 0.700 ◼ 0.014 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4317\t Score = 10.11\n",
            "🚂 Episode 4317\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.229 ↑ 0.371 → 0.300 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4318\t Score = -23.22\n",
            "🚂 Episode 4318\t 🏆 Score: -0.031 Avg: -0.019\t 💯 Done: 33.33% Avg: 31.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.181 ↑ 0.723 → 0.043 ◼ 0.021 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4319\t Score = 8.79\n",
            "🚂 Episode 4319\t 🏆 Score: 0.012 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4320\t Score = -23.22\n",
            "🚂 Episode 4320\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.085 → 0.532 ◼ 0.117 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 4321\t Score = 10.11\n",
            "🚂 Episode 4321\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.429 → 0.457 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4322\t Score = 10.11\n",
            "🚂 Episode 4322\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.071 ↑ 0.214 → 0.643 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4323\t Score = -22.619999999999997\n",
            "🚂 Episode 4323\t 🏆 Score: -0.030 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.046 ↑ 0.477 → 0.301 ◼ 0.013 ↓ 0.124 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4324\t Score = -23.22\n",
            "🚂 Episode 4324\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.372 ↑ 0.053 → 0.489 ◼ 0.053 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4325\t Score = -22.619999999999997\n",
            "🚂 Episode 4325\t 🏆 Score: -0.030 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.013 ← 0.150 ↑ 0.196 → 0.392 ◼ 0.007 ↓ 0.242 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4326\t Score = 10.11\n",
            "🚂 Episode 4326\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.414 ↑ 0.243 → 0.271 ◼ 0.014 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4327\t Score = -22.619999999999997\n",
            "🚂 Episode 4327\t 🏆 Score: -0.030 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.281 ← 0.111 ↑ 0.477 → 0.098 ◼ 0.013 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4328\t Score = -23.22\n",
            "🚂 Episode 4328\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.149 ← 0.191 ↑ 0.096 → 0.543 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4329\t Score = 8.79\n",
            "🚂 Episode 4329\t 🏆 Score: 0.012 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4330\t Score = -23.22\n",
            "🚂 Episode 4330\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.500 ↑ 0.043 → 0.372 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 4331\t Score = 10.11\n",
            "🚂 Episode 4331\t 🏆 Score: 0.013 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.214 → 0.329 ◼ 0.357 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4332\t Score = -23.22\n",
            "🚂 Episode 4332\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 31.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.426 ↑ 0.106 → 0.213 ◼ 0.117 ↓ 0.128 \t Metric 0.397 \n",
            "Episode Nr. 4333\t Score = 8.79\n",
            "🚂 Episode 4333\t 🏆 Score: 0.012 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4334\t Score = 8.79\n",
            "🚂 Episode 4334\t 🏆 Score: 0.012 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4335\t Score = 10.11\n",
            "🚂 Episode 4335\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.457 → 0.400 ◼ 0.086 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4336\t Score = 10.11\n",
            "🚂 Episode 4336\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.471 → 0.043 ◼ 0.429 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4337\t Score = 10.11\n",
            "🚂 Episode 4337\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 31.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.086 ↑ 0.186 → 0.500 ◼ 0.143 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4338\t Score = -23.22\n",
            "🚂 Episode 4338\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 31.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.223 → 0.564 ◼ 0.021 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4339\t Score = 10.11\n",
            "🚂 Episode 4339\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 31.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.500 ↑ 0.343 → 0.057 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4340\t Score = -23.22\n",
            "🚂 Episode 4340\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 31.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.287 ↑ 0.117 → 0.553 ◼ 0.021 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4341\t Score = -22.91\n",
            "🚂 Episode 4341\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 31.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.038 ← 0.147 ↑ 0.147 → 0.340 ◼ 0.045 ↓ 0.282 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 4342\t Score = -23.22\n",
            "🚂 Episode 4342\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.96%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.330 ↑ 0.106 → 0.160 ◼ 0.372 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4343\t Score = -23.22\n",
            "🚂 Episode 4343\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.628 ↑ 0.074 → 0.043 ◼ 0.011 ↓ 0.234 \t Metric 0.397 \n",
            "Episode Nr. 4344\t Score = 10.11\n",
            "🚂 Episode 4344\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 31.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.086 ↑ 0.300 → 0.543 ◼ 0.014 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4345\t Score = -23.22\n",
            "🚂 Episode 4345\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.00%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.766 ↑ 0.032 → 0.170 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4346\t Score = 8.79\n",
            "🚂 Episode 4346\t 🏆 Score: 0.012 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4347\t Score = -22.619999999999997\n",
            "🚂 Episode 4347\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.144 ← 0.098 ↑ 0.333 → 0.268 ◼ 0.007 ↓ 0.150 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4348\t Score = -23.22\n",
            "🚂 Episode 4348\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.04%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.138 ↑ 0.149 → 0.128 ◼ 0.021 ↓ 0.553 \t Metric 0.397 \n",
            "Episode Nr. 4349\t Score = 10.11\n",
            "🚂 Episode 4349\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.057 ↑ 0.371 → 0.486 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4350\t Score = 10.11\n",
            "🚂 Episode 4350\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.286 ↑ 0.471 → 0.043 ◼ 0.171 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4351\t Score = -23.22\n",
            "🚂 Episode 4351\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.426 ↑ 0.223 → 0.032 ◼ 0.234 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4352\t Score = -22.619999999999997\n",
            "🚂 Episode 4352\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.09%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.150 ← 0.183 ↑ 0.052 → 0.235 ◼ 0.196 ↓ 0.183 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4353\t Score = -22.619999999999997\n",
            "🚂 Episode 4353\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.281 ← 0.150 ↑ 0.111 → 0.183 ◼ 0.007 ↓ 0.268 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4354\t Score = 10.11\n",
            "🚂 Episode 4354\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.343 → 0.529 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4355\t Score = -22.619999999999997\n",
            "🚂 Episode 4355\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.111 ← 0.209 ↑ 0.203 → 0.222 ◼ 0.007 ↓ 0.248 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4356\t Score = -23.22\n",
            "🚂 Episode 4356\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.14%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.170 ↑ 0.234 → 0.468 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4357\t Score = 10.11\n",
            "🚂 Episode 4357\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.414 → 0.100 ◼ 0.429 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4358\t Score = 10.11\n",
            "🚂 Episode 4358\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.086 ↑ 0.214 → 0.500 ◼ 0.157 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4359\t Score = -22.619999999999997\n",
            "🚂 Episode 4359\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.281 ↑ 0.033 → 0.353 ◼ 0.033 ↓ 0.294 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4360\t Score = -23.22\n",
            "🚂 Episode 4360\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.266 ← 0.213 ↑ 0.074 → 0.053 ◼ 0.011 ↓ 0.383 \t Metric 0.397 \n",
            "Episode Nr. 4361\t Score = -22.619999999999997\n",
            "🚂 Episode 4361\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.503 ← 0.118 ↑ 0.281 → 0.052 ◼ 0.007 ↓ 0.039 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4362\t Score = 10.11\n",
            "🚂 Episode 4362\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.214 → 0.657 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4363\t Score = -23.22\n",
            "🚂 Episode 4363\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.213 → 0.117 ◼ 0.138 ↓ 0.319 \t Metric 0.397 \n",
            "Episode Nr. 4364\t Score = -23.22\n",
            "🚂 Episode 4364\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.213 ↑ 0.021 → 0.681 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 4365\t Score = -42.53999999999999\n",
            "🚂 Episode 4365\t 🏆 Score: -0.057 Avg: -0.017\t 💯 Done: 0.00% Avg: 31.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.485 ← 0.093 ↑ 0.097 → 0.318 ◼ 0.002 ↓ 0.004 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 4366\t Score = -22.619999999999997\n",
            "🚂 Episode 4366\t 🏆 Score: -0.030 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.170 ← 0.124 ↑ 0.346 → 0.268 ◼ 0.007 ↓ 0.085 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4367\t Score = -31.619999999999994\n",
            "🚂 Episode 4367\t 🏆 Score: -0.042 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.367 ← 0.200 ↑ 0.087 → 0.133 ◼ 0.193 ↓ 0.020 \t Metric 0.383 \n",
            "Episode Nr. 4368\t Score = -30.42\n",
            "🚂 Episode 4368\t 🏆 Score: -0.041 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.359 ↑ 0.035 → 0.021 ◼ 0.563 ↓ 0.014 \t Metric 0.385 \n",
            "Episode Nr. 4369\t Score = -26.52\n",
            "🚂 Episode 4369\t 🏆 Score: -0.035 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.97%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.233 ← 0.284 ↑ 0.138 → 0.207 ◼ 0.103 ↓ 0.034 \t Metric 0.39149999999999996 \n",
            "Episode Nr. 4370\t Score = 8.79\n",
            "🚂 Episode 4370\t 🏆 Score: 0.012 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.98%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4371\t Score = -23.22\n",
            "🚂 Episode 4371\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 31.99%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.138 → 0.638 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4372\t Score = -31.89999999999999\n",
            "🚂 Episode 4372\t 🏆 Score: -0.043 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.01%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.221 ← 0.080 ↑ 0.325 → 0.157 ◼ 0.133 ↓ 0.084 \t Metric 0.635 \n",
            "Episode Nr. 4373\t Score = -23.22\n",
            "🚂 Episode 4373\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.02%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.202 ↑ 0.351 → 0.372 ◼ 0.053 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4374\t Score = -23.22\n",
            "🚂 Episode 4374\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.03%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.074 ← 0.128 ↑ 0.543 → 0.234 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4375\t Score = 10.11\n",
            "🚂 Episode 4375\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.05%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.386 → 0.500 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4376\t Score = -23.22\n",
            "🚂 Episode 4376\t 🏆 Score: -0.031 Avg: -0.018\t 💯 Done: 33.33% Avg: 32.06%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.436 ← 0.223 ↑ 0.255 → 0.064 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4377\t Score = 10.11\n",
            "🚂 Episode 4377\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.07%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.057 ↑ 0.171 → 0.643 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4378\t Score = 10.11\n",
            "🚂 Episode 4378\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.08%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.271 → 0.243 ◼ 0.414 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4379\t Score = 10.11\n",
            "🚂 Episode 4379\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.10%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.071 ↑ 0.143 → 0.671 ◼ 0.029 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4380\t Score = -23.22\n",
            "🚂 Episode 4380\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.11%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.149 ← 0.191 ↑ 0.117 → 0.479 ◼ 0.021 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 4381\t Score = -22.619999999999997\n",
            "🚂 Episode 4381\t 🏆 Score: -0.030 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.12%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.399 ← 0.078 ↑ 0.268 → 0.092 ◼ 0.007 ↓ 0.157 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4382\t Score = -23.22\n",
            "🚂 Episode 4382\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.191 ↑ 0.106 → 0.670 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4383\t Score = -22.619999999999997\n",
            "🚂 Episode 4383\t 🏆 Score: -0.030 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.183 ← 0.301 ↑ 0.229 → 0.176 ◼ 0.033 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4384\t Score = 8.79\n",
            "🚂 Episode 4384\t 🏆 Score: 0.012 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.16%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4385\t Score = 9.973333333333331\n",
            "🚂 Episode 4385\t 🏆 Score: 0.013 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.028 ← 0.028 ↑ 0.375 → 0.403 ◼ 0.139 ↓ 0.028 \t Metric 0.593 \n",
            "Episode Nr. 4386\t Score = -22.619999999999997\n",
            "🚂 Episode 4386\t 🏆 Score: -0.030 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.052 ← 0.183 ↑ 0.235 → 0.366 ◼ 0.007 ↓ 0.157 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4387\t Score = 8.79\n",
            "🚂 Episode 4387\t 🏆 Score: 0.012 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4388\t Score = -23.22\n",
            "🚂 Episode 4388\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.564 ↑ 0.053 → 0.330 ◼ 0.021 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4389\t Score = 8.79\n",
            "🚂 Episode 4389\t 🏆 Score: 0.012 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4390\t Score = 8.79\n",
            "🚂 Episode 4390\t 🏆 Score: 0.012 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4391\t Score = -22.619999999999997\n",
            "🚂 Episode 4391\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.24%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.281 ← 0.131 ↑ 0.261 → 0.248 ◼ 0.033 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4392\t Score = 10.11\n",
            "🚂 Episode 4392\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.071 ↑ 0.143 → 0.286 ◼ 0.457 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4393\t Score = -23.22\n",
            "🚂 Episode 4393\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.181 ← 0.415 ↑ 0.096 → 0.287 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4394\t Score = 10.11\n",
            "🚂 Episode 4394\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.400 → 0.114 ◼ 0.429 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4395\t Score = -22.619999999999997\n",
            "🚂 Episode 4395\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.327 ← 0.105 ↑ 0.392 → 0.144 ◼ 0.007 ↓ 0.026 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4396\t Score = -23.22\n",
            "🚂 Episode 4396\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.734 ↑ 0.106 → 0.128 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4397\t Score = -23.22\n",
            "🚂 Episode 4397\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.213 ↑ 0.053 → 0.617 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 4398\t Score = -23.22\n",
            "🚂 Episode 4398\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.426 ↑ 0.234 → 0.032 ◼ 0.021 ↓ 0.266 \t Metric 0.397 \n",
            "Episode Nr. 4399\t Score = -23.22\n",
            "🚂 Episode 4399\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.543 ↑ 0.149 → 0.255 ◼ 0.021 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4400\t Score = -23.22\n",
            "🚂 Episode 4400\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.202 ← 0.106 ↑ 0.628 → 0.032 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4401\t Score = -23.22\n",
            "🚂 Episode 4401\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.649 ↑ 0.032 → 0.255 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 4402\t Score = 10.11\n",
            "🚂 Episode 4402\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.414 → 0.471 ◼ 0.014 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 4403\t Score = -22.619999999999997\n",
            "🚂 Episode 4403\t 🏆 Score: -0.030 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.072 ← 0.144 ↑ 0.353 → 0.399 ◼ 0.020 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4404\t Score = -22.619999999999997\n",
            "🚂 Episode 4404\t 🏆 Score: -0.030 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.366 ← 0.065 ↑ 0.327 → 0.190 ◼ 0.007 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4405\t Score = 10.11\n",
            "🚂 Episode 4405\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.343 → 0.529 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4406\t Score = -23.22\n",
            "🚂 Episode 4406\t 🏆 Score: -0.031 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.521 ↑ 0.106 → 0.340 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4407\t Score = -22.619999999999997\n",
            "🚂 Episode 4407\t 🏆 Score: -0.030 Avg: -0.017\t 💯 Done: 33.33% Avg: 32.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.261 ↑ 0.059 → 0.203 ◼ 0.046 ↓ 0.425 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4408\t Score = 9.973333333333331\n",
            "🚂 Episode 4408\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.111 ↑ 0.347 → 0.208 ◼ 0.250 ↓ 0.069 \t Metric 0.5935 \n",
            "Episode Nr. 4409\t Score = 8.79\n",
            "🚂 Episode 4409\t 🏆 Score: 0.012 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4410\t Score = 8.79\n",
            "🚂 Episode 4410\t 🏆 Score: 0.012 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4411\t Score = -22.619999999999997\n",
            "🚂 Episode 4411\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.163 ↑ 0.314 → 0.288 ◼ 0.007 ↓ 0.137 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4412\t Score = 8.79\n",
            "🚂 Episode 4412\t 🏆 Score: 0.012 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4413\t Score = 8.79\n",
            "🚂 Episode 4413\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4414\t Score = -42.53999999999999\n",
            "🚂 Episode 4414\t 🏆 Score: -0.057 Avg: -0.016\t 💯 Done: 0.00% Avg: 32.13%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.591 ← 0.002 ↑ 0.049 → 0.351 ◼ 0.002 ↓ 0.006 \t Metric 0.6625 \n",
            "Episode Nr. 4415\t Score = 10.11\n",
            "🚂 Episode 4415\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.14%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.414 → 0.457 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4416\t Score = -22.91\n",
            "🚂 Episode 4416\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.15%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.122 ← 0.250 ↑ 0.135 → 0.231 ◼ 0.071 ↓ 0.192 \t Metric 0.6608333333333334 \n",
            "Episode Nr. 4417\t Score = -22.619999999999997\n",
            "🚂 Episode 4417\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.17%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.098 ← 0.131 ↑ 0.386 → 0.190 ◼ 0.105 ↓ 0.092 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4418\t Score = 10.11\n",
            "🚂 Episode 4418\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.18%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.071 ↑ 0.300 → 0.529 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4419\t Score = -22.619999999999997\n",
            "🚂 Episode 4419\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.19%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.229 ← 0.085 ↑ 0.353 → 0.275 ◼ 0.007 ↓ 0.052 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4420\t Score = -23.22\n",
            "🚂 Episode 4420\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.20%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.670 ↑ 0.043 → 0.245 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4421\t Score = 8.79\n",
            "🚂 Episode 4421\t 🏆 Score: 0.012 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.21%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4422\t Score = 8.79\n",
            "🚂 Episode 4422\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.22%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4423\t Score = -22.619999999999997\n",
            "🚂 Episode 4423\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.23%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.216 ← 0.320 ↑ 0.268 → 0.085 ◼ 0.007 ↓ 0.105 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4424\t Score = -22.619999999999997\n",
            "🚂 Episode 4424\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.25%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.333 ← 0.098 ↑ 0.222 → 0.294 ◼ 0.020 ↓ 0.033 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4425\t Score = -23.22\n",
            "🚂 Episode 4425\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.26%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.106 ← 0.521 ↑ 0.085 → 0.213 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 4426\t Score = 10.11\n",
            "🚂 Episode 4426\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.27%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.400 → 0.343 ◼ 0.171 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4427\t Score = -23.22\n",
            "🚂 Episode 4427\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.28%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.330 ← 0.170 ↑ 0.191 → 0.085 ◼ 0.128 ↓ 0.096 \t Metric 0.397 \n",
            "Episode Nr. 4428\t Score = 10.11\n",
            "🚂 Episode 4428\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.29%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.086 ↑ 0.157 → 0.643 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4429\t Score = -23.22\n",
            "🚂 Episode 4429\t 🏆 Score: -0.031 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.30%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.319 ← 0.223 ↑ 0.106 → 0.330 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4430\t Score = -22.619999999999997\n",
            "🚂 Episode 4430\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.31%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.124 ← 0.078 ↑ 0.536 → 0.235 ◼ 0.007 ↓ 0.020 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4431\t Score = -22.619999999999997\n",
            "🚂 Episode 4431\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.32%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.059 ← 0.268 ↑ 0.033 → 0.392 ◼ 0.033 ↓ 0.216 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4432\t Score = -22.619999999999997\n",
            "🚂 Episode 4432\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.33%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.248 ← 0.118 ↑ 0.183 → 0.137 ◼ 0.007 ↓ 0.307 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4433\t Score = 10.11\n",
            "🚂 Episode 4433\t 🏆 Score: 0.013 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.34%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.214 ↑ 0.500 → 0.043 ◼ 0.200 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4434\t Score = 10.11\n",
            "🚂 Episode 4434\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.35%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.300 ↑ 0.171 → 0.414 ◼ 0.057 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4435\t Score = 10.11\n",
            "🚂 Episode 4435\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.36%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.086 ↑ 0.157 → 0.671 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4436\t Score = 10.11\n",
            "🚂 Episode 4436\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.37%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.057 ↑ 0.143 → 0.657 ◼ 0.014 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 4437\t Score = -23.22\n",
            "🚂 Episode 4437\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.38%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.500 ← 0.149 ↑ 0.213 → 0.064 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 4438\t Score = -23.22\n",
            "🚂 Episode 4438\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.39%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.511 ↑ 0.245 → 0.181 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4439\t Score = -22.619999999999997\n",
            "🚂 Episode 4439\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.40%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.222 ↑ 0.163 → 0.386 ◼ 0.065 ↓ 0.078 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4440\t Score = -22.619999999999997\n",
            "🚂 Episode 4440\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.41%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.020 ← 0.255 ↑ 0.085 → 0.301 ◼ 0.333 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4441\t Score = -22.619999999999997\n",
            "🚂 Episode 4441\t 🏆 Score: -0.030 Avg: -0.016\t 💯 Done: 33.33% Avg: 32.42%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.386 ↑ 0.399 → 0.020 ◼ 0.007 ↓ 0.183 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4442\t Score = 8.79\n",
            "🚂 Episode 4442\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4443\t Score = -23.22\n",
            "🚂 Episode 4443\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.43%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.117 ← 0.223 ↑ 0.287 → 0.351 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4444\t Score = 10.11\n",
            "🚂 Episode 4444\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.44%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.043 ↑ 0.386 → 0.486 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4445\t Score = 8.79\n",
            "🚂 Episode 4445\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.45%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4446\t Score = -23.22\n",
            "🚂 Episode 4446\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.46%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.660 ↑ 0.032 → 0.117 ◼ 0.021 ↓ 0.138 \t Metric 0.397 \n",
            "Episode Nr. 4447\t Score = 10.11\n",
            "🚂 Episode 4447\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.47%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.729 → 0.100 ◼ 0.100 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4448\t Score = -23.22\n",
            "🚂 Episode 4448\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.48%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.223 ↑ 0.213 → 0.479 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 4449\t Score = -22.619999999999997\n",
            "🚂 Episode 4449\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.49%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.072 ← 0.059 ↑ 0.464 → 0.386 ◼ 0.013 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4450\t Score = 10.11\n",
            "🚂 Episode 4450\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.429 ↑ 0.243 → 0.214 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4451\t Score = 8.643333333333333\n",
            "🚂 Episode 4451\t 🏆 Score: 0.012 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.50%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 4452\t Score = 10.11\n",
            "🚂 Episode 4452\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.51%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.086 ↑ 0.286 → 0.157 ◼ 0.429 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4453\t Score = -22.619999999999997\n",
            "🚂 Episode 4453\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.52%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.118 ↑ 0.229 → 0.353 ◼ 0.118 ↓ 0.176 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4454\t Score = -23.22\n",
            "🚂 Episode 4454\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.691 ↑ 0.117 → 0.032 ◼ 0.138 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4455\t Score = 8.79\n",
            "🚂 Episode 4455\t 🏆 Score: 0.012 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4456\t Score = -22.619999999999997\n",
            "🚂 Episode 4456\t 🏆 Score: -0.030 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.111 ← 0.111 ↑ 0.248 → 0.386 ◼ 0.007 ↓ 0.137 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4457\t Score = -23.22\n",
            "🚂 Episode 4457\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.479 ↑ 0.117 → 0.032 ◼ 0.277 ↓ 0.085 \t Metric 0.397 \n",
            "Episode Nr. 4458\t Score = -23.520000000000003\n",
            "🚂 Episode 4458\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.010 ← 0.229 ↑ 0.052 → 0.052 ◼ 0.583 ↓ 0.073 \t Metric 0.39649999999999996 \n",
            "Episode Nr. 4459\t Score = 10.11\n",
            "🚂 Episode 4459\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.414 → 0.314 ◼ 0.186 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4460\t Score = -23.22\n",
            "🚂 Episode 4460\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.287 ↑ 0.149 → 0.032 ◼ 0.500 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4461\t Score = 10.11\n",
            "🚂 Episode 4461\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.429 → 0.429 ◼ 0.014 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 4462\t Score = -23.22\n",
            "🚂 Episode 4462\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.511 ↑ 0.064 → 0.383 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4463\t Score = -22.619999999999997\n",
            "🚂 Episode 4463\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.118 ← 0.085 ↑ 0.386 → 0.359 ◼ 0.007 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4464\t Score = -22.619999999999997\n",
            "🚂 Episode 4464\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.196 ← 0.118 ↑ 0.222 → 0.268 ◼ 0.007 ↓ 0.190 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4465\t Score = 10.11\n",
            "🚂 Episode 4465\t 🏆 Score: 0.013 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.057 ↑ 0.343 → 0.200 ◼ 0.357 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4466\t Score = -22.619999999999997\n",
            "🚂 Episode 4466\t 🏆 Score: -0.030 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.033 ← 0.144 ↑ 0.059 → 0.562 ◼ 0.039 ↓ 0.163 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4467\t Score = 10.11\n",
            "🚂 Episode 4467\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.200 → 0.671 ◼ 0.014 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 4468\t Score = -23.22\n",
            "🚂 Episode 4468\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.489 ← 0.202 ↑ 0.106 → 0.138 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 4469\t Score = 10.11\n",
            "🚂 Episode 4469\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.071 ↑ 0.143 → 0.657 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4470\t Score = -23.22\n",
            "🚂 Episode 4470\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.362 ↑ 0.074 → 0.479 ◼ 0.011 ↓ 0.064 \t Metric 0.397 \n",
            "Episode Nr. 4471\t Score = -23.22\n",
            "🚂 Episode 4471\t 🏆 Score: -0.031 Avg: -0.015\t 💯 Done: 33.33% Avg: 32.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.085 ← 0.053 ↑ 0.649 → 0.191 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4472\t Score = 10.11\n",
            "🚂 Episode 4472\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.086 ↑ 0.414 → 0.129 ◼ 0.314 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4473\t Score = 10.11\n",
            "🚂 Episode 4473\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.100 ↑ 0.114 → 0.671 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4474\t Score = 10.11\n",
            "🚂 Episode 4474\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.029 ↑ 0.257 → 0.600 ◼ 0.014 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 4475\t Score = 10.11\n",
            "🚂 Episode 4475\t 🏆 Score: 0.013 Avg: -0.014\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.386 → 0.257 ◼ 0.243 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 4476\t Score = 8.79\n",
            "🚂 Episode 4476\t 🏆 Score: 0.012 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4477\t Score = -23.22\n",
            "🚂 Episode 4477\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.394 ↑ 0.074 → 0.053 ◼ 0.447 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4478\t Score = 8.643333333333333\n",
            "🚂 Episode 4478\t 🏆 Score: 0.012 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 4479\t Score = 8.79\n",
            "🚂 Episode 4479\t 🏆 Score: 0.012 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4480\t Score = -23.22\n",
            "🚂 Episode 4480\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.298 ← 0.181 ↑ 0.106 → 0.043 ◼ 0.128 ↓ 0.245 \t Metric 0.397 \n",
            "Episode Nr. 4481\t Score = 10.11\n",
            "🚂 Episode 4481\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.057 ↑ 0.357 → 0.457 ◼ 0.014 ↓ 0.100 \t Metric 0.5925 \n",
            "Episode Nr. 4482\t Score = -23.22\n",
            "🚂 Episode 4482\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.181 ↑ 0.096 → 0.043 ◼ 0.011 ↓ 0.649 \t Metric 0.397 \n",
            "Episode Nr. 4483\t Score = 10.11\n",
            "🚂 Episode 4483\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.414 ↑ 0.371 → 0.043 ◼ 0.014 ↓ 0.129 \t Metric 0.5925 \n",
            "Episode Nr. 4484\t Score = 10.11\n",
            "🚂 Episode 4484\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.243 ↑ 0.171 → 0.429 ◼ 0.043 ↓ 0.100 \t Metric 0.5925 \n",
            "Episode Nr. 4485\t Score = -22.619999999999997\n",
            "🚂 Episode 4485\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.065 ← 0.170 ↑ 0.373 → 0.353 ◼ 0.026 ↓ 0.013 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4486\t Score = -23.22\n",
            "🚂 Episode 4486\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.149 ← 0.564 ↑ 0.096 → 0.053 ◼ 0.117 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4487\t Score = 10.11\n",
            "🚂 Episode 4487\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.414 → 0.057 ◼ 0.414 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 4488\t Score = 10.11\n",
            "🚂 Episode 4488\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.229 → 0.643 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4489\t Score = 10.11\n",
            "🚂 Episode 4489\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.243 → 0.629 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4490\t Score = -22.619999999999997\n",
            "🚂 Episode 4490\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.052 ← 0.150 ↑ 0.085 → 0.464 ◼ 0.007 ↓ 0.242 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4491\t Score = -23.22\n",
            "🚂 Episode 4491\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.266 ← 0.106 ↑ 0.149 → 0.053 ◼ 0.011 ↓ 0.415 \t Metric 0.397 \n",
            "Episode Nr. 4492\t Score = -22.619999999999997\n",
            "🚂 Episode 4492\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.255 ← 0.111 ↑ 0.176 → 0.242 ◼ 0.020 ↓ 0.196 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4493\t Score = -22.619999999999997\n",
            "🚂 Episode 4493\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.098 ← 0.098 ↑ 0.353 → 0.412 ◼ 0.007 ↓ 0.033 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4494\t Score = 10.11\n",
            "🚂 Episode 4494\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.100 ↑ 0.414 → 0.400 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4495\t Score = 8.643333333333333\n",
            "🚂 Episode 4495\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 4496\t Score = 10.11\n",
            "🚂 Episode 4496\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.057 ↑ 0.257 → 0.600 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4497\t Score = -22.619999999999997\n",
            "🚂 Episode 4497\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.196 ← 0.144 ↑ 0.098 → 0.242 ◼ 0.092 ↓ 0.229 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4498\t Score = -22.619999999999997\n",
            "🚂 Episode 4498\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.124 ← 0.065 ↑ 0.438 → 0.314 ◼ 0.007 ↓ 0.052 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4499\t Score = -22.619999999999997\n",
            "🚂 Episode 4499\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.144 ← 0.111 ↑ 0.209 → 0.333 ◼ 0.007 ↓ 0.196 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4500\t Score = 10.11\n",
            "🚂 Episode 4500\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.071 ↑ 0.229 → 0.600 ◼ 0.043 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4501\t Score = 10.11\n",
            "🚂 Episode 4501\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.071 ↑ 0.157 → 0.614 ◼ 0.071 ↓ 0.071 \t Metric 0.5925 \n",
            "Episode Nr. 4502\t Score = -22.619999999999997\n",
            "🚂 Episode 4502\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.046 ← 0.131 ↑ 0.131 → 0.523 ◼ 0.007 ↓ 0.163 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4503\t Score = -23.22\n",
            "🚂 Episode 4503\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.383 ← 0.287 ↑ 0.191 → 0.032 ◼ 0.096 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4504\t Score = 10.11\n",
            "🚂 Episode 4504\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.086 ↑ 0.186 → 0.643 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4505\t Score = 8.643333333333333\n",
            "🚂 Episode 4505\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 4506\t Score = -23.22\n",
            "🚂 Episode 4506\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.383 ← 0.085 ↑ 0.213 → 0.266 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 4507\t Score = -42.53999999999999\n",
            "🚂 Episode 4507\t 🏆 Score: -0.057 Avg: -0.013\t 💯 Done: 0.00% Avg: 32.53%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.128 ← 0.117 ↑ 0.029 → 0.452 ◼ 0.062 ↓ 0.212 \t Metric 0.6658333333333333 \n",
            "Episode Nr. 4508\t Score = 10.11\n",
            "🚂 Episode 4508\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.029 ↑ 0.314 → 0.529 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4509\t Score = -22.619999999999997\n",
            "🚂 Episode 4509\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.54%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.268 ← 0.425 ↑ 0.242 → 0.052 ◼ 0.007 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4510\t Score = -23.22\n",
            "🚂 Episode 4510\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.55%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.191 ← 0.181 ↑ 0.223 → 0.383 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4511\t Score = -23.22\n",
            "🚂 Episode 4511\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.56%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.436 ← 0.277 ↑ 0.106 → 0.117 ◼ 0.011 ↓ 0.053 \t Metric 0.397 \n",
            "Episode Nr. 4512\t Score = 10.11\n",
            "🚂 Episode 4512\t 🏆 Score: 0.013 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.257 → 0.614 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4513\t Score = 10.11\n",
            "🚂 Episode 4513\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.57%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.286 → 0.557 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 4514\t Score = -22.619999999999997\n",
            "🚂 Episode 4514\t 🏆 Score: -0.030 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.58%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.026 ← 0.288 ↑ 0.346 → 0.170 ◼ 0.020 ↓ 0.150 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4515\t Score = 8.79\n",
            "🚂 Episode 4515\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.59%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4516\t Score = -23.22\n",
            "🚂 Episode 4516\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.170 ↑ 0.628 → 0.160 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4517\t Score = -23.22\n",
            "🚂 Episode 4517\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.60%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.638 ↑ 0.085 → 0.191 ◼ 0.043 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4518\t Score = 8.79\n",
            "🚂 Episode 4518\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.61%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4519\t Score = 10.11\n",
            "🚂 Episode 4519\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.62%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.086 ↑ 0.157 → 0.571 ◼ 0.043 ↓ 0.100 \t Metric 0.5925 \n",
            "Episode Nr. 4520\t Score = -22.619999999999997\n",
            "🚂 Episode 4520\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.092 ← 0.105 ↑ 0.386 → 0.353 ◼ 0.026 ↓ 0.039 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4521\t Score = -23.22\n",
            "🚂 Episode 4521\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.63%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.340 ↑ 0.202 → 0.394 ◼ 0.011 ↓ 0.043 \t Metric 0.397 \n",
            "Episode Nr. 4522\t Score = -23.22\n",
            "🚂 Episode 4522\t 🏆 Score: -0.031 Avg: -0.013\t 💯 Done: 33.33% Avg: 32.64%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.404 ↑ 0.191 → 0.340 ◼ 0.021 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4523\t Score = 10.11\n",
            "🚂 Episode 4523\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.443 ↑ 0.314 → 0.157 ◼ 0.057 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4524\t Score = 8.79\n",
            "🚂 Episode 4524\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.65%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4525\t Score = 8.79\n",
            "🚂 Episode 4525\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.66%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4526\t Score = 10.11\n",
            "🚂 Episode 4526\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.043 ↑ 0.171 → 0.671 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4527\t Score = 10.11\n",
            "🚂 Episode 4527\t 🏆 Score: 0.013 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.67%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.414 ↑ 0.457 → 0.057 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4528\t Score = -22.619999999999997\n",
            "🚂 Episode 4528\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.68%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.118 ← 0.366 ↑ 0.033 → 0.235 ◼ 0.007 ↓ 0.242 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4529\t Score = -23.22\n",
            "🚂 Episode 4529\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.330 ← 0.128 ↑ 0.128 → 0.394 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4530\t Score = 8.79\n",
            "🚂 Episode 4530\t 🏆 Score: 0.012 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.69%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4531\t Score = -23.22\n",
            "🚂 Episode 4531\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.70%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.181 ↑ 0.074 → 0.660 ◼ 0.032 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4532\t Score = -23.22\n",
            "🚂 Episode 4532\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.245 ↑ 0.234 → 0.447 ◼ 0.043 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4533\t Score = 10.11\n",
            "🚂 Episode 4533\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.71%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.043 ↑ 0.357 → 0.486 ◼ 0.043 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 4534\t Score = -23.22\n",
            "🚂 Episode 4534\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.72%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.511 ↑ 0.074 → 0.234 ◼ 0.160 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4535\t Score = -22.619999999999997\n",
            "🚂 Episode 4535\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.039 ← 0.176 ↑ 0.190 → 0.281 ◼ 0.105 ↓ 0.209 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4536\t Score = 10.11\n",
            "🚂 Episode 4536\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.73%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.414 → 0.371 ◼ 0.114 ↓ 0.057 \t Metric 0.5925 \n",
            "Episode Nr. 4537\t Score = 10.11\n",
            "🚂 Episode 4537\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.100 ↑ 0.300 → 0.143 ◼ 0.429 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4538\t Score = 8.79\n",
            "🚂 Episode 4538\t 🏆 Score: 0.012 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.74%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4539\t Score = 8.79\n",
            "🚂 Episode 4539\t 🏆 Score: 0.012 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4540\t Score = -23.22\n",
            "🚂 Episode 4540\t 🏆 Score: -0.031 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.75%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.319 ← 0.245 ↑ 0.117 → 0.234 ◼ 0.011 ↓ 0.074 \t Metric 0.397 \n",
            "Episode Nr. 4541\t Score = 8.79\n",
            "🚂 Episode 4541\t 🏆 Score: 0.012 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.76%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4542\t Score = 10.11\n",
            "🚂 Episode 4542\t 🏆 Score: 0.013 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.071 ↑ 0.271 → 0.557 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4543\t Score = -23.22\n",
            "🚂 Episode 4543\t 🏆 Score: -0.031 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.77%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.213 ↑ 0.085 → 0.043 ◼ 0.404 ↓ 0.245 \t Metric 0.397 \n",
            "Episode Nr. 4544\t Score = 10.11\n",
            "🚂 Episode 4544\t 🏆 Score: 0.013 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.157 ↑ 0.357 → 0.171 ◼ 0.257 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4545\t Score = 10.11\n",
            "🚂 Episode 4545\t 🏆 Score: 0.013 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.78%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.371 ↑ 0.200 → 0.271 ◼ 0.129 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4546\t Score = -22.619999999999997\n",
            "🚂 Episode 4546\t 🏆 Score: -0.030 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.242 ↑ 0.353 → 0.307 ◼ 0.059 ↓ 0.033 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4547\t Score = -23.22\n",
            "🚂 Episode 4547\t 🏆 Score: -0.031 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.79%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.213 ↑ 0.096 → 0.649 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4548\t Score = 8.79\n",
            "🚂 Episode 4548\t 🏆 Score: 0.012 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4549\t Score = 8.79\n",
            "🚂 Episode 4549\t 🏆 Score: 0.012 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.80%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4550\t Score = -23.22\n",
            "🚂 Episode 4550\t 🏆 Score: -0.031 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.81%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.383 ↑ 0.106 → 0.479 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4551\t Score = -23.22\n",
            "🚂 Episode 4551\t 🏆 Score: -0.031 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.372 ← 0.053 ↑ 0.500 → 0.053 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4552\t Score = -23.22\n",
            "🚂 Episode 4552\t 🏆 Score: -0.031 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.82%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.021 ← 0.787 ↑ 0.032 → 0.043 ◼ 0.011 ↓ 0.106 \t Metric 0.397 \n",
            "Episode Nr. 4553\t Score = -23.22\n",
            "🚂 Episode 4553\t 🏆 Score: -0.031 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.096 ↑ 0.553 → 0.298 ◼ 0.011 ↓ 0.032 \t Metric 0.397 \n",
            "Episode Nr. 4554\t Score = -23.22\n",
            "🚂 Episode 4554\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.83%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.032 ← 0.372 ↑ 0.128 → 0.436 ◼ 0.011 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4555\t Score = 10.11\n",
            "🚂 Episode 4555\t 🏆 Score: 0.013 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.086 ↑ 0.243 → 0.571 ◼ 0.043 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4556\t Score = -23.22\n",
            "🚂 Episode 4556\t 🏆 Score: -0.031 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.84%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.149 ← 0.340 ↑ 0.074 → 0.117 ◼ 0.011 ↓ 0.309 \t Metric 0.397 \n",
            "Episode Nr. 4557\t Score = -22.619999999999997\n",
            "🚂 Episode 4557\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.157 ← 0.405 ↑ 0.196 → 0.190 ◼ 0.007 ↓ 0.046 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4558\t Score = 10.11\n",
            "🚂 Episode 4558\t 🏆 Score: 0.013 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.85%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.686 → 0.143 ◼ 0.114 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4559\t Score = 8.79\n",
            "🚂 Episode 4559\t 🏆 Score: 0.012 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4560\t Score = -23.22\n",
            "🚂 Episode 4560\t 🏆 Score: -0.031 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.86%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.309 ↑ 0.085 → 0.340 ◼ 0.234 ↓ 0.021 \t Metric 0.397 \n",
            "Episode Nr. 4561\t Score = -22.619999999999997\n",
            "🚂 Episode 4561\t 🏆 Score: -0.030 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.007 ← 0.288 ↑ 0.477 → 0.052 ◼ 0.170 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4562\t Score = -23.22\n",
            "🚂 Episode 4562\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.670 ↑ 0.160 → 0.138 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4563\t Score = 10.11\n",
            "🚂 Episode 4563\t 🏆 Score: 0.013 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.87%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.014 ← 0.029 ↑ 0.400 → 0.071 ◼ 0.457 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4564\t Score = -23.22\n",
            "🚂 Episode 4564\t 🏆 Score: -0.031 Avg: -0.012\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.340 ← 0.181 ↑ 0.128 → 0.319 ◼ 0.021 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4565\t Score = 8.79\n",
            "🚂 Episode 4565\t 🏆 Score: 0.012 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.88%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4566\t Score = 8.79\n",
            "🚂 Episode 4566\t 🏆 Score: 0.012 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4567\t Score = 8.643333333333333\n",
            "🚂 Episode 4567\t 🏆 Score: 0.012 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.89%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4267857142857143 \n",
            "Episode Nr. 4568\t Score = 10.11\n",
            "🚂 Episode 4568\t 🏆 Score: 0.013 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.057 ↑ 0.200 → 0.643 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4569\t Score = 10.11\n",
            "🚂 Episode 4569\t 🏆 Score: 0.013 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.90%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.300 ↑ 0.457 → 0.157 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4570\t Score = -23.22\n",
            "🚂 Episode 4570\t 🏆 Score: -0.031 Avg: -0.011\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.011 ← 0.500 ↑ 0.106 → 0.362 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4571\t Score = 10.11\n",
            "🚂 Episode 4571\t 🏆 Score: 0.013 Avg: -0.010\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.371 → 0.457 ◼ 0.086 ↓ 0.029 \t Metric 0.5925 \n",
            "Episode Nr. 4572\t Score = 10.11\n",
            "🚂 Episode 4572\t 🏆 Score: 0.013 Avg: -0.010\t 💯 Done: 33.33% Avg: 32.91%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.086 ↑ 0.157 → 0.329 ◼ 0.386 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4573\t Score = -22.619999999999997\n",
            "🚂 Episode 4573\t 🏆 Score: -0.030 Avg: -0.010\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.098 ← 0.150 ↑ 0.144 → 0.366 ◼ 0.007 ↓ 0.235 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4574\t Score = 10.11\n",
            "🚂 Episode 4574\t 🏆 Score: 0.013 Avg: -0.010\t 💯 Done: 33.33% Avg: 32.92%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.043 ← 0.043 ↑ 0.271 → 0.586 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4575\t Score = 10.11\n",
            "🚂 Episode 4575\t 🏆 Score: 0.013 Avg: -0.010\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.029 ← 0.029 ↑ 0.343 → 0.543 ◼ 0.043 ↓ 0.014 \t Metric 0.5925 \n",
            "Episode Nr. 4576\t Score = 10.11\n",
            "🚂 Episode 4576\t 🏆 Score: 0.013 Avg: -0.010\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.057 ← 0.086 ↑ 0.171 → 0.629 ◼ 0.014 ↓ 0.043 \t Metric 0.5925 \n",
            "Episode Nr. 4577\t Score = 8.79\n",
            "🚂 Episode 4577\t 🏆 Score: 0.012 Avg: -0.010\t 💯 Done: 33.33% Avg: 32.93%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4578\t Score = 8.79\n",
            "🚂 Episode 4578\t 🏆 Score: 0.012 Avg: -0.009\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.167 ← 0.167 ↑ 0.167 → 0.167 ◼ 0.167 ↓ 0.167 \t Metric 0.4264285714285714 \n",
            "Episode Nr. 4579\t Score = -22.619999999999997\n",
            "🚂 Episode 4579\t 🏆 Score: -0.030 Avg: -0.010\t 💯 Done: 33.33% Avg: 32.94%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.131 ← 0.222 ↑ 0.190 → 0.379 ◼ 0.013 ↓ 0.065 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4580\t Score = -22.619999999999997\n",
            "🚂 Episode 4580\t 🏆 Score: -0.030 Avg: -0.010\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.163 ← 0.431 ↑ 0.124 → 0.242 ◼ 0.033 ↓ 0.007 \t Metric 0.6616666666666666 \n",
            "Episode Nr. 4581\t Score = -23.22\n",
            "🚂 Episode 4581\t 🏆 Score: -0.031 Avg: -0.010\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.191 ← 0.096 ↑ 0.362 → 0.330 ◼ 0.011 ↓ 0.011 \t Metric 0.397 \n",
            "Episode Nr. 4582\t Score = -22.619999999999997\n",
            "🚂 Episode 4582\t 🏆 Score: -0.030 Avg: -0.010\t 💯 Done: 33.33% Avg: 32.95%\t 🎲 Epsilon: 0.010 \t 🔀 Action Probs: ↻ 0.124 ← 0.320 ↑ 0.118 → 0.275 ◼ 0.013 ↓ 0.150 \t Metric 0.6616666666666666 "
          ]
        }
      ],
      "source": [
        "\n",
        "# The specs for the custom railway generation are taken from structures.py file\n",
        "specs = railway_example\n",
        "\n",
        "widht = len(specs[0])\n",
        "height = len(specs)\n",
        "\n",
        "stations_position = []\n",
        "\n",
        "# Defining the name of the different stations\n",
        "for i in range(1, len(stations)):\n",
        "    stations_position.append(stations[i][0])\n",
        "\n",
        "# Timetable conteins the station where the train should pass, from starting station to aim, and conteins the time at which\n",
        "# each train has to pass in the station, the last number represent the velocity of train (high velocity, intercity or regional)\n",
        "# Each row represent a different train\n",
        "\n",
        "print('------ Calculating the timetable')\n",
        "print()\n",
        "timetable = timetable_example\n",
        "\n",
        "# Number of agents is the rows of the timetable\n",
        "num_of_agents = len(timetable)\n",
        "\n",
        "# Check if the timetable is feaseble or not, the function is in schedule_generators\n",
        "# A timetable is feaseble if the difference of times between two stations is positive and let the trains to reach the successive station\n",
        "# if two stations are very distant from each other the difference of times can't be very small\n",
        "seed = 2\n",
        "\n",
        "# Generating the railway topology, with stations\n",
        "# Arguments of the generator (specs of the railway, position of stations, timetable)\n",
        "rail_custom = rail_custom_generator(specs, stations_position, timetable)\n",
        "\n",
        "transition_map_example, agent_hints = rail_custom(widht, height, num_of_agents)\n",
        "\n",
        "divide_trains_in_station_rails(timetable, transition_map_example)\n",
        "\n",
        "control_timetable(timetable,transition_map_example)\n",
        "\n",
        "for i in range(len(timetable)):\n",
        "    print(timetable[i])\n",
        " \n",
        "time.sleep(3)\n",
        "\n",
        "# We can now initiate the schedule generator with the given speed profiles\n",
        "schedule_generator_custom = custom_schedule_generator(timetable = timetable)\n",
        "\n",
        "print()\n",
        "print('------- Calculating the action scheduled')\n",
        "actions_scheduled = action_to_do(timetable, transition_map_example)\n",
        "\n",
        "# DEBUG\n",
        "for i in range(len(actions_scheduled)):\n",
        "    print()\n",
        "    print(actions_scheduled[i])\n",
        "    print()\n",
        "\n",
        "time.sleep(3)\n",
        "\n",
        "if multi_agent:\n",
        "\n",
        "    observation_parameters = Namespace(**obs_params)\n",
        "\n",
        "    observation_tree_depth = observation_parameters.observation_tree_depth\n",
        "    observation_radius = observation_parameters.observation_radius\n",
        "    observation_max_path_depth = observation_parameters.observation_max_path_depth\n",
        "\n",
        "    # Observation builder\n",
        "    predictor = ShortestPathPredictorForRailEnv(observation_max_path_depth)\n",
        "    Observer = TreeObsForRailEnv(max_depth=observation_tree_depth, predictor=predictor)\n",
        "else:\n",
        "    Observer = GlobalObsForRailEnv()\n",
        "    # Ricordarsi che noi vogliamo applicare il RL solo in un intorno della linea dove c'è stata l'interruzione\n",
        "    # Vogliamo in questo caso un osservatore globale? Forsse meglio valutarne anche uno limitato\n",
        "    # Ragiona se costruire un osservatore che consideri solo i binari possa essere tanto vantaggioso o no?\n",
        "\n",
        "stochastic_data = MalfunctionParameters(\n",
        "    malfunction_rate = 0,  # Rate of malfunction occurence\n",
        "    min_duration = 15,  # Minimal duration of malfunction\n",
        "    max_duration = 40  # Max duration of malfunction\n",
        ")\n",
        "\n",
        "malfunction_generator = ParamMalfunctionGen(stochastic_data)\n",
        "\n",
        "env = RailEnv(  width= widht,\n",
        "                height= height,\n",
        "                rail_generator = rail_custom,\n",
        "                line_generator=schedule_generator_custom,\n",
        "                number_of_agents= num_of_agents,\n",
        "                malfunction_generator = malfunction_generator,\n",
        "                obs_builder_object=Observer,\n",
        "                remove_agents_at_target=True,\n",
        "                record_steps=True,\n",
        "                max_episode_steps = max_steps - 1\n",
        "                )\n",
        "\n",
        "env.reset()\n",
        "\n",
        "\n",
        "# If I want I can delay a specific train a specific time\n",
        "'''\n",
        "delay_a_train(delay = 250, train = env.agents[1], delay_time = 2, time_of_train_generation = 1, actions = actions_scheduled)\n",
        "delay_a_train(delay = 250, train = env.agents[2], delay_time = 2, time_of_train_generation = 1, actions = actions_scheduled)\n",
        "'''\n",
        "\n",
        "for i in range(len(actions_scheduled)):\n",
        "    print(actions_scheduled[i])\n",
        "\n",
        "env_renderer = RenderTool(env,\n",
        "                          screen_height=480,\n",
        "                          screen_width=720)  # Adjust these parameters to fit your resolution\n",
        "\n",
        "\n",
        "# This thing is importand for the RL part, initialize the agent with (state, action) dimension\n",
        "# Initialize the agent with the parameters corresponding to the environment and observation_builder\n",
        "if multi_agent:\n",
        "    n_agents = env.get_num_agents()\n",
        "    n_features_per_node = env.obs_builder.observation_dim\n",
        "    n_nodes = sum([np.power(4, i) for i in range(observation_tree_depth + 1)])\n",
        "    state_size = n_features_per_node * n_nodes\n",
        "\n",
        "    action_size = env.action_space[0]\n",
        "\n",
        "    action_count = [0] * action_size\n",
        "    action_dict = dict()\n",
        "    agent_obs = [None] * n_agents\n",
        "    agent_prev_obs = [None] * n_agents\n",
        "    agent_prev_action = [2] * n_agents\n",
        "    update_values = [False] * n_agents\n",
        "\n",
        "    controller = RandomAgent(state_size, action_size)\n",
        "\n",
        "    # Smoothed values used as target for hyperparameter tuning\n",
        "    smoothed_normalized_score = -1.0\n",
        "    smoothed_eval_normalized_score = -1.0\n",
        "    smoothed_completion = 0.0\n",
        "    smoothed_eval_completion = 0.0\n",
        "\n",
        "    train_params = training_params\n",
        "\n",
        "    policy = DDDQNPolicy(state_size, action_size, train_params)\n",
        "\n",
        "    # TensorBoard writer\n",
        "    writer = SummaryWriter()\n",
        "    writer.add_hparams(vars(train_params), {})\n",
        "    writer.add_hparams(vars(train_params), {})\n",
        "    writer.add_hparams(vars(observation_parameters), {})\n",
        "\n",
        "    training_timer = Timer()\n",
        "    training_timer.start()\n",
        "\n",
        "else:\n",
        "    n_agents = env.get_num_agents()\n",
        "    state_size = (widht * height)\n",
        "    # The number of actions is the combination of the number of actions by the number of agents\n",
        "    action_size = env.action_space[0] ** env.get_num_agents()\n",
        "\n",
        "    action_count = [0] * action_size\n",
        "    action_dict = dict()\n",
        "    agent_obs = [None] * n_agents\n",
        "    agent_prev_obs = [None] * n_agents\n",
        "    agent_prev_action = [2] * n_agents\n",
        "    update_values = [False] * n_agents\n",
        "\n",
        "    controller = RandomAgent(state_size, action_size)\n",
        "\n",
        "    q_table = np.zeros([state_size, action_size])\n",
        "\n",
        "\n",
        "    alpha = 0.1\n",
        "    gamma = 0.6\n",
        "    epsilon = 0.1\n",
        "\n",
        "    # For plotting metrics\n",
        "    all_epochs = []\n",
        "    all_penalties = []\n",
        "\n",
        "\n",
        "# Lets try to enter with all of these agents at the same time\n",
        "action_dict = dict()\n",
        "\n",
        "# Now that you have seen these novel concepts that were introduced you will realize that agents don't need to take\n",
        "# an action at every time step as it will only change the outcome when actions are chosen at cell entry.\n",
        "# Therefore the environment provides information about what agents need to provide an action in the next step.\n",
        "# You can access this in the following way.\n",
        "\n",
        "# Chose an action for each agent\n",
        "for a in range(env.get_num_agents()):\n",
        "    action = controller.act(0)\n",
        "    action_dict.update({a: action})\n",
        "# Do the environment step\n",
        "\n",
        "observations, rewards, dones, information = env.step(action_dict)\n",
        "\n",
        "print(\"\\n The following agents can register an action:\")\n",
        "print(\"========================================\")\n",
        "for info in information['action_required']:\n",
        "    print(\"Agent {} needs to submit an action.\".format(info))\n",
        "\n",
        "# We recommend that you monitor the malfunction data and the action required in order to optimize your training\n",
        "# and controlling code.\n",
        "\n",
        "# Let us now look at an episode playing out \n",
        "\n",
        "print(\"\\nStart episode...\")\n",
        "\n",
        "# Reset the rendering system\n",
        "env_renderer.reset()\n",
        "\n",
        "# Here you can also further enhance the provided observation by means of normalization\n",
        "# See training navigation example in the baseline repository\n",
        "\n",
        "score = 0\n",
        "# Run episode\n",
        "frame_step = 0\n",
        "\n",
        "os.makedirs(\"output/frames\", exist_ok=True)\n",
        "\n",
        "for episode_idx in range(n_episodes + 1):\n",
        "    \n",
        "    deterministic_interruption_activation = False\n",
        "\n",
        "    step_timer = Timer()\n",
        "    reset_timer = Timer()\n",
        "    learn_timer = Timer()\n",
        "    preproc_timer = Timer()\n",
        "    inference_timer = Timer()\n",
        "\n",
        "    # Reset environment\n",
        "    reset_timer.start()\n",
        "\n",
        "    # Reset environment and get initial observations for all agents\n",
        "    obs, info = env.reset(regenerate_rail=True, regenerate_schedule=True)\n",
        "    reset_timer.end()\n",
        "    for idx in range(env.get_num_agents()):\n",
        "        tmp_agent = env.agents[idx]\n",
        "        tmp_agent.speed_counter.speed = 1 / (idx + 1)  # TODO rigestisci le velocità iniziali\n",
        "    env_renderer.reset()\n",
        "\n",
        "    if train_params.render:\n",
        "        env_renderer.set_new_rail()\n",
        "\n",
        "    score = 0\n",
        "    nb_steps = 0\n",
        "    actions_taken = []\n",
        "\n",
        "    if multi_agent:\n",
        "        # Build initial agent-specific observations\n",
        "        for agent in env.get_agent_handles():\n",
        "            if obs[agent]:\n",
        "                agent_obs[agent] = normalize_observation(obs[agent], observation_tree_depth, observation_radius=observation_radius)\n",
        "                agent_prev_obs[agent] = agent_obs[agent].copy()\n",
        "    else:\n",
        "        for agent in env.get_agent_handles():\n",
        "            agent_obs[agent] = obs[agent]\n",
        "            agent_prev_obs[agent] = agent_obs[agent].copy()\n",
        "\n",
        "    # Run episode (one day long, 1 step is 1 minute) 1440\n",
        "    for step in range(max_steps):\n",
        "        if video_save:\n",
        "            env_renderer.gl.save_image(\"output/frames/flatland_frame_step_{:04d}.bmp\".format(step))\n",
        "\n",
        "        inference_timer.start() \n",
        "\n",
        "    # Here define the actions to do\n",
        "        # Broken agents\n",
        "        # Broken agents\n",
        "        if training_flag == 'training0' and not deterministic_interruption_activation:\n",
        "            choose_a_random_training_configuration(env, max_steps)\n",
        "        if training_flag == 'training1':\n",
        "            make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "            make_a_deterministic_interruption(env.agents[3], max_steps)\n",
        "        if training_flag == 'training1.1':\n",
        "            make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "\n",
        "        # Chose an action for each agent in the environment\n",
        "        # If not interruption, the actions to do are stored in a matrix\n",
        "        #       - each row of the matrix is a train\n",
        "        #       - each column represent the action the train has to do at each time instant\n",
        "        \n",
        "        for a in range(env.get_num_agents()):\n",
        "            if env.agents[a].state == TrainState.DONE:\n",
        "                env.dones[a] = True\n",
        "            if env.agents[a].state == TrainState.MALFUNCTION:\n",
        "                interruption = True\n",
        "            if not multi_agent and interruption: # debug \n",
        "                break\n",
        "            if step >= timetable[a][1][0]:\n",
        "                # Normal plan to follow\n",
        "                if not interruption and (step - timetable[a][1][0]) < len(actions_scheduled[a]):\n",
        "                    action = actions_scheduled[a][step - timetable[a][1][0]]\n",
        "                # Interruption\n",
        "                elif interruption:\n",
        "                    if multi_agent:\n",
        "                        if info['action_required'][a]:\n",
        "                            update_values[a] = True\n",
        "                            action = policy.act(agent_obs[a], eps=eps_start)\n",
        "\n",
        "                            action_count[action] += 1\n",
        "                            actions_taken.append(action)\n",
        "                        else:\n",
        "                            # An action is not required if the train hasn't joined the railway network,\n",
        "                            # if it already reached its target, or if is currently malfunctioning.\n",
        "                            update_values[a] = False\n",
        "                            action = 0\n",
        "                    else:\n",
        "                        action = np.random.choice([RailEnvActions.MOVE_FORWARD, RailEnvActions.MOVE_RIGHT, RailEnvActions.MOVE_LEFT, \n",
        "                        RailEnvActions.STOP_MOVING, RailEnvActions.REVERSE])\n",
        "                # choose random from all the possible actions\n",
        "                else:\n",
        "                    action = np.random.choice([RailEnvActions.MOVE_FORWARD, RailEnvActions.MOVE_RIGHT, RailEnvActions.MOVE_LEFT, \n",
        "                        RailEnvActions.STOP_MOVING, RailEnvActions.REVERSE])\n",
        "\n",
        "                action_dict.update({a: action})\n",
        "\n",
        "\n",
        "        inference_timer.end()\n",
        "\n",
        "        # Environment step which returns the observations for all agents, their corresponding\n",
        "        # reward and whether their are done\n",
        "        # Environment step\n",
        "        step_timer.start()\n",
        "        next_obs, all_rewards, done, info = env.step(action_dict)\n",
        "        step_timer.end()\n",
        "\n",
        "        # Render an episode at some interval\n",
        "        if render:\n",
        "            env_renderer.render_env(\n",
        "                    show=True, show_observations = False, frames = True, episode = True, step = True\n",
        "                )\n",
        "        # Update replay buffer and train agent\n",
        "        if multi_agent:\n",
        "            for agent in env.get_agent_handles():\n",
        "                if update_values[agent] or done['__all__']:\n",
        "                    # Only learn from timesteps where somethings happened\n",
        "                    learn_timer.start()\n",
        "                    policy.step(agent_prev_obs[agent], agent_prev_action[agent], all_rewards[agent], agent_obs[agent], done[agent])\n",
        "                    learn_timer.end()\n",
        "\n",
        "                    agent_prev_obs[agent] = agent_obs[agent].copy()\n",
        "                    agent_prev_action[agent] = action_dict[agent]\n",
        "\n",
        "                # Preprocess the new observations\n",
        "                if next_obs[agent]:\n",
        "                    preproc_timer.start()\n",
        "                    agent_obs[agent] = normalize_observation(next_obs[agent], observation_tree_depth, observation_radius=observation_radius)\n",
        "                    preproc_timer.end()\n",
        "\n",
        "                score += all_rewards[agent]\n",
        "\n",
        "            nb_steps = step\n",
        "        else:\n",
        "            for a in range(env.get_num_agents()):\n",
        "                controller.step((obs[a], action_dict[a], all_rewards[a], next_obs[a], done[a]))\n",
        "                score += all_rewards[a]\n",
        "        obs = next_obs.copy()\n",
        "        if done['__all__']:\n",
        "            break\n",
        "        #break if the first agent has done\n",
        "        if ((training_flag == 'training0') and (env.dones[0] == True)) or \\\n",
        "            ((training_flag == 'training1') and (env.dones[0] == True) and (env.dones[1] == True)) or \\\n",
        "            ((training_flag == 'training1.1') and (env.dones[0] == True) and (env.dones[1] == True)):\n",
        "            break\n",
        "    print()\n",
        "    print('Episode Nr. {}\\t Score = {}'.format(episode_idx, score))\n",
        "\n",
        "    # metric most possible near to 0\n",
        "    metric = calculate_metric(env, timetable)\n",
        "    \n",
        "    if multi_agent:\n",
        "        # Epsilon decay\n",
        "        eps_start = max(eps_end, eps_decay * eps_start)\n",
        "\n",
        "        # Collect information about training\n",
        "        tasks_finished = sum(done[idx] for idx in env.get_agent_handles())\n",
        "        completion = tasks_finished / max(1, env.get_num_agents())\n",
        "        normalized_score = score / (max_steps * env.get_num_agents())\n",
        "        action_probs = action_count / np.sum(action_count)\n",
        "        action_count = [1] * action_size\n",
        "\n",
        "        smoothing = 0.99\n",
        "        smoothed_normalized_score = smoothed_normalized_score * smoothing + normalized_score * (1.0 - smoothing)\n",
        "        smoothed_completion = smoothed_completion * smoothing + completion * (1.0 - smoothing)\n",
        "\n",
        "        # Print logs\n",
        "        if episode_idx % checkpoint_interval == 0:\n",
        "            '''\n",
        "            torch.save(policy.qnetwork_local, './checkpoints/' + training_id + '-' + str(episode_idx) + '.pth')\n",
        "            if save_replay_buffer:\n",
        "                policy.save_replay_buffer('./replay_buffers/' + training_id + '-' + str(episode_idx) + '.pkl')\n",
        "            '''\n",
        "\n",
        "            if train_params.render:\n",
        "                env_renderer.close_window()\n",
        "\n",
        "        print(\n",
        "            '\\r🚂 Episode {}'\n",
        "            '\\t 🏆 Score: {:.3f}'\n",
        "            ' Avg: {:.3f}'\n",
        "            '\\t 💯 Done: {:.2f}%'\n",
        "            ' Avg: {:.2f}%'\n",
        "            '\\t 🎲 Epsilon: {:.3f} '\n",
        "            '\\t 🔀 Action Probs: {}'\n",
        "            '\\t Metric {}'.format(\n",
        "                episode_idx,\n",
        "                normalized_score,\n",
        "                smoothed_normalized_score,\n",
        "                100 * completion,\n",
        "                100 * smoothed_completion,\n",
        "                eps_start,\n",
        "                format_action_prob(action_probs),\n",
        "                metric\n",
        "            ), end=\" \")\n",
        "\n",
        "    interruption = False\n",
        "    writer.add_scalar(\"Reward\", score, episode_idx)\n",
        "    writer.add_scalar(\"Metric\", metric, episode_idx)\n",
        "    writer.flush()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx6BqGMZtb9P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "d0403add-7fd4-4e5a-d13b-0b0f2160d33c"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2wENop47ZHr"
      },
      "source": [
        "# Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxkXqDpk7ct5"
      },
      "source": [
        "## Render utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2XE2YoP1mJ3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%matplotlib inline\n",
        "\n",
        "# Helper function to visualize an episode\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation\n",
        "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
        "\n",
        "def display_episode(frames):\n",
        "    fig, ax = plt.subplots(figsize=(12,12))\n",
        "    imgplot = plt.imshow(frames[0])\n",
        "    def animate(i):\n",
        "        imgplot.set_data(frames[i])\n",
        "    animation = matplotlib.animation.FuncAnimation(fig, animate, frames=len(frames))\n",
        "    return animation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8ToFBwB7sLQ"
      },
      "source": [
        "## Test 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2w_qS1Xunmm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "6e65dbca-6f7a-4aca-c652-e3378ba10708"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-653385f663a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Reset the rendering system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0menv_renderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Reset environment and get initial observations for all agents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregenerate_rail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregenerate_schedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'env_renderer' is not defined"
          ]
        }
      ],
      "source": [
        "#################\n",
        "##### TEST 1 ####\n",
        "#################\n",
        "# Reset the rendering system\n",
        "env_renderer.reset()\n",
        "# Reset environment and get initial observations for all agents\n",
        "obs, info = env.reset(regenerate_rail=True, regenerate_schedule=True)\n",
        "# Change the position of the interrupted agents\n",
        "env.agents[1].initial_position = (6,10)\n",
        "env.agents[2].initial_position = (5,10)\n",
        "\n",
        "frame_step = 0\n",
        "frames = []\n",
        "score = 0\n",
        "\n",
        "for step in range(max_steps):\n",
        "    # Broken agents\n",
        "    if training_flag == 'training0':\n",
        "        make_a_deterministic_interruption(env.agents[1], max_steps)\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "    if training_flag == 'training1':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "        make_a_deterministic_interruption(env.agents[3], max_steps)\n",
        "    if training_flag == 'training1.1':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "    update_values[0] = True\n",
        "    action = policy.act(agent_obs[0], eps=eps_start)\n",
        "\n",
        "    action_count[action] += 1\n",
        "    actions_taken.append(action)\n",
        "    action_dict.update({0: action})\n",
        "    \n",
        "    next_obs, all_rewards, done, info = env.step(action_dict)\n",
        "\n",
        "    frame = env_renderer.render_env(show=False, show_observations=False, show_inactive_agents=True, show_predictions=False, return_image=True)\n",
        "    frames.append(frame)\n",
        "    frame_step += 1\n",
        "    \n",
        "    if done['__all__']:\n",
        "        break\n",
        "    #break if the first agent has done\n",
        "    if ((training_flag == 'training0') and (env.dones[0] == True)) or \\\n",
        "        ((training_flag == 'training1') and (env.dones[0] == True) and (env.dones[1] == True)) or \\\n",
        "        ((training_flag == 'training1.1') and (env.dones[0] == True) and (env.dones[1] == True)):\n",
        "        break\n",
        "\n",
        "\n",
        "score += all_rewards[0]\n",
        "# metric most possible near to 0\n",
        "metric = calculate_metric(env, timetable)\n",
        "\n",
        "tasks_finished = sum(done[idx] for idx in env.get_agent_handles())\n",
        "\n",
        "print(  'Test 1 concluded:'\n",
        "        '\\t 🏆 Score: {:.3f}'\n",
        "        '\\t Agent completed {}'\n",
        "        '\\t Metric {}'.format(\n",
        "            score,\n",
        "            tasks_finished,\n",
        "            metric\n",
        "        ), end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTImFlkk8c2X"
      },
      "outputs": [],
      "source": [
        "# RENDER\n",
        "%%capture\n",
        "animation = display_episode(frames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3c80YLP8tBG"
      },
      "outputs": [],
      "source": [
        "animation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUftVUZWuqV9"
      },
      "source": [
        "## Test 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAprhHdvutU-"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "##### TEST 2 ####\n",
        "#################\n",
        "# Reset the rendering system\n",
        "env_renderer.reset()\n",
        "# Reset environment and get initial observations for all agents\n",
        "obs, info = env.reset(regenerate_rail=True, regenerate_schedule=True)\n",
        "# Change the position of the interrupted agents\n",
        "env.agents[1].initial_position = (6,8)\n",
        "env.agents[2].initial_position = (-1,0)\n",
        "\n",
        "frame_step = 0\n",
        "frames = []\n",
        "\n",
        "for step in range(max_steps):\n",
        "    # Broken agents\n",
        "    if training_flag == 'training0':\n",
        "        make_a_deterministic_interruption(env.agents[1], max_steps)\n",
        "        env.agents[2].malfunction_handler.malfunction_down_counter = max_steps\n",
        "    if training_flag == 'training1':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "        make_a_deterministic_interruption(env.agents[3], max_steps)\n",
        "    if training_flag == 'training1.1':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "\n",
        "    update_values[0] = True\n",
        "    action = policy.act(agent_obs[0], eps=eps_start)\n",
        "\n",
        "    action_count[action] += 1\n",
        "    actions_taken.append(action)\n",
        "    action_dict.update({0: action})\n",
        "    \n",
        "    next_obs, all_rewards, done, info = env.step(action_dict)\n",
        "\n",
        "    frame = env_renderer.render_env(show=False, show_observations=False, show_inactive_agents=True, show_predictions=False, return_image=True)\n",
        "    frames.append(frame)\n",
        "    frame_step += 1\n",
        "    \n",
        "    if done['__all__']:\n",
        "        break\n",
        "    #break if the first agent has done\n",
        "    if ((training_flag == 'training0') and (env.dones[0] == True)) or \\\n",
        "        ((training_flag == 'training1') and (env.dones[0] == True) and (env.dones[1] == True)) or \\\n",
        "        ((training_flag == 'training1.1') and (env.dones[0] == True) and (env.dones[1] == True)):\n",
        "        break\n",
        "\n",
        "score += all_rewards[0]\n",
        "# metric most possible near to 0\n",
        "metric = calculate_metric(env, timetable)\n",
        "\n",
        "tasks_finished = sum(done[idx] for idx in env.get_agent_handles())\n",
        "\n",
        "print(  'Test 2 concluded:'\n",
        "        '\\t 🏆 Score: {:.3f}'\n",
        "        '\\t Agent completed {}'\n",
        "        '\\t Metric {}'.format(\n",
        "            score,\n",
        "            tasks_finished,\n",
        "            metric\n",
        "        ), end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2Dedr6x1V0G"
      },
      "outputs": [],
      "source": [
        "# RENDER\n",
        "%%capture\n",
        "animation = display_episode(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpmugMNg1YY8"
      },
      "outputs": [],
      "source": [
        "animation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpZFo8eNo59g"
      },
      "source": [
        "## Test 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCn-uMD2o9Q-"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "##### TEST 3 ####\n",
        "#################\n",
        "# Reset the rendering system\n",
        "env_renderer.reset()\n",
        "# Reset environment and get initial observations for all agents\n",
        "obs, info = env.reset(regenerate_rail=True, regenerate_schedule=True)\n",
        "# Change the position of the interrupted agents\n",
        "env.agents[1].initial_position = (6,14)\n",
        "env.agents[2].initial_position = (5,14)\n",
        "\n",
        "frame_step = 0\n",
        "frames = []\n",
        "\n",
        "for step in range(max_steps):\n",
        "    # Broken agents\n",
        "    if training_flag == 'training0':\n",
        "        make_a_deterministic_interruption(env.agents[1], max_steps)\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "    if training_flag == 'training1':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "        make_a_deterministic_interruption(env.agents[3], max_steps)\n",
        "    if training_flag == 'training1.1':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "\n",
        "    update_values[0] = True\n",
        "    action = policy.act(agent_obs[0], eps=eps_start)\n",
        "\n",
        "    action_count[action] += 1\n",
        "    actions_taken.append(action)\n",
        "    action_dict.update({0: action})\n",
        "    \n",
        "    next_obs, all_rewards, done, info = env.step(action_dict)\n",
        "\n",
        "    frame = env_renderer.render_env(show=False, show_observations=False, show_inactive_agents=True, show_predictions=False, return_image=True)\n",
        "    frames.append(frame)\n",
        "    frame_step += 1\n",
        "    \n",
        "    if done['__all__']:\n",
        "        break\n",
        "    #break if the first agent has done\n",
        "    if ((training_flag == 'training0') and (env.dones[0] == True)) or \\\n",
        "        ((training_flag == 'training1') and (env.dones[0] == True) and (env.dones[1] == True)) or \\\n",
        "        ((training_flag == 'training1.1') and (env.dones[0] == True) and (env.dones[1] == True)):\n",
        "        break\n",
        "\n",
        "score += all_rewards[0]\n",
        "# metric most possible near to 0\n",
        "metric = calculate_metric(env, timetable)\n",
        "\n",
        "tasks_finished = sum(done[idx] for idx in env.get_agent_handles())\n",
        "\n",
        "print(  'Test 3 concluded:'\n",
        "        '\\t 🏆 Score: {:.3f}'\n",
        "        '\\t Agent completed {}'\n",
        "        '\\t Metric {}'.format(\n",
        "            score,\n",
        "            tasks_finished,\n",
        "            metric\n",
        "        ), end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIeBUbCTugm4"
      },
      "outputs": [],
      "source": [
        "# RENDER\n",
        "%%capture\n",
        "animation = display_episode(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-twQYbWuiYl"
      },
      "outputs": [],
      "source": [
        "animation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xLye0LaphyN"
      },
      "source": [
        "## Test 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UaOxJwdpj02"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "##### TEST 4 ####\n",
        "#################\n",
        "# Reset the rendering system\n",
        "env_renderer.reset()\n",
        "# Reset environment and get initial observations for all agents\n",
        "obs, info = env.reset(regenerate_rail=True, regenerate_schedule=True)\n",
        "# Change the position of the interrupted agents\n",
        "env.agents[1].initial_position = (6,14)\n",
        "env.agents[2].initial_position = (-1,0)\n",
        "\n",
        "frame_step = 0\n",
        "frames = []\n",
        "\n",
        "for step in range(max_steps):\n",
        "    # Broken agents\n",
        "    if training_flag == 'training0':\n",
        "        make_a_deterministic_interruption(env.agents[1], max_steps)\n",
        "        env.agents[2].malfunction_handler.malfunction_down_counter = max_steps\n",
        "    if training_flag == 'training1':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "        make_a_deterministic_interruption(env.agents[3], max_steps)\n",
        "    if training_flag == 'training1.1':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "\n",
        "    update_values[0] = True\n",
        "    action = policy.act(agent_obs[0], eps=eps_start)\n",
        "\n",
        "    action_count[action] += 1\n",
        "    actions_taken.append(action)\n",
        "    action_dict.update({0: action})\n",
        "    \n",
        "    next_obs, all_rewards, done, info = env.step(action_dict)\n",
        "\n",
        "    frame = env_renderer.render_env(show=False, show_observations=False, show_inactive_agents=True, show_predictions=False, return_image=True)\n",
        "    frames.append(frame)\n",
        "    frame_step += 1\n",
        "    \n",
        "    if done['__all__']:\n",
        "        break\n",
        "    #break if the first agent has done\n",
        "    if ((training_flag == 'training0') and (env.dones[0] == True)) or \\\n",
        "        ((training_flag == 'training1') and (env.dones[0] == True) and (env.dones[1] == True)) or \\\n",
        "        ((training_flag == 'training1.1') and (env.dones[0] == True) and (env.dones[1] == True)):\n",
        "        break\n",
        "\n",
        "score += all_rewards[0]\n",
        "# metric most possible near to 0\n",
        "metric = calculate_metric(env, timetable)\n",
        "\n",
        "tasks_finished = sum(done[idx] for idx in env.get_agent_handles())\n",
        "\n",
        "print(  'Test 4 concluded:'\n",
        "        '\\t 🏆 Score: {:.3f}'\n",
        "        '\\t Agent completed {}'\n",
        "        '\\t Metric {}'.format(\n",
        "            score,\n",
        "            tasks_finished,\n",
        "            metric\n",
        "        ), end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSiGB4A-ulWj"
      },
      "outputs": [],
      "source": [
        "# RENDER\n",
        "%%capture\n",
        "animation = display_episode(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYPnyghkuoib"
      },
      "outputs": [],
      "source": [
        "animation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfV1Rwf2pyZi"
      },
      "source": [
        "## Test 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LyzeDw9Jpz4-"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "##### TEST 5 ####\n",
        "#################\n",
        "# Reset the rendering system\n",
        "env_renderer.reset()\n",
        "# Reset environment and get initial observations for all agents\n",
        "obs, info = env.reset(regenerate_rail=True, regenerate_schedule=True)\n",
        "# Change the position of the interrupted agents\n",
        "env.agents[2].initial_position = (5,10)\n",
        "env.agents[1].initial_position = (-1,0)\n",
        "\n",
        "frame_step = 0\n",
        "frames = []\n",
        "\n",
        "for step in range(max_steps):\n",
        "    # Broken agents\n",
        "    if training_flag == 'training0':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "        env.agents[1].malfunction_handler.malfunction_down_counter = max_steps\n",
        "    if training_flag == 'training1':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "        make_a_deterministic_interruption(env.agents[3], max_steps)\n",
        "    if training_flag == 'training1.1':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "\n",
        "    update_values[0] = True\n",
        "    action = policy.act(agent_obs[0], eps=eps_start)\n",
        "\n",
        "    action_count[action] += 1\n",
        "    actions_taken.append(action)\n",
        "    action_dict.update({0: action})\n",
        "    \n",
        "    next_obs, all_rewards, done, info = env.step(action_dict)\n",
        "\n",
        "    frame = env_renderer.render_env(show=False, show_observations=False, show_inactive_agents=True, show_predictions=False, return_image=True)\n",
        "    frames.append(frame)\n",
        "    frame_step += 1\n",
        "    \n",
        "    if done['__all__']:\n",
        "        break\n",
        "    #break if the first agent has done\n",
        "    if ((training_flag == 'training0') and (env.dones[0] == True)) or \\\n",
        "        ((training_flag == 'training1') and (env.dones[0] == True) and (env.dones[1] == True)) or \\\n",
        "        ((training_flag == 'training1.1') and (env.dones[0] == True) and (env.dones[1] == True)):\n",
        "        break\n",
        "\n",
        "\n",
        "score += all_rewards[0]\n",
        "# metric most possible near to 0\n",
        "metric = calculate_metric(env, timetable)\n",
        "\n",
        "tasks_finished = sum(done[idx] for idx in env.get_agent_handles())\n",
        "\n",
        "print(  'Test 5 concluded:'\n",
        "        '\\t 🏆 Score: {:.3f}'\n",
        "        '\\t Agent completed {}'\n",
        "        '\\t Metric {}'.format(\n",
        "            score,\n",
        "            tasks_finished,\n",
        "            metric\n",
        "        ), end=\" \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL5TbUo1urPH"
      },
      "outputs": [],
      "source": [
        "# RENDER\n",
        "%%capture\n",
        "animation = display_episode(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "km7S_lCQut9v"
      },
      "outputs": [],
      "source": [
        "animation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqYWxSVgp2gb"
      },
      "source": [
        "## Test 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2RoBn-yp34X"
      },
      "outputs": [],
      "source": [
        "#################\n",
        "##### TEST 6 ####\n",
        "#################\n",
        "# Reset the rendering system\n",
        "env_renderer.reset()\n",
        "# Reset environment and get initial observations for all agents\n",
        "obs, info = env.reset(regenerate_rail=True, regenerate_schedule=True)\n",
        "# Change the position of the interrupted agents\n",
        "env.agents[2].initial_position = (5,16)\n",
        "env.agents[1].initial_position = (-1,0)\n",
        "\n",
        "frame_step = 0\n",
        "frames = []\n",
        "\n",
        "for step in range(max_steps):\n",
        "    # Broken agents\n",
        "    if training_flag == 'training0':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "        env.agents[1].malfunction_handler.malfunction_down_counter = max_steps\n",
        "    if training_flag == 'training1':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "        make_a_deterministic_interruption(env.agents[3], max_steps)\n",
        "    if training_flag == 'training1.1':\n",
        "        make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "\n",
        "    update_values[0] = True\n",
        "    action = policy.act(agent_obs[0], eps=eps_start)\n",
        "\n",
        "    action_count[action] += 1\n",
        "    actions_taken.append(action)\n",
        "    action_dict.update({0: action})\n",
        "    \n",
        "    next_obs, all_rewards, done, info = env.step(action_dict)\n",
        "\n",
        "    frame = env_renderer.render_env(show=False, show_observations=False, show_inactive_agents=True, show_predictions=False, return_image=True)\n",
        "    frames.append(frame)\n",
        "    frame_step += 1\n",
        "    \n",
        "    if done['__all__']:\n",
        "        break\n",
        "    #break if the first agent has done\n",
        "    if ((training_flag == 'training0') and (env.dones[0] == True)) or \\\n",
        "        ((training_flag == 'training1') and (env.dones[0] == True) and (env.dones[1] == True)) or \\\n",
        "        ((training_flag == 'training1.1') and (env.dones[0] == True) and (env.dones[1] == True)):\n",
        "        break\n",
        "\n",
        "score += all_rewards[0]\n",
        "# metric most possible near to 0\n",
        "metric = calculate_metric(env, timetable)\n",
        "\n",
        "tasks_finished = sum(done[idx] for idx in env.get_agent_handles())\n",
        "\n",
        "print(  'Test 6 concluded:'\n",
        "        '\\t 🏆 Score: {:.3f}'\n",
        "        '\\t Agent completed {}'\n",
        "        '\\t Metric {}'.format(\n",
        "            score,\n",
        "            tasks_finished,\n",
        "            metric\n",
        "        ), end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmiRC_ENuvp1"
      },
      "outputs": [],
      "source": [
        "# RENDER\n",
        "%%capture\n",
        "animation = display_episode(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIpbrzOAuxFi"
      },
      "outputs": [],
      "source": [
        "animation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmcjxW99ygXw"
      },
      "source": [
        "## Test Prossimamente\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPM0Y3RIyoly"
      },
      "outputs": [],
      "source": [
        "env_renderer = RenderTool(env, gl=\"PGL\", screen_width=500, screen_height=500, show_debug=False)\n",
        "\n",
        "# Change the position of the interrupted agents\n",
        "env.reset()\n",
        "env_renderer.reset()\n",
        "\n",
        "# Casual Malfunctions for the agents\n",
        "stochastic_data = MalfunctionParameters(\n",
        "    malfunction_rate = 0.001,  # Rate of malfunction occurence\n",
        "    min_duration = 15,  # Minimal duration of malfunction\n",
        "    max_duration = 60  # Max duration of malfunction\n",
        ")\n",
        "\n",
        "malfunction_generator = ParamMalfunctionGen(stochastic_data)\n",
        "\n",
        "env = RailEnv(  width= widht,\n",
        "                height= height,\n",
        "                rail_generator = rail_custom,\n",
        "                line_generator=schedule_generator_custom,\n",
        "                number_of_agents= num_of_agents,\n",
        "                malfunction_generator = malfunction_generator,\n",
        "                obs_builder_object=Observer,\n",
        "                remove_agents_at_target=True,\n",
        "                record_steps=True,\n",
        "                max_episode_steps = max_steps - 1\n",
        "                )\n",
        "\n",
        "env.reset()\n",
        "\n",
        "#################\n",
        "##### TEST 3 ####\n",
        "#################\n",
        "for episodes in range(20):\n",
        "  \n",
        "  frame_step = 0\n",
        "  frames = []\n",
        "\n",
        "  for step in range(max_steps):\n",
        "      # Broken agents\n",
        "      if training_flag == 'training0':\n",
        "          make_a_deterministic_interruption(env.agents[1], max_steps)\n",
        "          make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "      if training_flag == 'training1':\n",
        "          make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "          make_a_deterministic_interruption(env.agents[3], max_steps)\n",
        "      if training_flag == 'training1.1':\n",
        "          make_a_deterministic_interruption(env.agents[2], max_steps)\n",
        "      for a in range(env.get_num_agents()):\n",
        "          update_values[a] = True\n",
        "          action = policy.act(agent_obs[a], eps=eps_start)\n",
        "\n",
        "          action_count[action] += 1\n",
        "          actions_taken.append(action)\n",
        "          action_dict.update({a: action})\n",
        "          \n",
        "          next_obs, all_rewards, done, info = env.step(action_dict)\n",
        "\n",
        "          frame = env_renderer.render_env(show=False, show_observations=False, show_inactive_agents=True, show_predictions=False, return_image=True)\n",
        "          frames.append(frame)\n",
        "          frame_step += 1\n",
        "      \n",
        "      if done['__all__']:\n",
        "          break\n",
        "      #break if the first agent has done\n",
        "      if ((training_flag == 'training0') and (env.dones[0] == True)) or \\\n",
        "          ((training_flag == 'training1') and (env.dones[0] == True) and (env.dones[1] == True)) or \\\n",
        "          ((training_flag == 'training1.1') and (env.dones[0] == True) and (env.dones[1] == True)):\n",
        "          break\n",
        "\n",
        "  # metric most possible near to 0\n",
        "  metric = calculate_metric(env, timetable)\n",
        "\n",
        "  tasks_finished = sum(done[idx] for idx in env.get_agent_handles())\n",
        "\n",
        "  print()\n",
        "  print(  'Test 1 concluded:'\n",
        "          '\\t 🏆 Score: {:.3f}'\n",
        "          '\\t Agent completed {}'\n",
        "          '\\t Metric {}'.format(\n",
        "              score,\n",
        "              tasks_finished,\n",
        "              metric\n",
        "          ), end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YA1-zlSP0d_u"
      },
      "outputs": [],
      "source": [
        "# RENDER\n",
        "%%capture\n",
        "animation = display_episode(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaGuqKZv0i-2"
      },
      "outputs": [],
      "source": [
        "animation"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8C2D4VVH366B",
        "F5ClfqgfTCe9",
        "2e5ILy1PYV9o",
        "25VWq_QpYWH0",
        "tEEkAbhEXvTb",
        "2tCkoOAPX3WZ",
        "Q80GIJJEX8Yk",
        "PcqtL8kcYBb3",
        "fDV9yKClYIy_",
        "_B01cYfcYNyt",
        "zXdkQKaRadDL",
        "pVWfJEALailv",
        "J1G5loAfPIi_",
        "CmcjxW99ygXw"
      ],
      "name": "Flatland-Railways.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}